{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5 12 21 32]\n"
     ]
    }
   ],
   "source": [
    "# Initialize two constants\n",
    "x1 = tf.constant([1,2,3,4])\n",
    "x2 = tf.constant([5,6,7,8])\n",
    "\n",
    "# Multiply\n",
    "result = tf.multiply(x1, x2)\n",
    "\n",
    "# Intialize the Session\n",
    "sess = tf.Session()\n",
    "\n",
    "# Print the result\n",
    "print(sess.run(result))\n",
    "\n",
    "# Close the session\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "var = tf.Variable(0)    # our first variable in the \"global_variable\" set. Initial value is 0\n",
    "add_operation = tf.assign(var, var+1)\n",
    "with tf.Session() as sess:\n",
    "    # once define variables, you have to initialize them by doing this\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for _ in range(3):\n",
    "        sess.run(add_operation)\n",
    "        print(sess.run(var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n",
      "3.0\n",
      "[[6. 6.]\n",
      " [6. 6.]]\n"
     ]
    }
   ],
   "source": [
    "# create placeholders\n",
    "x1 = tf.placeholder(dtype=tf.float32, shape=None)\n",
    "y1 = tf.placeholder(dtype=tf.float32, shape=None)\n",
    "z1 = x1 + y1\n",
    "\n",
    "x2 = tf.placeholder(dtype=tf.float32, shape=[2, 1])\n",
    "y2 = tf.placeholder(dtype=tf.float32, shape=[1, 2])\n",
    "z2 = tf.matmul(x2, y2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # when only one operation to run\n",
    "    z1_value = sess.run(z1, feed_dict={x1: 1, y1: 2})\n",
    "    print(z1_value)\n",
    "    # when run multiple operations\n",
    "    z1_value, z2_value = sess.run(\n",
    "        [z1, z2],       # run them together\n",
    "        feed_dict={\n",
    "            x1: 1, y1: 2,\n",
    "            x2: [[2], [2]], y2: [[3, 3]]\n",
    "        })\n",
    "    print(z1_value)\n",
    "    print(z2_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this demo, I am using the IRIS dataset that can downloaded from \n",
    "http://download.tensorflow.org/data/iris_training.csv\n",
    "\n",
    "http://download.tensorflow.org/data/iris_test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SepalLength  SepalWidth  PetalLength  PetalWidth\n",
      "0          6.4         2.8          5.6         2.2\n",
      "1          5.0         2.3          3.3         1.0\n",
      "2          4.9         2.5          4.5         1.7\n",
      "3          4.9         3.1          1.5         0.1\n",
      "4          5.7         3.8          1.7         0.3\n",
      "(120, 4)\n",
      "0    2\n",
      "1    1\n",
      "2    2\n",
      "3    0\n",
      "4    0\n",
      "Name: Species, dtype: int64\n",
      "   SepalLength  SepalWidth  PetalLength  PetalWidth\n",
      "0          5.9         3.0          4.2         1.5\n",
      "1          6.9         3.1          5.4         2.1\n",
      "2          5.1         3.3          1.7         0.5\n",
      "3          6.0         3.4          4.5         1.6\n",
      "4          5.5         2.5          4.0         1.3\n",
      "0    1\n",
      "1    2\n",
      "2    0\n",
      "3    1\n",
      "4    1\n",
      "Name: Species, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth',\n",
    "                    'PetalLength', 'PetalWidth', 'Species']\n",
    "def load_data(label_name='Species'):\n",
    "    # Parse the local CSV file.\n",
    "    train = pd.read_csv(\"iris_training.csv\",\n",
    "                        names=CSV_COLUMN_NAMES,  # list of column names\n",
    "                        header=0  # ignore the first row of the CSV file.\n",
    "                       )\n",
    "    # 1. Assign the DataFrame's labels (the right-most column) to train_label.\n",
    "    # 2. Delete (pop) the labels from the DataFrame.\n",
    "    # 3. Assign the remainder of the DataFrame to train_features\n",
    "    train_features, train_label = train, train.pop(label_name)\n",
    "    \n",
    "    test = pd.read_csv(\"iris_test.csv\", names=CSV_COLUMN_NAMES, header=0)\n",
    "    test_features, test_label = test, test.pop(label_name)\n",
    "\n",
    "    # Return four DataFrames.\n",
    "    return (train_features, train_label), (test_features, test_label)\n",
    "(train_feature, train_label), (test_feature, test_label) = load_data()\n",
    "print(train_feature.head())\n",
    "print(train_feature.shape)\n",
    "print(train_label.head())\n",
    "print(test_feature.head())\n",
    "print(test_label.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8000\n",
      "120/120 [==============================] - 0s 2ms/sample - loss: 1.9972 - acc: 0.3500\n",
      "Epoch 2/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 1.9148 - acc: 0.3500\n",
      "Epoch 3/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 1.8457 - acc: 0.3500\n",
      "Epoch 4/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 1.7892 - acc: 0.3500\n",
      "Epoch 5/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 1.7345 - acc: 0.3500\n",
      "Epoch 6/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 1.6872 - acc: 0.3500\n",
      "Epoch 7/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 1.6438 - acc: 0.3500\n",
      "Epoch 8/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 1.6017 - acc: 0.3500\n",
      "Epoch 9/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 1.5595 - acc: 0.3500\n",
      "Epoch 10/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 1.5166 - acc: 0.3500\n",
      "Epoch 11/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 1.4717 - acc: 0.3500\n",
      "Epoch 12/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 1.4256 - acc: 0.3500\n",
      "Epoch 13/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 1.3777 - acc: 0.3500\n",
      "Epoch 14/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 1.3273 - acc: 0.3500\n",
      "Epoch 15/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 1.2791 - acc: 0.3500\n",
      "Epoch 16/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 1.2290 - acc: 0.6333\n",
      "Epoch 17/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 1.1835 - acc: 0.7000\n",
      "Epoch 18/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 1.1405 - acc: 0.7000\n",
      "Epoch 19/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 1.0993 - acc: 0.7000\n",
      "Epoch 20/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 1.0624 - acc: 0.7000\n",
      "Epoch 21/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 1.0290 - acc: 0.7000\n",
      "Epoch 22/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.9998 - acc: 0.7000\n",
      "Epoch 23/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.9733 - acc: 0.7000\n",
      "Epoch 24/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.9488 - acc: 0.7000\n",
      "Epoch 25/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.9262 - acc: 0.7000\n",
      "Epoch 26/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.9053 - acc: 0.7000\n",
      "Epoch 27/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.8850 - acc: 0.7000\n",
      "Epoch 28/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.8667 - acc: 0.7000\n",
      "Epoch 29/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.8478 - acc: 0.7000\n",
      "Epoch 30/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.8295 - acc: 0.7000\n",
      "Epoch 31/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.8121 - acc: 0.7000\n",
      "Epoch 32/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.7965 - acc: 0.7000\n",
      "Epoch 33/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.7786 - acc: 0.7000\n",
      "Epoch 34/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.7620 - acc: 0.7000\n",
      "Epoch 35/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.7461 - acc: 0.7000\n",
      "Epoch 36/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.7316 - acc: 0.7000\n",
      "Epoch 37/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.7157 - acc: 0.7000\n",
      "Epoch 38/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.7006 - acc: 0.7000\n",
      "Epoch 39/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.6861 - acc: 0.7000\n",
      "Epoch 40/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.6725 - acc: 0.7083\n",
      "Epoch 41/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.6587 - acc: 0.7250\n",
      "Epoch 42/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.6443 - acc: 0.7167\n",
      "Epoch 43/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.6316 - acc: 0.7083\n",
      "Epoch 44/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.6191 - acc: 0.7167\n",
      "Epoch 45/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.6066 - acc: 0.7583\n",
      "Epoch 46/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.5928 - acc: 0.8083\n",
      "Epoch 47/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.5803 - acc: 0.8167\n",
      "Epoch 48/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.5688 - acc: 0.8333\n",
      "Epoch 49/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.5569 - acc: 0.8500\n",
      "Epoch 50/8000\n",
      "120/120 [==============================] - 0s 83us/sample - loss: 0.5450 - acc: 0.8500\n",
      "Epoch 51/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.5354 - acc: 0.8500\n",
      "Epoch 52/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.5240 - acc: 0.8667\n",
      "Epoch 53/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.5133 - acc: 0.8667\n",
      "Epoch 54/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.5032 - acc: 0.8833\n",
      "Epoch 55/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.4933 - acc: 0.8833\n",
      "Epoch 56/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.4842 - acc: 0.9000\n",
      "Epoch 57/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.4751 - acc: 0.8917\n",
      "Epoch 58/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.4672 - acc: 0.8833\n",
      "Epoch 59/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.4582 - acc: 0.9000\n",
      "Epoch 60/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.4499 - acc: 0.9083\n",
      "Epoch 61/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.4420 - acc: 0.9167\n",
      "Epoch 62/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.4343 - acc: 0.9167\n",
      "Epoch 63/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.4276 - acc: 0.9000\n",
      "Epoch 64/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.4200 - acc: 0.9000\n",
      "Epoch 65/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.4126 - acc: 0.9167\n",
      "Epoch 66/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.4067 - acc: 0.9250\n",
      "Epoch 67/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.4000 - acc: 0.9500\n",
      "Epoch 68/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.3935 - acc: 0.9500\n",
      "Epoch 69/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.3874 - acc: 0.9417\n",
      "Epoch 70/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.3811 - acc: 0.9333\n",
      "Epoch 71/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.3755 - acc: 0.9333\n",
      "Epoch 72/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.3719 - acc: 0.9500\n",
      "Epoch 73/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.3652 - acc: 0.9417\n",
      "Epoch 74/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.3592 - acc: 0.9417\n",
      "Epoch 75/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.3536 - acc: 0.9500\n",
      "Epoch 76/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.3499 - acc: 0.9500\n",
      "Epoch 77/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.3439 - acc: 0.9417\n",
      "Epoch 78/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.3395 - acc: 0.9583\n",
      "Epoch 79/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.3348 - acc: 0.9667\n",
      "Epoch 80/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.3303 - acc: 0.9667\n",
      "Epoch 81/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.3258 - acc: 0.9667\n",
      "Epoch 82/8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 92us/sample - loss: 0.3212 - acc: 0.9583\n",
      "Epoch 83/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.3181 - acc: 0.9500\n",
      "Epoch 84/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.3131 - acc: 0.9583\n",
      "Epoch 85/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.3092 - acc: 0.9583\n",
      "Epoch 86/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.3052 - acc: 0.9667\n",
      "Epoch 87/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.3014 - acc: 0.9667\n",
      "Epoch 88/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.2984 - acc: 0.9583\n",
      "Epoch 89/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.2949 - acc: 0.9667\n",
      "Epoch 90/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.2908 - acc: 0.9667\n",
      "Epoch 91/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.2878 - acc: 0.9667\n",
      "Epoch 92/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.2832 - acc: 0.9667\n",
      "Epoch 93/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.2800 - acc: 0.9667\n",
      "Epoch 94/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.2766 - acc: 0.9667\n",
      "Epoch 95/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.2736 - acc: 0.9667\n",
      "Epoch 96/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.2704 - acc: 0.9750\n",
      "Epoch 97/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.2669 - acc: 0.9667\n",
      "Epoch 98/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.2656 - acc: 0.9667\n",
      "Epoch 99/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.2639 - acc: 0.9667\n",
      "Epoch 100/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.2578 - acc: 0.9667\n",
      "Epoch 101/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.2550 - acc: 0.9667\n",
      "Epoch 102/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.2525 - acc: 0.9667\n",
      "Epoch 103/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.2501 - acc: 0.9667\n",
      "Epoch 104/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.2466 - acc: 0.9667\n",
      "Epoch 105/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.2440 - acc: 0.9750\n",
      "Epoch 106/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.2411 - acc: 0.9750\n",
      "Epoch 107/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.2384 - acc: 0.9750\n",
      "Epoch 108/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.2361 - acc: 0.9750\n",
      "Epoch 109/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.2336 - acc: 0.9750\n",
      "Epoch 110/8000\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.2310 - acc: 0.9750\n",
      "Epoch 111/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.2293 - acc: 0.9667\n",
      "Epoch 112/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.2262 - acc: 0.9667\n",
      "Epoch 113/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.2236 - acc: 0.9667\n",
      "Epoch 114/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.2213 - acc: 0.9750\n",
      "Epoch 115/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.2189 - acc: 0.9750\n",
      "Epoch 116/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.2165 - acc: 0.9750\n",
      "Epoch 117/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.2158 - acc: 0.9750\n",
      "Epoch 118/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.2126 - acc: 0.9750\n",
      "Epoch 119/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.2110 - acc: 0.9667\n",
      "Epoch 120/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.2088 - acc: 0.9667\n",
      "Epoch 121/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.2062 - acc: 0.9750\n",
      "Epoch 122/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.2039 - acc: 0.9833\n",
      "Epoch 123/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.2024 - acc: 0.9833\n",
      "Epoch 124/8000\n",
      "120/120 [==============================] - 0s 83us/sample - loss: 0.2004 - acc: 0.9833\n",
      "Epoch 125/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.1986 - acc: 0.9833\n",
      "Epoch 126/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.1965 - acc: 0.9833\n",
      "Epoch 127/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.1948 - acc: 0.9833\n",
      "Epoch 128/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.1925 - acc: 0.9833\n",
      "Epoch 129/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.1905 - acc: 0.9833\n",
      "Epoch 130/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.1892 - acc: 0.9833\n",
      "Epoch 131/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.1877 - acc: 0.9750\n",
      "Epoch 132/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.1859 - acc: 0.9833\n",
      "Epoch 133/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.1843 - acc: 0.9833\n",
      "Epoch 134/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.1827 - acc: 0.9833\n",
      "Epoch 135/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.1806 - acc: 0.9833\n",
      "Epoch 136/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.1790 - acc: 0.9833\n",
      "Epoch 137/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.1776 - acc: 0.9833\n",
      "Epoch 138/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.1754 - acc: 0.9833\n",
      "Epoch 139/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.1747 - acc: 0.9833\n",
      "Epoch 140/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.1731 - acc: 0.9833\n",
      "Epoch 141/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.1709 - acc: 0.9833\n",
      "Epoch 142/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.1704 - acc: 0.9833\n",
      "Epoch 143/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.1700 - acc: 0.9833\n",
      "Epoch 144/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.1671 - acc: 0.9833\n",
      "Epoch 145/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.1656 - acc: 0.9833\n",
      "Epoch 146/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.1650 - acc: 0.9833\n",
      "Epoch 147/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.1639 - acc: 0.9833\n",
      "Epoch 148/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.1627 - acc: 0.9833\n",
      "Epoch 149/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.1626 - acc: 0.9833\n",
      "Epoch 150/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.1595 - acc: 0.9833\n",
      "Epoch 151/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.1587 - acc: 0.9833\n",
      "Epoch 152/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.1577 - acc: 0.9833\n",
      "Epoch 153/8000\n",
      "120/120 [==============================] - 0s 83us/sample - loss: 0.1574 - acc: 0.9750\n",
      "Epoch 154/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.1540 - acc: 0.9833\n",
      "Epoch 155/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.1529 - acc: 0.9833\n",
      "Epoch 156/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.1539 - acc: 0.9750\n",
      "Epoch 157/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.1519 - acc: 0.9833\n",
      "Epoch 158/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.1503 - acc: 0.9833\n",
      "Epoch 159/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.1488 - acc: 0.9833\n",
      "Epoch 160/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.1507 - acc: 0.9833\n",
      "Epoch 161/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.1469 - acc: 0.9833\n",
      "Epoch 162/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.1451 - acc: 0.9833\n",
      "Epoch 163/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.1453 - acc: 0.9833\n",
      "Epoch 164/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.1442 - acc: 0.9833\n",
      "Epoch 165/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.1425 - acc: 0.9833\n",
      "Epoch 166/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.1419 - acc: 0.9833\n",
      "Epoch 167/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.1419 - acc: 0.9833\n",
      "Epoch 168/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.1397 - acc: 0.9833\n",
      "Epoch 169/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.1390 - acc: 0.9833\n",
      "Epoch 170/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.1385 - acc: 0.9833\n",
      "Epoch 171/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.1378 - acc: 0.9833\n",
      "Epoch 172/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.1376 - acc: 0.9833\n",
      "Epoch 173/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.1351 - acc: 0.9833\n",
      "Epoch 174/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.1341 - acc: 0.9833\n",
      "Epoch 175/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.1339 - acc: 0.9833\n",
      "Epoch 176/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.1326 - acc: 0.9833\n",
      "Epoch 177/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.1320 - acc: 0.9833\n",
      "Epoch 178/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.1311 - acc: 0.9833\n",
      "Epoch 179/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.1301 - acc: 0.9833\n",
      "Epoch 180/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.1293 - acc: 0.9833\n",
      "Epoch 181/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.1283 - acc: 0.9833\n",
      "Epoch 182/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.1282 - acc: 0.9833\n",
      "Epoch 183/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.1268 - acc: 0.9833\n",
      "Epoch 184/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.1262 - acc: 0.9833\n",
      "Epoch 185/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.1257 - acc: 0.9833\n",
      "Epoch 186/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.1246 - acc: 0.9833\n",
      "Epoch 187/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.1240 - acc: 0.9833\n",
      "Epoch 188/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.1231 - acc: 0.9833\n",
      "Epoch 189/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.1225 - acc: 0.9833\n",
      "Epoch 190/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.1217 - acc: 0.9833\n",
      "Epoch 191/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.1209 - acc: 0.9833\n",
      "Epoch 192/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.1206 - acc: 0.9833\n",
      "Epoch 193/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.1199 - acc: 0.9833\n",
      "Epoch 194/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.1225 - acc: 0.9833\n",
      "Epoch 195/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.1187 - acc: 0.9833\n",
      "Epoch 196/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.1189 - acc: 0.9833\n",
      "Epoch 197/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.1182 - acc: 0.9833\n",
      "Epoch 198/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.1170 - acc: 0.9833\n",
      "Epoch 199/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.1163 - acc: 0.9833\n",
      "Epoch 200/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.1160 - acc: 0.9833\n",
      "Epoch 201/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.1150 - acc: 0.9833\n",
      "Epoch 202/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.1153 - acc: 0.9833\n",
      "Epoch 203/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.1134 - acc: 0.9833\n",
      "Epoch 204/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.1129 - acc: 0.9833\n",
      "Epoch 205/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.1130 - acc: 0.9833\n",
      "Epoch 206/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.1118 - acc: 0.9833\n",
      "Epoch 207/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.1114 - acc: 0.9833\n",
      "Epoch 208/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.1116 - acc: 0.9833\n",
      "Epoch 209/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.1116 - acc: 0.9833\n",
      "Epoch 210/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.1107 - acc: 0.9833\n",
      "Epoch 211/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.1095 - acc: 0.9833\n",
      "Epoch 212/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.1092 - acc: 0.9833\n",
      "Epoch 213/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.1095 - acc: 0.9833\n",
      "Epoch 214/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.1087 - acc: 0.9833\n",
      "Epoch 215/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.1074 - acc: 0.9833\n",
      "Epoch 216/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.1067 - acc: 0.9833\n",
      "Epoch 217/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.1064 - acc: 0.9833\n",
      "Epoch 218/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.1065 - acc: 0.9833\n",
      "Epoch 219/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.1055 - acc: 0.9833\n",
      "Epoch 220/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.1409 - acc: 0.968 - 0s 67us/sample - loss: 0.1052 - acc: 0.9833\n",
      "Epoch 221/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.1050 - acc: 0.9833\n",
      "Epoch 222/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.1043 - acc: 0.9833\n",
      "Epoch 223/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.1040 - acc: 0.9833\n",
      "Epoch 224/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.1032 - acc: 0.9833\n",
      "Epoch 225/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.1023 - acc: 0.9833\n",
      "Epoch 226/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.1020 - acc: 0.9833\n",
      "Epoch 227/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.1027 - acc: 0.9833\n",
      "Epoch 228/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.1012 - acc: 0.9833\n",
      "Epoch 229/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.1006 - acc: 0.9833\n",
      "Epoch 230/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.1002 - acc: 0.9833\n",
      "Epoch 231/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.1022 - acc: 0.9833\n",
      "Epoch 232/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.1005 - acc: 0.9833\n",
      "Epoch 233/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0990 - acc: 0.9833\n",
      "Epoch 234/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.1001 - acc: 0.9833\n",
      "Epoch 235/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.1004 - acc: 0.9833\n",
      "Epoch 236/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.1006 - acc: 0.9833\n",
      "Epoch 237/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0980 - acc: 0.9833\n",
      "Epoch 238/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0975 - acc: 0.9833\n",
      "Epoch 239/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0980 - acc: 0.9833\n",
      "Epoch 240/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0966 - acc: 0.9833\n",
      "Epoch 241/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0963 - acc: 0.9833\n",
      "Epoch 242/8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0965 - acc: 0.9833\n",
      "Epoch 243/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0957 - acc: 0.9833\n",
      "Epoch 244/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0953 - acc: 0.9833\n",
      "Epoch 245/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0949 - acc: 0.9833\n",
      "Epoch 246/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0948 - acc: 0.9833\n",
      "Epoch 247/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0947 - acc: 0.9833\n",
      "Epoch 248/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0935 - acc: 0.9833\n",
      "Epoch 249/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0773 - acc: 1.000 - 0s 58us/sample - loss: 0.0932 - acc: 0.9833\n",
      "Epoch 250/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0952 - acc: 0.9833\n",
      "Epoch 251/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0936 - acc: 0.9833\n",
      "Epoch 252/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0926 - acc: 0.9833\n",
      "Epoch 253/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0922 - acc: 0.9833\n",
      "Epoch 254/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0923 - acc: 0.9833\n",
      "Epoch 255/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0918 - acc: 0.9833\n",
      "Epoch 256/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0914 - acc: 0.9833\n",
      "Epoch 257/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0913 - acc: 0.9833\n",
      "Epoch 258/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0907 - acc: 0.9833\n",
      "Epoch 259/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0904 - acc: 0.9833\n",
      "Epoch 260/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0899 - acc: 0.9833\n",
      "Epoch 261/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0904 - acc: 0.9833\n",
      "Epoch 262/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0913 - acc: 0.9833\n",
      "Epoch 263/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0896 - acc: 0.9833\n",
      "Epoch 264/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0885 - acc: 0.9833\n",
      "Epoch 265/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0889 - acc: 0.9833\n",
      "Epoch 266/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0887 - acc: 0.9833\n",
      "Epoch 267/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0884 - acc: 0.9833\n",
      "Epoch 268/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0887 - acc: 0.9833\n",
      "Epoch 269/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0876 - acc: 0.9833\n",
      "Epoch 270/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0876 - acc: 0.9833\n",
      "Epoch 271/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0880 - acc: 0.9833\n",
      "Epoch 272/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0870 - acc: 0.9833\n",
      "Epoch 273/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0877 - acc: 0.9833\n",
      "Epoch 274/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0872 - acc: 0.9833\n",
      "Epoch 275/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0860 - acc: 0.9833\n",
      "Epoch 276/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0857 - acc: 0.9833\n",
      "Epoch 277/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0858 - acc: 0.9833\n",
      "Epoch 278/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0853 - acc: 0.9833\n",
      "Epoch 279/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0852 - acc: 0.9833\n",
      "Epoch 280/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0850 - acc: 0.9833\n",
      "Epoch 281/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0845 - acc: 0.9833\n",
      "Epoch 282/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0852 - acc: 0.9833\n",
      "Epoch 283/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0846 - acc: 0.9833\n",
      "Epoch 284/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0845 - acc: 0.9833\n",
      "Epoch 285/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0837 - acc: 0.9833\n",
      "Epoch 286/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0842 - acc: 0.9833\n",
      "Epoch 287/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0833 - acc: 0.9833\n",
      "Epoch 288/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0837 - acc: 0.9833\n",
      "Epoch 289/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0831 - acc: 0.9833\n",
      "Epoch 290/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0830 - acc: 0.9833\n",
      "Epoch 291/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0831 - acc: 0.9833\n",
      "Epoch 292/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0818 - acc: 0.9833\n",
      "Epoch 293/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0821 - acc: 0.9833\n",
      "Epoch 294/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0844 - acc: 0.9833\n",
      "Epoch 295/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0822 - acc: 0.9833\n",
      "Epoch 296/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0834 - acc: 0.9833\n",
      "Epoch 297/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0832 - acc: 0.9833\n",
      "Epoch 298/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0821 - acc: 0.9833\n",
      "Epoch 299/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0810 - acc: 0.9833\n",
      "Epoch 300/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0819 - acc: 0.9833\n",
      "Epoch 301/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0836 - acc: 0.9833\n",
      "Epoch 302/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0814 - acc: 0.9833\n",
      "Epoch 303/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0810 - acc: 0.9833\n",
      "Epoch 304/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0799 - acc: 0.9833\n",
      "Epoch 305/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0800 - acc: 0.9833\n",
      "Epoch 306/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0798 - acc: 0.9833\n",
      "Epoch 307/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0794 - acc: 0.9833\n",
      "Epoch 308/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0790 - acc: 0.9833\n",
      "Epoch 309/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0798 - acc: 0.9833\n",
      "Epoch 310/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0787 - acc: 0.9833\n",
      "Epoch 311/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0786 - acc: 0.9833\n",
      "Epoch 312/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0786 - acc: 0.9833\n",
      "Epoch 313/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0782 - acc: 0.9833\n",
      "Epoch 314/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0779 - acc: 0.9833\n",
      "Epoch 315/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0811 - acc: 0.9833\n",
      "Epoch 316/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0773 - acc: 0.9833\n",
      "Epoch 317/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0783 - acc: 0.9833\n",
      "Epoch 318/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0778 - acc: 0.9833\n",
      "Epoch 319/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0775 - acc: 0.9833\n",
      "Epoch 320/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0789 - acc: 0.9833\n",
      "Epoch 321/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0778 - acc: 0.9833\n",
      "Epoch 322/8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0766 - acc: 0.9833\n",
      "Epoch 323/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0783 - acc: 0.9833\n",
      "Epoch 324/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0771 - acc: 0.9833\n",
      "Epoch 325/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0760 - acc: 0.9833\n",
      "Epoch 326/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0758 - acc: 0.9833\n",
      "Epoch 327/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0764 - acc: 0.9833\n",
      "Epoch 328/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0764 - acc: 0.9833\n",
      "Epoch 329/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0757 - acc: 0.9833\n",
      "Epoch 330/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0756 - acc: 0.9833\n",
      "Epoch 331/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0758 - acc: 0.9833\n",
      "Epoch 332/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0756 - acc: 0.9833\n",
      "Epoch 333/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0757 - acc: 0.9833\n",
      "Epoch 334/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0779 - acc: 0.9833\n",
      "Epoch 335/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0752 - acc: 0.9833\n",
      "Epoch 336/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0763 - acc: 0.9833\n",
      "Epoch 337/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0749 - acc: 0.9833\n",
      "Epoch 338/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0742 - acc: 0.9833\n",
      "Epoch 339/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0741 - acc: 0.9833\n",
      "Epoch 340/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0743 - acc: 0.9833\n",
      "Epoch 341/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0751 - acc: 0.9833\n",
      "Epoch 342/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0749 - acc: 0.9833\n",
      "Epoch 343/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0197 - acc: 1.000 - 0s 67us/sample - loss: 0.0736 - acc: 0.9833\n",
      "Epoch 344/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0740 - acc: 0.9833\n",
      "Epoch 345/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0740 - acc: 0.9833\n",
      "Epoch 346/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0741 - acc: 0.9833\n",
      "Epoch 347/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0738 - acc: 0.9833\n",
      "Epoch 348/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0735 - acc: 0.9833\n",
      "Epoch 349/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0733 - acc: 0.9833\n",
      "Epoch 350/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0728 - acc: 0.9833\n",
      "Epoch 351/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0727 - acc: 0.9833\n",
      "Epoch 352/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0724 - acc: 0.9833\n",
      "Epoch 353/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0734 - acc: 0.9833\n",
      "Epoch 354/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0731 - acc: 0.9833\n",
      "Epoch 355/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0724 - acc: 0.9833\n",
      "Epoch 356/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0721 - acc: 0.9833\n",
      "Epoch 357/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0724 - acc: 0.9833\n",
      "Epoch 358/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0723 - acc: 0.9833\n",
      "Epoch 359/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0714 - acc: 0.9833\n",
      "Epoch 360/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0719 - acc: 0.9833\n",
      "Epoch 361/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0713 - acc: 0.9833\n",
      "Epoch 362/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0718 - acc: 0.9833\n",
      "Epoch 363/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0715 - acc: 0.9833\n",
      "Epoch 364/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0709 - acc: 0.9833\n",
      "Epoch 365/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0719 - acc: 0.9833\n",
      "Epoch 366/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0715 - acc: 0.9833\n",
      "Epoch 367/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0714 - acc: 0.9833\n",
      "Epoch 368/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0712 - acc: 0.9833\n",
      "Epoch 369/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0717 - acc: 0.9833\n",
      "Epoch 370/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0706 - acc: 0.9833\n",
      "Epoch 371/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0706 - acc: 0.9833\n",
      "Epoch 372/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0700 - acc: 0.9833\n",
      "Epoch 373/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0712 - acc: 0.9833\n",
      "Epoch 374/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0705 - acc: 0.9833\n",
      "Epoch 375/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0698 - acc: 0.9833\n",
      "Epoch 376/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0702 - acc: 0.9833\n",
      "Epoch 377/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0697 - acc: 0.9833\n",
      "Epoch 378/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0694 - acc: 0.9833\n",
      "Epoch 379/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0693 - acc: 0.9833\n",
      "Epoch 380/8000\n",
      "120/120 [==============================] - 0s 59us/sample - loss: 0.0696 - acc: 0.9833\n",
      "Epoch 381/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0711 - acc: 0.9833\n",
      "Epoch 382/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0695 - acc: 0.9833\n",
      "Epoch 383/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0701 - acc: 0.9833\n",
      "Epoch 384/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0688 - acc: 0.9833\n",
      "Epoch 385/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0687 - acc: 0.9833\n",
      "Epoch 386/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0700 - acc: 0.9833\n",
      "Epoch 387/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0702 - acc: 0.9833\n",
      "Epoch 388/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0684 - acc: 0.9833\n",
      "Epoch 389/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0683 - acc: 0.9833\n",
      "Epoch 390/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0689 - acc: 0.9833\n",
      "Epoch 391/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0683 - acc: 0.9833\n",
      "Epoch 392/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0684 - acc: 0.9833\n",
      "Epoch 393/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0679 - acc: 0.9833\n",
      "Epoch 394/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0683 - acc: 0.9833\n",
      "Epoch 395/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0681 - acc: 0.9833\n",
      "Epoch 396/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0678 - acc: 0.9833\n",
      "Epoch 397/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0680 - acc: 0.9833\n",
      "Epoch 398/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0676 - acc: 0.9833\n",
      "Epoch 399/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0679 - acc: 0.9833\n",
      "Epoch 400/8000\n",
      "120/120 [==============================] - 0s 83us/sample - loss: 0.0672 - acc: 0.9833\n",
      "Epoch 401/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0687 - acc: 0.9833\n",
      "Epoch 402/8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0670 - acc: 0.9833\n",
      "Epoch 403/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0683 - acc: 0.9833\n",
      "Epoch 404/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0681 - acc: 0.9833\n",
      "Epoch 405/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0663 - acc: 0.9833\n",
      "Epoch 406/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0672 - acc: 0.9833\n",
      "Epoch 407/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0678 - acc: 0.9833\n",
      "Epoch 408/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0667 - acc: 0.9833\n",
      "Epoch 409/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0658 - acc: 0.9833\n",
      "Epoch 410/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0675 - acc: 0.9833\n",
      "Epoch 411/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0670 - acc: 0.9833\n",
      "Epoch 412/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0663 - acc: 0.9833\n",
      "Epoch 413/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0671 - acc: 0.9833\n",
      "Epoch 414/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0667 - acc: 0.9833\n",
      "Epoch 415/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0666 - acc: 0.9833\n",
      "Epoch 416/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0682 - acc: 0.9833\n",
      "Epoch 417/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0670 - acc: 0.9833\n",
      "Epoch 418/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0652 - acc: 0.9833\n",
      "Epoch 419/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0670 - acc: 0.9833\n",
      "Epoch 420/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0674 - acc: 0.9833\n",
      "Epoch 421/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0664 - acc: 0.9833\n",
      "Epoch 422/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0654 - acc: 0.9833\n",
      "Epoch 423/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0655 - acc: 0.9833\n",
      "Epoch 424/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0654 - acc: 0.9833\n",
      "Epoch 425/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0654 - acc: 0.9833\n",
      "Epoch 426/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0658 - acc: 0.9833\n",
      "Epoch 427/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0656 - acc: 0.9833\n",
      "Epoch 428/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0656 - acc: 0.9833\n",
      "Epoch 429/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0656 - acc: 0.9833\n",
      "Epoch 430/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0666 - acc: 0.9833\n",
      "Epoch 431/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0654 - acc: 0.9833\n",
      "Epoch 432/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0646 - acc: 0.9833\n",
      "Epoch 433/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0644 - acc: 0.9833\n",
      "Epoch 434/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0647 - acc: 0.9833\n",
      "Epoch 435/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0651 - acc: 0.9833\n",
      "Epoch 436/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0615 - acc: 1.000 - 0s 75us/sample - loss: 0.0686 - acc: 0.9833\n",
      "Epoch 437/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0655 - acc: 0.9833\n",
      "Epoch 438/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0649 - acc: 0.9833\n",
      "Epoch 439/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0645 - acc: 0.9833\n",
      "Epoch 440/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0661 - acc: 0.9833\n",
      "Epoch 441/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0655 - acc: 0.9833\n",
      "Epoch 442/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0646 - acc: 0.9833\n",
      "Epoch 443/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0656 - acc: 0.9833\n",
      "Epoch 444/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0639 - acc: 0.9833\n",
      "Epoch 445/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0636 - acc: 0.9833\n",
      "Epoch 446/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0639 - acc: 0.9833\n",
      "Epoch 447/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0643 - acc: 0.9833\n",
      "Epoch 448/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0644 - acc: 0.9833\n",
      "Epoch 449/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0636 - acc: 0.9833\n",
      "Epoch 450/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0637 - acc: 0.9833\n",
      "Epoch 451/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0633 - acc: 0.9833\n",
      "Epoch 452/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0634 - acc: 0.9833\n",
      "Epoch 453/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0639 - acc: 0.9833\n",
      "Epoch 454/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0635 - acc: 0.9833\n",
      "Epoch 455/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0634 - acc: 0.9833\n",
      "Epoch 456/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0668 - acc: 0.9833\n",
      "Epoch 457/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0629 - acc: 0.9833\n",
      "Epoch 458/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0664 - acc: 0.9750\n",
      "Epoch 459/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0639 - acc: 0.9750\n",
      "Epoch 460/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0621 - acc: 0.9833\n",
      "Epoch 461/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0638 - acc: 0.9833\n",
      "Epoch 462/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0637 - acc: 0.9833\n",
      "Epoch 463/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0625 - acc: 0.9833\n",
      "Epoch 464/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0620 - acc: 0.9833\n",
      "Epoch 465/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0629 - acc: 0.9833\n",
      "Epoch 466/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0633 - acc: 0.9833\n",
      "Epoch 467/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0629 - acc: 0.9833\n",
      "Epoch 468/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0620 - acc: 0.9833\n",
      "Epoch 469/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0620 - acc: 0.9833\n",
      "Epoch 470/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0636 - acc: 0.9833\n",
      "Epoch 471/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0624 - acc: 0.9833\n",
      "Epoch 472/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0623 - acc: 0.9833\n",
      "Epoch 473/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0622 - acc: 0.9833\n",
      "Epoch 474/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0620 - acc: 0.9833\n",
      "Epoch 475/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0617 - acc: 0.9833\n",
      "Epoch 476/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0615 - acc: 0.9833\n",
      "Epoch 477/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0624 - acc: 0.9833\n",
      "Epoch 478/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0620 - acc: 0.9833\n",
      "Epoch 479/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0622 - acc: 0.9833\n",
      "Epoch 480/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0615 - acc: 0.9833\n",
      "Epoch 481/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0665 - acc: 0.9750\n",
      "Epoch 482/8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0622 - acc: 0.9833\n",
      "Epoch 483/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0618 - acc: 0.9833\n",
      "Epoch 484/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0622 - acc: 0.9917\n",
      "Epoch 485/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0629 - acc: 0.9833\n",
      "Epoch 486/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0619 - acc: 0.9833\n",
      "Epoch 487/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0611 - acc: 0.9833\n",
      "Epoch 488/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0611 - acc: 0.9833\n",
      "Epoch 489/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0617 - acc: 0.9833\n",
      "Epoch 490/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0609 - acc: 0.9833\n",
      "Epoch 491/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0608 - acc: 0.9833\n",
      "Epoch 492/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0636 - acc: 0.9917\n",
      "Epoch 493/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0615 - acc: 0.9833\n",
      "Epoch 494/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0606 - acc: 0.9833\n",
      "Epoch 495/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0622 - acc: 0.9833\n",
      "Epoch 496/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0631 - acc: 0.9833\n",
      "Epoch 497/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0606 - acc: 0.9833\n",
      "Epoch 498/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0604 - acc: 0.9833\n",
      "Epoch 499/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0606 - acc: 0.9833\n",
      "Epoch 500/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0615 - acc: 0.9833\n",
      "Epoch 501/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0603 - acc: 0.9833\n",
      "Epoch 502/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0611 - acc: 0.9833\n",
      "Epoch 503/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0613 - acc: 0.9833\n",
      "Epoch 504/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0619 - acc: 0.9917\n",
      "Epoch 505/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0608 - acc: 0.9833\n",
      "Epoch 506/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0602 - acc: 0.9833\n",
      "Epoch 507/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0605 - acc: 0.9833\n",
      "Epoch 508/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0616 - acc: 0.9833\n",
      "Epoch 509/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0602 - acc: 0.9833\n",
      "Epoch 510/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0599 - acc: 0.9833\n",
      "Epoch 511/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0599 - acc: 0.9833\n",
      "Epoch 512/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0602 - acc: 0.9833\n",
      "Epoch 513/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0597 - acc: 0.9833\n",
      "Epoch 514/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0607 - acc: 0.9833\n",
      "Epoch 515/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0608 - acc: 0.9833\n",
      "Epoch 516/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0597 - acc: 0.9833\n",
      "Epoch 517/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0596 - acc: 0.9833\n",
      "Epoch 518/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0604 - acc: 0.9833\n",
      "Epoch 519/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0596 - acc: 0.9833\n",
      "Epoch 520/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0597 - acc: 0.9917\n",
      "Epoch 521/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0606 - acc: 0.9917\n",
      "Epoch 522/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0598 - acc: 0.9917\n",
      "Epoch 523/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0590 - acc: 0.9833\n",
      "Epoch 524/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0612 - acc: 0.9750\n",
      "Epoch 525/8000\n",
      "120/120 [==============================] - 0s 50us/sample - loss: 0.0597 - acc: 0.9750\n",
      "Epoch 526/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0590 - acc: 0.9833\n",
      "Epoch 527/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0595 - acc: 0.9917\n",
      "Epoch 528/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0593 - acc: 0.9917\n",
      "Epoch 529/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0592 - acc: 0.9833\n",
      "Epoch 530/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0597 - acc: 0.9833\n",
      "Epoch 531/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0589 - acc: 0.9833\n",
      "Epoch 532/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0590 - acc: 0.9833\n",
      "Epoch 533/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0587 - acc: 0.9833\n",
      "Epoch 534/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0594 - acc: 0.9833\n",
      "Epoch 535/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0604 - acc: 0.9833\n",
      "Epoch 536/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0587 - acc: 0.9833\n",
      "Epoch 537/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0589 - acc: 0.9833\n",
      "Epoch 538/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0593 - acc: 0.9833\n",
      "Epoch 539/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0585 - acc: 0.9917\n",
      "Epoch 540/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0585 - acc: 0.9833\n",
      "Epoch 541/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0586 - acc: 0.9833\n",
      "Epoch 542/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0600 - acc: 0.9833\n",
      "Epoch 543/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0589 - acc: 0.9833\n",
      "Epoch 544/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0589 - acc: 0.9833\n",
      "Epoch 545/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0595 - acc: 0.9833\n",
      "Epoch 546/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0585 - acc: 0.9833\n",
      "Epoch 547/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0587 - acc: 0.9917\n",
      "Epoch 548/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0588 - acc: 0.9833\n",
      "Epoch 549/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0580 - acc: 0.9833\n",
      "Epoch 550/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0583 - acc: 0.9833\n",
      "Epoch 551/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0582 - acc: 0.9833\n",
      "Epoch 552/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0607 - acc: 1.000 - 0s 58us/sample - loss: 0.0584 - acc: 0.9917\n",
      "Epoch 553/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0581 - acc: 0.9833\n",
      "Epoch 554/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0582 - acc: 0.9833\n",
      "Epoch 555/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0578 - acc: 0.9917\n",
      "Epoch 556/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0583 - acc: 0.9917\n",
      "Epoch 557/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0580 - acc: 0.9917\n",
      "Epoch 558/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0579 - acc: 0.9917\n",
      "Epoch 559/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0595 - acc: 0.9833\n",
      "Epoch 560/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0578 - acc: 0.9833\n",
      "Epoch 561/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0577 - acc: 0.9917\n",
      "Epoch 562/8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0594 - acc: 0.9917\n",
      "Epoch 563/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0576 - acc: 0.9917\n",
      "Epoch 564/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0588 - acc: 0.9833\n",
      "Epoch 565/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0593 - acc: 0.9833\n",
      "Epoch 566/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0592 - acc: 0.9833\n",
      "Epoch 567/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0582 - acc: 0.9833\n",
      "Epoch 568/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0563 - acc: 0.9833\n",
      "Epoch 569/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0574 - acc: 0.9917\n",
      "Epoch 570/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0585 - acc: 0.9917\n",
      "Epoch 571/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0585 - acc: 0.9917\n",
      "Epoch 572/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0571 - acc: 0.9917\n",
      "Epoch 573/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0578 - acc: 0.9917\n",
      "Epoch 574/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0572 - acc: 0.9833\n",
      "Epoch 575/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0579 - acc: 0.9917\n",
      "Epoch 576/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0595 - acc: 0.9833\n",
      "Epoch 577/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0568 - acc: 0.9917\n",
      "Epoch 578/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0582 - acc: 0.9917\n",
      "Epoch 579/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0577 - acc: 0.9917\n",
      "Epoch 580/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0576 - acc: 0.9917\n",
      "Epoch 581/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0570 - acc: 0.9833\n",
      "Epoch 582/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0570 - acc: 0.9833\n",
      "Epoch 583/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0569 - acc: 0.9833\n",
      "Epoch 584/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0572 - acc: 0.9917\n",
      "Epoch 585/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0569 - acc: 0.9833\n",
      "Epoch 586/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0570 - acc: 0.9833\n",
      "Epoch 587/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0578 - acc: 0.9833\n",
      "Epoch 588/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0565 - acc: 0.9917\n",
      "Epoch 589/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0567 - acc: 0.9833\n",
      "Epoch 590/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0574 - acc: 0.9833\n",
      "Epoch 591/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0565 - acc: 0.9833\n",
      "Epoch 592/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0571 - acc: 0.9917\n",
      "Epoch 593/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0590 - acc: 0.9917\n",
      "Epoch 594/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0598 - acc: 0.9833\n",
      "Epoch 595/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0580 - acc: 0.9750\n",
      "Epoch 596/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0574 - acc: 0.9750\n",
      "Epoch 597/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0562 - acc: 0.9833\n",
      "Epoch 598/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0568 - acc: 0.9917\n",
      "Epoch 599/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0566 - acc: 0.9917\n",
      "Epoch 600/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0561 - acc: 0.9917\n",
      "Epoch 601/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0577 - acc: 0.9833\n",
      "Epoch 602/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0564 - acc: 0.9833\n",
      "Epoch 603/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0569 - acc: 0.9833\n",
      "Epoch 604/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0565 - acc: 0.9917\n",
      "Epoch 605/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0566 - acc: 0.9917\n",
      "Epoch 606/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0557 - acc: 0.9917\n",
      "Epoch 607/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0584 - acc: 0.9833\n",
      "Epoch 608/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0571 - acc: 0.9833\n",
      "Epoch 609/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0562 - acc: 0.9917\n",
      "Epoch 610/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0557 - acc: 0.9917\n",
      "Epoch 611/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0568 - acc: 0.9917\n",
      "Epoch 612/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0559 - acc: 0.9917\n",
      "Epoch 613/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0556 - acc: 0.9917\n",
      "Epoch 614/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0577 - acc: 0.9917\n",
      "Epoch 615/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0559 - acc: 0.9917\n",
      "Epoch 616/8000\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.0559 - acc: 0.9917\n",
      "Epoch 617/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0557 - acc: 0.9833\n",
      "Epoch 618/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0563 - acc: 0.9833\n",
      "Epoch 619/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0564 - acc: 0.9833\n",
      "Epoch 620/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0556 - acc: 0.9917\n",
      "Epoch 621/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0568 - acc: 0.9917\n",
      "Epoch 622/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0553 - acc: 0.9917\n",
      "Epoch 623/8000\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.0558 - acc: 0.9917\n",
      "Epoch 624/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0561 - acc: 0.9917\n",
      "Epoch 625/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0559 - acc: 0.9917\n",
      "Epoch 626/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0558 - acc: 0.9917\n",
      "Epoch 627/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0553 - acc: 0.9917\n",
      "Epoch 628/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0554 - acc: 0.9917\n",
      "Epoch 629/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0553 - acc: 0.9917\n",
      "Epoch 630/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0561 - acc: 0.9917\n",
      "Epoch 631/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0554 - acc: 0.9917\n",
      "Epoch 632/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0565 - acc: 0.9917\n",
      "Epoch 633/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0555 - acc: 0.9917\n",
      "Epoch 634/8000\n",
      "120/120 [==============================] - 0s 175us/sample - loss: 0.0555 - acc: 0.9917\n",
      "Epoch 635/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0566 - acc: 0.9917\n",
      "Epoch 636/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0554 - acc: 0.9917\n",
      "Epoch 637/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0573 - acc: 0.9750\n",
      "Epoch 638/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0556 - acc: 0.9917\n",
      "Epoch 639/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0563 - acc: 0.9917\n",
      "Epoch 640/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0557 - acc: 0.9917\n",
      "Epoch 641/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0548 - acc: 0.9917\n",
      "Epoch 642/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0564 - acc: 0.9833\n",
      "Epoch 643/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0561 - acc: 0.9750\n",
      "Epoch 644/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0548 - acc: 0.9917\n",
      "Epoch 645/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0550 - acc: 0.9917\n",
      "Epoch 646/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0553 - acc: 0.9917\n",
      "Epoch 647/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0554 - acc: 0.9917\n",
      "Epoch 648/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0590 - acc: 0.9750\n",
      "Epoch 649/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0549 - acc: 0.9917\n",
      "Epoch 650/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0546 - acc: 0.9917\n",
      "Epoch 651/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0548 - acc: 0.9917\n",
      "Epoch 652/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0555 - acc: 0.9917\n",
      "Epoch 653/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0545 - acc: 0.9917\n",
      "Epoch 654/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0542 - acc: 0.9917\n",
      "Epoch 655/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0550 - acc: 0.9833\n",
      "Epoch 656/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0558 - acc: 0.9833\n",
      "Epoch 657/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0545 - acc: 0.9917\n",
      "Epoch 658/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0345 - acc: 1.000 - 0s 117us/sample - loss: 0.0547 - acc: 0.9917\n",
      "Epoch 659/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0545 - acc: 0.9917\n",
      "Epoch 660/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0546 - acc: 0.9917\n",
      "Epoch 661/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0541 - acc: 0.9917\n",
      "Epoch 662/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0544 - acc: 0.9917\n",
      "Epoch 663/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0548 - acc: 0.9917\n",
      "Epoch 664/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0545 - acc: 0.9917\n",
      "Epoch 665/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0544 - acc: 0.9917\n",
      "Epoch 666/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0540 - acc: 0.9917\n",
      "Epoch 667/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0544 - acc: 0.9917\n",
      "Epoch 668/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0544 - acc: 0.9917\n",
      "Epoch 669/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0543 - acc: 0.9917\n",
      "Epoch 670/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0542 - acc: 0.9917\n",
      "Epoch 671/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0548 - acc: 0.9917\n",
      "Epoch 672/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0547 - acc: 0.9917\n",
      "Epoch 673/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0554 - acc: 0.9917\n",
      "Epoch 674/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0543 - acc: 0.9917\n",
      "Epoch 675/8000\n",
      "120/120 [==============================] - 0s 83us/sample - loss: 0.0545 - acc: 0.9917\n",
      "Epoch 676/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0537 - acc: 0.9917\n",
      "Epoch 677/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0540 - acc: 0.9917\n",
      "Epoch 678/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0540 - acc: 0.9917\n",
      "Epoch 679/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0540 - acc: 0.9917\n",
      "Epoch 680/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0538 - acc: 0.9917\n",
      "Epoch 681/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0537 - acc: 0.9917\n",
      "Epoch 682/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0542 - acc: 0.9917\n",
      "Epoch 683/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0537 - acc: 0.9917\n",
      "Epoch 684/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0560 - acc: 0.9917\n",
      "Epoch 685/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0539 - acc: 0.9917\n",
      "Epoch 686/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0541 - acc: 0.9917\n",
      "Epoch 687/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0542 - acc: 0.9917\n",
      "Epoch 688/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0538 - acc: 0.9917\n",
      "Epoch 689/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0534 - acc: 0.9917\n",
      "Epoch 690/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0537 - acc: 0.9917\n",
      "Epoch 691/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0541 - acc: 0.9917\n",
      "Epoch 692/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0535 - acc: 0.9917\n",
      "Epoch 693/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0543 - acc: 0.9917\n",
      "Epoch 694/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0539 - acc: 0.9917\n",
      "Epoch 695/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0537 - acc: 0.9917\n",
      "Epoch 696/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0545 - acc: 0.9917\n",
      "Epoch 697/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0533 - acc: 0.9917\n",
      "Epoch 698/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0532 - acc: 0.9917\n",
      "Epoch 699/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0542 - acc: 0.9917\n",
      "Epoch 700/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0537 - acc: 0.9917\n",
      "Epoch 701/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0536 - acc: 0.9917\n",
      "Epoch 702/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0534 - acc: 0.9917\n",
      "Epoch 703/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0533 - acc: 0.9917\n",
      "Epoch 704/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0533 - acc: 0.9917\n",
      "Epoch 705/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0537 - acc: 0.9917\n",
      "Epoch 706/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0534 - acc: 0.9917\n",
      "Epoch 707/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0562 - acc: 0.9917\n",
      "Epoch 708/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0534 - acc: 0.9917\n",
      "Epoch 709/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0541 - acc: 0.9917\n",
      "Epoch 710/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0536 - acc: 0.9917\n",
      "Epoch 711/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0545 - acc: 0.9917\n",
      "Epoch 712/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0533 - acc: 0.9917\n",
      "Epoch 713/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0533 - acc: 0.9917\n",
      "Epoch 714/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0535 - acc: 0.9917\n",
      "Epoch 715/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0547 - acc: 0.9750\n",
      "Epoch 716/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0522 - acc: 0.9917\n",
      "Epoch 717/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0536 - acc: 0.9917\n",
      "Epoch 718/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0547 - acc: 0.9917\n",
      "Epoch 719/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0534 - acc: 0.9917\n",
      "Epoch 720/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0527 - acc: 0.9917\n",
      "Epoch 721/8000\n",
      "120/120 [==============================] - 0s 59us/sample - loss: 0.0535 - acc: 0.9917\n",
      "Epoch 722/8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0540 - acc: 0.9833\n",
      "Epoch 723/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0525 - acc: 0.9917\n",
      "Epoch 724/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0542 - acc: 0.9917\n",
      "Epoch 725/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0530 - acc: 0.9917\n",
      "Epoch 726/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0539 - acc: 0.9917\n",
      "Epoch 727/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0539 - acc: 0.9833\n",
      "Epoch 728/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0545 - acc: 0.9833\n",
      "Epoch 729/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0543 - acc: 0.9917\n",
      "Epoch 730/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0534 - acc: 0.9917\n",
      "Epoch 731/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0541 - acc: 0.9917\n",
      "Epoch 732/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0529 - acc: 0.9917\n",
      "Epoch 733/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0532 - acc: 0.9917\n",
      "Epoch 734/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0531 - acc: 0.9917\n",
      "Epoch 735/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0526 - acc: 0.9917\n",
      "Epoch 736/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0533 - acc: 0.9917\n",
      "Epoch 737/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0534 - acc: 0.9917\n",
      "Epoch 738/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0524 - acc: 0.9917\n",
      "Epoch 739/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0531 - acc: 0.9917\n",
      "Epoch 740/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0529 - acc: 0.9833\n",
      "Epoch 741/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0530 - acc: 0.9917\n",
      "Epoch 742/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0533 - acc: 0.9917\n",
      "Epoch 743/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0527 - acc: 0.9917\n",
      "Epoch 744/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0525 - acc: 0.9917\n",
      "Epoch 745/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0522 - acc: 0.9917\n",
      "Epoch 746/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0528 - acc: 0.9917\n",
      "Epoch 747/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0524 - acc: 0.9917\n",
      "Epoch 748/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0532 - acc: 0.9917\n",
      "Epoch 749/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0518 - acc: 0.9917\n",
      "Epoch 750/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0522 - acc: 0.9917\n",
      "Epoch 751/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0527 - acc: 0.9917\n",
      "Epoch 752/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0523 - acc: 0.9917\n",
      "Epoch 753/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0523 - acc: 0.9917\n",
      "Epoch 754/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0530 - acc: 0.9917\n",
      "Epoch 755/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0527 - acc: 0.9833\n",
      "Epoch 756/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0537 - acc: 0.9833\n",
      "Epoch 757/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0524 - acc: 0.9917\n",
      "Epoch 758/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0036 - acc: 1.000 - 0s 67us/sample - loss: 0.0537 - acc: 0.9917\n",
      "Epoch 759/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0517 - acc: 0.9917\n",
      "Epoch 760/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0538 - acc: 0.9833\n",
      "Epoch 761/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0535 - acc: 0.9833\n",
      "Epoch 762/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0520 - acc: 0.9917\n",
      "Epoch 763/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0534 - acc: 0.9917\n",
      "Epoch 764/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0525 - acc: 0.9917\n",
      "Epoch 765/8000\n",
      "120/120 [==============================] - 0s 59us/sample - loss: 0.0548 - acc: 0.9833\n",
      "Epoch 766/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0523 - acc: 0.9833\n",
      "Epoch 767/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0524 - acc: 0.9917\n",
      "Epoch 768/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0526 - acc: 0.9917\n",
      "Epoch 769/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0520 - acc: 0.9917\n",
      "Epoch 770/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0516 - acc: 0.9917\n",
      "Epoch 771/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0519 - acc: 0.9917\n",
      "Epoch 772/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0518 - acc: 0.9917\n",
      "Epoch 773/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0524 - acc: 0.9917\n",
      "Epoch 774/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0516 - acc: 0.9917\n",
      "Epoch 775/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0516 - acc: 0.9917\n",
      "Epoch 776/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0516 - acc: 0.9917\n",
      "Epoch 777/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0521 - acc: 0.9917\n",
      "Epoch 778/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0517 - acc: 0.9917\n",
      "Epoch 779/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0542 - acc: 0.9917\n",
      "Epoch 780/8000\n",
      "120/120 [==============================] - 0s 59us/sample - loss: 0.0529 - acc: 0.9917\n",
      "Epoch 781/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0529 - acc: 0.9917\n",
      "Epoch 782/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0522 - acc: 0.9917\n",
      "Epoch 783/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0516 - acc: 0.9917\n",
      "Epoch 784/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0522 - acc: 0.9917\n",
      "Epoch 785/8000\n",
      "120/120 [==============================] - 0s 59us/sample - loss: 0.0515 - acc: 0.9917\n",
      "Epoch 786/8000\n",
      "120/120 [==============================] - 0s 83us/sample - loss: 0.0515 - acc: 0.9917\n",
      "Epoch 787/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0518 - acc: 0.9917\n",
      "Epoch 788/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0516 - acc: 0.9917\n",
      "Epoch 789/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0532 - acc: 0.9833\n",
      "Epoch 790/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0518 - acc: 0.9917\n",
      "Epoch 791/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0512 - acc: 0.9917\n",
      "Epoch 792/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0518 - acc: 0.9917\n",
      "Epoch 793/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0518 - acc: 0.9917\n",
      "Epoch 794/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0514 - acc: 0.9917\n",
      "Epoch 795/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0521 - acc: 0.9833\n",
      "Epoch 796/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0520 - acc: 0.9917\n",
      "Epoch 797/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0514 - acc: 0.9917\n",
      "Epoch 798/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0512 - acc: 0.9917\n",
      "Epoch 799/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0516 - acc: 0.9917\n",
      "Epoch 800/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0516 - acc: 0.9917\n",
      "Epoch 801/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0513 - acc: 0.9917\n",
      "Epoch 802/8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0517 - acc: 0.9917\n",
      "Epoch 803/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0509 - acc: 0.9917\n",
      "Epoch 804/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0510 - acc: 0.9917\n",
      "Epoch 805/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0514 - acc: 0.9917\n",
      "Epoch 806/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0511 - acc: 0.9917\n",
      "Epoch 807/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0525 - acc: 0.9833\n",
      "Epoch 808/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0529 - acc: 0.9917\n",
      "Epoch 809/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0523 - acc: 0.9917\n",
      "Epoch 810/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0514 - acc: 0.9917\n",
      "Epoch 811/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0516 - acc: 0.9917\n",
      "Epoch 812/8000\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.0509 - acc: 0.9917\n",
      "Epoch 813/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0522 - acc: 0.9917\n",
      "Epoch 814/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0512 - acc: 0.9917\n",
      "Epoch 815/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0510 - acc: 0.9917\n",
      "Epoch 816/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0533 - acc: 0.9833\n",
      "Epoch 817/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0516 - acc: 0.9917\n",
      "Epoch 818/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0520 - acc: 0.9917\n",
      "Epoch 819/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0516 - acc: 0.9917\n",
      "Epoch 820/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0536 - acc: 0.9917\n",
      "Epoch 821/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0518 - acc: 0.9917\n",
      "Epoch 822/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0510 - acc: 0.9917\n",
      "Epoch 823/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0521 - acc: 0.9917\n",
      "Epoch 824/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0515 - acc: 0.9833\n",
      "Epoch 825/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0508 - acc: 0.9917\n",
      "Epoch 826/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0526 - acc: 0.9917\n",
      "Epoch 827/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0520 - acc: 0.9917\n",
      "Epoch 828/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0514 - acc: 0.9917\n",
      "Epoch 829/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0536 - acc: 0.9833\n",
      "Epoch 830/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0510 - acc: 0.9833\n",
      "Epoch 831/8000\n",
      "120/120 [==============================] - 0s 175us/sample - loss: 0.0509 - acc: 0.9917\n",
      "Epoch 832/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0521 - acc: 0.9917\n",
      "Epoch 833/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0520 - acc: 0.9917\n",
      "Epoch 834/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0507 - acc: 0.9917\n",
      "Epoch 835/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0507 - acc: 0.9917\n",
      "Epoch 836/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0507 - acc: 0.9917\n",
      "Epoch 837/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0503 - acc: 0.9917\n",
      "Epoch 838/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0509 - acc: 0.9917\n",
      "Epoch 839/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0512 - acc: 0.9917\n",
      "Epoch 840/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0508 - acc: 0.9917\n",
      "Epoch 841/8000\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.0505 - acc: 0.9917\n",
      "Epoch 842/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0507 - acc: 0.9917\n",
      "Epoch 843/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0507 - acc: 0.9917\n",
      "Epoch 844/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0513 - acc: 0.9917\n",
      "Epoch 845/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0513 - acc: 0.9917\n",
      "Epoch 846/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0504 - acc: 0.9917\n",
      "Epoch 847/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0521 - acc: 0.9833\n",
      "Epoch 848/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0505 - acc: 0.9917\n",
      "Epoch 849/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0507 - acc: 0.9917\n",
      "Epoch 850/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0507 - acc: 0.9917\n",
      "Epoch 851/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0511 - acc: 0.9917\n",
      "Epoch 852/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0505 - acc: 0.9917\n",
      "Epoch 853/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0511 - acc: 0.9917\n",
      "Epoch 854/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0532 - acc: 0.9917\n",
      "Epoch 855/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0525 - acc: 0.9917\n",
      "Epoch 856/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0502 - acc: 0.9917\n",
      "Epoch 857/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0502 - acc: 0.9917\n",
      "Epoch 858/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0500 - acc: 0.9917\n",
      "Epoch 859/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0501 - acc: 0.9917\n",
      "Epoch 860/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0505 - acc: 0.9917\n",
      "Epoch 861/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0505 - acc: 0.9917\n",
      "Epoch 862/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0503 - acc: 0.9917\n",
      "Epoch 863/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0505 - acc: 0.9917\n",
      "Epoch 864/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0505 - acc: 0.9917\n",
      "Epoch 865/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0502 - acc: 0.9917\n",
      "Epoch 866/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0505 - acc: 0.9917\n",
      "Epoch 867/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0498 - acc: 0.9917\n",
      "Epoch 868/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0519 - acc: 0.9917\n",
      "Epoch 869/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0508 - acc: 0.9917\n",
      "Epoch 870/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0500 - acc: 0.9917\n",
      "Epoch 871/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0505 - acc: 0.9917\n",
      "Epoch 872/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0504 - acc: 0.9917\n",
      "Epoch 873/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0503 - acc: 0.9917\n",
      "Epoch 874/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0498 - acc: 0.9917\n",
      "Epoch 875/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0501 - acc: 0.9917\n",
      "Epoch 876/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0504 - acc: 0.9917\n",
      "Epoch 877/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0508 - acc: 0.9917\n",
      "Epoch 878/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0497 - acc: 0.9917\n",
      "Epoch 879/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0495 - acc: 0.9917\n",
      "Epoch 880/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0529 - acc: 0.9833\n",
      "Epoch 881/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0496 - acc: 0.9833\n",
      "Epoch 882/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0516 - acc: 0.9917\n",
      "Epoch 883/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0508 - acc: 0.9917\n",
      "Epoch 884/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0539 - acc: 0.9917\n",
      "Epoch 885/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0505 - acc: 0.9833\n",
      "Epoch 886/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0506 - acc: 0.9917\n",
      "Epoch 887/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0516 - acc: 0.9917\n",
      "Epoch 888/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0507 - acc: 0.9917\n",
      "Epoch 889/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0495 - acc: 0.9917\n",
      "Epoch 890/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0499 - acc: 0.9917\n",
      "Epoch 891/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0498 - acc: 0.9917\n",
      "Epoch 892/8000\n",
      "120/120 [==============================] - 0s 83us/sample - loss: 0.0503 - acc: 0.9917\n",
      "Epoch 893/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0493 - acc: 0.9917\n",
      "Epoch 894/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0510 - acc: 0.9833\n",
      "Epoch 895/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0508 - acc: 0.9833\n",
      "Epoch 896/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0502 - acc: 0.9833\n",
      "Epoch 897/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0490 - acc: 0.9917\n",
      "Epoch 898/8000\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.0493 - acc: 0.9917\n",
      "Epoch 899/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0526 - acc: 0.9917\n",
      "Epoch 900/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0500 - acc: 0.9917\n",
      "Epoch 901/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0511 - acc: 0.9917\n",
      "Epoch 902/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0506 - acc: 0.9833\n",
      "Epoch 903/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0511 - acc: 0.9833\n",
      "Epoch 904/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0496 - acc: 0.9917\n",
      "Epoch 905/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0492 - acc: 0.9917\n",
      "Epoch 906/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0502 - acc: 0.9917\n",
      "Epoch 907/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0493 - acc: 0.9917\n",
      "Epoch 908/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0492 - acc: 0.9917\n",
      "Epoch 909/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0497 - acc: 0.9917\n",
      "Epoch 910/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0495 - acc: 0.9917\n",
      "Epoch 911/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0507 - acc: 0.9917\n",
      "Epoch 912/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0490 - acc: 0.9917\n",
      "Epoch 913/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0496 - acc: 0.9833\n",
      "Epoch 914/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0509 - acc: 0.9833\n",
      "Epoch 915/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0505 - acc: 0.9833\n",
      "Epoch 916/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0507 - acc: 0.9917\n",
      "Epoch 917/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0495 - acc: 0.9917\n",
      "Epoch 918/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0499 - acc: 0.9917\n",
      "Epoch 919/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0494 - acc: 0.9917\n",
      "Epoch 920/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0469 - acc: 1.000 - 0s 84us/sample - loss: 0.0522 - acc: 0.9833\n",
      "Epoch 921/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0495 - acc: 0.9833\n",
      "Epoch 922/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0504 - acc: 0.9917\n",
      "Epoch 923/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0530 - acc: 0.9917\n",
      "Epoch 924/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0504 - acc: 0.9917\n",
      "Epoch 925/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0508 - acc: 0.9917\n",
      "Epoch 926/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0511 - acc: 0.9833\n",
      "Epoch 927/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0493 - acc: 0.9917\n",
      "Epoch 928/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0491 - acc: 0.9917\n",
      "Epoch 929/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0497 - acc: 0.9917\n",
      "Epoch 930/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0517 - acc: 0.9917\n",
      "Epoch 931/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0494 - acc: 0.9917\n",
      "Epoch 932/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0494 - acc: 0.9917\n",
      "Epoch 933/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0506 - acc: 0.9917\n",
      "Epoch 934/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0492 - acc: 0.9917\n",
      "Epoch 935/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0498 - acc: 0.9917\n",
      "Epoch 936/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0500 - acc: 0.9917\n",
      "Epoch 937/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0501 - acc: 0.9917\n",
      "Epoch 938/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0488 - acc: 0.9917\n",
      "Epoch 939/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0492 - acc: 0.9917\n",
      "Epoch 940/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0488 - acc: 0.9917\n",
      "Epoch 941/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0487 - acc: 0.9917\n",
      "Epoch 942/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0286 - acc: 1.000 - 0s 84us/sample - loss: 0.0499 - acc: 0.9833\n",
      "Epoch 943/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0497 - acc: 0.9833\n",
      "Epoch 944/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0495 - acc: 0.9917\n",
      "Epoch 945/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0493 - acc: 0.9917\n",
      "Epoch 946/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0492 - acc: 0.9917\n",
      "Epoch 947/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0542 - acc: 0.9833\n",
      "Epoch 948/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0484 - acc: 0.9917\n",
      "Epoch 949/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0490 - acc: 0.9917\n",
      "Epoch 950/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0492 - acc: 0.9917\n",
      "Epoch 951/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0502 - acc: 0.9917\n",
      "Epoch 952/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0491 - acc: 0.9917\n",
      "Epoch 953/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0487 - acc: 0.9917\n",
      "Epoch 954/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0492 - acc: 0.9917\n",
      "Epoch 955/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0490 - acc: 0.9917\n",
      "Epoch 956/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0487 - acc: 0.9917\n",
      "Epoch 957/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0485 - acc: 0.9917\n",
      "Epoch 958/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0516 - acc: 0.9917\n",
      "Epoch 959/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0484 - acc: 0.9917\n",
      "Epoch 960/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0485 - acc: 0.9917\n",
      "Epoch 961/8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0494 - acc: 0.9833\n",
      "Epoch 962/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0491 - acc: 0.9833\n",
      "Epoch 963/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0489 - acc: 0.9833\n",
      "Epoch 964/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0490 - acc: 0.9917\n",
      "Epoch 965/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0499 - acc: 0.9917\n",
      "Epoch 966/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0493 - acc: 0.9917\n",
      "Epoch 967/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0496 - acc: 0.9917\n",
      "Epoch 968/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0491 - acc: 0.9917\n",
      "Epoch 969/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0489 - acc: 0.9917\n",
      "Epoch 970/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0486 - acc: 0.9917\n",
      "Epoch 971/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0486 - acc: 0.9917\n",
      "Epoch 972/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0496 - acc: 0.9917\n",
      "Epoch 973/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0495 - acc: 0.9917\n",
      "Epoch 974/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0492 - acc: 0.9917\n",
      "Epoch 975/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0506 - acc: 0.9917\n",
      "Epoch 976/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0497 - acc: 0.9917\n",
      "Epoch 977/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0489 - acc: 0.9917\n",
      "Epoch 978/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0485 - acc: 0.9917\n",
      "Epoch 979/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0487 - acc: 0.9917\n",
      "Epoch 980/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0485 - acc: 0.9917\n",
      "Epoch 981/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0484 - acc: 0.9917\n",
      "Epoch 982/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0485 - acc: 0.9917\n",
      "Epoch 983/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0481 - acc: 0.9917\n",
      "Epoch 984/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0487 - acc: 0.9917\n",
      "Epoch 985/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0486 - acc: 0.9917\n",
      "Epoch 986/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0489 - acc: 0.9917\n",
      "Epoch 987/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0484 - acc: 0.9917\n",
      "Epoch 988/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0491 - acc: 0.9917\n",
      "Epoch 989/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0484 - acc: 0.9917\n",
      "Epoch 990/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0489 - acc: 0.9917\n",
      "Epoch 991/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0483 - acc: 0.9917\n",
      "Epoch 992/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0484 - acc: 0.9917\n",
      "Epoch 993/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0499 - acc: 0.9917\n",
      "Epoch 994/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0482 - acc: 0.9917\n",
      "Epoch 995/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0490 - acc: 0.9833\n",
      "Epoch 996/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0487 - acc: 0.9833\n",
      "Epoch 997/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0483 - acc: 0.9917\n",
      "Epoch 998/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0480 - acc: 0.9917\n",
      "Epoch 999/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0482 - acc: 0.9917\n",
      "Epoch 1000/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0495 - acc: 0.9917\n",
      "Epoch 1001/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0475 - acc: 0.9917\n",
      "Epoch 1002/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0494 - acc: 0.9917\n",
      "Epoch 1003/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0494 - acc: 0.9833\n",
      "Epoch 1004/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0501 - acc: 0.9917\n",
      "Epoch 1005/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0480 - acc: 0.9917\n",
      "Epoch 1006/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0480 - acc: 0.9917\n",
      "Epoch 1007/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0491 - acc: 0.9917\n",
      "Epoch 1008/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0484 - acc: 0.9917\n",
      "Epoch 1009/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0494 - acc: 0.9833\n",
      "Epoch 1010/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0493 - acc: 0.9917\n",
      "Epoch 1011/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0489 - acc: 0.9917\n",
      "Epoch 1012/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0483 - acc: 0.9917\n",
      "Epoch 1013/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0495 - acc: 0.9917\n",
      "Epoch 1014/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0489 - acc: 0.9917\n",
      "Epoch 1015/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0493 - acc: 0.9917\n",
      "Epoch 1016/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0496 - acc: 0.9917\n",
      "Epoch 1017/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0480 - acc: 0.9917\n",
      "Epoch 1018/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0490 - acc: 0.9917\n",
      "Epoch 1019/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0486 - acc: 0.9917\n",
      "Epoch 1020/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0490 - acc: 0.9917\n",
      "Epoch 1021/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0479 - acc: 0.9917\n",
      "Epoch 1022/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0494 - acc: 0.9917\n",
      "Epoch 1023/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0481 - acc: 0.9917\n",
      "Epoch 1024/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0479 - acc: 0.9917\n",
      "Epoch 1025/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0481 - acc: 0.9917\n",
      "Epoch 1026/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0486 - acc: 0.9917\n",
      "Epoch 1027/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0478 - acc: 0.9917\n",
      "Epoch 1028/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0477 - acc: 0.9917\n",
      "Epoch 1029/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0483 - acc: 0.9917\n",
      "Epoch 1030/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0482 - acc: 0.9917\n",
      "Epoch 1031/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0481 - acc: 0.9917\n",
      "Epoch 1032/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0482 - acc: 0.9917\n",
      "Epoch 1033/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0472 - acc: 0.9917\n",
      "Epoch 1034/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0491 - acc: 0.9917\n",
      "Epoch 1035/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0487 - acc: 0.9833\n",
      "Epoch 1036/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0489 - acc: 0.9833\n",
      "Epoch 1037/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0480 - acc: 0.9917\n",
      "Epoch 1038/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0525 - acc: 0.9917\n",
      "Epoch 1039/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0486 - acc: 0.9917\n",
      "Epoch 1040/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0491 - acc: 0.9917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1041/8000\n",
      "120/120 [==============================] - 0s 50us/sample - loss: 0.0491 - acc: 0.9833\n",
      "Epoch 1042/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0478 - acc: 0.9917\n",
      "Epoch 1043/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0491 - acc: 0.9917\n",
      "Epoch 1044/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0499 - acc: 0.9917\n",
      "Epoch 1045/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0481 - acc: 0.9917\n",
      "Epoch 1046/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0495 - acc: 0.9917\n",
      "Epoch 1047/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0477 - acc: 0.9917\n",
      "Epoch 1048/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0472 - acc: 0.9917\n",
      "Epoch 1049/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0477 - acc: 0.9917\n",
      "Epoch 1050/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0478 - acc: 0.9917\n",
      "Epoch 1051/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0480 - acc: 0.9917\n",
      "Epoch 1052/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0477 - acc: 0.9917\n",
      "Epoch 1053/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0483 - acc: 0.9917\n",
      "Epoch 1054/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0480 - acc: 0.9833\n",
      "Epoch 1055/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0494 - acc: 0.9917\n",
      "Epoch 1056/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0475 - acc: 0.9917\n",
      "Epoch 1057/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0475 - acc: 0.9917\n",
      "Epoch 1058/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0474 - acc: 0.9917\n",
      "Epoch 1059/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0479 - acc: 0.9917\n",
      "Epoch 1060/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0477 - acc: 0.9917\n",
      "Epoch 1061/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0473 - acc: 0.9917\n",
      "Epoch 1062/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0475 - acc: 0.9917\n",
      "Epoch 1063/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0488 - acc: 0.9917\n",
      "Epoch 1064/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0489 - acc: 0.9833\n",
      "Epoch 1065/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0474 - acc: 0.9917\n",
      "Epoch 1066/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0481 - acc: 0.9917\n",
      "Epoch 1067/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0487 - acc: 0.9917\n",
      "Epoch 1068/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0478 - acc: 0.9917\n",
      "Epoch 1069/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0319 - acc: 1.000 - 0s 59us/sample - loss: 0.0471 - acc: 0.9917\n",
      "Epoch 1070/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0488 - acc: 0.9833\n",
      "Epoch 1071/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0476 - acc: 0.9917\n",
      "Epoch 1072/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0474 - acc: 0.9917\n",
      "Epoch 1073/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0474 - acc: 0.9917\n",
      "Epoch 1074/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0475 - acc: 0.9917\n",
      "Epoch 1075/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0476 - acc: 0.9917\n",
      "Epoch 1076/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0472 - acc: 0.9917\n",
      "Epoch 1077/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0473 - acc: 0.9917\n",
      "Epoch 1078/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0475 - acc: 0.9917\n",
      "Epoch 1079/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0473 - acc: 0.9917\n",
      "Epoch 1080/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0481 - acc: 0.9917\n",
      "Epoch 1081/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0474 - acc: 0.9917\n",
      "Epoch 1082/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0471 - acc: 0.9917\n",
      "Epoch 1083/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0475 - acc: 0.9917\n",
      "Epoch 1084/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0483 - acc: 0.9917\n",
      "Epoch 1085/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0479 - acc: 0.9917\n",
      "Epoch 1086/8000\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.0482 - acc: 0.9917\n",
      "Epoch 1087/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0488 - acc: 0.9917\n",
      "Epoch 1088/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0485 - acc: 0.9917\n",
      "Epoch 1089/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0470 - acc: 0.9917\n",
      "Epoch 1090/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0488 - acc: 0.9833\n",
      "Epoch 1091/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0475 - acc: 0.9917\n",
      "Epoch 1092/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0469 - acc: 0.9917\n",
      "Epoch 1093/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0497 - acc: 0.9917\n",
      "Epoch 1094/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0473 - acc: 0.9917\n",
      "Epoch 1095/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0468 - acc: 0.9917\n",
      "Epoch 1096/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0487 - acc: 0.9833\n",
      "Epoch 1097/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0481 - acc: 0.9917\n",
      "Epoch 1098/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0475 - acc: 0.9917\n",
      "Epoch 1099/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0483 - acc: 0.9917\n",
      "Epoch 1100/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0486 - acc: 0.9917\n",
      "Epoch 1101/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0466 - acc: 0.9917\n",
      "Epoch 1102/8000\n",
      "120/120 [==============================] - 0s 83us/sample - loss: 0.0513 - acc: 0.9833\n",
      "Epoch 1103/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0500 - acc: 0.9833\n",
      "Epoch 1104/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0466 - acc: 0.9917\n",
      "Epoch 1105/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0476 - acc: 0.9917\n",
      "Epoch 1106/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0474 - acc: 0.9917\n",
      "Epoch 1107/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0469 - acc: 0.9917\n",
      "Epoch 1108/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0469 - acc: 0.9917\n",
      "Epoch 1109/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0470 - acc: 0.9917\n",
      "Epoch 1110/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0475 - acc: 0.9917\n",
      "Epoch 1111/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0479 - acc: 0.9917\n",
      "Epoch 1112/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0480 - acc: 0.9917\n",
      "Epoch 1113/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0514 - acc: 0.9917\n",
      "Epoch 1114/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0492 - acc: 0.9917\n",
      "Epoch 1115/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0475 - acc: 0.9917\n",
      "Epoch 1116/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0472 - acc: 0.9917\n",
      "Epoch 1117/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0481 - acc: 0.9917\n",
      "Epoch 1118/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0476 - acc: 0.9917\n",
      "Epoch 1119/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0473 - acc: 0.9917\n",
      "Epoch 1120/8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0482 - acc: 0.9917\n",
      "Epoch 1121/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0489 - acc: 0.9917\n",
      "Epoch 1122/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0469 - acc: 0.9917\n",
      "Epoch 1123/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0474 - acc: 0.9917\n",
      "Epoch 1124/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0469 - acc: 0.9917\n",
      "Epoch 1125/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0471 - acc: 0.9917\n",
      "Epoch 1126/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0468 - acc: 0.9917\n",
      "Epoch 1127/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0468 - acc: 0.9917\n",
      "Epoch 1128/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0480 - acc: 0.9833\n",
      "Epoch 1129/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0469 - acc: 0.9917\n",
      "Epoch 1130/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0460 - acc: 0.9917\n",
      "Epoch 1131/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0472 - acc: 0.9917\n",
      "Epoch 1132/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0494 - acc: 0.9917\n",
      "Epoch 1133/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0472 - acc: 0.9917\n",
      "Epoch 1134/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0487 - acc: 0.9833\n",
      "Epoch 1135/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0475 - acc: 0.9833\n",
      "Epoch 1136/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0468 - acc: 0.9917\n",
      "Epoch 1137/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0464 - acc: 0.9917\n",
      "Epoch 1138/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0468 - acc: 0.9917\n",
      "Epoch 1139/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0474 - acc: 0.9917\n",
      "Epoch 1140/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0476 - acc: 0.9917\n",
      "Epoch 1141/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0469 - acc: 0.9917\n",
      "Epoch 1142/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0472 - acc: 0.9917\n",
      "Epoch 1143/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0466 - acc: 0.9917\n",
      "Epoch 1144/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0470 - acc: 0.9917\n",
      "Epoch 1145/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0470 - acc: 0.9917\n",
      "Epoch 1146/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0471 - acc: 0.9917\n",
      "Epoch 1147/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0463 - acc: 0.9917\n",
      "Epoch 1148/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0468 - acc: 0.9917\n",
      "Epoch 1149/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0471 - acc: 0.9833\n",
      "Epoch 1150/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0474 - acc: 0.9917\n",
      "Epoch 1151/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0466 - acc: 0.9917\n",
      "Epoch 1152/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0472 - acc: 0.9917\n",
      "Epoch 1153/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0464 - acc: 0.9917\n",
      "Epoch 1154/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0473 - acc: 0.9917\n",
      "Epoch 1155/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0463 - acc: 0.9917\n",
      "Epoch 1156/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0463 - acc: 0.9917\n",
      "Epoch 1157/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0467 - acc: 0.9917\n",
      "Epoch 1158/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0466 - acc: 0.9917\n",
      "Epoch 1159/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0471 - acc: 0.9917\n",
      "Epoch 1160/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0469 - acc: 0.9917\n",
      "Epoch 1161/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0472 - acc: 0.9917\n",
      "Epoch 1162/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0469 - acc: 0.9917\n",
      "Epoch 1163/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0463 - acc: 0.9917\n",
      "Epoch 1164/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0468 - acc: 0.9917\n",
      "Epoch 1165/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0477 - acc: 0.9917\n",
      "Epoch 1166/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0463 - acc: 0.9917\n",
      "Epoch 1167/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0479 - acc: 0.9833\n",
      "Epoch 1168/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0477 - acc: 0.9833\n",
      "Epoch 1169/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0468 - acc: 0.9917\n",
      "Epoch 1170/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0466 - acc: 0.9917\n",
      "Epoch 1171/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0464 - acc: 0.9917\n",
      "Epoch 1172/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0465 - acc: 0.9917\n",
      "Epoch 1173/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0465 - acc: 0.9917\n",
      "Epoch 1174/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0465 - acc: 0.9917\n",
      "Epoch 1175/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0478 - acc: 0.9917\n",
      "Epoch 1176/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0475 - acc: 0.9833\n",
      "Epoch 1177/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0471 - acc: 0.9917\n",
      "Epoch 1178/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0475 - acc: 0.9917\n",
      "Epoch 1179/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0466 - acc: 0.9917\n",
      "Epoch 1180/8000\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.0470 - acc: 0.9917\n",
      "Epoch 1181/8000\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.0462 - acc: 0.9917\n",
      "Epoch 1182/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0465 - acc: 0.9917\n",
      "Epoch 1183/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0466 - acc: 0.9917\n",
      "Epoch 1184/8000\n",
      "120/120 [==============================] - 0s 59us/sample - loss: 0.0466 - acc: 0.9917\n",
      "Epoch 1185/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0475 - acc: 0.9917\n",
      "Epoch 1186/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0464 - acc: 0.9917\n",
      "Epoch 1187/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0464 - acc: 0.9917\n",
      "Epoch 1188/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0471 - acc: 0.9917\n",
      "Epoch 1189/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0468 - acc: 0.9917\n",
      "Epoch 1190/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0459 - acc: 0.9917\n",
      "Epoch 1191/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0463 - acc: 0.9917\n",
      "Epoch 1192/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0469 - acc: 0.9917\n",
      "Epoch 1193/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0462 - acc: 0.9917\n",
      "Epoch 1194/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0460 - acc: 0.9917\n",
      "Epoch 1195/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0461 - acc: 0.9917\n",
      "Epoch 1196/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0468 - acc: 0.9833\n",
      "Epoch 1197/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0469 - acc: 0.9917\n",
      "Epoch 1198/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0462 - acc: 0.9917\n",
      "Epoch 1199/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0463 - acc: 0.9917\n",
      "Epoch 1200/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0461 - acc: 0.9917\n",
      "Epoch 1201/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0471 - acc: 0.9917\n",
      "Epoch 1202/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0468 - acc: 0.9917\n",
      "Epoch 1203/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0460 - acc: 0.9917\n",
      "Epoch 1204/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0460 - acc: 0.9917\n",
      "Epoch 1205/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0458 - acc: 0.9917\n",
      "Epoch 1206/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0462 - acc: 0.9917\n",
      "Epoch 1207/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0462 - acc: 0.9917\n",
      "Epoch 1208/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0459 - acc: 0.9917\n",
      "Epoch 1209/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0463 - acc: 0.9917\n",
      "Epoch 1210/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0463 - acc: 0.9917\n",
      "Epoch 1211/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0469 - acc: 0.9917\n",
      "Epoch 1212/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0459 - acc: 0.9917\n",
      "Epoch 1213/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0460 - acc: 0.9917\n",
      "Epoch 1214/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0466 - acc: 0.9833\n",
      "Epoch 1215/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0467 - acc: 0.9917\n",
      "Epoch 1216/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0464 - acc: 0.9917\n",
      "Epoch 1217/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0466 - acc: 0.9917\n",
      "Epoch 1218/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0462 - acc: 0.9917\n",
      "Epoch 1219/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0470 - acc: 0.9917\n",
      "Epoch 1220/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0462 - acc: 0.9917\n",
      "Epoch 1221/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0463 - acc: 0.9917\n",
      "Epoch 1222/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0467 - acc: 0.9917\n",
      "Epoch 1223/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0466 - acc: 0.9917\n",
      "Epoch 1224/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0454 - acc: 0.9917\n",
      "Epoch 1225/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0466 - acc: 0.9917\n",
      "Epoch 1226/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0467 - acc: 0.9917\n",
      "Epoch 1227/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0460 - acc: 0.9917\n",
      "Epoch 1228/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0463 - acc: 0.9917\n",
      "Epoch 1229/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0463 - acc: 0.9917\n",
      "Epoch 1230/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0464 - acc: 0.9917\n",
      "Epoch 1231/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0478 - acc: 0.9833\n",
      "Epoch 1232/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0474 - acc: 0.9833\n",
      "Epoch 1233/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0459 - acc: 0.9917\n",
      "Epoch 1234/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0456 - acc: 0.9917\n",
      "Epoch 1235/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0459 - acc: 0.9917\n",
      "Epoch 1236/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0457 - acc: 0.9917\n",
      "Epoch 1237/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0459 - acc: 0.9917\n",
      "Epoch 1238/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0470 - acc: 0.9917\n",
      "Epoch 1239/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0463 - acc: 0.9917\n",
      "Epoch 1240/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0484 - acc: 0.9917\n",
      "Epoch 1241/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0470 - acc: 0.9833\n",
      "Epoch 1242/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0446 - acc: 0.9917\n",
      "Epoch 1243/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0466 - acc: 0.9917\n",
      "Epoch 1244/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0475 - acc: 0.9917\n",
      "Epoch 1245/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0470 - acc: 0.9917\n",
      "Epoch 1246/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0457 - acc: 0.9917\n",
      "Epoch 1247/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0470 - acc: 0.9833\n",
      "Epoch 1248/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0465 - acc: 0.9917\n",
      "Epoch 1249/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0457 - acc: 0.9917\n",
      "Epoch 1250/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0455 - acc: 0.9917\n",
      "Epoch 1251/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0459 - acc: 0.9917\n",
      "Epoch 1252/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0466 - acc: 0.9917\n",
      "Epoch 1253/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0464 - acc: 0.9917\n",
      "Epoch 1254/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0455 - acc: 0.9917\n",
      "Epoch 1255/8000\n",
      "120/120 [==============================] - 0s 50us/sample - loss: 0.0459 - acc: 0.9917\n",
      "Epoch 1256/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0456 - acc: 0.9917\n",
      "Epoch 1257/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0462 - acc: 0.9917\n",
      "Epoch 1258/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0456 - acc: 0.9917\n",
      "Epoch 1259/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0460 - acc: 0.9917\n",
      "Epoch 1260/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0457 - acc: 0.9917\n",
      "Epoch 1261/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0457 - acc: 0.9917\n",
      "Epoch 1262/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0458 - acc: 0.9917\n",
      "Epoch 1263/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0455 - acc: 0.9917\n",
      "Epoch 1264/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0463 - acc: 0.9917\n",
      "Epoch 1265/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0460 - acc: 0.9917\n",
      "Epoch 1266/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0457 - acc: 0.9917\n",
      "Epoch 1267/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0469 - acc: 0.9917\n",
      "Epoch 1268/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0467 - acc: 0.9917\n",
      "Epoch 1269/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0457 - acc: 0.9917\n",
      "Epoch 1270/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0451 - acc: 0.9917\n",
      "Epoch 1271/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0452 - acc: 0.9917\n",
      "Epoch 1272/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0461 - acc: 0.9917\n",
      "Epoch 1273/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0458 - acc: 0.9917\n",
      "Epoch 1274/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0463 - acc: 0.9917\n",
      "Epoch 1275/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0456 - acc: 0.9917\n",
      "Epoch 1276/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0456 - acc: 0.9917\n",
      "Epoch 1277/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0472 - acc: 0.9917\n",
      "Epoch 1278/8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0456 - acc: 0.9917\n",
      "Epoch 1279/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0453 - acc: 0.9917\n",
      "Epoch 1280/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0454 - acc: 0.9917\n",
      "Epoch 1281/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0473 - acc: 0.9833\n",
      "Epoch 1282/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0456 - acc: 0.9917\n",
      "Epoch 1283/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0456 - acc: 0.9917\n",
      "Epoch 1284/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0464 - acc: 0.9917\n",
      "Epoch 1285/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0461 - acc: 0.9917\n",
      "Epoch 1286/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0452 - acc: 0.9917\n",
      "Epoch 1287/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0471 - acc: 0.9833\n",
      "Epoch 1288/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0459 - acc: 0.9917\n",
      "Epoch 1289/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0464 - acc: 0.9917\n",
      "Epoch 1290/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0456 - acc: 0.9917\n",
      "Epoch 1291/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0472 - acc: 0.9917\n",
      "Epoch 1292/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0467 - acc: 0.9917\n",
      "Epoch 1293/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0469 - acc: 0.9917\n",
      "Epoch 1294/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0468 - acc: 0.9917\n",
      "Epoch 1295/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0488 - acc: 0.9917\n",
      "Epoch 1296/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0453 - acc: 0.9917\n",
      "Epoch 1297/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0466 - acc: 0.9917\n",
      "Epoch 1298/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0475 - acc: 0.9917\n",
      "Epoch 1299/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0458 - acc: 0.9917\n",
      "Epoch 1300/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0458 - acc: 0.9917\n",
      "Epoch 1301/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0457 - acc: 0.9917\n",
      "Epoch 1302/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0458 - acc: 0.9917\n",
      "Epoch 1303/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0454 - acc: 0.9917\n",
      "Epoch 1304/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0463 - acc: 0.9917\n",
      "Epoch 1305/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0464 - acc: 0.9917\n",
      "Epoch 1306/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0469 - acc: 0.9917\n",
      "Epoch 1307/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0456 - acc: 0.9917\n",
      "Epoch 1308/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0447 - acc: 0.9917\n",
      "Epoch 1309/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0455 - acc: 0.9917\n",
      "Epoch 1310/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0462 - acc: 0.9917\n",
      "Epoch 1311/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0452 - acc: 0.9917\n",
      "Epoch 1312/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0451 - acc: 0.9917\n",
      "Epoch 1313/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0456 - acc: 0.9917\n",
      "Epoch 1314/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0487 - acc: 0.9917\n",
      "Epoch 1315/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0455 - acc: 0.9917\n",
      "Epoch 1316/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0460 - acc: 0.9917\n",
      "Epoch 1317/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0450 - acc: 0.9917\n",
      "Epoch 1318/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0452 - acc: 0.9917\n",
      "Epoch 1319/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0455 - acc: 0.9917\n",
      "Epoch 1320/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0448 - acc: 0.9917\n",
      "Epoch 1321/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0452 - acc: 0.9917\n",
      "Epoch 1322/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0456 - acc: 0.9917\n",
      "Epoch 1323/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0451 - acc: 0.9917\n",
      "Epoch 1324/8000\n",
      "120/120 [==============================] - 0s 83us/sample - loss: 0.0450 - acc: 0.9917\n",
      "Epoch 1325/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0450 - acc: 0.9917\n",
      "Epoch 1326/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0451 - acc: 0.9917\n",
      "Epoch 1327/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0447 - acc: 0.9917\n",
      "Epoch 1328/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0448 - acc: 0.9917\n",
      "Epoch 1329/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0457 - acc: 0.9917\n",
      "Epoch 1330/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0451 - acc: 0.9917\n",
      "Epoch 1331/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0450 - acc: 0.9917\n",
      "Epoch 1332/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0457 - acc: 0.9917\n",
      "Epoch 1333/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0467 - acc: 0.9917\n",
      "Epoch 1334/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0455 - acc: 0.9917\n",
      "Epoch 1335/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0453 - acc: 0.9917\n",
      "Epoch 1336/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0448 - acc: 0.9917\n",
      "Epoch 1337/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0450 - acc: 0.9917\n",
      "Epoch 1338/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0451 - acc: 0.9917\n",
      "Epoch 1339/8000\n",
      "120/120 [==============================] - 0s 59us/sample - loss: 0.0448 - acc: 0.9917\n",
      "Epoch 1340/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0273 - acc: 1.000 - 0s 84us/sample - loss: 0.0458 - acc: 0.9917\n",
      "Epoch 1341/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0458 - acc: 0.9917\n",
      "Epoch 1342/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0451 - acc: 0.9917\n",
      "Epoch 1343/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0455 - acc: 0.9917\n",
      "Epoch 1344/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0452 - acc: 0.9917\n",
      "Epoch 1345/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0448 - acc: 0.9917\n",
      "Epoch 1346/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0446 - acc: 0.9917\n",
      "Epoch 1347/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0448 - acc: 0.9917\n",
      "Epoch 1348/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0452 - acc: 0.9917\n",
      "Epoch 1349/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0448 - acc: 0.9917\n",
      "Epoch 1350/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0455 - acc: 0.9917\n",
      "Epoch 1351/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0465 - acc: 0.9917\n",
      "Epoch 1352/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0448 - acc: 0.9917\n",
      "Epoch 1353/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0449 - acc: 0.9917\n",
      "Epoch 1354/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0449 - acc: 0.9917\n",
      "Epoch 1355/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0456 - acc: 0.9917\n",
      "Epoch 1356/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0446 - acc: 0.9917\n",
      "Epoch 1357/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0455 - acc: 0.9917\n",
      "Epoch 1358/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0454 - acc: 0.9917\n",
      "Epoch 1359/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0448 - acc: 0.9917\n",
      "Epoch 1360/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0449 - acc: 0.9917\n",
      "Epoch 1361/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0454 - acc: 0.9917\n",
      "Epoch 1362/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0455 - acc: 0.9917\n",
      "Epoch 1363/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0452 - acc: 0.9917\n",
      "Epoch 1364/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0456 - acc: 0.9917\n",
      "Epoch 1365/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0458 - acc: 0.9833\n",
      "Epoch 1366/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0450 - acc: 0.9917\n",
      "Epoch 1367/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0447 - acc: 0.9917\n",
      "Epoch 1368/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0446 - acc: 0.9917\n",
      "Epoch 1369/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0447 - acc: 0.9917\n",
      "Epoch 1370/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0447 - acc: 0.9917\n",
      "Epoch 1371/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0444 - acc: 0.9917\n",
      "Epoch 1372/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0456 - acc: 0.9917\n",
      "Epoch 1373/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0469 - acc: 0.9917\n",
      "Epoch 1374/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0458 - acc: 0.9833\n",
      "Epoch 1375/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0456 - acc: 0.9917\n",
      "Epoch 1376/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0448 - acc: 0.9917\n",
      "Epoch 1377/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0445 - acc: 0.9917\n",
      "Epoch 1378/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0449 - acc: 0.9917\n",
      "Epoch 1379/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0457 - acc: 0.9917\n",
      "Epoch 1380/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0447 - acc: 0.9917\n",
      "Epoch 1381/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0447 - acc: 0.9917\n",
      "Epoch 1382/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0445 - acc: 0.9917\n",
      "Epoch 1383/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0455 - acc: 0.9917\n",
      "Epoch 1384/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0464 - acc: 0.9917\n",
      "Epoch 1385/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0443 - acc: 0.9917\n",
      "Epoch 1386/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0454 - acc: 0.9917\n",
      "Epoch 1387/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0444 - acc: 0.9917\n",
      "Epoch 1388/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0449 - acc: 0.9917\n",
      "Epoch 1389/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0449 - acc: 0.9917\n",
      "Epoch 1390/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0449 - acc: 0.9917\n",
      "Epoch 1391/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0452 - acc: 0.9917\n",
      "Epoch 1392/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0459 - acc: 0.9917\n",
      "Epoch 1393/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0436 - acc: 0.9917\n",
      "Epoch 1394/8000\n",
      "120/120 [==============================] - 0s 59us/sample - loss: 0.0439 - acc: 0.9917\n",
      "Epoch 1395/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0449 - acc: 0.9833\n",
      "Epoch 1396/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0455 - acc: 0.9833\n",
      "Epoch 1397/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0459 - acc: 0.9833\n",
      "Epoch 1398/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0446 - acc: 0.9917\n",
      "Epoch 1399/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0453 - acc: 0.9917\n",
      "Epoch 1400/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0443 - acc: 0.9917\n",
      "Epoch 1401/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0446 - acc: 0.9917\n",
      "Epoch 1402/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0460 - acc: 0.9917\n",
      "Epoch 1403/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0445 - acc: 0.9917\n",
      "Epoch 1404/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0446 - acc: 0.9917\n",
      "Epoch 1405/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0500 - acc: 0.9833\n",
      "Epoch 1406/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0453 - acc: 0.9833\n",
      "Epoch 1407/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0441 - acc: 0.9917\n",
      "Epoch 1408/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0452 - acc: 0.9917\n",
      "Epoch 1409/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0464 - acc: 0.9917\n",
      "Epoch 1410/8000\n",
      "120/120 [==============================] - 0s 83us/sample - loss: 0.0447 - acc: 0.9917\n",
      "Epoch 1411/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0449 - acc: 0.9917\n",
      "Epoch 1412/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0453 - acc: 0.9917\n",
      "Epoch 1413/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0465 - acc: 0.9917\n",
      "Epoch 1414/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0448 - acc: 0.9917\n",
      "Epoch 1415/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0448 - acc: 0.9917\n",
      "Epoch 1416/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0442 - acc: 0.9917\n",
      "Epoch 1417/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0444 - acc: 0.9917\n",
      "Epoch 1418/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0441 - acc: 0.9917\n",
      "Epoch 1419/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0444 - acc: 0.9917\n",
      "Epoch 1420/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0443 - acc: 0.9917\n",
      "Epoch 1421/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0445 - acc: 0.9917\n",
      "Epoch 1422/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0445 - acc: 0.9917\n",
      "Epoch 1423/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0445 - acc: 0.9917\n",
      "Epoch 1424/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0449 - acc: 0.9917\n",
      "Epoch 1425/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0451 - acc: 0.9917\n",
      "Epoch 1426/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0449 - acc: 0.9917\n",
      "Epoch 1427/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0444 - acc: 0.9917\n",
      "Epoch 1428/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0453 - acc: 0.9917\n",
      "Epoch 1429/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0448 - acc: 0.9917\n",
      "Epoch 1430/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0444 - acc: 0.9917\n",
      "Epoch 1431/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0447 - acc: 0.9917\n",
      "Epoch 1432/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0444 - acc: 0.9917\n",
      "Epoch 1433/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0441 - acc: 0.9917\n",
      "Epoch 1434/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0444 - acc: 0.9917\n",
      "Epoch 1435/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0442 - acc: 0.9917\n",
      "Epoch 1436/8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 83us/sample - loss: 0.0449 - acc: 0.9917\n",
      "Epoch 1437/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0442 - acc: 0.9917\n",
      "Epoch 1438/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0442 - acc: 0.9917\n",
      "Epoch 1439/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0452 - acc: 0.9917\n",
      "Epoch 1440/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0440 - acc: 0.9917\n",
      "Epoch 1441/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0441 - acc: 0.9917\n",
      "Epoch 1442/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0444 - acc: 0.9917\n",
      "Epoch 1443/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0443 - acc: 0.9917\n",
      "Epoch 1444/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0455 - acc: 0.9917\n",
      "Epoch 1445/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0444 - acc: 0.9917\n",
      "Epoch 1446/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0438 - acc: 0.9917\n",
      "Epoch 1447/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0449 - acc: 0.9917\n",
      "Epoch 1448/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0465 - acc: 0.9917\n",
      "Epoch 1449/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0439 - acc: 0.9917\n",
      "Epoch 1450/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0439 - acc: 0.9917\n",
      "Epoch 1451/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0459 - acc: 0.9917\n",
      "Epoch 1452/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0436 - acc: 0.9917\n",
      "Epoch 1453/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0438 - acc: 0.9917\n",
      "Epoch 1454/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0449 - acc: 0.9917\n",
      "Epoch 1455/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0446 - acc: 0.9917\n",
      "Epoch 1456/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0452 - acc: 0.9917\n",
      "Epoch 1457/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0442 - acc: 0.9917\n",
      "Epoch 1458/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0441 - acc: 0.9917\n",
      "Epoch 1459/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0445 - acc: 0.9917\n",
      "Epoch 1460/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0444 - acc: 0.9917\n",
      "Epoch 1461/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0453 - acc: 0.9917\n",
      "Epoch 1462/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0445 - acc: 0.9917\n",
      "Epoch 1463/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0449 - acc: 0.9917\n",
      "Epoch 1464/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0438 - acc: 0.9917\n",
      "Epoch 1465/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0453 - acc: 0.9917\n",
      "Epoch 1466/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0437 - acc: 0.9917\n",
      "Epoch 1467/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0452 - acc: 0.9917\n",
      "Epoch 1468/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0448 - acc: 0.9917\n",
      "Epoch 1469/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0439 - acc: 0.9917\n",
      "Epoch 1470/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0438 - acc: 0.9917\n",
      "Epoch 1471/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0454 - acc: 0.9917\n",
      "Epoch 1472/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0457 - acc: 0.9917\n",
      "Epoch 1473/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0453 - acc: 0.9917\n",
      "Epoch 1474/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0440 - acc: 0.9917\n",
      "Epoch 1475/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.1164 - acc: 0.968 - 0s 75us/sample - loss: 0.0456 - acc: 0.9917\n",
      "Epoch 1476/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0443 - acc: 0.9917\n",
      "Epoch 1477/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0437 - acc: 0.9917\n",
      "Epoch 1478/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0441 - acc: 0.9917\n",
      "Epoch 1479/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0441 - acc: 0.9917\n",
      "Epoch 1480/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0439 - acc: 0.9917\n",
      "Epoch 1481/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0440 - acc: 0.9917\n",
      "Epoch 1482/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0441 - acc: 0.9917\n",
      "Epoch 1483/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0444 - acc: 0.9917\n",
      "Epoch 1484/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0445 - acc: 0.9917\n",
      "Epoch 1485/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0442 - acc: 0.9917\n",
      "Epoch 1486/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0436 - acc: 0.9917\n",
      "Epoch 1487/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0461 - acc: 0.9917\n",
      "Epoch 1488/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0444 - acc: 0.9917\n",
      "Epoch 1489/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0469 - acc: 0.9833\n",
      "Epoch 1490/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0455 - acc: 0.9833\n",
      "Epoch 1491/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0437 - acc: 0.9917\n",
      "Epoch 1492/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0436 - acc: 0.9917\n",
      "Epoch 1493/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0442 - acc: 0.9917\n",
      "Epoch 1494/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0438 - acc: 0.9917\n",
      "Epoch 1495/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0437 - acc: 0.9917\n",
      "Epoch 1496/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0439 - acc: 0.9917\n",
      "Epoch 1497/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0477 - acc: 0.9833\n",
      "Epoch 1498/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0436 - acc: 0.9917\n",
      "Epoch 1499/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0436 - acc: 0.9917\n",
      "Epoch 1500/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0437 - acc: 0.9917\n",
      "Epoch 1501/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0446 - acc: 0.9917\n",
      "Epoch 1502/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0446 - acc: 0.9917\n",
      "Epoch 1503/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0435 - acc: 0.9917\n",
      "Epoch 1504/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0441 - acc: 0.9917\n",
      "Epoch 1505/8000\n",
      "120/120 [==============================] - 0s 59us/sample - loss: 0.0444 - acc: 0.9917\n",
      "Epoch 1506/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0435 - acc: 0.9917\n",
      "Epoch 1507/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0444 - acc: 0.9917\n",
      "Epoch 1508/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0444 - acc: 0.9917\n",
      "Epoch 1509/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0463 - acc: 0.9833\n",
      "Epoch 1510/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0449 - acc: 0.9833\n",
      "Epoch 1511/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0437 - acc: 0.9917\n",
      "Epoch 1512/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0484 - acc: 0.9917\n",
      "Epoch 1513/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0379 - acc: 1.000 - 0s 67us/sample - loss: 0.0460 - acc: 0.9917\n",
      "Epoch 1514/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0444 - acc: 0.9917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1515/8000\n",
      "120/120 [==============================] - 0s 59us/sample - loss: 0.0446 - acc: 0.9917\n",
      "Epoch 1516/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0433 - acc: 0.9917\n",
      "Epoch 1517/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0441 - acc: 0.9917\n",
      "Epoch 1518/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0440 - acc: 0.9917\n",
      "Epoch 1519/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0440 - acc: 0.9917\n",
      "Epoch 1520/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0435 - acc: 0.9917\n",
      "Epoch 1521/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0436 - acc: 0.9917\n",
      "Epoch 1522/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0445 - acc: 0.9917\n",
      "Epoch 1523/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0434 - acc: 0.9917\n",
      "Epoch 1524/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0452 - acc: 0.9917\n",
      "Epoch 1525/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0436 - acc: 0.9917\n",
      "Epoch 1526/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0443 - acc: 0.9917\n",
      "Epoch 1527/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0468 - acc: 0.9917\n",
      "Epoch 1528/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0449 - acc: 0.9917\n",
      "Epoch 1529/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0443 - acc: 0.9917\n",
      "Epoch 1530/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0438 - acc: 0.9917\n",
      "Epoch 1531/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0444 - acc: 0.9833\n",
      "Epoch 1532/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0436 - acc: 0.9917\n",
      "Epoch 1533/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0462 - acc: 0.9917\n",
      "Epoch 1534/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0441 - acc: 0.9917\n",
      "Epoch 1535/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0431 - acc: 0.9917\n",
      "Epoch 1536/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0431 - acc: 0.9917\n",
      "Epoch 1537/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0434 - acc: 0.9917\n",
      "Epoch 1538/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0434 - acc: 0.9917\n",
      "Epoch 1539/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0438 - acc: 0.9917\n",
      "Epoch 1540/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0432 - acc: 0.9917\n",
      "Epoch 1541/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0440 - acc: 0.9917\n",
      "Epoch 1542/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0438 - acc: 0.9917\n",
      "Epoch 1543/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0429 - acc: 0.9917\n",
      "Epoch 1544/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0436 - acc: 0.9917\n",
      "Epoch 1545/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0440 - acc: 0.9917\n",
      "Epoch 1546/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0434 - acc: 0.9917\n",
      "Epoch 1547/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0451 - acc: 0.9917\n",
      "Epoch 1548/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0449 - acc: 0.9917\n",
      "Epoch 1549/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0440 - acc: 0.9917\n",
      "Epoch 1550/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0434 - acc: 0.9917\n",
      "Epoch 1551/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0433 - acc: 0.9917\n",
      "Epoch 1552/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0435 - acc: 0.9917\n",
      "Epoch 1553/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0441 - acc: 0.9917\n",
      "Epoch 1554/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0429 - acc: 0.9917\n",
      "Epoch 1555/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0433 - acc: 0.9917\n",
      "Epoch 1556/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0443 - acc: 0.9917\n",
      "Epoch 1557/8000\n",
      "120/120 [==============================] - 0s 50us/sample - loss: 0.0488 - acc: 0.9917\n",
      "Epoch 1558/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0438 - acc: 0.9917\n",
      "Epoch 1559/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0437 - acc: 0.9917\n",
      "Epoch 1560/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0433 - acc: 0.9917\n",
      "Epoch 1561/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0431 - acc: 0.9917\n",
      "Epoch 1562/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0432 - acc: 0.9917\n",
      "Epoch 1563/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0439 - acc: 0.9917\n",
      "Epoch 1564/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0433 - acc: 0.9917\n",
      "Epoch 1565/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0433 - acc: 0.9917\n",
      "Epoch 1566/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0436 - acc: 0.9917\n",
      "Epoch 1567/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0435 - acc: 0.9917\n",
      "Epoch 1568/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0444 - acc: 0.9917\n",
      "Epoch 1569/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0433 - acc: 0.9917\n",
      "Epoch 1570/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0441 - acc: 0.9917\n",
      "Epoch 1571/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0448 - acc: 0.9917\n",
      "Epoch 1572/8000\n",
      "120/120 [==============================] - 0s 59us/sample - loss: 0.0447 - acc: 0.9917\n",
      "Epoch 1573/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0436 - acc: 0.9917\n",
      "Epoch 1574/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0433 - acc: 0.9917\n",
      "Epoch 1575/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0447 - acc: 0.9833\n",
      "Epoch 1576/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0442 - acc: 0.9833\n",
      "Epoch 1577/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0433 - acc: 0.9917\n",
      "Epoch 1578/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0436 - acc: 0.9917\n",
      "Epoch 1579/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0441 - acc: 0.9917\n",
      "Epoch 1580/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0434 - acc: 0.9917\n",
      "Epoch 1581/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0450 - acc: 0.9917\n",
      "Epoch 1582/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0440 - acc: 0.9917\n",
      "Epoch 1583/8000\n",
      "120/120 [==============================] - 0s 59us/sample - loss: 0.0431 - acc: 0.9917\n",
      "Epoch 1584/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0437 - acc: 0.9917\n",
      "Epoch 1585/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0439 - acc: 0.9917\n",
      "Epoch 1586/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0439 - acc: 0.9917\n",
      "Epoch 1587/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0436 - acc: 0.9917\n",
      "Epoch 1588/8000\n",
      "120/120 [==============================] - 0s 83us/sample - loss: 0.0429 - acc: 0.9917\n",
      "Epoch 1589/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0432 - acc: 0.9917\n",
      "Epoch 1590/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0433 - acc: 0.9917\n",
      "Epoch 1591/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0433 - acc: 0.9917\n",
      "Epoch 1592/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0434 - acc: 0.9917\n",
      "Epoch 1593/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0427 - acc: 0.9917\n",
      "Epoch 1594/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0441 - acc: 0.9917\n",
      "Epoch 1595/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0442 - acc: 0.9917\n",
      "Epoch 1596/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0442 - acc: 0.9917\n",
      "Epoch 1597/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0428 - acc: 0.9917\n",
      "Epoch 1598/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0429 - acc: 0.9917\n",
      "Epoch 1599/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0434 - acc: 0.9917\n",
      "Epoch 1600/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0438 - acc: 0.9917\n",
      "Epoch 1601/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0431 - acc: 0.9917\n",
      "Epoch 1602/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0433 - acc: 0.9917\n",
      "Epoch 1603/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0429 - acc: 0.9917\n",
      "Epoch 1604/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0432 - acc: 0.9917\n",
      "Epoch 1605/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0435 - acc: 0.9917\n",
      "Epoch 1606/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0429 - acc: 0.9917\n",
      "Epoch 1607/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0435 - acc: 0.9917\n",
      "Epoch 1608/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0441 - acc: 0.9917\n",
      "Epoch 1609/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0433 - acc: 0.9917\n",
      "Epoch 1610/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0431 - acc: 0.9917\n",
      "Epoch 1611/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0426 - acc: 0.9917\n",
      "Epoch 1612/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0436 - acc: 0.9917\n",
      "Epoch 1613/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0467 - acc: 0.9833\n",
      "Epoch 1614/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0433 - acc: 0.9917\n",
      "Epoch 1615/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0425 - acc: 0.9917\n",
      "Epoch 1616/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0434 - acc: 0.9917\n",
      "Epoch 1617/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0443 - acc: 0.9917\n",
      "Epoch 1618/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0448 - acc: 0.9917\n",
      "Epoch 1619/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0444 - acc: 0.9917\n",
      "Epoch 1620/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0434 - acc: 0.9917\n",
      "Epoch 1621/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0429 - acc: 0.9917\n",
      "Epoch 1622/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0429 - acc: 0.9917\n",
      "Epoch 1623/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0428 - acc: 0.9917\n",
      "Epoch 1624/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0427 - acc: 0.9917\n",
      "Epoch 1625/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0427 - acc: 0.9917\n",
      "Epoch 1626/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0439 - acc: 0.9917\n",
      "Epoch 1627/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0428 - acc: 0.9917\n",
      "Epoch 1628/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0431 - acc: 0.9917\n",
      "Epoch 1629/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0427 - acc: 0.9917\n",
      "Epoch 1630/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0448 - acc: 0.9917\n",
      "Epoch 1631/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0431 - acc: 0.9917\n",
      "Epoch 1632/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0439 - acc: 0.9917\n",
      "Epoch 1633/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0436 - acc: 0.9917\n",
      "Epoch 1634/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0437 - acc: 0.9917\n",
      "Epoch 1635/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0427 - acc: 0.9917\n",
      "Epoch 1636/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0425 - acc: 0.9917\n",
      "Epoch 1637/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0439 - acc: 0.9917\n",
      "Epoch 1638/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0432 - acc: 0.9917\n",
      "Epoch 1639/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0428 - acc: 0.9917\n",
      "Epoch 1640/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0430 - acc: 0.9917\n",
      "Epoch 1641/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0439 - acc: 0.9917\n",
      "Epoch 1642/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0426 - acc: 0.9917\n",
      "Epoch 1643/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0435 - acc: 0.9917\n",
      "Epoch 1644/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0433 - acc: 0.9917\n",
      "Epoch 1645/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0439 - acc: 0.9917\n",
      "Epoch 1646/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0453 - acc: 0.9917\n",
      "Epoch 1647/8000\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.0432 - acc: 0.9917\n",
      "Epoch 1648/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0441 - acc: 0.9917\n",
      "Epoch 1649/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0442 - acc: 0.9917\n",
      "Epoch 1650/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0441 - acc: 0.9917\n",
      "Epoch 1651/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0437 - acc: 0.9917\n",
      "Epoch 1652/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0426 - acc: 0.9917\n",
      "Epoch 1653/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0427 - acc: 0.9917\n",
      "Epoch 1654/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0428 - acc: 0.9917\n",
      "Epoch 1655/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0429 - acc: 0.9917\n",
      "Epoch 1656/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0429 - acc: 0.9917\n",
      "Epoch 1657/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0423 - acc: 0.9917\n",
      "Epoch 1658/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0427 - acc: 0.9917\n",
      "Epoch 1659/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0427 - acc: 0.9917\n",
      "Epoch 1660/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0429 - acc: 0.9917\n",
      "Epoch 1661/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0431 - acc: 0.9917\n",
      "Epoch 1662/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0429 - acc: 0.9917\n",
      "Epoch 1663/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0427 - acc: 0.9917\n",
      "Epoch 1664/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0426 - acc: 0.9917\n",
      "Epoch 1665/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0427 - acc: 0.9917\n",
      "Epoch 1666/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0447 - acc: 0.9917\n",
      "Epoch 1667/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0441 - acc: 0.9917\n",
      "Epoch 1668/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0438 - acc: 0.9917\n",
      "Epoch 1669/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0431 - acc: 0.9917\n",
      "Epoch 1670/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0422 - acc: 0.9917\n",
      "Epoch 1671/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0451 - acc: 0.9917\n",
      "Epoch 1672/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0447 - acc: 0.9917\n",
      "Epoch 1673/8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0432 - acc: 0.9917\n",
      "Epoch 1674/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0423 - acc: 0.9917\n",
      "Epoch 1675/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0444 - acc: 0.9917\n",
      "Epoch 1676/8000\n",
      "120/120 [==============================] - 0s 83us/sample - loss: 0.0424 - acc: 0.9917\n",
      "Epoch 1677/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0420 - acc: 0.9917\n",
      "Epoch 1678/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0423 - acc: 0.9917\n",
      "Epoch 1679/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0428 - acc: 0.9917\n",
      "Epoch 1680/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0426 - acc: 0.9917\n",
      "Epoch 1681/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0430 - acc: 0.9917\n",
      "Epoch 1682/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0435 - acc: 0.9917\n",
      "Epoch 1683/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0442 - acc: 0.9917\n",
      "Epoch 1684/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0432 - acc: 0.9917\n",
      "Epoch 1685/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0429 - acc: 0.9917\n",
      "Epoch 1686/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0435 - acc: 0.9917\n",
      "Epoch 1687/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0423 - acc: 0.9917\n",
      "Epoch 1688/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0429 - acc: 0.9917\n",
      "Epoch 1689/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0431 - acc: 0.9917\n",
      "Epoch 1690/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0424 - acc: 0.9917\n",
      "Epoch 1691/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0428 - acc: 0.9917\n",
      "Epoch 1692/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0425 - acc: 0.9917\n",
      "Epoch 1693/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0428 - acc: 0.9917\n",
      "Epoch 1694/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0423 - acc: 0.9917\n",
      "Epoch 1695/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0462 - acc: 0.9917\n",
      "Epoch 1696/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0452 - acc: 0.9917\n",
      "Epoch 1697/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0430 - acc: 0.9917\n",
      "Epoch 1698/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0428 - acc: 0.9917\n",
      "Epoch 1699/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0428 - acc: 0.9917\n",
      "Epoch 1700/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0422 - acc: 0.9917\n",
      "Epoch 1701/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0424 - acc: 0.9917\n",
      "Epoch 1702/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0423 - acc: 0.9917\n",
      "Epoch 1703/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0422 - acc: 0.9917\n",
      "Epoch 1704/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0429 - acc: 0.9917\n",
      "Epoch 1705/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0426 - acc: 0.9917\n",
      "Epoch 1706/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0426 - acc: 0.9917\n",
      "Epoch 1707/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0436 - acc: 0.9917\n",
      "Epoch 1708/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0430 - acc: 0.9917\n",
      "Epoch 1709/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0425 - acc: 0.9917\n",
      "Epoch 1710/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0433 - acc: 0.9917\n",
      "Epoch 1711/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0438 - acc: 0.9917\n",
      "Epoch 1712/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0426 - acc: 0.9917\n",
      "Epoch 1713/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0420 - acc: 0.9917\n",
      "Epoch 1714/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0428 - acc: 0.9917\n",
      "Epoch 1715/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0425 - acc: 0.9917\n",
      "Epoch 1716/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0420 - acc: 0.9917\n",
      "Epoch 1717/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0425 - acc: 0.9917\n",
      "Epoch 1718/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0428 - acc: 0.9917\n",
      "Epoch 1719/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0422 - acc: 0.9917\n",
      "Epoch 1720/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0426 - acc: 0.9917\n",
      "Epoch 1721/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0438 - acc: 0.9917\n",
      "Epoch 1722/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0426 - acc: 0.9917\n",
      "Epoch 1723/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0424 - acc: 0.9917\n",
      "Epoch 1724/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0430 - acc: 0.9917\n",
      "Epoch 1725/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0440 - acc: 0.9917\n",
      "Epoch 1726/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0426 - acc: 0.9917\n",
      "Epoch 1727/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0423 - acc: 0.9917\n",
      "Epoch 1728/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0430 - acc: 0.9917\n",
      "Epoch 1729/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0430 - acc: 0.9917\n",
      "Epoch 1730/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0426 - acc: 0.9917\n",
      "Epoch 1731/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0425 - acc: 0.9917\n",
      "Epoch 1732/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0423 - acc: 0.9917\n",
      "Epoch 1733/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0432 - acc: 0.9917\n",
      "Epoch 1734/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0439 - acc: 0.9917\n",
      "Epoch 1735/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.1066 - acc: 0.968 - 0s 75us/sample - loss: 0.0419 - acc: 0.9917\n",
      "Epoch 1736/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0425 - acc: 0.9917\n",
      "Epoch 1737/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0425 - acc: 0.9917\n",
      "Epoch 1738/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0419 - acc: 0.9917\n",
      "Epoch 1739/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0346 - acc: 1.000 - 0s 75us/sample - loss: 0.0424 - acc: 0.9917\n",
      "Epoch 1740/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0440 - acc: 0.9917\n",
      "Epoch 1741/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0425 - acc: 0.9917\n",
      "Epoch 1742/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0422 - acc: 0.9917\n",
      "Epoch 1743/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0431 - acc: 0.9917\n",
      "Epoch 1744/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0424 - acc: 0.9917\n",
      "Epoch 1745/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0425 - acc: 0.9917\n",
      "Epoch 1746/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0422 - acc: 0.9917\n",
      "Epoch 1747/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0420 - acc: 0.9917\n",
      "Epoch 1748/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0419 - acc: 0.9917\n",
      "Epoch 1749/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0424 - acc: 0.9917\n",
      "Epoch 1750/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0422 - acc: 0.9917\n",
      "Epoch 1751/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0423 - acc: 0.9917\n",
      "Epoch 1752/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0442 - acc: 0.9917\n",
      "Epoch 1753/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0426 - acc: 0.9917\n",
      "Epoch 1754/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0447 - acc: 0.9917\n",
      "Epoch 1755/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0428 - acc: 0.9917\n",
      "Epoch 1756/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0422 - acc: 0.9917\n",
      "Epoch 1757/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0426 - acc: 0.9917\n",
      "Epoch 1758/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0420 - acc: 0.9917\n",
      "Epoch 1759/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0427 - acc: 0.9917\n",
      "Epoch 1760/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0421 - acc: 0.9917\n",
      "Epoch 1761/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0425 - acc: 0.9917\n",
      "Epoch 1762/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0420 - acc: 0.9917\n",
      "Epoch 1763/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0428 - acc: 0.9917\n",
      "Epoch 1764/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0430 - acc: 0.9917\n",
      "Epoch 1765/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0428 - acc: 0.9917\n",
      "Epoch 1766/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0445 - acc: 0.9917\n",
      "Epoch 1767/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0421 - acc: 0.9917\n",
      "Epoch 1768/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0414 - acc: 0.9917\n",
      "Epoch 1769/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0419 - acc: 0.9917\n",
      "Epoch 1770/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0813 - acc: 0.968 - 0s 75us/sample - loss: 0.0433 - acc: 0.9917\n",
      "Epoch 1771/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0428 - acc: 0.9917\n",
      "Epoch 1772/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0419 - acc: 1.000 - 0s 67us/sample - loss: 0.0421 - acc: 0.9917\n",
      "Epoch 1773/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0417 - acc: 0.9917\n",
      "Epoch 1774/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0423 - acc: 0.9917\n",
      "Epoch 1775/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0436 - acc: 0.9917\n",
      "Epoch 1776/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0425 - acc: 0.9917\n",
      "Epoch 1777/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0432 - acc: 0.9917\n",
      "Epoch 1778/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0428 - acc: 0.9917\n",
      "Epoch 1779/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0422 - acc: 0.9917\n",
      "Epoch 1780/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0457 - acc: 0.9917\n",
      "Epoch 1781/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0423 - acc: 0.9917\n",
      "Epoch 1782/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0413 - acc: 0.9917\n",
      "Epoch 1783/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0445 - acc: 0.9833\n",
      "Epoch 1784/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0438 - acc: 0.9833\n",
      "Epoch 1785/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0413 - acc: 0.9917\n",
      "Epoch 1786/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0449 - acc: 0.9917\n",
      "Epoch 1787/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0452 - acc: 0.9750\n",
      "Epoch 1788/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0423 - acc: 0.9917\n",
      "Epoch 1789/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0410 - acc: 0.9917\n",
      "Epoch 1790/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0424 - acc: 0.9833\n",
      "Epoch 1791/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0438 - acc: 0.9833\n",
      "Epoch 1792/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0429 - acc: 0.9917\n",
      "Epoch 1793/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0417 - acc: 0.9917\n",
      "Epoch 1794/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0421 - acc: 0.9917\n",
      "Epoch 1795/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0418 - acc: 0.9917\n",
      "Epoch 1796/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0425 - acc: 0.9917\n",
      "Epoch 1797/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0424 - acc: 0.9917\n",
      "Epoch 1798/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0421 - acc: 0.9917\n",
      "Epoch 1799/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0424 - acc: 0.9917\n",
      "Epoch 1800/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0422 - acc: 0.9917\n",
      "Epoch 1801/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0433 - acc: 0.9917\n",
      "Epoch 1802/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0428 - acc: 0.9917\n",
      "Epoch 1803/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0421 - acc: 0.9917\n",
      "Epoch 1804/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0419 - acc: 0.9917\n",
      "Epoch 1805/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0422 - acc: 0.9917\n",
      "Epoch 1806/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0421 - acc: 0.9917\n",
      "Epoch 1807/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0415 - acc: 0.9917\n",
      "Epoch 1808/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0429 - acc: 0.9917\n",
      "Epoch 1809/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0434 - acc: 0.9917\n",
      "Epoch 1810/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0437 - acc: 0.9917\n",
      "Epoch 1811/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0422 - acc: 0.9917\n",
      "Epoch 1812/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0414 - acc: 0.9917\n",
      "Epoch 1813/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0429 - acc: 0.9917\n",
      "Epoch 1814/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0449 - acc: 0.9917\n",
      "Epoch 1815/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0420 - acc: 0.9917\n",
      "Epoch 1816/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0425 - acc: 0.9917\n",
      "Epoch 1817/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0420 - acc: 0.9917\n",
      "Epoch 1818/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0417 - acc: 0.9917\n",
      "Epoch 1819/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0418 - acc: 0.9917\n",
      "Epoch 1820/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0414 - acc: 0.9917\n",
      "Epoch 1821/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0413 - acc: 0.9917\n",
      "Epoch 1822/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0417 - acc: 0.9917\n",
      "Epoch 1823/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0418 - acc: 0.9917\n",
      "Epoch 1824/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0428 - acc: 0.9917\n",
      "Epoch 1825/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0420 - acc: 0.9917\n",
      "Epoch 1826/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0423 - acc: 0.9917\n",
      "Epoch 1827/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0419 - acc: 0.9917\n",
      "Epoch 1828/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0418 - acc: 0.9917\n",
      "Epoch 1829/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0425 - acc: 0.9917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1830/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0424 - acc: 0.9917\n",
      "Epoch 1831/8000\n",
      "120/120 [==============================] - 0s 83us/sample - loss: 0.0421 - acc: 0.9917\n",
      "Epoch 1832/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0420 - acc: 0.9917\n",
      "Epoch 1833/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0446 - acc: 0.9917\n",
      "Epoch 1834/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0424 - acc: 0.9917\n",
      "Epoch 1835/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0412 - acc: 0.9917\n",
      "Epoch 1836/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0427 - acc: 0.9917\n",
      "Epoch 1837/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0417 - acc: 0.9917\n",
      "Epoch 1838/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0433 - acc: 0.9917\n",
      "Epoch 1839/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0422 - acc: 0.9917\n",
      "Epoch 1840/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0418 - acc: 0.9917\n",
      "Epoch 1841/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0414 - acc: 0.9917\n",
      "Epoch 1842/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0421 - acc: 0.9917\n",
      "Epoch 1843/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0416 - acc: 0.9917\n",
      "Epoch 1844/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0425 - acc: 0.9917\n",
      "Epoch 1845/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0414 - acc: 0.9917\n",
      "Epoch 1846/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0417 - acc: 0.9917\n",
      "Epoch 1847/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0417 - acc: 0.9917\n",
      "Epoch 1848/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0416 - acc: 0.9917\n",
      "Epoch 1849/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0427 - acc: 0.9917\n",
      "Epoch 1850/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0413 - acc: 0.9917\n",
      "Epoch 1851/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0441 - acc: 0.9917\n",
      "Epoch 1852/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0424 - acc: 0.9917\n",
      "Epoch 1853/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0419 - acc: 0.9917\n",
      "Epoch 1854/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0418 - acc: 0.9917\n",
      "Epoch 1855/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0422 - acc: 0.9917\n",
      "Epoch 1856/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0416 - acc: 0.9917\n",
      "Epoch 1857/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0412 - acc: 0.9917\n",
      "Epoch 1858/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0411 - acc: 0.9917\n",
      "Epoch 1859/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0417 - acc: 0.9917\n",
      "Epoch 1860/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0422 - acc: 0.9917\n",
      "Epoch 1861/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0463 - acc: 0.9917\n",
      "Epoch 1862/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0426 - acc: 0.9917\n",
      "Epoch 1863/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0414 - acc: 0.9917\n",
      "Epoch 1864/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0419 - acc: 0.9917\n",
      "Epoch 1865/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0414 - acc: 0.9917\n",
      "Epoch 1866/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0417 - acc: 0.9917\n",
      "Epoch 1867/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0423 - acc: 0.9917\n",
      "Epoch 1868/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0413 - acc: 0.9917\n",
      "Epoch 1869/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0418 - acc: 0.9917\n",
      "Epoch 1870/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0426 - acc: 0.9917\n",
      "Epoch 1871/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0417 - acc: 0.9917\n",
      "Epoch 1872/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0414 - acc: 0.9917\n",
      "Epoch 1873/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0414 - acc: 0.9917\n",
      "Epoch 1874/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0416 - acc: 0.9917\n",
      "Epoch 1875/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0429 - acc: 0.9917\n",
      "Epoch 1876/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0415 - acc: 0.9917\n",
      "Epoch 1877/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0418 - acc: 0.9917\n",
      "Epoch 1878/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0413 - acc: 0.9917\n",
      "Epoch 1879/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0418 - acc: 0.9917\n",
      "Epoch 1880/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0416 - acc: 0.9917\n",
      "Epoch 1881/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0417 - acc: 0.9917\n",
      "Epoch 1882/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0418 - acc: 0.9917\n",
      "Epoch 1883/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0431 - acc: 0.9917\n",
      "Epoch 1884/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0420 - acc: 0.9917\n",
      "Epoch 1885/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0412 - acc: 0.9917\n",
      "Epoch 1886/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0410 - acc: 0.9917\n",
      "Epoch 1887/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0422 - acc: 0.9917\n",
      "Epoch 1888/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0415 - acc: 0.9917\n",
      "Epoch 1889/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0428 - acc: 0.9917\n",
      "Epoch 1890/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0431 - acc: 0.9917\n",
      "Epoch 1891/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0412 - acc: 0.9917\n",
      "Epoch 1892/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0412 - acc: 0.9917\n",
      "Epoch 1893/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0418 - acc: 0.9917\n",
      "Epoch 1894/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0435 - acc: 0.9917\n",
      "Epoch 1895/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0420 - acc: 0.9917\n",
      "Epoch 1896/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0412 - acc: 0.9917\n",
      "Epoch 1897/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0411 - acc: 0.9917\n",
      "Epoch 1898/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0419 - acc: 0.9917\n",
      "Epoch 1899/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0412 - acc: 0.9917\n",
      "Epoch 1900/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0308 - acc: 1.000 - 0s 67us/sample - loss: 0.0420 - acc: 0.9917\n",
      "Epoch 1901/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0412 - acc: 0.9917\n",
      "Epoch 1902/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0409 - acc: 0.9917\n",
      "Epoch 1903/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0429 - acc: 0.9917\n",
      "Epoch 1904/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0415 - acc: 0.9917\n",
      "Epoch 1905/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0422 - acc: 0.9833\n",
      "Epoch 1906/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0423 - acc: 0.9917\n",
      "Epoch 1907/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0412 - acc: 0.9917\n",
      "Epoch 1908/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0416 - acc: 0.9917\n",
      "Epoch 1909/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0421 - acc: 0.9917\n",
      "Epoch 1910/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0415 - acc: 0.9917\n",
      "Epoch 1911/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0431 - acc: 0.9917\n",
      "Epoch 1912/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0418 - acc: 0.9917\n",
      "Epoch 1913/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0426 - acc: 0.9917\n",
      "Epoch 1914/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0414 - acc: 0.9917\n",
      "Epoch 1915/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0412 - acc: 0.9917\n",
      "Epoch 1916/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0408 - acc: 0.9917\n",
      "Epoch 1917/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0415 - acc: 0.9917\n",
      "Epoch 1918/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0410 - acc: 0.9917\n",
      "Epoch 1919/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0426 - acc: 0.9917\n",
      "Epoch 1920/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0413 - acc: 0.9917\n",
      "Epoch 1921/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0408 - acc: 0.9917\n",
      "Epoch 1922/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0408 - acc: 0.9917\n",
      "Epoch 1923/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0412 - acc: 0.9917\n",
      "Epoch 1924/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0416 - acc: 0.9917\n",
      "Epoch 1925/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0411 - acc: 0.9917\n",
      "Epoch 1926/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0407 - acc: 0.9917\n",
      "Epoch 1927/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0436 - acc: 0.9917\n",
      "Epoch 1928/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0416 - acc: 0.9917\n",
      "Epoch 1929/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0423 - acc: 0.9917\n",
      "Epoch 1930/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0425 - acc: 0.9917\n",
      "Epoch 1931/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0412 - acc: 0.9917\n",
      "Epoch 1932/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0413 - acc: 0.9917\n",
      "Epoch 1933/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0411 - acc: 0.9917\n",
      "Epoch 1934/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0410 - acc: 0.9917\n",
      "Epoch 1935/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0419 - acc: 0.9917\n",
      "Epoch 1936/8000\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.0414 - acc: 0.9917\n",
      "Epoch 1937/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0409 - acc: 0.9917\n",
      "Epoch 1938/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0423 - acc: 0.9917\n",
      "Epoch 1939/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0409 - acc: 0.9917\n",
      "Epoch 1940/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0405 - acc: 0.9917\n",
      "Epoch 1941/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0409 - acc: 0.9917\n",
      "Epoch 1942/8000\n",
      "120/120 [==============================] - 0s 101us/sample - loss: 0.0415 - acc: 0.9917\n",
      "Epoch 1943/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0425 - acc: 0.9917\n",
      "Epoch 1944/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0419 - acc: 0.9917\n",
      "Epoch 1945/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0409 - acc: 0.9917\n",
      "Epoch 1946/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0420 - acc: 0.9917\n",
      "Epoch 1947/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0412 - acc: 0.9917\n",
      "Epoch 1948/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0411 - acc: 0.9917\n",
      "Epoch 1949/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0415 - acc: 0.9917\n",
      "Epoch 1950/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0416 - acc: 0.9917\n",
      "Epoch 1951/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0415 - acc: 0.9917\n",
      "Epoch 1952/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0407 - acc: 0.9917\n",
      "Epoch 1953/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0407 - acc: 0.9917\n",
      "Epoch 1954/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0409 - acc: 0.9917\n",
      "Epoch 1955/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0415 - acc: 0.9917\n",
      "Epoch 1956/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0419 - acc: 0.9917\n",
      "Epoch 1957/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0421 - acc: 0.9917\n",
      "Epoch 1958/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0411 - acc: 0.9917\n",
      "Epoch 1959/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0408 - acc: 0.9917\n",
      "Epoch 1960/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0416 - acc: 0.9917\n",
      "Epoch 1961/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0411 - acc: 0.9917\n",
      "Epoch 1962/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0417 - acc: 0.9917\n",
      "Epoch 1963/8000\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.0417 - acc: 0.9917\n",
      "Epoch 1964/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0409 - acc: 0.9917\n",
      "Epoch 1965/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0408 - acc: 0.9917\n",
      "Epoch 1966/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0407 - acc: 0.9917\n",
      "Epoch 1967/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0422 - acc: 0.9917\n",
      "Epoch 1968/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0410 - acc: 0.9917\n",
      "Epoch 1969/8000\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.0407 - acc: 0.9917\n",
      "Epoch 1970/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0430 - acc: 0.9917\n",
      "Epoch 1971/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0424 - acc: 0.9917\n",
      "Epoch 1972/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0414 - acc: 0.9917\n",
      "Epoch 1973/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0417 - acc: 0.9917\n",
      "Epoch 1974/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0431 - acc: 0.9917\n",
      "Epoch 1975/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0416 - acc: 0.9917\n",
      "Epoch 1976/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0413 - acc: 0.9917\n",
      "Epoch 1977/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0416 - acc: 0.9917\n",
      "Epoch 1978/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0416 - acc: 0.9917\n",
      "Epoch 1979/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0410 - acc: 0.9917\n",
      "Epoch 1980/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0429 - acc: 0.9917\n",
      "Epoch 1981/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0413 - acc: 0.9917\n",
      "Epoch 1982/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0451 - acc: 0.9917\n",
      "Epoch 1983/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0411 - acc: 0.9917\n",
      "Epoch 1984/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0443 - acc: 0.9917\n",
      "Epoch 1985/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0414 - acc: 0.9917\n",
      "Epoch 1986/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0415 - acc: 0.9917\n",
      "Epoch 1987/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0411 - acc: 0.9917\n",
      "Epoch 1988/8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0408 - acc: 0.9917\n",
      "Epoch 1989/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0406 - acc: 0.9917\n",
      "Epoch 1990/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0413 - acc: 0.9917\n",
      "Epoch 1991/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0413 - acc: 0.9917\n",
      "Epoch 1992/8000\n",
      "120/120 [==============================] - 0s 150us/sample - loss: 0.0424 - acc: 0.9917\n",
      "Epoch 1993/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0418 - acc: 0.9917\n",
      "Epoch 1994/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0408 - acc: 0.9917\n",
      "Epoch 1995/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0409 - acc: 0.9917\n",
      "Epoch 1996/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0409 - acc: 0.9917\n",
      "Epoch 1997/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0407 - acc: 0.9917\n",
      "Epoch 1998/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0405 - acc: 0.9917\n",
      "Epoch 1999/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0424 - acc: 0.9917\n",
      "Epoch 2000/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0417 - acc: 0.9917\n",
      "Epoch 2001/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0408 - acc: 0.9917\n",
      "Epoch 2002/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0408 - acc: 0.9917\n",
      "Epoch 2003/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0416 - acc: 0.9917\n",
      "Epoch 2004/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0407 - acc: 0.9917\n",
      "Epoch 2005/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0414 - acc: 0.9917\n",
      "Epoch 2006/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0409 - acc: 0.9917\n",
      "Epoch 2007/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0411 - acc: 0.9917\n",
      "Epoch 2008/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0405 - acc: 0.9917\n",
      "Epoch 2009/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0403 - acc: 0.9917\n",
      "Epoch 2010/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0407 - acc: 0.9917\n",
      "Epoch 2011/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0413 - acc: 0.9917\n",
      "Epoch 2012/8000\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.0412 - acc: 0.9917\n",
      "Epoch 2013/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0408 - acc: 0.9917\n",
      "Epoch 2014/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0404 - acc: 0.9917\n",
      "Epoch 2015/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0410 - acc: 0.9917\n",
      "Epoch 2016/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0403 - acc: 0.9917\n",
      "Epoch 2017/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0403 - acc: 0.9917\n",
      "Epoch 2018/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0404 - acc: 0.9917\n",
      "Epoch 2019/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0428 - acc: 0.9917\n",
      "Epoch 2020/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0413 - acc: 0.9917\n",
      "Epoch 2021/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0423 - acc: 0.9917\n",
      "Epoch 2022/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0417 - acc: 0.9917\n",
      "Epoch 2023/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0410 - acc: 0.9917\n",
      "Epoch 2024/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0425 - acc: 0.9917\n",
      "Epoch 2025/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0416 - acc: 0.9917\n",
      "Epoch 2026/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0406 - acc: 0.9917\n",
      "Epoch 2027/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0418 - acc: 0.9917\n",
      "Epoch 2028/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0402 - acc: 0.9917\n",
      "Epoch 2029/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0409 - acc: 0.9917\n",
      "Epoch 2030/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0421 - acc: 0.9917\n",
      "Epoch 2031/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0410 - acc: 0.9917\n",
      "Epoch 2032/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0409 - acc: 0.9917\n",
      "Epoch 2033/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0410 - acc: 0.9917\n",
      "Epoch 2034/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0417 - acc: 0.9917\n",
      "Epoch 2035/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0404 - acc: 0.9917\n",
      "Epoch 2036/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0438 - acc: 0.9833\n",
      "Epoch 2037/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0409 - acc: 0.9917\n",
      "Epoch 2038/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0403 - acc: 0.9917\n",
      "Epoch 2039/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0424 - acc: 0.9917\n",
      "Epoch 2040/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0434 - acc: 0.9917\n",
      "Epoch 2041/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0426 - acc: 0.9917\n",
      "Epoch 2042/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0403 - acc: 0.9917\n",
      "Epoch 2043/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0404 - acc: 0.9917\n",
      "Epoch 2044/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0407 - acc: 0.9917\n",
      "Epoch 2045/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0407 - acc: 0.9917\n",
      "Epoch 2046/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0427 - acc: 0.9917\n",
      "Epoch 2047/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0418 - acc: 0.9917\n",
      "Epoch 2048/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0416 - acc: 0.9917\n",
      "Epoch 2049/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0398 - acc: 0.9917\n",
      "Epoch 2050/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0412 - acc: 0.9917\n",
      "Epoch 2051/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0409 - acc: 0.9917\n",
      "Epoch 2052/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0403 - acc: 0.9917\n",
      "Epoch 2053/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0403 - acc: 0.9917\n",
      "Epoch 2054/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0422 - acc: 0.9917\n",
      "Epoch 2055/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0413 - acc: 0.9917\n",
      "Epoch 2056/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0418 - acc: 0.9917\n",
      "Epoch 2057/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0410 - acc: 0.9917\n",
      "Epoch 2058/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0409 - acc: 0.9917\n",
      "Epoch 2059/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0426 - acc: 0.9917\n",
      "Epoch 2060/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0412 - acc: 0.9917\n",
      "Epoch 2061/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0402 - acc: 0.9917\n",
      "Epoch 2062/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0411 - acc: 0.9917\n",
      "Epoch 2063/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0411 - acc: 0.9917\n",
      "Epoch 2064/8000\n",
      "120/120 [==============================] - 0s 59us/sample - loss: 0.0404 - acc: 0.9917\n",
      "Epoch 2065/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0416 - acc: 0.9917\n",
      "Epoch 2066/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0400 - acc: 0.9917\n",
      "Epoch 2067/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0409 - acc: 0.9917\n",
      "Epoch 2068/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0411 - acc: 0.9917\n",
      "Epoch 2069/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0402 - acc: 0.9917\n",
      "Epoch 2070/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0431 - acc: 0.9917\n",
      "Epoch 2071/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0411 - acc: 0.9917\n",
      "Epoch 2072/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0403 - acc: 0.9917\n",
      "Epoch 2073/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0404 - acc: 0.9917\n",
      "Epoch 2074/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0407 - acc: 0.9917\n",
      "Epoch 2075/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0419 - acc: 0.9917\n",
      "Epoch 2076/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0401 - acc: 0.9917\n",
      "Epoch 2077/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0401 - acc: 0.9917\n",
      "Epoch 2078/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0404 - acc: 0.9917\n",
      "Epoch 2079/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0408 - acc: 0.9917\n",
      "Epoch 2080/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0430 - acc: 0.9917\n",
      "Epoch 2081/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0408 - acc: 0.9917\n",
      "Epoch 2082/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0429 - acc: 0.9917\n",
      "Epoch 2083/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0405 - acc: 0.9917\n",
      "Epoch 2084/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0405 - acc: 0.9917\n",
      "Epoch 2085/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0423 - acc: 0.9917\n",
      "Epoch 2086/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0420 - acc: 0.9917\n",
      "Epoch 2087/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0403 - acc: 0.9917\n",
      "Epoch 2088/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0401 - acc: 0.9917\n",
      "Epoch 2089/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0408 - acc: 0.9917\n",
      "Epoch 2090/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0402 - acc: 0.9917\n",
      "Epoch 2091/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0400 - acc: 0.9917\n",
      "Epoch 2092/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0409 - acc: 0.9917\n",
      "Epoch 2093/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0403 - acc: 0.9917\n",
      "Epoch 2094/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0402 - acc: 0.9917\n",
      "Epoch 2095/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0412 - acc: 0.9917\n",
      "Epoch 2096/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0405 - acc: 0.9917\n",
      "Epoch 2097/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0400 - acc: 0.9917\n",
      "Epoch 2098/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0405 - acc: 0.9917\n",
      "Epoch 2099/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0402 - acc: 0.9917\n",
      "Epoch 2100/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0403 - acc: 0.9917\n",
      "Epoch 2101/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0408 - acc: 0.9917\n",
      "Epoch 2102/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0398 - acc: 0.9917\n",
      "Epoch 2103/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0405 - acc: 0.9917\n",
      "Epoch 2104/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0401 - acc: 0.9917\n",
      "Epoch 2105/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0401 - acc: 0.9917\n",
      "Epoch 2106/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0405 - acc: 0.9917\n",
      "Epoch 2107/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0408 - acc: 0.9917\n",
      "Epoch 2108/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0398 - acc: 0.9917\n",
      "Epoch 2109/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0419 - acc: 0.9917\n",
      "Epoch 2110/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0402 - acc: 0.9917\n",
      "Epoch 2111/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0407 - acc: 0.9917\n",
      "Epoch 2112/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0405 - acc: 0.9917\n",
      "Epoch 2113/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0408 - acc: 0.9917\n",
      "Epoch 2114/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0400 - acc: 0.9917\n",
      "Epoch 2115/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0401 - acc: 0.9917\n",
      "Epoch 2116/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0401 - acc: 0.9917\n",
      "Epoch 2117/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0403 - acc: 0.9917\n",
      "Epoch 2118/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0403 - acc: 0.9917\n",
      "Epoch 2119/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0408 - acc: 0.9917\n",
      "Epoch 2120/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0856 - acc: 0.968 - 0s 67us/sample - loss: 0.0405 - acc: 0.9917\n",
      "Epoch 2121/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0408 - acc: 0.9917\n",
      "Epoch 2122/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0416 - acc: 0.9917\n",
      "Epoch 2123/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0407 - acc: 0.9917\n",
      "Epoch 2124/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0437 - acc: 0.9917\n",
      "Epoch 2125/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0406 - acc: 0.9917\n",
      "Epoch 2126/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0434 - acc: 0.9917\n",
      "Epoch 2127/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0415 - acc: 0.9917\n",
      "Epoch 2128/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0404 - acc: 0.9917\n",
      "Epoch 2129/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0401 - acc: 0.9917\n",
      "Epoch 2130/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0398 - acc: 0.9917\n",
      "Epoch 2131/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0403 - acc: 0.9917\n",
      "Epoch 2132/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0399 - acc: 0.9917\n",
      "Epoch 2133/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0402 - acc: 0.9917\n",
      "Epoch 2134/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0404 - acc: 0.9917\n",
      "Epoch 2135/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0397 - acc: 0.9917\n",
      "Epoch 2136/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0400 - acc: 0.9917\n",
      "Epoch 2137/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0401 - acc: 0.9917\n",
      "Epoch 2138/8000\n",
      "120/120 [==============================] - 0s 59us/sample - loss: 0.0397 - acc: 0.9917\n",
      "Epoch 2139/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0405 - acc: 0.9917\n",
      "Epoch 2140/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0401 - acc: 0.9917\n",
      "Epoch 2141/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0408 - acc: 0.9917\n",
      "Epoch 2142/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0397 - acc: 0.9917\n",
      "Epoch 2143/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0400 - acc: 0.9917\n",
      "Epoch 2144/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0398 - acc: 0.9917\n",
      "Epoch 2145/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0399 - acc: 0.9917\n",
      "Epoch 2146/8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0404 - acc: 0.9917\n",
      "Epoch 2147/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0401 - acc: 0.9917\n",
      "Epoch 2148/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0398 - acc: 0.9917\n",
      "Epoch 2149/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0408 - acc: 0.9917\n",
      "Epoch 2150/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0412 - acc: 0.9917\n",
      "Epoch 2151/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0398 - acc: 0.9917\n",
      "Epoch 2152/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0406 - acc: 0.9917\n",
      "Epoch 2153/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0398 - acc: 0.9917\n",
      "Epoch 2154/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0408 - acc: 0.9917\n",
      "Epoch 2155/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0414 - acc: 0.9917\n",
      "Epoch 2156/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0395 - acc: 0.9917\n",
      "Epoch 2157/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0403 - acc: 0.9917\n",
      "Epoch 2158/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0428 - acc: 0.9833\n",
      "Epoch 2159/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0396 - acc: 0.9917\n",
      "Epoch 2160/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0403 - acc: 0.9917\n",
      "Epoch 2161/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0420 - acc: 0.9917\n",
      "Epoch 2162/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0401 - acc: 0.9917\n",
      "Epoch 2163/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0402 - acc: 0.9917\n",
      "Epoch 2164/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0403 - acc: 0.9917\n",
      "Epoch 2165/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0402 - acc: 0.9917\n",
      "Epoch 2166/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0397 - acc: 0.9917\n",
      "Epoch 2167/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0399 - acc: 0.9917\n",
      "Epoch 2168/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0405 - acc: 0.9917\n",
      "Epoch 2169/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0401 - acc: 0.9917\n",
      "Epoch 2170/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0403 - acc: 0.9917\n",
      "Epoch 2171/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0398 - acc: 0.9917\n",
      "Epoch 2172/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0399 - acc: 0.9917\n",
      "Epoch 2173/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0399 - acc: 0.9917\n",
      "Epoch 2174/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0400 - acc: 0.9917\n",
      "Epoch 2175/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0397 - acc: 0.9917\n",
      "Epoch 2176/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0405 - acc: 0.9917\n",
      "Epoch 2177/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0394 - acc: 0.9917\n",
      "Epoch 2178/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0418 - acc: 0.9917\n",
      "Epoch 2179/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0405 - acc: 0.9917\n",
      "Epoch 2180/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0399 - acc: 0.9917\n",
      "Epoch 2181/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0402 - acc: 0.9917\n",
      "Epoch 2182/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0406 - acc: 0.9917\n",
      "Epoch 2183/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0401 - acc: 0.9917\n",
      "Epoch 2184/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0415 - acc: 0.9917\n",
      "Epoch 2185/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0396 - acc: 0.9917\n",
      "Epoch 2186/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0402 - acc: 0.9917\n",
      "Epoch 2187/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0399 - acc: 0.9917\n",
      "Epoch 2188/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0394 - acc: 0.9917\n",
      "Epoch 2189/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0411 - acc: 0.9917\n",
      "Epoch 2190/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0392 - acc: 0.9917\n",
      "Epoch 2191/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0400 - acc: 0.9917\n",
      "Epoch 2192/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0407 - acc: 0.9917\n",
      "Epoch 2193/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0402 - acc: 0.9917\n",
      "Epoch 2194/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0397 - acc: 0.9917\n",
      "Epoch 2195/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0398 - acc: 0.9917\n",
      "Epoch 2196/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0408 - acc: 0.9917\n",
      "Epoch 2197/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0403 - acc: 0.9917\n",
      "Epoch 2198/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0411 - acc: 0.9917\n",
      "Epoch 2199/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0407 - acc: 0.9917\n",
      "Epoch 2200/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0399 - acc: 0.9917\n",
      "Epoch 2201/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0406 - acc: 0.9917\n",
      "Epoch 2202/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0405 - acc: 0.9917\n",
      "Epoch 2203/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0406 - acc: 0.9917\n",
      "Epoch 2204/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0389 - acc: 0.9917\n",
      "Epoch 2205/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0411 - acc: 0.9917\n",
      "Epoch 2206/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0423 - acc: 0.9917\n",
      "Epoch 2207/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0401 - acc: 0.9917\n",
      "Epoch 2208/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0398 - acc: 0.9917\n",
      "Epoch 2209/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0400 - acc: 0.9917\n",
      "Epoch 2210/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0395 - acc: 0.9917\n",
      "Epoch 2211/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0410 - acc: 0.9917\n",
      "Epoch 2212/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0394 - acc: 0.9917\n",
      "Epoch 2213/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0402 - acc: 0.9917\n",
      "Epoch 2214/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0411 - acc: 0.9917\n",
      "Epoch 2215/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0394 - acc: 0.9917\n",
      "Epoch 2216/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0394 - acc: 0.9917\n",
      "Epoch 2217/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0409 - acc: 0.9917\n",
      "Epoch 2218/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0393 - acc: 0.9917\n",
      "Epoch 2219/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0396 - acc: 0.9917\n",
      "Epoch 2220/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0397 - acc: 0.9917\n",
      "Epoch 2221/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0400 - acc: 0.9917\n",
      "Epoch 2222/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0400 - acc: 0.9917\n",
      "Epoch 2223/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0393 - acc: 0.9917\n",
      "Epoch 2224/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0401 - acc: 0.9917\n",
      "Epoch 2225/8000\n",
      "120/120 [==============================] - 0s 59us/sample - loss: 0.0393 - acc: 0.9917\n",
      "Epoch 2226/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0395 - acc: 0.9917\n",
      "Epoch 2227/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0393 - acc: 0.9917\n",
      "Epoch 2228/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0398 - acc: 0.9917\n",
      "Epoch 2229/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0402 - acc: 0.9917\n",
      "Epoch 2230/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0397 - acc: 0.9917\n",
      "Epoch 2231/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0392 - acc: 0.9917\n",
      "Epoch 2232/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0400 - acc: 0.9917\n",
      "Epoch 2233/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0394 - acc: 0.9917\n",
      "Epoch 2234/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0401 - acc: 0.9917\n",
      "Epoch 2235/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0275 - acc: 1.000 - 0s 84us/sample - loss: 0.0401 - acc: 0.9917\n",
      "Epoch 2236/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0406 - acc: 0.9917\n",
      "Epoch 2237/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0395 - acc: 0.9917\n",
      "Epoch 2238/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0402 - acc: 0.9917\n",
      "Epoch 2239/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0396 - acc: 0.9917\n",
      "Epoch 2240/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0396 - acc: 0.9917\n",
      "Epoch 2241/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0397 - acc: 0.9917\n",
      "Epoch 2242/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0400 - acc: 0.9917\n",
      "Epoch 2243/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0394 - acc: 0.9917\n",
      "Epoch 2244/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0394 - acc: 0.9917\n",
      "Epoch 2245/8000\n",
      "120/120 [==============================] - 0s 83us/sample - loss: 0.0398 - acc: 0.9917\n",
      "Epoch 2246/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0391 - acc: 0.9917\n",
      "Epoch 2247/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0397 - acc: 0.9917\n",
      "Epoch 2248/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0396 - acc: 0.9917\n",
      "Epoch 2249/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0399 - acc: 0.9917\n",
      "Epoch 2250/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0390 - acc: 0.9917\n",
      "Epoch 2251/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0435 - acc: 0.9833\n",
      "Epoch 2252/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0406 - acc: 0.9917\n",
      "Epoch 2253/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0392 - acc: 0.9917\n",
      "Epoch 2254/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0397 - acc: 0.9917\n",
      "Epoch 2255/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0396 - acc: 0.9917\n",
      "Epoch 2256/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0395 - acc: 0.9917\n",
      "Epoch 2257/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0397 - acc: 0.9917\n",
      "Epoch 2258/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0391 - acc: 0.9917\n",
      "Epoch 2259/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0407 - acc: 0.9917\n",
      "Epoch 2260/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0393 - acc: 0.9917\n",
      "Epoch 2261/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0402 - acc: 0.9917\n",
      "Epoch 2262/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0397 - acc: 0.9917\n",
      "Epoch 2263/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0416 - acc: 0.9917\n",
      "Epoch 2264/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0394 - acc: 0.9917\n",
      "Epoch 2265/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0395 - acc: 0.9917\n",
      "Epoch 2266/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0400 - acc: 0.9917\n",
      "Epoch 2267/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0415 - acc: 0.9917\n",
      "Epoch 2268/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0392 - acc: 0.9917\n",
      "Epoch 2269/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0394 - acc: 0.9917\n",
      "Epoch 2270/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0405 - acc: 0.9917\n",
      "Epoch 2271/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0398 - acc: 0.9917\n",
      "Epoch 2272/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0383 - acc: 0.9917\n",
      "Epoch 2273/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0388 - acc: 0.9917\n",
      "Epoch 2274/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0409 - acc: 0.9917\n",
      "Epoch 2275/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0400 - acc: 0.9917\n",
      "Epoch 2276/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0390 - acc: 0.9917\n",
      "Epoch 2277/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0393 - acc: 0.9917\n",
      "Epoch 2278/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0395 - acc: 0.9917\n",
      "Epoch 2279/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0402 - acc: 0.9917\n",
      "Epoch 2280/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0403 - acc: 0.9917\n",
      "Epoch 2281/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0406 - acc: 0.9917\n",
      "Epoch 2282/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0398 - acc: 0.9917\n",
      "Epoch 2283/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0405 - acc: 0.9917\n",
      "Epoch 2284/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0390 - acc: 0.9917\n",
      "Epoch 2285/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0401 - acc: 0.9917\n",
      "Epoch 2286/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0405 - acc: 0.9917\n",
      "Epoch 2287/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0396 - acc: 0.9917\n",
      "Epoch 2288/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0392 - acc: 0.9917\n",
      "Epoch 2289/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0395 - acc: 0.9917\n",
      "Epoch 2290/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0396 - acc: 0.9917\n",
      "Epoch 2291/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0393 - acc: 0.9917\n",
      "Epoch 2292/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0399 - acc: 0.9917\n",
      "Epoch 2293/8000\n",
      "120/120 [==============================] - 0s 83us/sample - loss: 0.0398 - acc: 0.9917\n",
      "Epoch 2294/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0405 - acc: 0.9917\n",
      "Epoch 2295/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0395 - acc: 0.9917\n",
      "Epoch 2296/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0398 - acc: 0.9917\n",
      "Epoch 2297/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0391 - acc: 0.9917\n",
      "Epoch 2298/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0393 - acc: 0.9917\n",
      "Epoch 2299/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0393 - acc: 0.9917\n",
      "Epoch 2300/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0396 - acc: 0.9917\n",
      "Epoch 2301/8000\n",
      "120/120 [==============================] - 0s 59us/sample - loss: 0.0399 - acc: 0.9917\n",
      "Epoch 2302/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0390 - acc: 0.9917\n",
      "Epoch 2303/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0397 - acc: 0.9917\n",
      "Epoch 2304/8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0400 - acc: 0.9917\n",
      "Epoch 2305/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0400 - acc: 0.9917\n",
      "Epoch 2306/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0392 - acc: 0.9917\n",
      "Epoch 2307/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0391 - acc: 0.9917\n",
      "Epoch 2308/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0390 - acc: 0.9917\n",
      "Epoch 2309/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0402 - acc: 0.9917\n",
      "Epoch 2310/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0393 - acc: 0.9917\n",
      "Epoch 2311/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0402 - acc: 0.9917\n",
      "Epoch 2312/8000\n",
      "120/120 [==============================] - 0s 50us/sample - loss: 0.0392 - acc: 0.9917\n",
      "Epoch 2313/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0391 - acc: 0.9917\n",
      "Epoch 2314/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0387 - acc: 0.9917\n",
      "Epoch 2315/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0396 - acc: 0.9917\n",
      "Epoch 2316/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0393 - acc: 0.9917\n",
      "Epoch 2317/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0396 - acc: 0.9917\n",
      "Epoch 2318/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0399 - acc: 0.9917\n",
      "Epoch 2319/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0383 - acc: 0.9917\n",
      "Epoch 2320/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0390 - acc: 0.9917\n",
      "Epoch 2321/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0399 - acc: 0.9917\n",
      "Epoch 2322/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0401 - acc: 0.9917\n",
      "Epoch 2323/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0392 - acc: 0.9917\n",
      "Epoch 2324/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0414 - acc: 0.9917\n",
      "Epoch 2325/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0410 - acc: 0.9917\n",
      "Epoch 2326/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0397 - acc: 0.9917\n",
      "Epoch 2327/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0390 - acc: 0.9917\n",
      "Epoch 2328/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0418 - acc: 0.9917\n",
      "Epoch 2329/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0397 - acc: 0.9917\n",
      "Epoch 2330/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0389 - acc: 0.9917\n",
      "Epoch 2331/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0397 - acc: 0.9917\n",
      "Epoch 2332/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0394 - acc: 0.9917\n",
      "Epoch 2333/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0392 - acc: 0.9917\n",
      "Epoch 2334/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0397 - acc: 0.9917\n",
      "Epoch 2335/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0393 - acc: 0.9917\n",
      "Epoch 2336/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0397 - acc: 0.9917\n",
      "Epoch 2337/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0394 - acc: 0.9917\n",
      "Epoch 2338/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0396 - acc: 0.9917\n",
      "Epoch 2339/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0400 - acc: 0.9917\n",
      "Epoch 2340/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0387 - acc: 0.9917\n",
      "Epoch 2341/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0390 - acc: 0.9917\n",
      "Epoch 2342/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0387 - acc: 0.9917\n",
      "Epoch 2343/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0400 - acc: 0.9917\n",
      "Epoch 2344/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0386 - acc: 0.9917\n",
      "Epoch 2345/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0394 - acc: 0.9917\n",
      "Epoch 2346/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0392 - acc: 0.9917\n",
      "Epoch 2347/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0390 - acc: 0.9917\n",
      "Epoch 2348/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0398 - acc: 0.9917\n",
      "Epoch 2349/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0389 - acc: 0.9917\n",
      "Epoch 2350/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0386 - acc: 0.9917\n",
      "Epoch 2351/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0387 - acc: 0.9917\n",
      "Epoch 2352/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0393 - acc: 0.9917\n",
      "Epoch 2353/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0395 - acc: 0.9917\n",
      "Epoch 2354/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0390 - acc: 0.9917\n",
      "Epoch 2355/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0391 - acc: 0.9917\n",
      "Epoch 2356/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0386 - acc: 0.9917\n",
      "Epoch 2357/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0391 - acc: 0.9917\n",
      "Epoch 2358/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0392 - acc: 0.9917\n",
      "Epoch 2359/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0385 - acc: 0.9917\n",
      "Epoch 2360/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0390 - acc: 0.9917\n",
      "Epoch 2361/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0398 - acc: 0.9917\n",
      "Epoch 2362/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0391 - acc: 0.9917\n",
      "Epoch 2363/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0387 - acc: 0.9917\n",
      "Epoch 2364/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0214 - acc: 1.000 - 0s 92us/sample - loss: 0.0429 - acc: 0.9917\n",
      "Epoch 2365/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0398 - acc: 0.9917\n",
      "Epoch 2366/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0412 - acc: 0.9917\n",
      "Epoch 2367/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0397 - acc: 0.9917\n",
      "Epoch 2368/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0411 - acc: 0.9917\n",
      "Epoch 2369/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0400 - acc: 0.9917\n",
      "Epoch 2370/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0392 - acc: 0.9917\n",
      "Epoch 2371/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0393 - acc: 0.9917\n",
      "Epoch 2372/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0391 - acc: 0.9917\n",
      "Epoch 2373/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0388 - acc: 0.9917\n",
      "Epoch 2374/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0396 - acc: 0.9917\n",
      "Epoch 2375/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0390 - acc: 0.9917\n",
      "Epoch 2376/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0408 - acc: 0.9917\n",
      "Epoch 2377/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0391 - acc: 0.9917\n",
      "Epoch 2378/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0396 - acc: 0.9917\n",
      "Epoch 2379/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0399 - acc: 0.9917\n",
      "Epoch 2380/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0392 - acc: 0.9917\n",
      "Epoch 2381/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0392 - acc: 0.9917\n",
      "Epoch 2382/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0393 - acc: 0.9917\n",
      "Epoch 2383/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0388 - acc: 0.9917\n",
      "Epoch 2384/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0393 - acc: 0.9917\n",
      "Epoch 2385/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0387 - acc: 0.9917\n",
      "Epoch 2386/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0389 - acc: 0.9917\n",
      "Epoch 2387/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0414 - acc: 0.9917\n",
      "Epoch 2388/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0395 - acc: 0.9917\n",
      "Epoch 2389/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0385 - acc: 0.9917\n",
      "Epoch 2390/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0388 - acc: 0.9917\n",
      "Epoch 2391/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0401 - acc: 0.9917\n",
      "Epoch 2392/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0401 - acc: 0.9917\n",
      "Epoch 2393/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0388 - acc: 0.9917\n",
      "Epoch 2394/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0399 - acc: 0.9917\n",
      "Epoch 2395/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0389 - acc: 0.9917\n",
      "Epoch 2396/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0389 - acc: 0.9917\n",
      "Epoch 2397/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0405 - acc: 0.9917\n",
      "Epoch 2398/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0397 - acc: 0.9917\n",
      "Epoch 2399/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0401 - acc: 0.9917\n",
      "Epoch 2400/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0389 - acc: 0.9917\n",
      "Epoch 2401/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0389 - acc: 0.9917\n",
      "Epoch 2402/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0385 - acc: 0.9917\n",
      "Epoch 2403/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0391 - acc: 0.9917\n",
      "Epoch 2404/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0383 - acc: 0.9917\n",
      "Epoch 2405/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0386 - acc: 0.9917\n",
      "Epoch 2406/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0387 - acc: 0.9917\n",
      "Epoch 2407/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0385 - acc: 0.9917\n",
      "Epoch 2408/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0388 - acc: 0.9917\n",
      "Epoch 2409/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0388 - acc: 0.9917\n",
      "Epoch 2410/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0397 - acc: 0.9917\n",
      "Epoch 2411/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0386 - acc: 0.9917\n",
      "Epoch 2412/8000\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.0384 - acc: 0.9917\n",
      "Epoch 2413/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0398 - acc: 0.9917\n",
      "Epoch 2414/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0385 - acc: 0.9917\n",
      "Epoch 2415/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0390 - acc: 0.9917\n",
      "Epoch 2416/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0380 - acc: 0.9917\n",
      "Epoch 2417/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0385 - acc: 0.9917\n",
      "Epoch 2418/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0393 - acc: 0.9917\n",
      "Epoch 2419/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0321 - acc: 1.000 - 0s 84us/sample - loss: 0.0395 - acc: 0.9917\n",
      "Epoch 2420/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0389 - acc: 0.9917\n",
      "Epoch 2421/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0386 - acc: 0.9917\n",
      "Epoch 2422/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0386 - acc: 0.9917\n",
      "Epoch 2423/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0397 - acc: 0.9917\n",
      "Epoch 2424/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0383 - acc: 0.9917\n",
      "Epoch 2425/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0392 - acc: 0.9917\n",
      "Epoch 2426/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0394 - acc: 0.9917\n",
      "Epoch 2427/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0375 - acc: 0.9917\n",
      "Epoch 2428/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0394 - acc: 0.9917\n",
      "Epoch 2429/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0446 - acc: 0.9917\n",
      "Epoch 2430/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0403 - acc: 0.9917\n",
      "Epoch 2431/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0384 - acc: 0.9917\n",
      "Epoch 2432/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0386 - acc: 0.9917\n",
      "Epoch 2433/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0382 - acc: 0.9917\n",
      "Epoch 2434/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0416 - acc: 0.9917\n",
      "Epoch 2435/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0415 - acc: 0.9917\n",
      "Epoch 2436/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0387 - acc: 0.9917\n",
      "Epoch 2437/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0388 - acc: 0.9917\n",
      "Epoch 2438/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0385 - acc: 0.9917\n",
      "Epoch 2439/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0383 - acc: 0.9917\n",
      "Epoch 2440/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0405 - acc: 0.9917\n",
      "Epoch 2441/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0398 - acc: 0.9917\n",
      "Epoch 2442/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0391 - acc: 0.9917\n",
      "Epoch 2443/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0389 - acc: 0.9917\n",
      "Epoch 2444/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0388 - acc: 0.9917\n",
      "Epoch 2445/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0393 - acc: 0.9917\n",
      "Epoch 2446/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0411 - acc: 0.9917\n",
      "Epoch 2447/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0390 - acc: 0.9917\n",
      "Epoch 2448/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0381 - acc: 0.9917\n",
      "Epoch 2449/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0381 - acc: 0.9917\n",
      "Epoch 2450/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0390 - acc: 0.9917\n",
      "Epoch 2451/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0388 - acc: 0.9917\n",
      "Epoch 2452/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0386 - acc: 0.9917\n",
      "Epoch 2453/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0385 - acc: 0.9917\n",
      "Epoch 2454/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0383 - acc: 0.9917\n",
      "Epoch 2455/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0383 - acc: 0.9917\n",
      "Epoch 2456/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0390 - acc: 0.9917\n",
      "Epoch 2457/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0402 - acc: 0.9917\n",
      "Epoch 2458/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0388 - acc: 0.9917\n",
      "Epoch 2459/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0407 - acc: 0.9917\n",
      "Epoch 2460/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0387 - acc: 0.9917\n",
      "Epoch 2461/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0385 - acc: 0.9917\n",
      "Epoch 2462/8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0411 - acc: 0.9917\n",
      "Epoch 2463/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0382 - acc: 0.9917\n",
      "Epoch 2464/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0381 - acc: 0.9917\n",
      "Epoch 2465/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0389 - acc: 0.9917\n",
      "Epoch 2466/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0402 - acc: 0.9917\n",
      "Epoch 2467/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0393 - acc: 0.9917\n",
      "Epoch 2468/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0386 - acc: 0.9917\n",
      "Epoch 2469/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0383 - acc: 0.9917\n",
      "Epoch 2470/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0387 - acc: 0.9917\n",
      "Epoch 2471/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0382 - acc: 0.9917\n",
      "Epoch 2472/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0381 - acc: 0.9917\n",
      "Epoch 2473/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0382 - acc: 0.9917\n",
      "Epoch 2474/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0381 - acc: 0.9917\n",
      "Epoch 2475/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0386 - acc: 0.9917\n",
      "Epoch 2476/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0407 - acc: 0.9917\n",
      "Epoch 2477/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0401 - acc: 0.9917\n",
      "Epoch 2478/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0381 - acc: 0.9917\n",
      "Epoch 2479/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0381 - acc: 0.9917\n",
      "Epoch 2480/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0387 - acc: 0.9917\n",
      "Epoch 2481/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0381 - acc: 0.9917\n",
      "Epoch 2482/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0380 - acc: 0.9917\n",
      "Epoch 2483/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0391 - acc: 0.9917\n",
      "Epoch 2484/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0395 - acc: 0.9917\n",
      "Epoch 2485/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0386 - acc: 0.9917\n",
      "Epoch 2486/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0388 - acc: 0.9917\n",
      "Epoch 2487/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0381 - acc: 0.9917\n",
      "Epoch 2488/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0385 - acc: 0.9917\n",
      "Epoch 2489/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0408 - acc: 0.9917\n",
      "Epoch 2490/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0407 - acc: 0.9917\n",
      "Epoch 2491/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0391 - acc: 0.9917\n",
      "Epoch 2492/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0395 - acc: 0.9917\n",
      "Epoch 2493/8000\n",
      "120/120 [==============================] - 0s 83us/sample - loss: 0.0389 - acc: 0.9917\n",
      "Epoch 2494/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0386 - acc: 0.9917\n",
      "Epoch 2495/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0396 - acc: 0.9917\n",
      "Epoch 2496/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0381 - acc: 0.9917\n",
      "Epoch 2497/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0384 - acc: 0.9917\n",
      "Epoch 2498/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0392 - acc: 0.9917\n",
      "Epoch 2499/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0385 - acc: 0.9917\n",
      "Epoch 2500/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0387 - acc: 0.9917\n",
      "Epoch 2501/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0381 - acc: 0.9917\n",
      "Epoch 2502/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0385 - acc: 0.9917\n",
      "Epoch 2503/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0314 - acc: 1.000 - 0s 67us/sample - loss: 0.0398 - acc: 0.9917\n",
      "Epoch 2504/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0386 - acc: 0.9917\n",
      "Epoch 2505/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0387 - acc: 0.9917\n",
      "Epoch 2506/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0379 - acc: 0.9917\n",
      "Epoch 2507/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0386 - acc: 0.9917\n",
      "Epoch 2508/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0397 - acc: 0.9917\n",
      "Epoch 2509/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0380 - acc: 0.9917\n",
      "Epoch 2510/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0392 - acc: 0.9917\n",
      "Epoch 2511/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0397 - acc: 0.9917\n",
      "Epoch 2512/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0390 - acc: 0.9917\n",
      "Epoch 2513/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0383 - acc: 0.9917\n",
      "Epoch 2514/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0389 - acc: 0.9917\n",
      "Epoch 2515/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0382 - acc: 0.9917\n",
      "Epoch 2516/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0391 - acc: 0.9917\n",
      "Epoch 2517/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0376 - acc: 0.9917\n",
      "Epoch 2518/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0405 - acc: 0.9917\n",
      "Epoch 2519/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0394 - acc: 0.9917\n",
      "Epoch 2520/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0412 - acc: 0.9917\n",
      "Epoch 2521/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0386 - acc: 0.9917\n",
      "Epoch 2522/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0391 - acc: 0.9917\n",
      "Epoch 2523/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0382 - acc: 0.9917\n",
      "Epoch 2524/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0380 - acc: 0.9917\n",
      "Epoch 2525/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0392 - acc: 0.9917\n",
      "Epoch 2526/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0382 - acc: 0.9917\n",
      "Epoch 2527/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0383 - acc: 0.9917\n",
      "Epoch 2528/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0384 - acc: 0.9917\n",
      "Epoch 2529/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0389 - acc: 0.9917\n",
      "Epoch 2530/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0387 - acc: 0.9917\n",
      "Epoch 2531/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0384 - acc: 0.9917\n",
      "Epoch 2532/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0383 - acc: 0.9917\n",
      "Epoch 2533/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0388 - acc: 0.9917\n",
      "Epoch 2534/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0377 - acc: 0.9917\n",
      "Epoch 2535/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0377 - acc: 0.9917\n",
      "Epoch 2536/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0391 - acc: 0.9917\n",
      "Epoch 2537/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0387 - acc: 0.9917\n",
      "Epoch 2538/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0383 - acc: 0.9917\n",
      "Epoch 2539/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0381 - acc: 0.9917\n",
      "Epoch 2540/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0384 - acc: 0.9917\n",
      "Epoch 2541/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0382 - acc: 0.9917\n",
      "Epoch 2542/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0378 - acc: 0.9917\n",
      "Epoch 2543/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0381 - acc: 0.9917\n",
      "Epoch 2544/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0378 - acc: 0.9917\n",
      "Epoch 2545/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0379 - acc: 0.9917\n",
      "Epoch 2546/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0388 - acc: 0.9917\n",
      "Epoch 2547/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0399 - acc: 0.9917\n",
      "Epoch 2548/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0380 - acc: 0.9917\n",
      "Epoch 2549/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0392 - acc: 0.9917\n",
      "Epoch 2550/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0391 - acc: 0.9917\n",
      "Epoch 2551/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0379 - acc: 0.9917\n",
      "Epoch 2552/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0377 - acc: 0.9917\n",
      "Epoch 2553/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0387 - acc: 0.9917\n",
      "Epoch 2554/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0384 - acc: 0.9917\n",
      "Epoch 2555/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0377 - acc: 0.9917\n",
      "Epoch 2556/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0393 - acc: 0.9917\n",
      "Epoch 2557/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0390 - acc: 0.9917\n",
      "Epoch 2558/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0391 - acc: 0.9917\n",
      "Epoch 2559/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0381 - acc: 0.9917\n",
      "Epoch 2560/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0390 - acc: 0.9917\n",
      "Epoch 2561/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0379 - acc: 0.9917\n",
      "Epoch 2562/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0384 - acc: 0.9917\n",
      "Epoch 2563/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0383 - acc: 0.9917\n",
      "Epoch 2564/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0379 - acc: 0.9917\n",
      "Epoch 2565/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0379 - acc: 0.9917\n",
      "Epoch 2566/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0379 - acc: 0.9917\n",
      "Epoch 2567/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0388 - acc: 0.9917\n",
      "Epoch 2568/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0043 - acc: 1.000 - 0s 75us/sample - loss: 0.0390 - acc: 0.9917\n",
      "Epoch 2569/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0383 - acc: 0.9917\n",
      "Epoch 2570/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0371 - acc: 0.9917\n",
      "Epoch 2571/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0391 - acc: 0.9917\n",
      "Epoch 2572/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0411 - acc: 0.9917\n",
      "Epoch 2573/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0380 - acc: 0.9917\n",
      "Epoch 2574/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0389 - acc: 0.9917\n",
      "Epoch 2575/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0390 - acc: 0.9917\n",
      "Epoch 2576/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0382 - acc: 0.9917\n",
      "Epoch 2577/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0385 - acc: 0.9917\n",
      "Epoch 2578/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0396 - acc: 0.9917\n",
      "Epoch 2579/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0393 - acc: 0.9917\n",
      "Epoch 2580/8000\n",
      "120/120 [==============================] - 0s 83us/sample - loss: 0.0382 - acc: 0.9917\n",
      "Epoch 2581/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0376 - acc: 0.9917\n",
      "Epoch 2582/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0378 - acc: 0.9917\n",
      "Epoch 2583/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0381 - acc: 0.9917\n",
      "Epoch 2584/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0379 - acc: 0.9917\n",
      "Epoch 2585/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0378 - acc: 0.9917\n",
      "Epoch 2586/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0389 - acc: 0.9917\n",
      "Epoch 2587/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0379 - acc: 0.9917\n",
      "Epoch 2588/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0383 - acc: 0.9917\n",
      "Epoch 2589/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0388 - acc: 0.9917\n",
      "Epoch 2590/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0382 - acc: 0.9917\n",
      "Epoch 2591/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0378 - acc: 0.9917\n",
      "Epoch 2592/8000\n",
      "120/120 [==============================] - 0s 83us/sample - loss: 0.0380 - acc: 0.9917\n",
      "Epoch 2593/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0381 - acc: 0.9917\n",
      "Epoch 2594/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0412 - acc: 0.9917\n",
      "Epoch 2595/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0399 - acc: 0.9917\n",
      "Epoch 2596/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0376 - acc: 0.9917\n",
      "Epoch 2597/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0384 - acc: 0.9917\n",
      "Epoch 2598/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0379 - acc: 0.9917\n",
      "Epoch 2599/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0380 - acc: 0.9917\n",
      "Epoch 2600/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0392 - acc: 0.9917\n",
      "Epoch 2601/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0384 - acc: 0.9917\n",
      "Epoch 2602/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0376 - acc: 0.9917\n",
      "Epoch 2603/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0374 - acc: 0.9917\n",
      "Epoch 2604/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0426 - acc: 0.9917\n",
      "Epoch 2605/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0394 - acc: 0.9917\n",
      "Epoch 2606/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0381 - acc: 0.9917\n",
      "Epoch 2607/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0393 - acc: 0.9917\n",
      "Epoch 2608/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0413 - acc: 0.9917\n",
      "Epoch 2609/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0376 - acc: 0.9917\n",
      "Epoch 2610/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0393 - acc: 0.9917\n",
      "Epoch 2611/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0396 - acc: 0.9917\n",
      "Epoch 2612/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0376 - acc: 0.9917\n",
      "Epoch 2613/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0395 - acc: 0.9917\n",
      "Epoch 2614/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0381 - acc: 0.9917\n",
      "Epoch 2615/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0379 - acc: 0.9917\n",
      "Epoch 2616/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0388 - acc: 0.9917\n",
      "Epoch 2617/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0374 - acc: 0.9917\n",
      "Epoch 2618/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0378 - acc: 0.9917\n",
      "Epoch 2619/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0383 - acc: 0.9917\n",
      "Epoch 2620/8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0406 - acc: 0.9917\n",
      "Epoch 2621/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0381 - acc: 0.9917\n",
      "Epoch 2622/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0389 - acc: 0.9917\n",
      "Epoch 2623/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0387 - acc: 0.9917\n",
      "Epoch 2624/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0375 - acc: 0.9917\n",
      "Epoch 2625/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0378 - acc: 0.9917\n",
      "Epoch 2626/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0379 - acc: 0.9917\n",
      "Epoch 2627/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0378 - acc: 0.9917\n",
      "Epoch 2628/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0375 - acc: 0.9917\n",
      "Epoch 2629/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0378 - acc: 0.9917\n",
      "Epoch 2630/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0374 - acc: 0.9917\n",
      "Epoch 2631/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0377 - acc: 0.9917\n",
      "Epoch 2632/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0378 - acc: 0.9917\n",
      "Epoch 2633/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0380 - acc: 0.9917\n",
      "Epoch 2634/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0378 - acc: 0.9917\n",
      "Epoch 2635/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0376 - acc: 0.9917\n",
      "Epoch 2636/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0376 - acc: 0.9917\n",
      "Epoch 2637/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0377 - acc: 0.9917\n",
      "Epoch 2638/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0381 - acc: 0.9917\n",
      "Epoch 2639/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0382 - acc: 0.9917\n",
      "Epoch 2640/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0381 - acc: 0.9917\n",
      "Epoch 2641/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0389 - acc: 0.9917\n",
      "Epoch 2642/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0374 - acc: 0.9917\n",
      "Epoch 2643/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0378 - acc: 0.9917\n",
      "Epoch 2644/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0383 - acc: 0.9917\n",
      "Epoch 2645/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0373 - acc: 0.9917\n",
      "Epoch 2646/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0376 - acc: 0.9917\n",
      "Epoch 2647/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0378 - acc: 0.9917\n",
      "Epoch 2648/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0389 - acc: 0.9917\n",
      "Epoch 2649/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0376 - acc: 0.9917\n",
      "Epoch 2650/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0375 - acc: 0.9917\n",
      "Epoch 2651/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0374 - acc: 0.9917\n",
      "Epoch 2652/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0374 - acc: 0.9917\n",
      "Epoch 2653/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0190 - acc: 1.000 - 0s 84us/sample - loss: 0.0373 - acc: 0.9917\n",
      "Epoch 2654/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0379 - acc: 0.9917\n",
      "Epoch 2655/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0373 - acc: 0.9917\n",
      "Epoch 2656/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0374 - acc: 0.9917\n",
      "Epoch 2657/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0375 - acc: 0.9917\n",
      "Epoch 2658/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0382 - acc: 0.9917\n",
      "Epoch 2659/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0374 - acc: 0.9917\n",
      "Epoch 2660/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0373 - acc: 0.9917\n",
      "Epoch 2661/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0377 - acc: 0.9917\n",
      "Epoch 2662/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0376 - acc: 0.9917\n",
      "Epoch 2663/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0379 - acc: 0.9917\n",
      "Epoch 2664/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0382 - acc: 0.9917\n",
      "Epoch 2665/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0372 - acc: 0.9917\n",
      "Epoch 2666/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0388 - acc: 0.9917\n",
      "Epoch 2667/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0382 - acc: 0.9917\n",
      "Epoch 2668/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0379 - acc: 0.9917\n",
      "Epoch 2669/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0387 - acc: 0.9917\n",
      "Epoch 2670/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0382 - acc: 0.9917\n",
      "Epoch 2671/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0376 - acc: 0.9917\n",
      "Epoch 2672/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0374 - acc: 0.9917\n",
      "Epoch 2673/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0378 - acc: 0.9917\n",
      "Epoch 2674/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0371 - acc: 0.9917\n",
      "Epoch 2675/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0376 - acc: 0.9917\n",
      "Epoch 2676/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0379 - acc: 0.9917\n",
      "Epoch 2677/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0376 - acc: 0.9917\n",
      "Epoch 2678/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0397 - acc: 0.9917\n",
      "Epoch 2679/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0384 - acc: 0.9917\n",
      "Epoch 2680/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0383 - acc: 0.9917\n",
      "Epoch 2681/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0376 - acc: 0.9917\n",
      "Epoch 2682/8000\n",
      "120/120 [==============================] - 0s 59us/sample - loss: 0.0372 - acc: 0.9917\n",
      "Epoch 2683/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0376 - acc: 0.9917\n",
      "Epoch 2684/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0785 - acc: 0.968 - 0s 109us/sample - loss: 0.0375 - acc: 0.9917\n",
      "Epoch 2685/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0400 - acc: 0.9917\n",
      "Epoch 2686/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0377 - acc: 0.9917\n",
      "Epoch 2687/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0374 - acc: 0.9917\n",
      "Epoch 2688/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0396 - acc: 0.9917\n",
      "Epoch 2689/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0383 - acc: 0.9917\n",
      "Epoch 2690/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0374 - acc: 0.9917\n",
      "Epoch 2691/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0402 - acc: 0.9917\n",
      "Epoch 2692/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0387 - acc: 0.9917\n",
      "Epoch 2693/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0396 - acc: 0.9917\n",
      "Epoch 2694/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0373 - acc: 0.9917\n",
      "Epoch 2695/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0378 - acc: 0.9917\n",
      "Epoch 2696/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0382 - acc: 0.9917\n",
      "Epoch 2697/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0373 - acc: 0.9917\n",
      "Epoch 2698/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0395 - acc: 0.9917\n",
      "Epoch 2699/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0380 - acc: 0.9917\n",
      "Epoch 2700/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0376 - acc: 0.9917\n",
      "Epoch 2701/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0400 - acc: 0.9917\n",
      "Epoch 2702/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0377 - acc: 0.9917\n",
      "Epoch 2703/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0375 - acc: 0.9917\n",
      "Epoch 2704/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0384 - acc: 0.9917\n",
      "Epoch 2705/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0378 - acc: 0.9917\n",
      "Epoch 2706/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0378 - acc: 0.9917\n",
      "Epoch 2707/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0371 - acc: 0.9917\n",
      "Epoch 2708/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0377 - acc: 0.9917\n",
      "Epoch 2709/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0370 - acc: 0.9917\n",
      "Epoch 2710/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0372 - acc: 0.9917\n",
      "Epoch 2711/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0379 - acc: 0.9917\n",
      "Epoch 2712/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0381 - acc: 0.9917\n",
      "Epoch 2713/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0381 - acc: 0.9917\n",
      "Epoch 2714/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0379 - acc: 0.9917\n",
      "Epoch 2715/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0372 - acc: 0.9917\n",
      "Epoch 2716/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0370 - acc: 0.9917\n",
      "Epoch 2717/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0378 - acc: 0.9917\n",
      "Epoch 2718/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0378 - acc: 0.9917\n",
      "Epoch 2719/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0381 - acc: 0.9917\n",
      "Epoch 2720/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0377 - acc: 0.9917\n",
      "Epoch 2721/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0374 - acc: 0.9917\n",
      "Epoch 2722/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0373 - acc: 0.9917\n",
      "Epoch 2723/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0378 - acc: 0.9917\n",
      "Epoch 2724/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0381 - acc: 0.9917\n",
      "Epoch 2725/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0393 - acc: 0.9917\n",
      "Epoch 2726/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0384 - acc: 0.9917\n",
      "Epoch 2727/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0378 - acc: 0.9917\n",
      "Epoch 2728/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0372 - acc: 0.9917\n",
      "Epoch 2729/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0373 - acc: 0.9917\n",
      "Epoch 2730/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0382 - acc: 0.9917\n",
      "Epoch 2731/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0379 - acc: 0.9917\n",
      "Epoch 2732/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0381 - acc: 0.9917\n",
      "Epoch 2733/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0369 - acc: 0.9917\n",
      "Epoch 2734/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0374 - acc: 0.9917\n",
      "Epoch 2735/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0371 - acc: 0.9917\n",
      "Epoch 2736/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0368 - acc: 0.9917\n",
      "Epoch 2737/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0377 - acc: 0.9917\n",
      "Epoch 2738/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0412 - acc: 0.9917\n",
      "Epoch 2739/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0380 - acc: 0.9917\n",
      "Epoch 2740/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0364 - acc: 0.9917\n",
      "Epoch 2741/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0400 - acc: 0.9917\n",
      "Epoch 2742/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0387 - acc: 0.9917\n",
      "Epoch 2743/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0369 - acc: 0.9917\n",
      "Epoch 2744/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0372 - acc: 0.9917\n",
      "Epoch 2745/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0386 - acc: 0.9917\n",
      "Epoch 2746/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0375 - acc: 0.9917\n",
      "Epoch 2747/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0373 - acc: 0.9917\n",
      "Epoch 2748/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0375 - acc: 0.9917\n",
      "Epoch 2749/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0374 - acc: 0.9917\n",
      "Epoch 2750/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0370 - acc: 0.9917\n",
      "Epoch 2751/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0413 - acc: 0.9917\n",
      "Epoch 2752/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0384 - acc: 0.9917\n",
      "Epoch 2753/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0389 - acc: 0.9917\n",
      "Epoch 2754/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0374 - acc: 0.9917\n",
      "Epoch 2755/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0370 - acc: 0.9917\n",
      "Epoch 2756/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0369 - acc: 0.9917\n",
      "Epoch 2757/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0371 - acc: 0.9917\n",
      "Epoch 2758/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0376 - acc: 0.9917\n",
      "Epoch 2759/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0369 - acc: 0.9917\n",
      "Epoch 2760/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0381 - acc: 0.9917\n",
      "Epoch 2761/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0371 - acc: 0.9917\n",
      "Epoch 2762/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0369 - acc: 0.9917\n",
      "Epoch 2763/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0370 - acc: 0.9917\n",
      "Epoch 2764/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0371 - acc: 0.9917\n",
      "Epoch 2765/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0370 - acc: 0.9917\n",
      "Epoch 2766/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0379 - acc: 0.9917\n",
      "Epoch 2767/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0372 - acc: 0.9917\n",
      "Epoch 2768/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0370 - acc: 0.9917\n",
      "Epoch 2769/8000\n",
      "120/120 [==============================] - 0s 83us/sample - loss: 0.0370 - acc: 0.9917\n",
      "Epoch 2770/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0374 - acc: 0.9917\n",
      "Epoch 2771/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0369 - acc: 0.9917\n",
      "Epoch 2772/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0377 - acc: 0.9917\n",
      "Epoch 2773/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0378 - acc: 0.9917\n",
      "Epoch 2774/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0223 - acc: 1.000 - 0s 75us/sample - loss: 0.0383 - acc: 0.9917\n",
      "Epoch 2775/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0367 - acc: 0.9917\n",
      "Epoch 2776/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0370 - acc: 0.9917\n",
      "Epoch 2777/8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0370 - acc: 0.9917\n",
      "Epoch 2778/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0370 - acc: 0.9917\n",
      "Epoch 2779/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0368 - acc: 0.9917\n",
      "Epoch 2780/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0370 - acc: 0.9917\n",
      "Epoch 2781/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0375 - acc: 0.9917\n",
      "Epoch 2782/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0370 - acc: 0.9917\n",
      "Epoch 2783/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0368 - acc: 0.9917\n",
      "Epoch 2784/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0383 - acc: 0.9917\n",
      "Epoch 2785/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0373 - acc: 0.9917\n",
      "Epoch 2786/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0375 - acc: 0.9917\n",
      "Epoch 2787/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0377 - acc: 0.9917\n",
      "Epoch 2788/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0366 - acc: 0.9917\n",
      "Epoch 2789/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0376 - acc: 0.9917\n",
      "Epoch 2790/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0385 - acc: 0.9917\n",
      "Epoch 2791/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0370 - acc: 0.9917\n",
      "Epoch 2792/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0358 - acc: 0.9917\n",
      "Epoch 2793/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0400 - acc: 0.9917\n",
      "Epoch 2794/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0396 - acc: 0.9917\n",
      "Epoch 2795/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0367 - acc: 0.9917\n",
      "Epoch 2796/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0374 - acc: 0.9917\n",
      "Epoch 2797/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0372 - acc: 0.9917\n",
      "Epoch 2798/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0372 - acc: 0.9917\n",
      "Epoch 2799/8000\n",
      "120/120 [==============================] - 0s 59us/sample - loss: 0.0368 - acc: 0.9917\n",
      "Epoch 2800/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0367 - acc: 0.9917\n",
      "Epoch 2801/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0375 - acc: 0.9917\n",
      "Epoch 2802/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0383 - acc: 0.9917\n",
      "Epoch 2803/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0372 - acc: 0.9917\n",
      "Epoch 2804/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0373 - acc: 0.9917\n",
      "Epoch 2805/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0404 - acc: 0.9917\n",
      "Epoch 2806/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0400 - acc: 0.9917\n",
      "Epoch 2807/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0369 - acc: 0.9917\n",
      "Epoch 2808/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0376 - acc: 0.9917\n",
      "Epoch 2809/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0394 - acc: 0.9917\n",
      "Epoch 2810/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0386 - acc: 0.9917\n",
      "Epoch 2811/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0412 - acc: 0.9917\n",
      "Epoch 2812/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0382 - acc: 0.9917\n",
      "Epoch 2813/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0369 - acc: 0.9917\n",
      "Epoch 2814/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0367 - acc: 0.9917\n",
      "Epoch 2815/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0369 - acc: 0.9917\n",
      "Epoch 2816/8000\n",
      "120/120 [==============================] - 0s 59us/sample - loss: 0.0369 - acc: 0.9917\n",
      "Epoch 2817/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0378 - acc: 0.9917\n",
      "Epoch 2818/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0375 - acc: 0.9917\n",
      "Epoch 2819/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0368 - acc: 0.9917\n",
      "Epoch 2820/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0366 - acc: 0.9917\n",
      "Epoch 2821/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0365 - acc: 0.9917\n",
      "Epoch 2822/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0367 - acc: 0.9917\n",
      "Epoch 2823/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0284 - acc: 1.000 - 0s 67us/sample - loss: 0.0365 - acc: 0.9917\n",
      "Epoch 2824/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0369 - acc: 0.9917\n",
      "Epoch 2825/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0365 - acc: 0.9917\n",
      "Epoch 2826/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0369 - acc: 0.9917\n",
      "Epoch 2827/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0389 - acc: 0.9917\n",
      "Epoch 2828/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0361 - acc: 0.9917\n",
      "Epoch 2829/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0400 - acc: 0.9917\n",
      "Epoch 2830/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0390 - acc: 0.9917\n",
      "Epoch 2831/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0366 - acc: 0.9917\n",
      "Epoch 2832/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0374 - acc: 0.9917\n",
      "Epoch 2833/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0371 - acc: 0.9917\n",
      "Epoch 2834/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0367 - acc: 0.9917\n",
      "Epoch 2835/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0369 - acc: 0.9917\n",
      "Epoch 2836/8000\n",
      "120/120 [==============================] - 0s 83us/sample - loss: 0.0389 - acc: 0.9917\n",
      "Epoch 2837/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0368 - acc: 0.9917\n",
      "Epoch 2838/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0413 - acc: 0.9917\n",
      "Epoch 2839/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0383 - acc: 0.9917\n",
      "Epoch 2840/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0366 - acc: 0.9917\n",
      "Epoch 2841/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0364 - acc: 0.9917\n",
      "Epoch 2842/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0892 - acc: 0.968 - 0s 67us/sample - loss: 0.0388 - acc: 0.9917\n",
      "Epoch 2843/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0368 - acc: 0.9917\n",
      "Epoch 2844/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0374 - acc: 0.9917\n",
      "Epoch 2845/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0376 - acc: 0.9917\n",
      "Epoch 2846/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0367 - acc: 0.9917\n",
      "Epoch 2847/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0368 - acc: 0.9917\n",
      "Epoch 2848/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0368 - acc: 0.9917\n",
      "Epoch 2849/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0365 - acc: 0.9917\n",
      "Epoch 2850/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0373 - acc: 0.9917\n",
      "Epoch 2851/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0372 - acc: 0.9917\n",
      "Epoch 2852/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0372 - acc: 0.9917\n",
      "Epoch 2853/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0370 - acc: 0.9917\n",
      "Epoch 2854/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0376 - acc: 0.9917\n",
      "Epoch 2855/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0368 - acc: 0.9917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2856/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0365 - acc: 0.9917\n",
      "Epoch 2857/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0364 - acc: 0.9917\n",
      "Epoch 2858/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0365 - acc: 0.9917\n",
      "Epoch 2859/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0376 - acc: 0.9917\n",
      "Epoch 2860/8000\n",
      "120/120 [==============================] - 0s 83us/sample - loss: 0.0380 - acc: 0.9917\n",
      "Epoch 2861/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0400 - acc: 0.9917\n",
      "Epoch 2862/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0376 - acc: 0.9917\n",
      "Epoch 2863/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0364 - acc: 0.9917\n",
      "Epoch 2864/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0363 - acc: 0.9917\n",
      "Epoch 2865/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0385 - acc: 0.9917\n",
      "Epoch 2866/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0369 - acc: 0.9917\n",
      "Epoch 2867/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0394 - acc: 0.9917\n",
      "Epoch 2868/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0374 - acc: 0.9917\n",
      "Epoch 2869/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0395 - acc: 0.9917\n",
      "Epoch 2870/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0371 - acc: 0.9917\n",
      "Epoch 2871/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0365 - acc: 0.9917\n",
      "Epoch 2872/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0364 - acc: 0.9917\n",
      "Epoch 2873/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0363 - acc: 0.9917\n",
      "Epoch 2874/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0369 - acc: 0.9917\n",
      "Epoch 2875/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0371 - acc: 0.9917\n",
      "Epoch 2876/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0370 - acc: 0.9917\n",
      "Epoch 2877/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0367 - acc: 0.9917\n",
      "Epoch 2878/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0370 - acc: 0.9917\n",
      "Epoch 2879/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0363 - acc: 0.9917\n",
      "Epoch 2880/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0371 - acc: 0.9917\n",
      "Epoch 2881/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0374 - acc: 0.9917\n",
      "Epoch 2882/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0370 - acc: 0.9917\n",
      "Epoch 2883/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0369 - acc: 0.9917\n",
      "Epoch 2884/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0365 - acc: 0.9917\n",
      "Epoch 2885/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0367 - acc: 0.9917\n",
      "Epoch 2886/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0374 - acc: 0.9917\n",
      "Epoch 2887/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0365 - acc: 0.9917\n",
      "Epoch 2888/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0370 - acc: 0.9917\n",
      "Epoch 2889/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0378 - acc: 0.9917\n",
      "Epoch 2890/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0369 - acc: 0.9917\n",
      "Epoch 2891/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0370 - acc: 0.9917\n",
      "Epoch 2892/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0372 - acc: 0.9917\n",
      "Epoch 2893/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0364 - acc: 0.9917\n",
      "Epoch 2894/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0369 - acc: 0.9917\n",
      "Epoch 2895/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0366 - acc: 0.9917\n",
      "Epoch 2896/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0364 - acc: 0.9917\n",
      "Epoch 2897/8000\n",
      "120/120 [==============================] - 0s 83us/sample - loss: 0.0366 - acc: 0.9917\n",
      "Epoch 2898/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0362 - acc: 0.9917\n",
      "Epoch 2899/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0363 - acc: 0.9917\n",
      "Epoch 2900/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0375 - acc: 0.9917\n",
      "Epoch 2901/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0363 - acc: 0.9917\n",
      "Epoch 2902/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0370 - acc: 0.9917\n",
      "Epoch 2903/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0367 - acc: 0.9917\n",
      "Epoch 2904/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0374 - acc: 0.9917\n",
      "Epoch 2905/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0365 - acc: 0.9917\n",
      "Epoch 2906/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0365 - acc: 0.9917\n",
      "Epoch 2907/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0373 - acc: 0.9917\n",
      "Epoch 2908/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0371 - acc: 0.9917\n",
      "Epoch 2909/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0352 - acc: 0.9917\n",
      "Epoch 2910/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0384 - acc: 0.9917\n",
      "Epoch 2911/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0378 - acc: 0.9917\n",
      "Epoch 2912/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0360 - acc: 0.9917\n",
      "Epoch 2913/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0361 - acc: 0.9917\n",
      "Epoch 2914/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0365 - acc: 0.9917\n",
      "Epoch 2915/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0373 - acc: 0.9917\n",
      "Epoch 2916/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0361 - acc: 0.9917\n",
      "Epoch 2917/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0375 - acc: 0.9917\n",
      "Epoch 2918/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0373 - acc: 0.9917\n",
      "Epoch 2919/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0359 - acc: 0.9917\n",
      "Epoch 2920/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0372 - acc: 0.9917\n",
      "Epoch 2921/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0392 - acc: 0.9917\n",
      "Epoch 2922/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0383 - acc: 0.9917\n",
      "Epoch 2923/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0362 - acc: 0.9917\n",
      "Epoch 2924/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0360 - acc: 0.9917\n",
      "Epoch 2925/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0381 - acc: 0.9917\n",
      "Epoch 2926/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0376 - acc: 0.9917\n",
      "Epoch 2927/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0369 - acc: 0.9917\n",
      "Epoch 2928/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0392 - acc: 0.9917\n",
      "Epoch 2929/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0389 - acc: 0.9917\n",
      "Epoch 2930/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0367 - acc: 0.9917\n",
      "Epoch 2931/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0366 - acc: 0.9917\n",
      "Epoch 2932/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0368 - acc: 0.9917\n",
      "Epoch 2933/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0368 - acc: 0.9917\n",
      "Epoch 2934/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0379 - acc: 0.9917\n",
      "Epoch 2935/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0381 - acc: 0.9917\n",
      "Epoch 2936/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0375 - acc: 0.9917\n",
      "Epoch 2937/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0220 - acc: 1.000 - 0s 75us/sample - loss: 0.0369 - acc: 0.9917\n",
      "Epoch 2938/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0363 - acc: 0.9917\n",
      "Epoch 2939/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0365 - acc: 0.9917\n",
      "Epoch 2940/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0364 - acc: 0.9917\n",
      "Epoch 2941/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0370 - acc: 0.9917\n",
      "Epoch 2942/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0359 - acc: 0.9917\n",
      "Epoch 2943/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0388 - acc: 0.9917\n",
      "Epoch 2944/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0369 - acc: 0.9917\n",
      "Epoch 2945/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0363 - acc: 0.9917\n",
      "Epoch 2946/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0360 - acc: 0.9917\n",
      "Epoch 2947/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0365 - acc: 0.9917\n",
      "Epoch 2948/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0364 - acc: 0.9917\n",
      "Epoch 2949/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0366 - acc: 0.9917\n",
      "Epoch 2950/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0362 - acc: 0.9917\n",
      "Epoch 2951/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0365 - acc: 0.9917\n",
      "Epoch 2952/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0365 - acc: 0.9917\n",
      "Epoch 2953/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0377 - acc: 0.9917\n",
      "Epoch 2954/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0374 - acc: 0.9917\n",
      "Epoch 2955/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0361 - acc: 0.9917\n",
      "Epoch 2956/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0365 - acc: 0.9917\n",
      "Epoch 2957/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0361 - acc: 0.9917\n",
      "Epoch 2958/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0358 - acc: 0.9917\n",
      "Epoch 2959/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0359 - acc: 0.9917\n",
      "Epoch 2960/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0384 - acc: 0.9917\n",
      "Epoch 2961/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0365 - acc: 0.9917\n",
      "Epoch 2962/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0383 - acc: 0.9917\n",
      "Epoch 2963/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0381 - acc: 0.9917\n",
      "Epoch 2964/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0362 - acc: 0.9917\n",
      "Epoch 2965/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0367 - acc: 0.9917\n",
      "Epoch 2966/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0364 - acc: 0.9917\n",
      "Epoch 2967/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0366 - acc: 0.9917\n",
      "Epoch 2968/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0373 - acc: 0.9917\n",
      "Epoch 2969/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0367 - acc: 0.9917\n",
      "Epoch 2970/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0357 - acc: 0.9917\n",
      "Epoch 2971/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0366 - acc: 0.9917\n",
      "Epoch 2972/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0373 - acc: 0.9917\n",
      "Epoch 2973/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0360 - acc: 0.9917\n",
      "Epoch 2974/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0358 - acc: 0.9917\n",
      "Epoch 2975/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0360 - acc: 0.9917\n",
      "Epoch 2976/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0367 - acc: 0.9917\n",
      "Epoch 2977/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0361 - acc: 0.9917\n",
      "Epoch 2978/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0364 - acc: 0.9917\n",
      "Epoch 2979/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0383 - acc: 0.9917\n",
      "Epoch 2980/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0368 - acc: 0.9917\n",
      "Epoch 2981/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0367 - acc: 0.9917\n",
      "Epoch 2982/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0361 - acc: 0.9917\n",
      "Epoch 2983/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0362 - acc: 0.9917\n",
      "Epoch 2984/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0406 - acc: 0.9917\n",
      "Epoch 2985/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0361 - acc: 0.9917\n",
      "Epoch 2986/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0361 - acc: 0.9917\n",
      "Epoch 2987/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0364 - acc: 0.9917\n",
      "Epoch 2988/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0364 - acc: 0.9917\n",
      "Epoch 2989/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0381 - acc: 0.9917\n",
      "Epoch 2990/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0372 - acc: 0.9917\n",
      "Epoch 2991/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0366 - acc: 0.9917\n",
      "Epoch 2992/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0358 - acc: 0.9917\n",
      "Epoch 2993/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0359 - acc: 0.9917\n",
      "Epoch 2994/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0368 - acc: 0.9917\n",
      "Epoch 2995/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0383 - acc: 0.9917\n",
      "Epoch 2996/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0372 - acc: 0.9917\n",
      "Epoch 2997/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0390 - acc: 0.9917\n",
      "Epoch 2998/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0370 - acc: 0.9917\n",
      "Epoch 2999/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0391 - acc: 0.9917\n",
      "Epoch 3000/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0396 - acc: 0.9833\n",
      "Epoch 3001/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0401 - acc: 0.9917\n",
      "Epoch 3002/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0356 - acc: 0.9917\n",
      "Epoch 3003/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0380 - acc: 0.9917\n",
      "Epoch 3004/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0364 - acc: 0.9917\n",
      "Epoch 3005/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0352 - acc: 0.9917\n",
      "Epoch 3006/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0363 - acc: 0.9917\n",
      "Epoch 3007/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0379 - acc: 0.9917\n",
      "Epoch 3008/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0363 - acc: 0.9917\n",
      "Epoch 3009/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0356 - acc: 0.9917\n",
      "Epoch 3010/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0384 - acc: 0.9917\n",
      "Epoch 3011/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0374 - acc: 0.9917\n",
      "Epoch 3012/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0371 - acc: 0.9917\n",
      "Epoch 3013/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0366 - acc: 0.9917\n",
      "Epoch 3014/8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0366 - acc: 0.9917\n",
      "Epoch 3015/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0362 - acc: 0.9917\n",
      "Epoch 3016/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0367 - acc: 0.9917\n",
      "Epoch 3017/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0370 - acc: 0.9917\n",
      "Epoch 3018/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0354 - acc: 0.9917\n",
      "Epoch 3019/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0360 - acc: 0.9917\n",
      "Epoch 3020/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0360 - acc: 0.9917\n",
      "Epoch 3021/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0375 - acc: 0.9917\n",
      "Epoch 3022/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0362 - acc: 0.9917\n",
      "Epoch 3023/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0369 - acc: 0.9917\n",
      "Epoch 3024/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0370 - acc: 0.9917\n",
      "Epoch 3025/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0374 - acc: 0.9917\n",
      "Epoch 3026/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0362 - acc: 0.9917\n",
      "Epoch 3027/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0356 - acc: 0.9917\n",
      "Epoch 3028/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0362 - acc: 0.9917\n",
      "Epoch 3029/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0372 - acc: 0.9917\n",
      "Epoch 3030/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0360 - acc: 0.9917\n",
      "Epoch 3031/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0368 - acc: 0.9917\n",
      "Epoch 3032/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0358 - acc: 0.9917\n",
      "Epoch 3033/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0373 - acc: 0.9917\n",
      "Epoch 3034/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0368 - acc: 0.9917\n",
      "Epoch 3035/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0366 - acc: 0.9917\n",
      "Epoch 3036/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0365 - acc: 0.9917\n",
      "Epoch 3037/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0359 - acc: 0.9917\n",
      "Epoch 3038/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0358 - acc: 0.9917\n",
      "Epoch 3039/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0372 - acc: 0.9917\n",
      "Epoch 3040/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0363 - acc: 0.9917\n",
      "Epoch 3041/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0363 - acc: 0.9917\n",
      "Epoch 3042/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0365 - acc: 0.9917\n",
      "Epoch 3043/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0371 - acc: 0.9917\n",
      "Epoch 3044/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0359 - acc: 0.9917\n",
      "Epoch 3045/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0366 - acc: 0.9917\n",
      "Epoch 3046/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0361 - acc: 0.9917\n",
      "Epoch 3047/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0371 - acc: 0.9917\n",
      "Epoch 3048/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0364 - acc: 0.9917\n",
      "Epoch 3049/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0357 - acc: 0.9917\n",
      "Epoch 3050/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0358 - acc: 0.9917\n",
      "Epoch 3051/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0357 - acc: 0.9917\n",
      "Epoch 3052/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0360 - acc: 0.9917\n",
      "Epoch 3053/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0357 - acc: 0.9917\n",
      "Epoch 3054/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0369 - acc: 0.9917\n",
      "Epoch 3055/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0357 - acc: 0.9917\n",
      "Epoch 3056/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0369 - acc: 0.9917\n",
      "Epoch 3057/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0362 - acc: 0.9917\n",
      "Epoch 3058/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0358 - acc: 0.9917\n",
      "Epoch 3059/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0362 - acc: 0.9917\n",
      "Epoch 3060/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0368 - acc: 0.9917\n",
      "Epoch 3061/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0359 - acc: 0.9917\n",
      "Epoch 3062/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0361 - acc: 0.9917\n",
      "Epoch 3063/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0373 - acc: 0.9917\n",
      "Epoch 3064/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0352 - acc: 0.9917\n",
      "Epoch 3065/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0351 - acc: 0.9917\n",
      "Epoch 3066/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0369 - acc: 0.9917\n",
      "Epoch 3067/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0370 - acc: 0.9917\n",
      "Epoch 3068/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0355 - acc: 0.9917\n",
      "Epoch 3069/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0372 - acc: 0.9917\n",
      "Epoch 3070/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0366 - acc: 0.9917\n",
      "Epoch 3071/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0383 - acc: 0.9917\n",
      "Epoch 3072/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0362 - acc: 0.9917\n",
      "Epoch 3073/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0362 - acc: 0.9917\n",
      "Epoch 3074/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0368 - acc: 0.9917\n",
      "Epoch 3075/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0358 - acc: 0.9917\n",
      "Epoch 3076/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0376 - acc: 0.9917\n",
      "Epoch 3077/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0365 - acc: 0.9917\n",
      "Epoch 3078/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0360 - acc: 0.9917\n",
      "Epoch 3079/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0360 - acc: 0.9917\n",
      "Epoch 3080/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0355 - acc: 0.9917\n",
      "Epoch 3081/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0357 - acc: 0.9917\n",
      "Epoch 3082/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0358 - acc: 0.9917\n",
      "Epoch 3083/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0353 - acc: 0.9917\n",
      "Epoch 3084/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0357 - acc: 0.9917\n",
      "Epoch 3085/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0373 - acc: 0.9917\n",
      "Epoch 3086/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0378 - acc: 0.9917\n",
      "Epoch 3087/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0362 - acc: 0.9917\n",
      "Epoch 3088/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0355 - acc: 0.9917\n",
      "Epoch 3089/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0359 - acc: 0.9917\n",
      "Epoch 3090/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0359 - acc: 0.9917\n",
      "Epoch 3091/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0357 - acc: 0.9917\n",
      "Epoch 3092/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0360 - acc: 0.9917\n",
      "Epoch 3093/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0354 - acc: 0.9917\n",
      "Epoch 3094/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0365 - acc: 0.9917\n",
      "Epoch 3095/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0354 - acc: 0.9917\n",
      "Epoch 3096/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0358 - acc: 0.9917\n",
      "Epoch 3097/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0374 - acc: 0.9917\n",
      "Epoch 3098/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0361 - acc: 0.9917\n",
      "Epoch 3099/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0358 - acc: 0.9917\n",
      "Epoch 3100/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0368 - acc: 0.9917\n",
      "Epoch 3101/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0360 - acc: 0.9917\n",
      "Epoch 3102/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0364 - acc: 0.9917\n",
      "Epoch 3103/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0362 - acc: 0.9917\n",
      "Epoch 3104/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0364 - acc: 0.9917\n",
      "Epoch 3105/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0354 - acc: 0.9917\n",
      "Epoch 3106/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0358 - acc: 0.9917\n",
      "Epoch 3107/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0354 - acc: 0.9917\n",
      "Epoch 3108/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0364 - acc: 0.9917\n",
      "Epoch 3109/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0360 - acc: 0.9917\n",
      "Epoch 3110/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0361 - acc: 0.9917\n",
      "Epoch 3111/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0357 - acc: 0.9917\n",
      "Epoch 3112/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0363 - acc: 0.9917\n",
      "Epoch 3113/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0355 - acc: 0.9917\n",
      "Epoch 3114/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0389 - acc: 0.9917\n",
      "Epoch 3115/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0362 - acc: 0.9917\n",
      "Epoch 3116/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0357 - acc: 0.9917\n",
      "Epoch 3117/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0374 - acc: 0.9917\n",
      "Epoch 3118/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0373 - acc: 0.9917\n",
      "Epoch 3119/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0351 - acc: 0.9917\n",
      "Epoch 3120/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0354 - acc: 0.9917\n",
      "Epoch 3121/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0363 - acc: 0.9917\n",
      "Epoch 3122/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0369 - acc: 0.9917\n",
      "Epoch 3123/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0375 - acc: 0.9917\n",
      "Epoch 3124/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0358 - acc: 0.9917\n",
      "Epoch 3125/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0368 - acc: 0.9917\n",
      "Epoch 3126/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0367 - acc: 0.9917\n",
      "Epoch 3127/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0344 - acc: 0.9917\n",
      "Epoch 3128/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0351 - acc: 0.9917\n",
      "Epoch 3129/8000\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.0376 - acc: 0.9917\n",
      "Epoch 3130/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0364 - acc: 0.9917\n",
      "Epoch 3131/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0370 - acc: 0.9917\n",
      "Epoch 3132/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0361 - acc: 0.9917\n",
      "Epoch 3133/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0357 - acc: 0.9917\n",
      "Epoch 3134/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0357 - acc: 0.9917\n",
      "Epoch 3135/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0357 - acc: 0.9917\n",
      "Epoch 3136/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0362 - acc: 0.9917\n",
      "Epoch 3137/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0357 - acc: 0.9917\n",
      "Epoch 3138/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0361 - acc: 0.9917\n",
      "Epoch 3139/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0361 - acc: 0.9917\n",
      "Epoch 3140/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0363 - acc: 0.9917\n",
      "Epoch 3141/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0353 - acc: 0.9917\n",
      "Epoch 3142/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0353 - acc: 0.9917\n",
      "Epoch 3143/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0355 - acc: 0.9917\n",
      "Epoch 3144/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0381 - acc: 0.9917\n",
      "Epoch 3145/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0353 - acc: 0.9917\n",
      "Epoch 3146/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0354 - acc: 0.9917\n",
      "Epoch 3147/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0357 - acc: 0.9917\n",
      "Epoch 3148/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0359 - acc: 0.9917\n",
      "Epoch 3149/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0353 - acc: 0.9917\n",
      "Epoch 3150/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0354 - acc: 0.9917\n",
      "Epoch 3151/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0352 - acc: 0.9917\n",
      "Epoch 3152/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0354 - acc: 0.9917\n",
      "Epoch 3153/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0361 - acc: 0.9917\n",
      "Epoch 3154/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0354 - acc: 0.9917\n",
      "Epoch 3155/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0362 - acc: 0.9917\n",
      "Epoch 3156/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0351 - acc: 0.9917\n",
      "Epoch 3157/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0353 - acc: 0.9917\n",
      "Epoch 3158/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0359 - acc: 0.9917\n",
      "Epoch 3159/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0358 - acc: 0.9917\n",
      "Epoch 3160/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0423 - acc: 0.9917\n",
      "Epoch 3161/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0377 - acc: 0.9917\n",
      "Epoch 3162/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0354 - acc: 0.9917\n",
      "Epoch 3163/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0359 - acc: 0.9917\n",
      "Epoch 3164/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0360 - acc: 0.9917\n",
      "Epoch 3165/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0389 - acc: 0.9917\n",
      "Epoch 3166/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0383 - acc: 0.9917\n",
      "Epoch 3167/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0360 - acc: 0.9917\n",
      "Epoch 3168/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0360 - acc: 0.9917\n",
      "Epoch 3169/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0356 - acc: 0.9917\n",
      "Epoch 3170/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0356 - acc: 0.9917\n",
      "Epoch 3171/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0358 - acc: 0.9917\n",
      "Epoch 3172/8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0350 - acc: 0.9917\n",
      "Epoch 3173/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0352 - acc: 0.9917\n",
      "Epoch 3174/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0353 - acc: 0.9917\n",
      "Epoch 3175/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0358 - acc: 0.9917\n",
      "Epoch 3176/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0355 - acc: 0.9917\n",
      "Epoch 3177/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0353 - acc: 0.9917\n",
      "Epoch 3178/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0361 - acc: 0.9917\n",
      "Epoch 3179/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0356 - acc: 0.9917\n",
      "Epoch 3180/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0361 - acc: 0.9917\n",
      "Epoch 3181/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0352 - acc: 0.9917\n",
      "Epoch 3182/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0353 - acc: 0.9917\n",
      "Epoch 3183/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0352 - acc: 0.9917\n",
      "Epoch 3184/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0367 - acc: 0.9917\n",
      "Epoch 3185/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0354 - acc: 0.9917\n",
      "Epoch 3186/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0357 - acc: 0.9917\n",
      "Epoch 3187/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0361 - acc: 0.9917\n",
      "Epoch 3188/8000\n",
      "120/120 [==============================] - 0s 59us/sample - loss: 0.0357 - acc: 0.9917\n",
      "Epoch 3189/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0363 - acc: 0.9917\n",
      "Epoch 3190/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0361 - acc: 0.9917\n",
      "Epoch 3191/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0267 - acc: 1.000 - 0s 75us/sample - loss: 0.0349 - acc: 0.9917\n",
      "Epoch 3192/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0359 - acc: 0.9917\n",
      "Epoch 3193/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0373 - acc: 0.9917\n",
      "Epoch 3194/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0363 - acc: 0.9917\n",
      "Epoch 3195/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0356 - acc: 0.9917\n",
      "Epoch 3196/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0376 - acc: 0.9917\n",
      "Epoch 3197/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0350 - acc: 0.9917\n",
      "Epoch 3198/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0353 - acc: 0.9917\n",
      "Epoch 3199/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0356 - acc: 0.9917\n",
      "Epoch 3200/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0363 - acc: 0.9917\n",
      "Epoch 3201/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0354 - acc: 0.9917\n",
      "Epoch 3202/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0351 - acc: 0.9917\n",
      "Epoch 3203/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0360 - acc: 0.9917\n",
      "Epoch 3204/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0356 - acc: 0.9917\n",
      "Epoch 3205/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0358 - acc: 0.9917\n",
      "Epoch 3206/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0369 - acc: 0.9917\n",
      "Epoch 3207/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0356 - acc: 0.9917\n",
      "Epoch 3208/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0357 - acc: 0.9917\n",
      "Epoch 3209/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0354 - acc: 0.9917\n",
      "Epoch 3210/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0371 - acc: 0.9917\n",
      "Epoch 3211/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0367 - acc: 0.9917\n",
      "Epoch 3212/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0359 - acc: 0.9917\n",
      "Epoch 3213/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0355 - acc: 0.9917\n",
      "Epoch 3214/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0354 - acc: 0.9917\n",
      "Epoch 3215/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0351 - acc: 0.9917\n",
      "Epoch 3216/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0352 - acc: 0.9917\n",
      "Epoch 3217/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0350 - acc: 0.9917\n",
      "Epoch 3218/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0353 - acc: 0.9917\n",
      "Epoch 3219/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0351 - acc: 0.9917\n",
      "Epoch 3220/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0350 - acc: 0.9917\n",
      "Epoch 3221/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0366 - acc: 0.9917\n",
      "Epoch 3222/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0353 - acc: 0.9917\n",
      "Epoch 3223/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0354 - acc: 0.9917\n",
      "Epoch 3224/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0359 - acc: 0.9917\n",
      "Epoch 3225/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0368 - acc: 0.9917\n",
      "Epoch 3226/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0366 - acc: 0.9917\n",
      "Epoch 3227/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0360 - acc: 0.9917\n",
      "Epoch 3228/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0354 - acc: 0.9917\n",
      "Epoch 3229/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0371 - acc: 0.9917\n",
      "Epoch 3230/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0350 - acc: 0.9917\n",
      "Epoch 3231/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0352 - acc: 0.9917\n",
      "Epoch 3232/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0361 - acc: 0.9917\n",
      "Epoch 3233/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0348 - acc: 0.9917\n",
      "Epoch 3234/8000\n",
      "120/120 [==============================] - 0s 59us/sample - loss: 0.0381 - acc: 0.9917\n",
      "Epoch 3235/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0346 - acc: 0.9917\n",
      "Epoch 3236/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0360 - acc: 0.9917\n",
      "Epoch 3237/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0378 - acc: 0.9917\n",
      "Epoch 3238/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0349 - acc: 0.9917\n",
      "Epoch 3239/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0358 - acc: 0.9917\n",
      "Epoch 3240/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0360 - acc: 0.9917\n",
      "Epoch 3241/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0353 - acc: 0.9917\n",
      "Epoch 3242/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0353 - acc: 0.9917\n",
      "Epoch 3243/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0129 - acc: 1.000 - 0s 84us/sample - loss: 0.0360 - acc: 0.9917\n",
      "Epoch 3244/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0362 - acc: 0.9917\n",
      "Epoch 3245/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0379 - acc: 0.9917\n",
      "Epoch 3246/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0367 - acc: 0.9917\n",
      "Epoch 3247/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0375 - acc: 0.9917\n",
      "Epoch 3248/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0368 - acc: 0.9917\n",
      "Epoch 3249/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0358 - acc: 0.9917\n",
      "Epoch 3250/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0369 - acc: 0.9917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3251/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0350 - acc: 0.9917\n",
      "Epoch 3252/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0348 - acc: 0.9917\n",
      "Epoch 3253/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0354 - acc: 0.9917\n",
      "Epoch 3254/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0354 - acc: 0.9917\n",
      "Epoch 3255/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0369 - acc: 0.9917\n",
      "Epoch 3256/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0349 - acc: 0.9917\n",
      "Epoch 3257/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0351 - acc: 0.9917\n",
      "Epoch 3258/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0355 - acc: 0.9917\n",
      "Epoch 3259/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0351 - acc: 0.9917\n",
      "Epoch 3260/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0347 - acc: 0.9917\n",
      "Epoch 3261/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0355 - acc: 0.9917\n",
      "Epoch 3262/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0383 - acc: 0.9917\n",
      "Epoch 3263/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0356 - acc: 0.9917\n",
      "Epoch 3264/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0354 - acc: 0.9917\n",
      "Epoch 3265/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0361 - acc: 0.9917\n",
      "Epoch 3266/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0356 - acc: 0.9917\n",
      "Epoch 3267/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0356 - acc: 0.9917\n",
      "Epoch 3268/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0351 - acc: 0.9917\n",
      "Epoch 3269/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0356 - acc: 0.9917\n",
      "Epoch 3270/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0356 - acc: 0.9917\n",
      "Epoch 3271/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0347 - acc: 0.9917\n",
      "Epoch 3272/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0351 - acc: 0.9917\n",
      "Epoch 3273/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0359 - acc: 0.9917\n",
      "Epoch 3274/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0349 - acc: 0.9917\n",
      "Epoch 3275/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0351 - acc: 0.9917\n",
      "Epoch 3276/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0349 - acc: 0.9917\n",
      "Epoch 3277/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0349 - acc: 0.9917\n",
      "Epoch 3278/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0358 - acc: 0.9917\n",
      "Epoch 3279/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0363 - acc: 0.9917\n",
      "Epoch 3280/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0356 - acc: 0.9917\n",
      "Epoch 3281/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0364 - acc: 0.9917\n",
      "Epoch 3282/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0346 - acc: 0.9917\n",
      "Epoch 3283/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0346 - acc: 0.9917\n",
      "Epoch 3284/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0349 - acc: 0.9917\n",
      "Epoch 3285/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0350 - acc: 0.9917\n",
      "Epoch 3286/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0352 - acc: 0.9917\n",
      "Epoch 3287/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0377 - acc: 0.9917\n",
      "Epoch 3288/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0354 - acc: 0.9917\n",
      "Epoch 3289/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0347 - acc: 0.9917\n",
      "Epoch 3290/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0355 - acc: 0.9917\n",
      "Epoch 3291/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0343 - acc: 0.9917\n",
      "Epoch 3292/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0370 - acc: 0.9917\n",
      "Epoch 3293/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0355 - acc: 0.9917\n",
      "Epoch 3294/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0344 - acc: 0.9917\n",
      "Epoch 3295/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0360 - acc: 0.9917\n",
      "Epoch 3296/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0355 - acc: 0.9917\n",
      "Epoch 3297/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0349 - acc: 0.9917\n",
      "Epoch 3298/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0344 - acc: 0.9917\n",
      "Epoch 3299/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0353 - acc: 0.9917\n",
      "Epoch 3300/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0367 - acc: 0.9917\n",
      "Epoch 3301/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0353 - acc: 0.9917\n",
      "Epoch 3302/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0337 - acc: 0.9917\n",
      "Epoch 3303/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0344 - acc: 0.9917\n",
      "Epoch 3304/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0355 - acc: 0.9917\n",
      "Epoch 3305/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0362 - acc: 0.9917\n",
      "Epoch 3306/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0365 - acc: 0.9917\n",
      "Epoch 3307/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0348 - acc: 0.9917\n",
      "Epoch 3308/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0349 - acc: 0.9917\n",
      "Epoch 3309/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0351 - acc: 0.9917\n",
      "Epoch 3310/8000\n",
      "120/120 [==============================] - 0s 59us/sample - loss: 0.0349 - acc: 0.9917\n",
      "Epoch 3311/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0345 - acc: 0.9917\n",
      "Epoch 3312/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0356 - acc: 0.9917\n",
      "Epoch 3313/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0354 - acc: 0.9917\n",
      "Epoch 3314/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0349 - acc: 0.9917\n",
      "Epoch 3315/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0345 - acc: 0.9917\n",
      "Epoch 3316/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0359 - acc: 0.9917\n",
      "Epoch 3317/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0351 - acc: 0.9917\n",
      "Epoch 3318/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0345 - acc: 0.9917\n",
      "Epoch 3319/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0347 - acc: 0.9917\n",
      "Epoch 3320/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0356 - acc: 0.9917\n",
      "Epoch 3321/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0349 - acc: 0.9917\n",
      "Epoch 3322/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0169 - acc: 1.000 - 0s 67us/sample - loss: 0.0356 - acc: 0.9917\n",
      "Epoch 3323/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0349 - acc: 0.9917\n",
      "Epoch 3324/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0346 - acc: 0.9917\n",
      "Epoch 3325/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0348 - acc: 0.9917\n",
      "Epoch 3326/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0350 - acc: 0.9917\n",
      "Epoch 3327/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0357 - acc: 0.9917\n",
      "Epoch 3328/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0344 - acc: 0.9917\n",
      "Epoch 3329/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0351 - acc: 0.9917\n",
      "Epoch 3330/8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0353 - acc: 0.9917\n",
      "Epoch 3331/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0346 - acc: 0.9917\n",
      "Epoch 3332/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0346 - acc: 0.9917\n",
      "Epoch 3333/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0352 - acc: 0.9917\n",
      "Epoch 3334/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0348 - acc: 0.9917\n",
      "Epoch 3335/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0352 - acc: 0.9917\n",
      "Epoch 3336/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0355 - acc: 0.9917\n",
      "Epoch 3337/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0348 - acc: 0.9917\n",
      "Epoch 3338/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0347 - acc: 0.9917\n",
      "Epoch 3339/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0355 - acc: 0.9917\n",
      "Epoch 3340/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0345 - acc: 0.9917\n",
      "Epoch 3341/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0346 - acc: 0.9917\n",
      "Epoch 3342/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0351 - acc: 0.9917\n",
      "Epoch 3343/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0348 - acc: 0.9917\n",
      "Epoch 3344/8000\n",
      "120/120 [==============================] - 0s 50us/sample - loss: 0.0351 - acc: 0.9917\n",
      "Epoch 3345/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0350 - acc: 0.9917\n",
      "Epoch 3346/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0352 - acc: 0.9917\n",
      "Epoch 3347/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0347 - acc: 0.9917\n",
      "Epoch 3348/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0344 - acc: 0.9917\n",
      "Epoch 3349/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0345 - acc: 0.9917\n",
      "Epoch 3350/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0358 - acc: 0.9917\n",
      "Epoch 3351/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0350 - acc: 0.9917\n",
      "Epoch 3352/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0355 - acc: 0.9917\n",
      "Epoch 3353/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0343 - acc: 0.9917\n",
      "Epoch 3354/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0368 - acc: 0.9917\n",
      "Epoch 3355/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0346 - acc: 0.9917\n",
      "Epoch 3356/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0340 - acc: 0.9917\n",
      "Epoch 3357/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0351 - acc: 0.9917\n",
      "Epoch 3358/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0377 - acc: 0.9917\n",
      "Epoch 3359/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0356 - acc: 0.9917\n",
      "Epoch 3360/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0327 - acc: 0.9917\n",
      "Epoch 3361/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0380 - acc: 0.9917\n",
      "Epoch 3362/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0372 - acc: 0.9833\n",
      "Epoch 3363/8000\n",
      "120/120 [==============================] - 0s 83us/sample - loss: 0.0342 - acc: 0.9917\n",
      "Epoch 3364/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0357 - acc: 0.9917\n",
      "Epoch 3365/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0368 - acc: 0.9917\n",
      "Epoch 3366/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0351 - acc: 0.9917\n",
      "Epoch 3367/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0348 - acc: 0.9917\n",
      "Epoch 3368/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0362 - acc: 0.9917\n",
      "Epoch 3369/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0353 - acc: 0.9917\n",
      "Epoch 3370/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0345 - acc: 0.9917\n",
      "Epoch 3371/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0358 - acc: 0.9917\n",
      "Epoch 3372/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0350 - acc: 0.9917\n",
      "Epoch 3373/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0364 - acc: 0.9917\n",
      "Epoch 3374/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0362 - acc: 0.9917\n",
      "Epoch 3375/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0349 - acc: 0.9917\n",
      "Epoch 3376/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0348 - acc: 0.9917\n",
      "Epoch 3377/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0358 - acc: 0.9917\n",
      "Epoch 3378/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0343 - acc: 0.9917\n",
      "Epoch 3379/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0383 - acc: 0.9917\n",
      "Epoch 3380/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0360 - acc: 0.9917\n",
      "Epoch 3381/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0379 - acc: 0.9917\n",
      "Epoch 3382/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0345 - acc: 0.9917\n",
      "Epoch 3383/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0348 - acc: 0.9917\n",
      "Epoch 3384/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0345 - acc: 0.9917\n",
      "Epoch 3385/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0345 - acc: 0.9917\n",
      "Epoch 3386/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0342 - acc: 0.9917\n",
      "Epoch 3387/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0372 - acc: 0.9917\n",
      "Epoch 3388/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0367 - acc: 0.9917\n",
      "Epoch 3389/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0342 - acc: 0.9917\n",
      "Epoch 3390/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0345 - acc: 0.9917\n",
      "Epoch 3391/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0341 - acc: 0.9917\n",
      "Epoch 3392/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0343 - acc: 0.9917\n",
      "Epoch 3393/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0360 - acc: 0.9917\n",
      "Epoch 3394/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0346 - acc: 0.9917\n",
      "Epoch 3395/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0337 - acc: 0.9917\n",
      "Epoch 3396/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0367 - acc: 0.9917\n",
      "Epoch 3397/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0357 - acc: 0.9917\n",
      "Epoch 3398/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0357 - acc: 0.9917\n",
      "Epoch 3399/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0345 - acc: 0.9917\n",
      "Epoch 3400/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0348 - acc: 0.9917\n",
      "Epoch 3401/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0344 - acc: 0.9917\n",
      "Epoch 3402/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0347 - acc: 0.9917\n",
      "Epoch 3403/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0346 - acc: 0.9917\n",
      "Epoch 3404/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0343 - acc: 0.9917\n",
      "Epoch 3405/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0344 - acc: 0.9917\n",
      "Epoch 3406/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0348 - acc: 0.9917\n",
      "Epoch 3407/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0343 - acc: 0.9917\n",
      "Epoch 3408/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0355 - acc: 0.9917\n",
      "Epoch 3409/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0344 - acc: 0.9917\n",
      "Epoch 3410/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0345 - acc: 0.9917\n",
      "Epoch 3411/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0356 - acc: 0.9917\n",
      "Epoch 3412/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0344 - acc: 0.9917\n",
      "Epoch 3413/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0365 - acc: 0.9917\n",
      "Epoch 3414/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0350 - acc: 0.9917\n",
      "Epoch 3415/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0342 - acc: 0.9917\n",
      "Epoch 3416/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0341 - acc: 0.9917\n",
      "Epoch 3417/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0347 - acc: 0.9917\n",
      "Epoch 3418/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0344 - acc: 0.9917\n",
      "Epoch 3419/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0357 - acc: 0.9917\n",
      "Epoch 3420/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0352 - acc: 0.9917\n",
      "Epoch 3421/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0357 - acc: 0.9917\n",
      "Epoch 3422/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0349 - acc: 0.9917\n",
      "Epoch 3423/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0343 - acc: 0.9917\n",
      "Epoch 3424/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0344 - acc: 0.9917\n",
      "Epoch 3425/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0343 - acc: 0.9917\n",
      "Epoch 3426/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0343 - acc: 0.9917\n",
      "Epoch 3427/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0340 - acc: 0.9917\n",
      "Epoch 3428/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0347 - acc: 0.9917\n",
      "Epoch 3429/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0342 - acc: 0.9917\n",
      "Epoch 3430/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0342 - acc: 0.9917\n",
      "Epoch 3431/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0345 - acc: 0.9917\n",
      "Epoch 3432/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0346 - acc: 0.9917\n",
      "Epoch 3433/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0350 - acc: 0.9917\n",
      "Epoch 3434/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0339 - acc: 0.9917\n",
      "Epoch 3435/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0356 - acc: 0.9917\n",
      "Epoch 3436/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0356 - acc: 0.9917\n",
      "Epoch 3437/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0156 - acc: 1.000 - 0s 67us/sample - loss: 0.0341 - acc: 0.9917\n",
      "Epoch 3438/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0371 - acc: 0.9917\n",
      "Epoch 3439/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0357 - acc: 0.9917\n",
      "Epoch 3440/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0366 - acc: 0.9917\n",
      "Epoch 3441/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0360 - acc: 0.9917\n",
      "Epoch 3442/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0357 - acc: 0.9917\n",
      "Epoch 3443/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0343 - acc: 0.9917\n",
      "Epoch 3444/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0347 - acc: 0.9917\n",
      "Epoch 3445/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0357 - acc: 0.9917\n",
      "Epoch 3446/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0344 - acc: 0.9917\n",
      "Epoch 3447/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0344 - acc: 0.9917\n",
      "Epoch 3448/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0346 - acc: 0.9917\n",
      "Epoch 3449/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0355 - acc: 0.9917\n",
      "Epoch 3450/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0416 - acc: 0.9917\n",
      "Epoch 3451/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0361 - acc: 0.9917\n",
      "Epoch 3452/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0345 - acc: 0.9917\n",
      "Epoch 3453/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0362 - acc: 0.9917\n",
      "Epoch 3454/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0365 - acc: 0.9917\n",
      "Epoch 3455/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0345 - acc: 0.9917\n",
      "Epoch 3456/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0353 - acc: 0.9917\n",
      "Epoch 3457/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0352 - acc: 0.9917\n",
      "Epoch 3458/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0345 - acc: 0.9917\n",
      "Epoch 3459/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0350 - acc: 0.9917\n",
      "Epoch 3460/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0343 - acc: 0.9917\n",
      "Epoch 3461/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0340 - acc: 0.9917\n",
      "Epoch 3462/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0347 - acc: 0.9917\n",
      "Epoch 3463/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0343 - acc: 0.9917\n",
      "Epoch 3464/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0341 - acc: 0.9917\n",
      "Epoch 3465/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0355 - acc: 0.9917\n",
      "Epoch 3466/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0342 - acc: 0.9917\n",
      "Epoch 3467/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0343 - acc: 0.9917\n",
      "Epoch 3468/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0347 - acc: 0.9917\n",
      "Epoch 3469/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0340 - acc: 0.9917\n",
      "Epoch 3470/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0344 - acc: 0.9917\n",
      "Epoch 3471/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0369 - acc: 0.9917\n",
      "Epoch 3472/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0347 - acc: 0.9917\n",
      "Epoch 3473/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0390 - acc: 0.9917\n",
      "Epoch 3474/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0348 - acc: 0.9917\n",
      "Epoch 3475/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0329 - acc: 0.9917\n",
      "Epoch 3476/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0351 - acc: 0.9917\n",
      "Epoch 3477/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0356 - acc: 0.9917\n",
      "Epoch 3478/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0354 - acc: 0.9917\n",
      "Epoch 3479/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0349 - acc: 0.9917\n",
      "Epoch 3480/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0352 - acc: 0.9917\n",
      "Epoch 3481/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0339 - acc: 0.9917\n",
      "Epoch 3482/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0344 - acc: 0.9917\n",
      "Epoch 3483/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0364 - acc: 0.9917\n",
      "Epoch 3484/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0339 - acc: 0.9917\n",
      "Epoch 3485/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0379 - acc: 0.9917\n",
      "Epoch 3486/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0374 - acc: 0.9833\n",
      "Epoch 3487/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0379 - acc: 0.9917\n",
      "Epoch 3488/8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0345 - acc: 0.9917\n",
      "Epoch 3489/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0344 - acc: 0.9917\n",
      "Epoch 3490/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0343 - acc: 0.9917\n",
      "Epoch 3491/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0344 - acc: 0.9917\n",
      "Epoch 3492/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0342 - acc: 0.9917\n",
      "Epoch 3493/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0345 - acc: 0.9917\n",
      "Epoch 3494/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0346 - acc: 0.9917\n",
      "Epoch 3495/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0343 - acc: 0.9917\n",
      "Epoch 3496/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0345 - acc: 0.9917\n",
      "Epoch 3497/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0340 - acc: 0.9917\n",
      "Epoch 3498/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0337 - acc: 0.9917\n",
      "Epoch 3499/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0344 - acc: 0.9917\n",
      "Epoch 3500/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0359 - acc: 0.9917\n",
      "Epoch 3501/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0353 - acc: 0.9917\n",
      "Epoch 3502/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0337 - acc: 0.9917\n",
      "Epoch 3503/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0340 - acc: 0.9917\n",
      "Epoch 3504/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0350 - acc: 0.9917\n",
      "Epoch 3505/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0207 - acc: 1.000 - 0s 58us/sample - loss: 0.0342 - acc: 0.9917\n",
      "Epoch 3506/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0393 - acc: 0.9917\n",
      "Epoch 3507/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0360 - acc: 0.9917\n",
      "Epoch 3508/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0364 - acc: 0.9917\n",
      "Epoch 3509/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0359 - acc: 0.9917\n",
      "Epoch 3510/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0357 - acc: 0.9917\n",
      "Epoch 3511/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0338 - acc: 0.9917\n",
      "Epoch 3512/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0337 - acc: 0.9917\n",
      "Epoch 3513/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0347 - acc: 0.9917\n",
      "Epoch 3514/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0341 - acc: 0.9917\n",
      "Epoch 3515/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0352 - acc: 0.9917\n",
      "Epoch 3516/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0347 - acc: 0.9917\n",
      "Epoch 3517/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0337 - acc: 0.9917\n",
      "Epoch 3518/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0346 - acc: 0.9917\n",
      "Epoch 3519/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0351 - acc: 0.9917\n",
      "Epoch 3520/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0359 - acc: 0.9917\n",
      "Epoch 3521/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0360 - acc: 0.9917\n",
      "Epoch 3522/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0348 - acc: 0.9917\n",
      "Epoch 3523/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0340 - acc: 0.9917\n",
      "Epoch 3524/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0341 - acc: 0.9917\n",
      "Epoch 3525/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0344 - acc: 0.9917\n",
      "Epoch 3526/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0355 - acc: 0.9917\n",
      "Epoch 3527/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0361 - acc: 0.9917\n",
      "Epoch 3528/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0371 - acc: 0.9917\n",
      "Epoch 3529/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0348 - acc: 0.9917\n",
      "Epoch 3530/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0337 - acc: 0.9917\n",
      "Epoch 3531/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0340 - acc: 0.9917\n",
      "Epoch 3532/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0343 - acc: 0.9917\n",
      "Epoch 3533/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0343 - acc: 0.9917\n",
      "Epoch 3534/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0350 - acc: 0.9917\n",
      "Epoch 3535/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0340 - acc: 0.9917\n",
      "Epoch 3536/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0339 - acc: 0.9917\n",
      "Epoch 3537/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0359 - acc: 0.9917\n",
      "Epoch 3538/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0359 - acc: 0.9917\n",
      "Epoch 3539/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0350 - acc: 0.9917\n",
      "Epoch 3540/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0341 - acc: 0.9917\n",
      "Epoch 3541/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0337 - acc: 0.9917\n",
      "Epoch 3542/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0368 - acc: 0.9917\n",
      "Epoch 3543/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0351 - acc: 0.9917\n",
      "Epoch 3544/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0365 - acc: 0.9917\n",
      "Epoch 3545/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0354 - acc: 0.9917\n",
      "Epoch 3546/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0346 - acc: 0.9917\n",
      "Epoch 3547/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0347 - acc: 0.9917\n",
      "Epoch 3548/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0342 - acc: 0.9917\n",
      "Epoch 3549/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0342 - acc: 0.9917\n",
      "Epoch 3550/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0338 - acc: 0.9917\n",
      "Epoch 3551/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0338 - acc: 0.9917\n",
      "Epoch 3552/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0347 - acc: 0.9917\n",
      "Epoch 3553/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0345 - acc: 0.9917\n",
      "Epoch 3554/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0336 - acc: 0.9917\n",
      "Epoch 3555/8000\n",
      "120/120 [==============================] - 0s 83us/sample - loss: 0.0343 - acc: 0.9917\n",
      "Epoch 3556/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0347 - acc: 0.9917\n",
      "Epoch 3557/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0348 - acc: 0.9917\n",
      "Epoch 3558/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0333 - acc: 0.9917\n",
      "Epoch 3559/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0340 - acc: 0.9917\n",
      "Epoch 3560/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0346 - acc: 0.9917\n",
      "Epoch 3561/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0338 - acc: 0.9917\n",
      "Epoch 3562/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0336 - acc: 0.9917\n",
      "Epoch 3563/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0360 - acc: 0.9917\n",
      "Epoch 3564/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0365 - acc: 0.9917\n",
      "Epoch 3565/8000\n",
      "120/120 [==============================] - 0s 59us/sample - loss: 0.0346 - acc: 0.9917\n",
      "Epoch 3566/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0336 - acc: 0.9917\n",
      "Epoch 3567/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0345 - acc: 0.9917\n",
      "Epoch 3568/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0357 - acc: 0.9917\n",
      "Epoch 3569/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0328 - acc: 0.9917\n",
      "Epoch 3570/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0368 - acc: 0.9917\n",
      "Epoch 3571/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0383 - acc: 0.9833\n",
      "Epoch 3572/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0341 - acc: 0.9917\n",
      "Epoch 3573/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0351 - acc: 0.9917\n",
      "Epoch 3574/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0390 - acc: 0.9833\n",
      "Epoch 3575/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0179 - acc: 1.000 - 0s 58us/sample - loss: 0.0359 - acc: 0.9917\n",
      "Epoch 3576/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0358 - acc: 0.9917\n",
      "Epoch 3577/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0377 - acc: 0.9833\n",
      "Epoch 3578/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0338 - acc: 0.9917\n",
      "Epoch 3579/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0351 - acc: 0.9917\n",
      "Epoch 3580/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0350 - acc: 0.9917\n",
      "Epoch 3581/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0350 - acc: 0.9917\n",
      "Epoch 3582/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0371 - acc: 0.9917\n",
      "Epoch 3583/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0351 - acc: 0.9917\n",
      "Epoch 3584/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0338 - acc: 0.9917\n",
      "Epoch 3585/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0338 - acc: 0.9917\n",
      "Epoch 3586/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0343 - acc: 0.9917\n",
      "Epoch 3587/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0346 - acc: 0.9917\n",
      "Epoch 3588/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0341 - acc: 0.9917\n",
      "Epoch 3589/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0336 - acc: 0.9917\n",
      "Epoch 3590/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0351 - acc: 0.9917\n",
      "Epoch 3591/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0334 - acc: 0.9917\n",
      "Epoch 3592/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0338 - acc: 0.9917\n",
      "Epoch 3593/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0342 - acc: 0.9917\n",
      "Epoch 3594/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0342 - acc: 0.9917\n",
      "Epoch 3595/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0371 - acc: 0.9917\n",
      "Epoch 3596/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0354 - acc: 0.9917\n",
      "Epoch 3597/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0339 - acc: 0.9917\n",
      "Epoch 3598/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0342 - acc: 0.9917\n",
      "Epoch 3599/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0338 - acc: 0.9917\n",
      "Epoch 3600/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0338 - acc: 0.9917\n",
      "Epoch 3601/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0336 - acc: 0.9917\n",
      "Epoch 3602/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0342 - acc: 0.9917\n",
      "Epoch 3603/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0334 - acc: 0.9917\n",
      "Epoch 3604/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0339 - acc: 0.9917\n",
      "Epoch 3605/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0347 - acc: 0.9917\n",
      "Epoch 3606/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0343 - acc: 0.9917\n",
      "Epoch 3607/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0332 - acc: 0.9917\n",
      "Epoch 3608/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0329 - acc: 0.9917\n",
      "Epoch 3609/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0356 - acc: 0.9917\n",
      "Epoch 3610/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0357 - acc: 0.9917\n",
      "Epoch 3611/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0347 - acc: 0.9917\n",
      "Epoch 3612/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0339 - acc: 0.9917\n",
      "Epoch 3613/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0345 - acc: 0.9917\n",
      "Epoch 3614/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0337 - acc: 0.9917\n",
      "Epoch 3615/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0343 - acc: 0.9917\n",
      "Epoch 3616/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0329 - acc: 0.9917\n",
      "Epoch 3617/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0366 - acc: 0.9833\n",
      "Epoch 3618/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0401 - acc: 0.9917\n",
      "Epoch 3619/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0335 - acc: 0.9917\n",
      "Epoch 3620/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0350 - acc: 0.9917\n",
      "Epoch 3621/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0337 - acc: 0.9917\n",
      "Epoch 3622/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0335 - acc: 0.9917\n",
      "Epoch 3623/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0345 - acc: 0.9917\n",
      "Epoch 3624/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0337 - acc: 0.9917\n",
      "Epoch 3625/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0339 - acc: 0.9917\n",
      "Epoch 3626/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0345 - acc: 0.9917\n",
      "Epoch 3627/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0346 - acc: 0.9917\n",
      "Epoch 3628/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0337 - acc: 0.9917\n",
      "Epoch 3629/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0345 - acc: 0.9917\n",
      "Epoch 3630/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0355 - acc: 0.9917\n",
      "Epoch 3631/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0352 - acc: 0.9917\n",
      "Epoch 3632/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0344 - acc: 0.9917\n",
      "Epoch 3633/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0340 - acc: 0.9917\n",
      "Epoch 3634/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0345 - acc: 0.9917\n",
      "Epoch 3635/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0340 - acc: 0.9917\n",
      "Epoch 3636/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0337 - acc: 0.9917\n",
      "Epoch 3637/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0353 - acc: 0.9917\n",
      "Epoch 3638/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0364 - acc: 0.9917\n",
      "Epoch 3639/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0359 - acc: 0.9917\n",
      "Epoch 3640/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0344 - acc: 0.9917\n",
      "Epoch 3641/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0339 - acc: 0.9917\n",
      "Epoch 3642/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0334 - acc: 0.9917\n",
      "Epoch 3643/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0335 - acc: 0.9917\n",
      "Epoch 3644/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0348 - acc: 0.9917\n",
      "Epoch 3645/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0165 - acc: 1.000 - 0s 75us/sample - loss: 0.0333 - acc: 0.9917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3646/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0345 - acc: 0.9917\n",
      "Epoch 3647/8000\n",
      "120/120 [==============================] - 0s 83us/sample - loss: 0.0346 - acc: 0.9917\n",
      "Epoch 3648/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0340 - acc: 0.9917\n",
      "Epoch 3649/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0340 - acc: 0.9917\n",
      "Epoch 3650/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0334 - acc: 0.9917\n",
      "Epoch 3651/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0339 - acc: 0.9917\n",
      "Epoch 3652/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0334 - acc: 0.9917\n",
      "Epoch 3653/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0345 - acc: 0.9917\n",
      "Epoch 3654/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0338 - acc: 0.9917\n",
      "Epoch 3655/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0340 - acc: 0.9917\n",
      "Epoch 3656/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0340 - acc: 0.9917\n",
      "Epoch 3657/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0337 - acc: 0.9917\n",
      "Epoch 3658/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0346 - acc: 0.9917\n",
      "Epoch 3659/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0336 - acc: 0.9917\n",
      "Epoch 3660/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0334 - acc: 0.9917\n",
      "Epoch 3661/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0334 - acc: 0.9917\n",
      "Epoch 3662/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0339 - acc: 0.9917\n",
      "Epoch 3663/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0337 - acc: 0.9917\n",
      "Epoch 3664/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0338 - acc: 0.9917\n",
      "Epoch 3665/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0340 - acc: 0.9917\n",
      "Epoch 3666/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0324 - acc: 0.9917\n",
      "Epoch 3667/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0345 - acc: 0.9917\n",
      "Epoch 3668/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0359 - acc: 0.9917\n",
      "Epoch 3669/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0340 - acc: 0.9917\n",
      "Epoch 3670/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0340 - acc: 0.9917\n",
      "Epoch 3671/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0335 - acc: 0.9917\n",
      "Epoch 3672/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0334 - acc: 0.9917\n",
      "Epoch 3673/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0335 - acc: 0.9917\n",
      "Epoch 3674/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0332 - acc: 0.9917\n",
      "Epoch 3675/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0340 - acc: 0.9917\n",
      "Epoch 3676/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0329 - acc: 0.9917\n",
      "Epoch 3677/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0366 - acc: 0.9917\n",
      "Epoch 3678/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0109 - acc: 1.000 - 0s 84us/sample - loss: 0.0353 - acc: 0.9917\n",
      "Epoch 3679/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0340 - acc: 0.9917\n",
      "Epoch 3680/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0337 - acc: 0.9917\n",
      "Epoch 3681/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0335 - acc: 0.9917\n",
      "Epoch 3682/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0336 - acc: 0.9917\n",
      "Epoch 3683/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0338 - acc: 0.9917\n",
      "Epoch 3684/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0351 - acc: 0.9917\n",
      "Epoch 3685/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0335 - acc: 0.9917\n",
      "Epoch 3686/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0371 - acc: 0.9917\n",
      "Epoch 3687/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0345 - acc: 0.9917\n",
      "Epoch 3688/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0332 - acc: 0.9917\n",
      "Epoch 3689/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0329 - acc: 0.9917\n",
      "Epoch 3690/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0345 - acc: 0.9917\n",
      "Epoch 3691/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0361 - acc: 0.9917\n",
      "Epoch 3692/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0345 - acc: 0.9917\n",
      "Epoch 3693/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0352 - acc: 0.9917\n",
      "Epoch 3694/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0338 - acc: 0.9917\n",
      "Epoch 3695/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0332 - acc: 0.9917\n",
      "Epoch 3696/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0341 - acc: 0.9917\n",
      "Epoch 3697/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0347 - acc: 0.9917\n",
      "Epoch 3698/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0350 - acc: 0.9917\n",
      "Epoch 3699/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0342 - acc: 0.9917\n",
      "Epoch 3700/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0346 - acc: 0.9917\n",
      "Epoch 3701/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0346 - acc: 0.9917\n",
      "Epoch 3702/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0348 - acc: 0.9917\n",
      "Epoch 3703/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0352 - acc: 0.9917\n",
      "Epoch 3704/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0334 - acc: 0.9917\n",
      "Epoch 3705/8000\n",
      "120/120 [==============================] - 0s 83us/sample - loss: 0.0343 - acc: 0.9917\n",
      "Epoch 3706/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0335 - acc: 0.9917\n",
      "Epoch 3707/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0335 - acc: 0.9917\n",
      "Epoch 3708/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0336 - acc: 0.9917\n",
      "Epoch 3709/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0100 - acc: 1.000 - 0s 75us/sample - loss: 0.0336 - acc: 0.9917\n",
      "Epoch 3710/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0340 - acc: 0.9917\n",
      "Epoch 3711/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0352 - acc: 0.9917\n",
      "Epoch 3712/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0333 - acc: 0.9917\n",
      "Epoch 3713/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0329 - acc: 0.9917\n",
      "Epoch 3714/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0336 - acc: 0.9917\n",
      "Epoch 3715/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0339 - acc: 0.9917\n",
      "Epoch 3716/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0344 - acc: 0.9917\n",
      "Epoch 3717/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0336 - acc: 0.9917\n",
      "Epoch 3718/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0361 - acc: 0.9917\n",
      "Epoch 3719/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0336 - acc: 0.9917\n",
      "Epoch 3720/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0335 - acc: 0.9917\n",
      "Epoch 3721/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0342 - acc: 0.9917\n",
      "Epoch 3722/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0341 - acc: 0.9917\n",
      "Epoch 3723/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0339 - acc: 0.9917\n",
      "Epoch 3724/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0369 - acc: 0.9917\n",
      "Epoch 3725/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0339 - acc: 0.9917\n",
      "Epoch 3726/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0367 - acc: 0.9917\n",
      "Epoch 3727/8000\n",
      "120/120 [==============================] - 0s 83us/sample - loss: 0.0338 - acc: 0.9917\n",
      "Epoch 3728/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0334 - acc: 0.9917\n",
      "Epoch 3729/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0335 - acc: 0.9917\n",
      "Epoch 3730/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0333 - acc: 0.9917\n",
      "Epoch 3731/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0330 - acc: 0.9917\n",
      "Epoch 3732/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0338 - acc: 0.9917\n",
      "Epoch 3733/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0335 - acc: 0.9917\n",
      "Epoch 3734/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0336 - acc: 0.9917\n",
      "Epoch 3735/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0342 - acc: 0.9917\n",
      "Epoch 3736/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0369 - acc: 0.9917\n",
      "Epoch 3737/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0355 - acc: 0.9917\n",
      "Epoch 3738/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0340 - acc: 0.9917\n",
      "Epoch 3739/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0348 - acc: 0.9917\n",
      "Epoch 3740/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0354 - acc: 0.9917\n",
      "Epoch 3741/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0373 - acc: 0.9917\n",
      "Epoch 3742/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0328 - acc: 0.9917\n",
      "Epoch 3743/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0361 - acc: 0.9917\n",
      "Epoch 3744/8000\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.0354 - acc: 0.9917\n",
      "Epoch 3745/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0342 - acc: 0.9917\n",
      "Epoch 3746/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0329 - acc: 0.9917\n",
      "Epoch 3747/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0373 - acc: 0.9917\n",
      "Epoch 3748/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0388 - acc: 0.9917\n",
      "Epoch 3749/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0333 - acc: 0.9917\n",
      "Epoch 3750/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0333 - acc: 0.9917\n",
      "Epoch 3751/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0334 - acc: 0.9917\n",
      "Epoch 3752/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0335 - acc: 0.9917\n",
      "Epoch 3753/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0348 - acc: 0.9917\n",
      "Epoch 3754/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0331 - acc: 0.9917\n",
      "Epoch 3755/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0327 - acc: 0.9917\n",
      "Epoch 3756/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0339 - acc: 0.9917\n",
      "Epoch 3757/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0356 - acc: 0.9917\n",
      "Epoch 3758/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0344 - acc: 0.9917\n",
      "Epoch 3759/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0340 - acc: 0.9917\n",
      "Epoch 3760/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0372 - acc: 0.9917\n",
      "Epoch 3761/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0329 - acc: 0.9917\n",
      "Epoch 3762/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0328 - acc: 0.9917\n",
      "Epoch 3763/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0338 - acc: 0.9917\n",
      "Epoch 3764/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0335 - acc: 0.9917\n",
      "Epoch 3765/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0351 - acc: 0.9917\n",
      "Epoch 3766/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0345 - acc: 0.9917\n",
      "Epoch 3767/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0330 - acc: 0.9917\n",
      "Epoch 3768/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0332 - acc: 0.9917\n",
      "Epoch 3769/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0332 - acc: 0.9917\n",
      "Epoch 3770/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0344 - acc: 0.9917\n",
      "Epoch 3771/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0346 - acc: 0.9917\n",
      "Epoch 3772/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0335 - acc: 0.9917\n",
      "Epoch 3773/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0328 - acc: 0.9917\n",
      "Epoch 3774/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0339 - acc: 0.9917\n",
      "Epoch 3775/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0329 - acc: 0.9917\n",
      "Epoch 3776/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0336 - acc: 0.9917\n",
      "Epoch 3777/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0338 - acc: 0.9917\n",
      "Epoch 3778/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0336 - acc: 0.9917\n",
      "Epoch 3779/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0326 - acc: 0.9917\n",
      "Epoch 3780/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0338 - acc: 0.9917\n",
      "Epoch 3781/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0335 - acc: 0.9917\n",
      "Epoch 3782/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0337 - acc: 0.9917\n",
      "Epoch 3783/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0333 - acc: 0.9917\n",
      "Epoch 3784/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0328 - acc: 0.9917\n",
      "Epoch 3785/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0332 - acc: 0.9917\n",
      "Epoch 3786/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0349 - acc: 0.9917\n",
      "Epoch 3787/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0349 - acc: 0.9917\n",
      "Epoch 3788/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0334 - acc: 0.9917\n",
      "Epoch 3789/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0333 - acc: 0.9917\n",
      "Epoch 3790/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0327 - acc: 0.9917\n",
      "Epoch 3791/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0338 - acc: 0.9917\n",
      "Epoch 3792/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0333 - acc: 0.9917\n",
      "Epoch 3793/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0360 - acc: 0.9917\n",
      "Epoch 3794/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0335 - acc: 0.9917\n",
      "Epoch 3795/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0333 - acc: 0.9917\n",
      "Epoch 3796/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0340 - acc: 0.9917\n",
      "Epoch 3797/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0330 - acc: 0.9917\n",
      "Epoch 3798/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0334 - acc: 0.9917\n",
      "Epoch 3799/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0331 - acc: 0.9917\n",
      "Epoch 3800/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0330 - acc: 0.9917\n",
      "Epoch 3801/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0336 - acc: 0.9917\n",
      "Epoch 3802/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0330 - acc: 0.9917\n",
      "Epoch 3803/8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0329 - acc: 0.9917\n",
      "Epoch 3804/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0343 - acc: 0.9917\n",
      "Epoch 3805/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0333 - acc: 0.9917\n",
      "Epoch 3806/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0328 - acc: 0.9917\n",
      "Epoch 3807/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0332 - acc: 0.9917\n",
      "Epoch 3808/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0331 - acc: 0.9917\n",
      "Epoch 3809/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0338 - acc: 0.9917\n",
      "Epoch 3810/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0334 - acc: 0.9917\n",
      "Epoch 3811/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0337 - acc: 0.9917\n",
      "Epoch 3812/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0335 - acc: 0.9917\n",
      "Epoch 3813/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0329 - acc: 0.9917\n",
      "Epoch 3814/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0328 - acc: 0.9917\n",
      "Epoch 3815/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0331 - acc: 0.9917\n",
      "Epoch 3816/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0329 - acc: 0.9917\n",
      "Epoch 3817/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0077 - acc: 1.000 - 0s 75us/sample - loss: 0.0329 - acc: 0.9917\n",
      "Epoch 3818/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0329 - acc: 0.9917\n",
      "Epoch 3819/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0340 - acc: 0.9917\n",
      "Epoch 3820/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0329 - acc: 0.9917\n",
      "Epoch 3821/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0331 - acc: 0.9917\n",
      "Epoch 3822/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0334 - acc: 0.9917\n",
      "Epoch 3823/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0334 - acc: 0.9917\n",
      "Epoch 3824/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0339 - acc: 0.9917\n",
      "Epoch 3825/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0337 - acc: 0.9917\n",
      "Epoch 3826/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0343 - acc: 0.9917\n",
      "Epoch 3827/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0349 - acc: 0.9917\n",
      "Epoch 3828/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0351 - acc: 0.9917\n",
      "Epoch 3829/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0338 - acc: 0.9917\n",
      "Epoch 3830/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0347 - acc: 0.9917\n",
      "Epoch 3831/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0336 - acc: 0.9917\n",
      "Epoch 3832/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0326 - acc: 0.9917\n",
      "Epoch 3833/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0833 - acc: 0.968 - 0s 67us/sample - loss: 0.0334 - acc: 0.9917\n",
      "Epoch 3834/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0335 - acc: 0.9917\n",
      "Epoch 3835/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0330 - acc: 0.9917\n",
      "Epoch 3836/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0327 - acc: 0.9917\n",
      "Epoch 3837/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0332 - acc: 0.9917\n",
      "Epoch 3838/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0331 - acc: 0.9917\n",
      "Epoch 3839/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0327 - acc: 0.9917\n",
      "Epoch 3840/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0332 - acc: 0.9917\n",
      "Epoch 3841/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0330 - acc: 0.9917\n",
      "Epoch 3842/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0336 - acc: 0.9917\n",
      "Epoch 3843/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0330 - acc: 0.9917\n",
      "Epoch 3844/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0332 - acc: 0.9917\n",
      "Epoch 3845/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0329 - acc: 0.9917\n",
      "Epoch 3846/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0334 - acc: 0.9917\n",
      "Epoch 3847/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0335 - acc: 0.9917\n",
      "Epoch 3848/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0334 - acc: 0.9917\n",
      "Epoch 3849/8000\n",
      "120/120 [==============================] - 0s 59us/sample - loss: 0.0328 - acc: 0.9917\n",
      "Epoch 3850/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0326 - acc: 0.9917\n",
      "Epoch 3851/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0329 - acc: 0.9917\n",
      "Epoch 3852/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0332 - acc: 0.9917\n",
      "Epoch 3853/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0336 - acc: 0.9917\n",
      "Epoch 3854/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0338 - acc: 0.9917\n",
      "Epoch 3855/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0341 - acc: 0.9917\n",
      "Epoch 3856/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0337 - acc: 0.9917\n",
      "Epoch 3857/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0322 - acc: 0.9917\n",
      "Epoch 3858/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0366 - acc: 0.9917\n",
      "Epoch 3859/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0349 - acc: 0.9917\n",
      "Epoch 3860/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0332 - acc: 0.9917\n",
      "Epoch 3861/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0328 - acc: 0.9917\n",
      "Epoch 3862/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0340 - acc: 0.9917\n",
      "Epoch 3863/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0357 - acc: 0.9917\n",
      "Epoch 3864/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0341 - acc: 0.9917\n",
      "Epoch 3865/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0337 - acc: 0.9917\n",
      "Epoch 3866/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0327 - acc: 0.9917\n",
      "Epoch 3867/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0333 - acc: 0.9917\n",
      "Epoch 3868/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0330 - acc: 0.9917\n",
      "Epoch 3869/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0327 - acc: 0.9917\n",
      "Epoch 3870/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0330 - acc: 0.9917\n",
      "Epoch 3871/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0337 - acc: 0.9917\n",
      "Epoch 3872/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0330 - acc: 0.9917\n",
      "Epoch 3873/8000\n",
      "120/120 [==============================] - 0s 83us/sample - loss: 0.0326 - acc: 0.9917\n",
      "Epoch 3874/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0328 - acc: 0.9917\n",
      "Epoch 3875/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0333 - acc: 0.9917\n",
      "Epoch 3876/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0335 - acc: 0.9917\n",
      "Epoch 3877/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0325 - acc: 0.9917\n",
      "Epoch 3878/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0335 - acc: 0.9917\n",
      "Epoch 3879/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0329 - acc: 0.9917\n",
      "Epoch 3880/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0323 - acc: 0.9917\n",
      "Epoch 3881/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0327 - acc: 0.9917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3882/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0334 - acc: 0.9917\n",
      "Epoch 3883/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0334 - acc: 0.9917\n",
      "Epoch 3884/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0325 - acc: 0.9917\n",
      "Epoch 3885/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0342 - acc: 0.9917\n",
      "Epoch 3886/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0398 - acc: 0.9917\n",
      "Epoch 3887/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0334 - acc: 0.9917\n",
      "Epoch 3888/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0330 - acc: 0.9917\n",
      "Epoch 3889/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0359 - acc: 0.9917\n",
      "Epoch 3890/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0347 - acc: 0.9917\n",
      "Epoch 3891/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0335 - acc: 0.9917\n",
      "Epoch 3892/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0332 - acc: 0.9917\n",
      "Epoch 3893/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0334 - acc: 0.9917\n",
      "Epoch 3894/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0228 - acc: 1.000 - 0s 58us/sample - loss: 0.0330 - acc: 0.9917\n",
      "Epoch 3895/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0325 - acc: 0.9917\n",
      "Epoch 3896/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0332 - acc: 0.9917\n",
      "Epoch 3897/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0353 - acc: 0.9917\n",
      "Epoch 3898/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0335 - acc: 0.9917\n",
      "Epoch 3899/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0320 - acc: 0.9917\n",
      "Epoch 3900/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0345 - acc: 0.9917\n",
      "Epoch 3901/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0351 - acc: 0.9917\n",
      "Epoch 3902/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0348 - acc: 0.9917\n",
      "Epoch 3903/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0324 - acc: 0.9917\n",
      "Epoch 3904/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0329 - acc: 0.9917\n",
      "Epoch 3905/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0349 - acc: 0.9917\n",
      "Epoch 3906/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0331 - acc: 0.9917\n",
      "Epoch 3907/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0325 - acc: 0.9917\n",
      "Epoch 3908/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0361 - acc: 0.9917\n",
      "Epoch 3909/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0341 - acc: 0.9917\n",
      "Epoch 3910/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0333 - acc: 0.9917\n",
      "Epoch 3911/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0329 - acc: 0.9917\n",
      "Epoch 3912/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0327 - acc: 0.9917\n",
      "Epoch 3913/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0375 - acc: 0.9917\n",
      "Epoch 3914/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0328 - acc: 0.9917\n",
      "Epoch 3915/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0335 - acc: 0.9917\n",
      "Epoch 3916/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0332 - acc: 0.9917\n",
      "Epoch 3917/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0327 - acc: 0.9917\n",
      "Epoch 3918/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0330 - acc: 0.9917\n",
      "Epoch 3919/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0332 - acc: 0.9917\n",
      "Epoch 3920/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0331 - acc: 0.9917\n",
      "Epoch 3921/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0338 - acc: 0.9917\n",
      "Epoch 3922/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0325 - acc: 0.9917\n",
      "Epoch 3923/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0330 - acc: 0.9917\n",
      "Epoch 3924/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0327 - acc: 0.9917\n",
      "Epoch 3925/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0332 - acc: 0.9917\n",
      "Epoch 3926/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0327 - acc: 0.9917\n",
      "Epoch 3927/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0325 - acc: 0.9917\n",
      "Epoch 3928/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0332 - acc: 0.9917\n",
      "Epoch 3929/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0333 - acc: 0.9917\n",
      "Epoch 3930/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0325 - acc: 0.9917\n",
      "Epoch 3931/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0326 - acc: 0.9917\n",
      "Epoch 3932/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0328 - acc: 0.9917\n",
      "Epoch 3933/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0335 - acc: 0.9917\n",
      "Epoch 3934/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0331 - acc: 0.9917\n",
      "Epoch 3935/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0340 - acc: 0.9917\n",
      "Epoch 3936/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0325 - acc: 0.9917\n",
      "Epoch 3937/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0331 - acc: 0.9917\n",
      "Epoch 3938/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0365 - acc: 0.9917\n",
      "Epoch 3939/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0336 - acc: 0.9917\n",
      "Epoch 3940/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0333 - acc: 0.9917\n",
      "Epoch 3941/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0338 - acc: 0.9917\n",
      "Epoch 3942/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0343 - acc: 0.9917\n",
      "Epoch 3943/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0337 - acc: 0.9917\n",
      "Epoch 3944/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0328 - acc: 0.9917\n",
      "Epoch 3945/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0336 - acc: 0.9917\n",
      "Epoch 3946/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0320 - acc: 0.9917\n",
      "Epoch 3947/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0363 - acc: 0.9917\n",
      "Epoch 3948/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0342 - acc: 0.9917\n",
      "Epoch 3949/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0329 - acc: 0.9917\n",
      "Epoch 3950/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0340 - acc: 0.9917\n",
      "Epoch 3951/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0331 - acc: 0.9917\n",
      "Epoch 3952/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0330 - acc: 0.9917\n",
      "Epoch 3953/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0319 - acc: 0.9917\n",
      "Epoch 3954/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0322 - acc: 0.9917\n",
      "Epoch 3955/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0331 - acc: 0.9917\n",
      "Epoch 3956/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0332 - acc: 0.9917\n",
      "Epoch 3957/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0324 - acc: 0.9917\n",
      "Epoch 3958/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0325 - acc: 0.9917\n",
      "Epoch 3959/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0327 - acc: 0.9917\n",
      "Epoch 3960/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0339 - acc: 0.9917\n",
      "Epoch 3961/8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0351 - acc: 0.9917\n",
      "Epoch 3962/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0339 - acc: 0.9917\n",
      "Epoch 3963/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0327 - acc: 0.9917\n",
      "Epoch 3964/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0332 - acc: 0.9917\n",
      "Epoch 3965/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0327 - acc: 0.9917\n",
      "Epoch 3966/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0320 - acc: 0.9917\n",
      "Epoch 3967/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0328 - acc: 0.9917\n",
      "Epoch 3968/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0328 - acc: 0.9917\n",
      "Epoch 3969/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0325 - acc: 0.9917\n",
      "Epoch 3970/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0327 - acc: 0.9917\n",
      "Epoch 3971/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0322 - acc: 0.9917\n",
      "Epoch 3972/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0369 - acc: 0.9917\n",
      "Epoch 3973/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0340 - acc: 0.9917\n",
      "Epoch 3974/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0386 - acc: 0.9917\n",
      "Epoch 3975/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0338 - acc: 0.9917\n",
      "Epoch 3976/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0324 - acc: 0.9917\n",
      "Epoch 3977/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0334 - acc: 0.9917\n",
      "Epoch 3978/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0330 - acc: 0.9917\n",
      "Epoch 3979/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0342 - acc: 0.9917\n",
      "Epoch 3980/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0325 - acc: 0.9917\n",
      "Epoch 3981/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0335 - acc: 0.9917\n",
      "Epoch 3982/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0322 - acc: 0.9917\n",
      "Epoch 3983/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0330 - acc: 0.9917\n",
      "Epoch 3984/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0341 - acc: 0.9917\n",
      "Epoch 3985/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0083 - acc: 1.000 - 0s 84us/sample - loss: 0.0324 - acc: 0.9917\n",
      "Epoch 3986/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0335 - acc: 0.9917\n",
      "Epoch 3987/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0333 - acc: 0.9917\n",
      "Epoch 3988/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0328 - acc: 0.9917\n",
      "Epoch 3989/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0327 - acc: 0.9917\n",
      "Epoch 3990/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0336 - acc: 0.9917\n",
      "Epoch 3991/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0341 - acc: 0.9917\n",
      "Epoch 3992/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0330 - acc: 0.9917\n",
      "Epoch 3993/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0738 - acc: 0.968 - 0s 67us/sample - loss: 0.0332 - acc: 0.9917\n",
      "Epoch 3994/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0323 - acc: 0.9917\n",
      "Epoch 3995/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0341 - acc: 0.9917\n",
      "Epoch 3996/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0325 - acc: 0.9917\n",
      "Epoch 3997/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0343 - acc: 0.9917\n",
      "Epoch 3998/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0337 - acc: 0.9917\n",
      "Epoch 3999/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0327 - acc: 0.9917\n",
      "Epoch 4000/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0323 - acc: 0.9917\n",
      "Epoch 4001/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0324 - acc: 0.9917\n",
      "Epoch 4002/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0329 - acc: 0.9917\n",
      "Epoch 4003/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0340 - acc: 0.9917\n",
      "Epoch 4004/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0328 - acc: 0.9917\n",
      "Epoch 4005/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0323 - acc: 0.9917\n",
      "Epoch 4006/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0334 - acc: 0.9917\n",
      "Epoch 4007/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0331 - acc: 0.9917\n",
      "Epoch 4008/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0344 - acc: 0.9917\n",
      "Epoch 4009/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0322 - acc: 0.9917\n",
      "Epoch 4010/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0325 - acc: 0.9917\n",
      "Epoch 4011/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0331 - acc: 0.9917\n",
      "Epoch 4012/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0325 - acc: 0.9917\n",
      "Epoch 4013/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0324 - acc: 0.9917\n",
      "Epoch 4014/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0327 - acc: 0.9917\n",
      "Epoch 4015/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0322 - acc: 0.9917\n",
      "Epoch 4016/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0334 - acc: 0.9917\n",
      "Epoch 4017/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0329 - acc: 0.9917\n",
      "Epoch 4018/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0334 - acc: 0.9917\n",
      "Epoch 4019/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0340 - acc: 0.9917\n",
      "Epoch 4020/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0338 - acc: 0.9917\n",
      "Epoch 4021/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0321 - acc: 0.9917\n",
      "Epoch 4022/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0326 - acc: 0.9917\n",
      "Epoch 4023/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0325 - acc: 0.9917\n",
      "Epoch 4024/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0333 - acc: 0.9917\n",
      "Epoch 4025/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0139 - acc: 1.000 - 0s 67us/sample - loss: 0.0339 - acc: 0.9917\n",
      "Epoch 4026/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0327 - acc: 0.9917\n",
      "Epoch 4027/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0331 - acc: 0.9917\n",
      "Epoch 4028/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0337 - acc: 0.9917\n",
      "Epoch 4029/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0321 - acc: 0.9917\n",
      "Epoch 4030/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0324 - acc: 0.9917\n",
      "Epoch 4031/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0323 - acc: 0.9917\n",
      "Epoch 4032/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0329 - acc: 0.9917\n",
      "Epoch 4033/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0329 - acc: 0.9917\n",
      "Epoch 4034/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0331 - acc: 0.9917\n",
      "Epoch 4035/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0326 - acc: 0.9917\n",
      "Epoch 4036/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0328 - acc: 0.9917\n",
      "Epoch 4037/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0329 - acc: 0.9917\n",
      "Epoch 4038/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0328 - acc: 0.9917\n",
      "Epoch 4039/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0323 - acc: 0.9917\n",
      "Epoch 4040/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0325 - acc: 0.9917\n",
      "Epoch 4041/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0327 - acc: 0.9917\n",
      "Epoch 4042/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0321 - acc: 0.9917\n",
      "Epoch 4043/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0339 - acc: 0.9917\n",
      "Epoch 4044/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0326 - acc: 0.9917\n",
      "Epoch 4045/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0320 - acc: 0.9917\n",
      "Epoch 4046/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0323 - acc: 0.9917\n",
      "Epoch 4047/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0325 - acc: 0.9917\n",
      "Epoch 4048/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0324 - acc: 0.9917\n",
      "Epoch 4049/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0328 - acc: 0.9917\n",
      "Epoch 4050/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0319 - acc: 0.9917\n",
      "Epoch 4051/8000\n",
      "120/120 [==============================] - 0s 83us/sample - loss: 0.0319 - acc: 0.9917\n",
      "Epoch 4052/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0325 - acc: 0.9917\n",
      "Epoch 4053/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0327 - acc: 0.9917\n",
      "Epoch 4054/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0324 - acc: 0.9917\n",
      "Epoch 4055/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0332 - acc: 0.9917\n",
      "Epoch 4056/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0346 - acc: 0.9917\n",
      "Epoch 4057/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0324 - acc: 0.9917\n",
      "Epoch 4058/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0314 - acc: 0.9917\n",
      "Epoch 4059/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0340 - acc: 0.9917\n",
      "Epoch 4060/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0354 - acc: 0.9917\n",
      "Epoch 4061/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0323 - acc: 0.9917\n",
      "Epoch 4062/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0324 - acc: 0.9917\n",
      "Epoch 4063/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0357 - acc: 0.9917\n",
      "Epoch 4064/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0339 - acc: 0.9917\n",
      "Epoch 4065/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0323 - acc: 0.9917\n",
      "Epoch 4066/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0325 - acc: 0.9917\n",
      "Epoch 4067/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0337 - acc: 0.9917\n",
      "Epoch 4068/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0337 - acc: 0.9917\n",
      "Epoch 4069/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0327 - acc: 0.9917\n",
      "Epoch 4070/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0321 - acc: 0.9917\n",
      "Epoch 4071/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0322 - acc: 0.9917\n",
      "Epoch 4072/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0320 - acc: 0.9917\n",
      "Epoch 4073/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0322 - acc: 0.9917\n",
      "Epoch 4074/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0321 - acc: 0.9917\n",
      "Epoch 4075/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0321 - acc: 0.9917\n",
      "Epoch 4076/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0339 - acc: 0.9917\n",
      "Epoch 4077/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0350 - acc: 0.9917\n",
      "Epoch 4078/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0323 - acc: 0.9917\n",
      "Epoch 4079/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0332 - acc: 0.9917\n",
      "Epoch 4080/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0327 - acc: 0.9917\n",
      "Epoch 4081/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0321 - acc: 0.9917\n",
      "Epoch 4082/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0322 - acc: 0.9917\n",
      "Epoch 4083/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0326 - acc: 0.9917\n",
      "Epoch 4084/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0323 - acc: 0.9917\n",
      "Epoch 4085/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0322 - acc: 0.9917\n",
      "Epoch 4086/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0325 - acc: 0.9917\n",
      "Epoch 4087/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0252 - acc: 1.000 - 0s 67us/sample - loss: 0.0328 - acc: 0.9917\n",
      "Epoch 4088/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0331 - acc: 0.9917\n",
      "Epoch 4089/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0325 - acc: 0.9917\n",
      "Epoch 4090/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0315 - acc: 0.9917\n",
      "Epoch 4091/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0322 - acc: 0.9917\n",
      "Epoch 4092/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0335 - acc: 0.9917\n",
      "Epoch 4093/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0322 - acc: 0.9917\n",
      "Epoch 4094/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0335 - acc: 0.9917\n",
      "Epoch 4095/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0325 - acc: 0.9917\n",
      "Epoch 4096/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0315 - acc: 0.9917\n",
      "Epoch 4097/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0323 - acc: 0.9917\n",
      "Epoch 4098/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0342 - acc: 0.9917\n",
      "Epoch 4099/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0277 - acc: 1.000 - 0s 75us/sample - loss: 0.0330 - acc: 0.9917\n",
      "Epoch 4100/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0330 - acc: 0.9917\n",
      "Epoch 4101/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0323 - acc: 0.9917\n",
      "Epoch 4102/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0328 - acc: 0.9917\n",
      "Epoch 4103/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0328 - acc: 0.9917\n",
      "Epoch 4104/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0324 - acc: 0.9917\n",
      "Epoch 4105/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0318 - acc: 0.9917\n",
      "Epoch 4106/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0341 - acc: 0.9917\n",
      "Epoch 4107/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0333 - acc: 0.9917\n",
      "Epoch 4108/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0319 - acc: 0.9917\n",
      "Epoch 4109/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0323 - acc: 0.9917\n",
      "Epoch 4110/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0322 - acc: 0.9917\n",
      "Epoch 4111/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0318 - acc: 0.9917\n",
      "Epoch 4112/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0324 - acc: 0.9917\n",
      "Epoch 4113/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0346 - acc: 0.9917\n",
      "Epoch 4114/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0317 - acc: 0.9917\n",
      "Epoch 4115/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0333 - acc: 0.9917\n",
      "Epoch 4116/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0317 - acc: 0.9917\n",
      "Epoch 4117/8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0325 - acc: 0.9917\n",
      "Epoch 4118/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0337 - acc: 0.9917\n",
      "Epoch 4119/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0316 - acc: 0.9917\n",
      "Epoch 4120/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0333 - acc: 0.9917\n",
      "Epoch 4121/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0325 - acc: 0.9917\n",
      "Epoch 4122/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0328 - acc: 0.9917\n",
      "Epoch 4123/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0332 - acc: 0.9917\n",
      "Epoch 4124/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0341 - acc: 0.9917\n",
      "Epoch 4125/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0317 - acc: 0.9917\n",
      "Epoch 4126/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0322 - acc: 0.9917\n",
      "Epoch 4127/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0322 - acc: 0.9917\n",
      "Epoch 4128/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0321 - acc: 0.9917\n",
      "Epoch 4129/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0320 - acc: 0.9917\n",
      "Epoch 4130/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0334 - acc: 0.9917\n",
      "Epoch 4131/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0323 - acc: 0.9917\n",
      "Epoch 4132/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0329 - acc: 0.9917\n",
      "Epoch 4133/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0317 - acc: 0.9917\n",
      "Epoch 4134/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0317 - acc: 0.9917\n",
      "Epoch 4135/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0330 - acc: 0.9917\n",
      "Epoch 4136/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0331 - acc: 0.9917\n",
      "Epoch 4137/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0349 - acc: 0.9917\n",
      "Epoch 4138/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0316 - acc: 0.9917\n",
      "Epoch 4139/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0328 - acc: 0.9917\n",
      "Epoch 4140/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0331 - acc: 0.9917\n",
      "Epoch 4141/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0323 - acc: 0.9917\n",
      "Epoch 4142/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0320 - acc: 0.9917\n",
      "Epoch 4143/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0319 - acc: 0.9917\n",
      "Epoch 4144/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0328 - acc: 0.9917\n",
      "Epoch 4145/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0317 - acc: 0.9917\n",
      "Epoch 4146/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0330 - acc: 0.9917\n",
      "Epoch 4147/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0320 - acc: 0.9917\n",
      "Epoch 4148/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0323 - acc: 0.9917\n",
      "Epoch 4149/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0344 - acc: 0.9917\n",
      "Epoch 4150/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0346 - acc: 0.9917\n",
      "Epoch 4151/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0321 - acc: 0.9917\n",
      "Epoch 4152/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0339 - acc: 0.9917\n",
      "Epoch 4153/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0314 - acc: 0.9917\n",
      "Epoch 4154/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0352 - acc: 0.9917\n",
      "Epoch 4155/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0320 - acc: 0.9917\n",
      "Epoch 4156/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0314 - acc: 0.9917\n",
      "Epoch 4157/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0324 - acc: 0.9917\n",
      "Epoch 4158/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0332 - acc: 0.9917\n",
      "Epoch 4159/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0328 - acc: 0.9917\n",
      "Epoch 4160/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0326 - acc: 0.9917\n",
      "Epoch 4161/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0339 - acc: 0.9917\n",
      "Epoch 4162/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0331 - acc: 0.9917\n",
      "Epoch 4163/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0323 - acc: 0.9917\n",
      "Epoch 4164/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0328 - acc: 0.9917\n",
      "Epoch 4165/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0311 - acc: 0.9917\n",
      "Epoch 4166/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0324 - acc: 0.9917\n",
      "Epoch 4167/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0341 - acc: 0.9917\n",
      "Epoch 4168/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0313 - acc: 0.9917\n",
      "Epoch 4169/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0348 - acc: 0.9917\n",
      "Epoch 4170/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0380 - acc: 0.9750\n",
      "Epoch 4171/8000\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 0.0336 - acc: 0.9917\n",
      "Epoch 4172/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0343 - acc: 0.9917\n",
      "Epoch 4173/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0340 - acc: 0.9917\n",
      "Epoch 4174/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0326 - acc: 0.9917\n",
      "Epoch 4175/8000\n",
      "120/120 [==============================] - 0s 59us/sample - loss: 0.0317 - acc: 0.9917\n",
      "Epoch 4176/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0343 - acc: 0.9917\n",
      "Epoch 4177/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0320 - acc: 0.9917\n",
      "Epoch 4178/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0342 - acc: 0.9917\n",
      "Epoch 4179/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0327 - acc: 0.9917\n",
      "Epoch 4180/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0335 - acc: 0.9917\n",
      "Epoch 4181/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0325 - acc: 0.9917\n",
      "Epoch 4182/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0328 - acc: 0.9917\n",
      "Epoch 4183/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0319 - acc: 0.9917\n",
      "Epoch 4184/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0251 - acc: 1.000 - 0s 100us/sample - loss: 0.0327 - acc: 0.9917\n",
      "Epoch 4185/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0350 - acc: 0.9917\n",
      "Epoch 4186/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0318 - acc: 0.9917\n",
      "Epoch 4187/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0317 - acc: 0.9917\n",
      "Epoch 4188/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0315 - acc: 0.9917\n",
      "Epoch 4189/8000\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.0317 - acc: 0.9917\n",
      "Epoch 4190/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0326 - acc: 0.9917\n",
      "Epoch 4191/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0323 - acc: 0.9917\n",
      "Epoch 4192/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0323 - acc: 0.9917\n",
      "Epoch 4193/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0322 - acc: 0.9917\n",
      "Epoch 4194/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0317 - acc: 0.9917\n",
      "Epoch 4195/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0329 - acc: 0.9917\n",
      "Epoch 4196/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0326 - acc: 0.9917\n",
      "Epoch 4197/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0320 - acc: 0.9917\n",
      "Epoch 4198/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0317 - acc: 0.9917\n",
      "Epoch 4199/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0341 - acc: 0.9917\n",
      "Epoch 4200/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0335 - acc: 0.9917\n",
      "Epoch 4201/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0337 - acc: 0.9917\n",
      "Epoch 4202/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0318 - acc: 0.9917\n",
      "Epoch 4203/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0313 - acc: 0.9917\n",
      "Epoch 4204/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0324 - acc: 0.9917\n",
      "Epoch 4205/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0325 - acc: 0.9917\n",
      "Epoch 4206/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0321 - acc: 0.9917\n",
      "Epoch 4207/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0323 - acc: 0.9917\n",
      "Epoch 4208/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0322 - acc: 0.9917\n",
      "Epoch 4209/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0318 - acc: 0.9917\n",
      "Epoch 4210/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0324 - acc: 0.9917\n",
      "Epoch 4211/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0320 - acc: 0.9917\n",
      "Epoch 4212/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0331 - acc: 0.9917\n",
      "Epoch 4213/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0320 - acc: 0.9917\n",
      "Epoch 4214/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0320 - acc: 0.9917\n",
      "Epoch 4215/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0327 - acc: 0.9917\n",
      "Epoch 4216/8000\n",
      "120/120 [==============================] - 0s 150us/sample - loss: 0.0324 - acc: 0.9917\n",
      "Epoch 4217/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0320 - acc: 0.9917\n",
      "Epoch 4218/8000\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.0341 - acc: 0.9917\n",
      "Epoch 4219/8000\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.0324 - acc: 0.9917\n",
      "Epoch 4220/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0328 - acc: 0.9917\n",
      "Epoch 4221/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0315 - acc: 0.9917\n",
      "Epoch 4222/8000\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.0311 - acc: 0.9917\n",
      "Epoch 4223/8000\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.0366 - acc: 0.9833\n",
      "Epoch 4224/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0340 - acc: 0.9833\n",
      "Epoch 4225/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0326 - acc: 0.9917\n",
      "Epoch 4226/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0325 - acc: 0.9917\n",
      "Epoch 4227/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0330 - acc: 0.9917\n",
      "Epoch 4228/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0400 - acc: 1.000 - 0s 125us/sample - loss: 0.0327 - acc: 0.9917\n",
      "Epoch 4229/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0321 - acc: 0.9917\n",
      "Epoch 4230/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0319 - acc: 0.9917\n",
      "Epoch 4231/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0321 - acc: 0.9917\n",
      "Epoch 4232/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0314 - acc: 0.9917\n",
      "Epoch 4233/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0316 - acc: 0.9917\n",
      "Epoch 4234/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0321 - acc: 0.9917\n",
      "Epoch 4235/8000\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.0326 - acc: 0.9917\n",
      "Epoch 4236/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0325 - acc: 0.9917\n",
      "Epoch 4237/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0311 - acc: 0.9917\n",
      "Epoch 4238/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0319 - acc: 0.9917\n",
      "Epoch 4239/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0318 - acc: 0.9917\n",
      "Epoch 4240/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0330 - acc: 0.9917\n",
      "Epoch 4241/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0315 - acc: 0.9917\n",
      "Epoch 4242/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0318 - acc: 0.9917\n",
      "Epoch 4243/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0322 - acc: 0.9917\n",
      "Epoch 4244/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0337 - acc: 0.9917\n",
      "Epoch 4245/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0315 - acc: 0.9917\n",
      "Epoch 4246/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0316 - acc: 0.9917\n",
      "Epoch 4247/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0322 - acc: 0.9917\n",
      "Epoch 4248/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0327 - acc: 0.9917\n",
      "Epoch 4249/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0320 - acc: 0.9917\n",
      "Epoch 4250/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0314 - acc: 0.9917\n",
      "Epoch 4251/8000\n",
      "120/120 [==============================] - 0s 134us/sample - loss: 0.0311 - acc: 0.9917\n",
      "Epoch 4252/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0318 - acc: 0.9917\n",
      "Epoch 4253/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0317 - acc: 0.9917\n",
      "Epoch 4254/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0313 - acc: 0.9917\n",
      "Epoch 4255/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0310 - acc: 0.9917\n",
      "Epoch 4256/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0335 - acc: 0.9917\n",
      "Epoch 4257/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0319 - acc: 0.9917\n",
      "Epoch 4258/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0354 - acc: 0.9917\n",
      "Epoch 4259/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0350 - acc: 0.9917\n",
      "Epoch 4260/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0329 - acc: 0.9917\n",
      "Epoch 4261/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0315 - acc: 0.9917\n",
      "Epoch 4262/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0312 - acc: 0.9917\n",
      "Epoch 4263/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0318 - acc: 0.9917\n",
      "Epoch 4264/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0327 - acc: 0.9917\n",
      "Epoch 4265/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0309 - acc: 0.9917\n",
      "Epoch 4266/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0786 - acc: 0.968 - 0s 84us/sample - loss: 0.0315 - acc: 0.9917\n",
      "Epoch 4267/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0321 - acc: 0.9917\n",
      "Epoch 4268/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0336 - acc: 0.9917\n",
      "Epoch 4269/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0338 - acc: 0.9917\n",
      "Epoch 4270/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0322 - acc: 0.9917\n",
      "Epoch 4271/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0319 - acc: 0.9917\n",
      "Epoch 4272/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0321 - acc: 0.9917\n",
      "Epoch 4273/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0318 - acc: 0.9917\n",
      "Epoch 4274/8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0319 - acc: 0.9917\n",
      "Epoch 4275/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0314 - acc: 0.9917\n",
      "Epoch 4276/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0331 - acc: 0.9917\n",
      "Epoch 4277/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0323 - acc: 0.9917\n",
      "Epoch 4278/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0313 - acc: 0.9917\n",
      "Epoch 4279/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0318 - acc: 0.9917\n",
      "Epoch 4280/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0319 - acc: 0.9917\n",
      "Epoch 4281/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0321 - acc: 0.9917\n",
      "Epoch 4282/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0315 - acc: 0.9917\n",
      "Epoch 4283/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0327 - acc: 0.9917\n",
      "Epoch 4284/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0314 - acc: 0.9917\n",
      "Epoch 4285/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0310 - acc: 0.9917\n",
      "Epoch 4286/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0322 - acc: 0.9917\n",
      "Epoch 4287/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0318 - acc: 0.9917\n",
      "Epoch 4288/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0342 - acc: 0.9917\n",
      "Epoch 4289/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0318 - acc: 0.9917\n",
      "Epoch 4290/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0339 - acc: 0.9917\n",
      "Epoch 4291/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0313 - acc: 0.9917\n",
      "Epoch 4292/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0317 - acc: 0.9917\n",
      "Epoch 4293/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0328 - acc: 0.9917\n",
      "Epoch 4294/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0319 - acc: 0.9917\n",
      "Epoch 4295/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0314 - acc: 0.9917\n",
      "Epoch 4296/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0316 - acc: 0.9917\n",
      "Epoch 4297/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0313 - acc: 0.9917\n",
      "Epoch 4298/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0314 - acc: 0.9917\n",
      "Epoch 4299/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0315 - acc: 0.9917\n",
      "Epoch 4300/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0313 - acc: 0.9917\n",
      "Epoch 4301/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0315 - acc: 0.9917\n",
      "Epoch 4302/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0310 - acc: 0.9917\n",
      "Epoch 4303/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0317 - acc: 0.9917\n",
      "Epoch 4304/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0336 - acc: 0.9917\n",
      "Epoch 4305/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0322 - acc: 0.9917\n",
      "Epoch 4306/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0312 - acc: 0.9917\n",
      "Epoch 4307/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0334 - acc: 0.9917\n",
      "Epoch 4308/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0311 - acc: 0.9917\n",
      "Epoch 4309/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0338 - acc: 0.9917\n",
      "Epoch 4310/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0337 - acc: 0.9833\n",
      "Epoch 4311/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0359 - acc: 0.9917\n",
      "Epoch 4312/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0332 - acc: 0.9917\n",
      "Epoch 4313/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0319 - acc: 0.9917\n",
      "Epoch 4314/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0329 - acc: 0.9917\n",
      "Epoch 4315/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0030 - acc: 1.000 - 0s 75us/sample - loss: 0.0320 - acc: 0.9917\n",
      "Epoch 4316/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0315 - acc: 0.9917\n",
      "Epoch 4317/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0329 - acc: 0.9917\n",
      "Epoch 4318/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0315 - acc: 0.9917\n",
      "Epoch 4319/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0317 - acc: 0.9917\n",
      "Epoch 4320/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0313 - acc: 0.9917\n",
      "Epoch 4321/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0329 - acc: 0.9917\n",
      "Epoch 4322/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0318 - acc: 0.9917\n",
      "Epoch 4323/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0330 - acc: 0.9917\n",
      "Epoch 4324/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0325 - acc: 0.9917\n",
      "Epoch 4325/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0313 - acc: 0.9917\n",
      "Epoch 4326/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0317 - acc: 0.9917\n",
      "Epoch 4327/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0337 - acc: 0.9917\n",
      "Epoch 4328/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0326 - acc: 0.9917\n",
      "Epoch 4329/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0315 - acc: 0.9917\n",
      "Epoch 4330/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0325 - acc: 0.9917\n",
      "Epoch 4331/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0346 - acc: 0.9917\n",
      "Epoch 4332/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0311 - acc: 0.9917\n",
      "Epoch 4333/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0317 - acc: 0.9917\n",
      "Epoch 4334/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0312 - acc: 0.9917\n",
      "Epoch 4335/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0313 - acc: 0.9917\n",
      "Epoch 4336/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0315 - acc: 0.9917\n",
      "Epoch 4337/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0319 - acc: 0.9917\n",
      "Epoch 4338/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0316 - acc: 0.9917\n",
      "Epoch 4339/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0316 - acc: 0.9917\n",
      "Epoch 4340/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0314 - acc: 0.9917\n",
      "Epoch 4341/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0315 - acc: 0.9917\n",
      "Epoch 4342/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0328 - acc: 0.9917\n",
      "Epoch 4343/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0319 - acc: 0.9917\n",
      "Epoch 4344/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0320 - acc: 0.9917\n",
      "Epoch 4345/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0333 - acc: 0.9917\n",
      "Epoch 4346/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0319 - acc: 0.9917\n",
      "Epoch 4347/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0324 - acc: 0.9917\n",
      "Epoch 4348/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0324 - acc: 0.9917\n",
      "Epoch 4349/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0313 - acc: 0.9917\n",
      "Epoch 4350/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0323 - acc: 0.9917\n",
      "Epoch 4351/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0310 - acc: 0.9917\n",
      "Epoch 4352/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0309 - acc: 0.9917\n",
      "Epoch 4353/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0337 - acc: 0.9917\n",
      "Epoch 4354/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0324 - acc: 0.9917\n",
      "Epoch 4355/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0322 - acc: 0.9917\n",
      "Epoch 4356/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0313 - acc: 0.9917\n",
      "Epoch 4357/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0316 - acc: 0.9917\n",
      "Epoch 4358/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0318 - acc: 0.9917\n",
      "Epoch 4359/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0334 - acc: 0.9917\n",
      "Epoch 4360/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0321 - acc: 0.9917\n",
      "Epoch 4361/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0333 - acc: 0.9917\n",
      "Epoch 4362/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0315 - acc: 0.9917\n",
      "Epoch 4363/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0310 - acc: 0.9917\n",
      "Epoch 4364/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0342 - acc: 0.9917\n",
      "Epoch 4365/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0328 - acc: 0.9917\n",
      "Epoch 4366/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0343 - acc: 0.9917\n",
      "Epoch 4367/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0312 - acc: 0.9917\n",
      "Epoch 4368/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0306 - acc: 0.9917\n",
      "Epoch 4369/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0321 - acc: 0.9917\n",
      "Epoch 4370/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0341 - acc: 0.9917\n",
      "Epoch 4371/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0323 - acc: 0.9917\n",
      "Epoch 4372/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0321 - acc: 0.9917\n",
      "Epoch 4373/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0312 - acc: 0.9917\n",
      "Epoch 4374/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0310 - acc: 0.9917\n",
      "Epoch 4375/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0312 - acc: 0.9917\n",
      "Epoch 4376/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0316 - acc: 0.9917\n",
      "Epoch 4377/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0316 - acc: 0.9917\n",
      "Epoch 4378/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0311 - acc: 0.9917\n",
      "Epoch 4379/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0313 - acc: 0.9917\n",
      "Epoch 4380/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0313 - acc: 0.9917\n",
      "Epoch 4381/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0322 - acc: 0.9917\n",
      "Epoch 4382/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0316 - acc: 0.9917\n",
      "Epoch 4383/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0312 - acc: 0.9917\n",
      "Epoch 4384/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0309 - acc: 0.9917\n",
      "Epoch 4385/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0308 - acc: 0.9917\n",
      "Epoch 4386/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0319 - acc: 0.9917\n",
      "Epoch 4387/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0317 - acc: 0.9917\n",
      "Epoch 4388/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0326 - acc: 0.9917\n",
      "Epoch 4389/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0309 - acc: 0.9917\n",
      "Epoch 4390/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0335 - acc: 0.9917\n",
      "Epoch 4391/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0318 - acc: 0.9917\n",
      "Epoch 4392/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0325 - acc: 0.9917\n",
      "Epoch 4393/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0316 - acc: 0.9917\n",
      "Epoch 4394/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0316 - acc: 0.9917\n",
      "Epoch 4395/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0178 - acc: 1.000 - 0s 92us/sample - loss: 0.0316 - acc: 0.9917\n",
      "Epoch 4396/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0326 - acc: 0.9917\n",
      "Epoch 4397/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0321 - acc: 0.9917\n",
      "Epoch 4398/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0311 - acc: 0.9917\n",
      "Epoch 4399/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0314 - acc: 0.9917\n",
      "Epoch 4400/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0322 - acc: 0.9917\n",
      "Epoch 4401/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0309 - acc: 0.9917\n",
      "Epoch 4402/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0308 - acc: 0.9917\n",
      "Epoch 4403/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0315 - acc: 0.9917\n",
      "Epoch 4404/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0315 - acc: 0.9917\n",
      "Epoch 4405/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0318 - acc: 0.9917\n",
      "Epoch 4406/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0309 - acc: 0.9917\n",
      "Epoch 4407/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0319 - acc: 0.9917\n",
      "Epoch 4408/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0317 - acc: 0.9917\n",
      "Epoch 4409/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0323 - acc: 0.9917\n",
      "Epoch 4410/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0315 - acc: 0.9917\n",
      "Epoch 4411/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0310 - acc: 0.9917\n",
      "Epoch 4412/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0312 - acc: 0.9917\n",
      "Epoch 4413/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0310 - acc: 0.9917\n",
      "Epoch 4414/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0312 - acc: 0.9917\n",
      "Epoch 4415/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0325 - acc: 0.9917\n",
      "Epoch 4416/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0311 - acc: 0.9917\n",
      "Epoch 4417/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0314 - acc: 0.9917\n",
      "Epoch 4418/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0314 - acc: 0.9917\n",
      "Epoch 4419/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0314 - acc: 0.9917\n",
      "Epoch 4420/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0314 - acc: 0.9917\n",
      "Epoch 4421/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0322 - acc: 0.9917\n",
      "Epoch 4422/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0309 - acc: 0.9917\n",
      "Epoch 4423/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0315 - acc: 0.9917\n",
      "Epoch 4424/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0328 - acc: 0.9917\n",
      "Epoch 4425/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0319 - acc: 0.9917\n",
      "Epoch 4426/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0307 - acc: 0.9917\n",
      "Epoch 4427/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0347 - acc: 0.9917\n",
      "Epoch 4428/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0312 - acc: 0.9917\n",
      "Epoch 4429/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0323 - acc: 0.9917\n",
      "Epoch 4430/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0329 - acc: 0.9917\n",
      "Epoch 4431/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0316 - acc: 0.9917\n",
      "Epoch 4432/8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0309 - acc: 0.9917\n",
      "Epoch 4433/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0312 - acc: 0.9917\n",
      "Epoch 4434/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0311 - acc: 0.9917\n",
      "Epoch 4435/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0311 - acc: 0.9917\n",
      "Epoch 4436/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0323 - acc: 0.9917\n",
      "Epoch 4437/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0317 - acc: 0.9917\n",
      "Epoch 4438/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0319 - acc: 0.9917\n",
      "Epoch 4439/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0309 - acc: 0.9917\n",
      "Epoch 4440/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0310 - acc: 0.9917\n",
      "Epoch 4441/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0308 - acc: 0.9917\n",
      "Epoch 4442/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0314 - acc: 0.9917\n",
      "Epoch 4443/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0309 - acc: 0.9917\n",
      "Epoch 4444/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0308 - acc: 0.9917\n",
      "Epoch 4445/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0322 - acc: 0.9917\n",
      "Epoch 4446/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0321 - acc: 0.9917\n",
      "Epoch 4447/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0312 - acc: 0.9917\n",
      "Epoch 4448/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0326 - acc: 0.9917\n",
      "Epoch 4449/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0317 - acc: 0.9917\n",
      "Epoch 4450/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0324 - acc: 0.9917\n",
      "Epoch 4451/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0309 - acc: 0.9917\n",
      "Epoch 4452/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0307 - acc: 0.9917\n",
      "Epoch 4453/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0313 - acc: 0.9917\n",
      "Epoch 4454/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0305 - acc: 0.9917\n",
      "Epoch 4455/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0312 - acc: 0.9917\n",
      "Epoch 4456/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0323 - acc: 0.9917\n",
      "Epoch 4457/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0312 - acc: 0.9917\n",
      "Epoch 4458/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0313 - acc: 0.9917\n",
      "Epoch 4459/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0307 - acc: 0.9917\n",
      "Epoch 4460/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0328 - acc: 0.9917\n",
      "Epoch 4461/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0311 - acc: 0.9917\n",
      "Epoch 4462/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0351 - acc: 0.9917\n",
      "Epoch 4463/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0314 - acc: 0.9917\n",
      "Epoch 4464/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0314 - acc: 0.9917\n",
      "Epoch 4465/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0311 - acc: 0.9917\n",
      "Epoch 4466/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0324 - acc: 0.9917\n",
      "Epoch 4467/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0306 - acc: 0.9917\n",
      "Epoch 4468/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0310 - acc: 0.9917\n",
      "Epoch 4469/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0194 - acc: 1.000 - 0s 84us/sample - loss: 0.0307 - acc: 0.9917\n",
      "Epoch 4470/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0321 - acc: 0.9917\n",
      "Epoch 4471/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0307 - acc: 0.9917\n",
      "Epoch 4472/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0332 - acc: 0.9917\n",
      "Epoch 4473/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0329 - acc: 0.9917\n",
      "Epoch 4474/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0310 - acc: 0.9917\n",
      "Epoch 4475/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0310 - acc: 0.9917\n",
      "Epoch 4476/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0309 - acc: 0.9917\n",
      "Epoch 4477/8000\n",
      "120/120 [==============================] - 0s 59us/sample - loss: 0.0311 - acc: 0.9917\n",
      "Epoch 4478/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0311 - acc: 0.9917\n",
      "Epoch 4479/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0313 - acc: 0.9917\n",
      "Epoch 4480/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0309 - acc: 0.9917\n",
      "Epoch 4481/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0311 - acc: 0.9917\n",
      "Epoch 4482/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0315 - acc: 0.9917\n",
      "Epoch 4483/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0307 - acc: 0.9917\n",
      "Epoch 4484/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0309 - acc: 0.9917\n",
      "Epoch 4485/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0309 - acc: 0.9917\n",
      "Epoch 4486/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0311 - acc: 0.9917\n",
      "Epoch 4487/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0306 - acc: 0.9917\n",
      "Epoch 4488/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0307 - acc: 0.9917\n",
      "Epoch 4489/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0313 - acc: 0.9917\n",
      "Epoch 4490/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0313 - acc: 0.9917\n",
      "Epoch 4491/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0308 - acc: 0.9917\n",
      "Epoch 4492/8000\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.0315 - acc: 0.9917\n",
      "Epoch 4493/8000\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.0308 - acc: 0.9917\n",
      "Epoch 4494/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0308 - acc: 0.9917\n",
      "Epoch 4495/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0312 - acc: 0.9917\n",
      "Epoch 4496/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0315 - acc: 0.9917\n",
      "Epoch 4497/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0311 - acc: 0.9917\n",
      "Epoch 4498/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0314 - acc: 0.9917\n",
      "Epoch 4499/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0332 - acc: 0.9917\n",
      "Epoch 4500/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0314 - acc: 0.9917\n",
      "Epoch 4501/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0318 - acc: 0.9917\n",
      "Epoch 4502/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0326 - acc: 0.9917\n",
      "Epoch 4503/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0125 - acc: 1.000 - 0s 75us/sample - loss: 0.0309 - acc: 0.9917\n",
      "Epoch 4504/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0309 - acc: 0.9917\n",
      "Epoch 4505/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0332 - acc: 0.9917\n",
      "Epoch 4506/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0310 - acc: 0.9917\n",
      "Epoch 4507/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0313 - acc: 0.9917\n",
      "Epoch 4508/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0317 - acc: 0.9917\n",
      "Epoch 4509/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0318 - acc: 0.9917\n",
      "Epoch 4510/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0302 - acc: 0.9917\n",
      "Epoch 4511/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0312 - acc: 0.9917\n",
      "Epoch 4512/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0311 - acc: 0.9917\n",
      "Epoch 4513/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0304 - acc: 0.9917\n",
      "Epoch 4514/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0324 - acc: 0.9917\n",
      "Epoch 4515/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0322 - acc: 0.9917\n",
      "Epoch 4516/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0309 - acc: 0.9917\n",
      "Epoch 4517/8000\n",
      "120/120 [==============================] - 0s 59us/sample - loss: 0.0309 - acc: 0.9917\n",
      "Epoch 4518/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0325 - acc: 0.9917\n",
      "Epoch 4519/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0390 - acc: 0.9917\n",
      "Epoch 4520/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0318 - acc: 0.9917\n",
      "Epoch 4521/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0330 - acc: 0.9917\n",
      "Epoch 4522/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0312 - acc: 0.9917\n",
      "Epoch 4523/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0306 - acc: 0.9917\n",
      "Epoch 4524/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0174 - acc: 1.000 - 0s 75us/sample - loss: 0.0325 - acc: 0.9917\n",
      "Epoch 4525/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0309 - acc: 0.9917\n",
      "Epoch 4526/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0306 - acc: 0.9917\n",
      "Epoch 4527/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0307 - acc: 0.9917\n",
      "Epoch 4528/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0312 - acc: 0.9917\n",
      "Epoch 4529/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0306 - acc: 0.9917\n",
      "Epoch 4530/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0309 - acc: 0.9917\n",
      "Epoch 4531/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0313 - acc: 0.9917\n",
      "Epoch 4532/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0316 - acc: 0.9917\n",
      "Epoch 4533/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0314 - acc: 0.9917\n",
      "Epoch 4534/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0309 - acc: 0.9917\n",
      "Epoch 4535/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0307 - acc: 0.9917\n",
      "Epoch 4536/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0318 - acc: 0.9917\n",
      "Epoch 4537/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0296 - acc: 0.9917\n",
      "Epoch 4538/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0306 - acc: 0.9917\n",
      "Epoch 4539/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0322 - acc: 0.9917\n",
      "Epoch 4540/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0310 - acc: 0.9917\n",
      "Epoch 4541/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0349 - acc: 0.9917\n",
      "Epoch 4542/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0312 - acc: 0.9917\n",
      "Epoch 4543/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0214 - acc: 1.000 - 0s 75us/sample - loss: 0.0307 - acc: 0.9917\n",
      "Epoch 4544/8000\n",
      "120/120 [==============================] - 0s 59us/sample - loss: 0.0308 - acc: 0.9917\n",
      "Epoch 4545/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0313 - acc: 0.9917\n",
      "Epoch 4546/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0300 - acc: 0.9917\n",
      "Epoch 4547/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0306 - acc: 0.9917\n",
      "Epoch 4548/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0311 - acc: 0.9917\n",
      "Epoch 4549/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0336 - acc: 0.9917\n",
      "Epoch 4550/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0309 - acc: 0.9917\n",
      "Epoch 4551/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0305 - acc: 0.9917\n",
      "Epoch 4552/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0307 - acc: 0.9917\n",
      "Epoch 4553/8000\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.0306 - acc: 0.9917\n",
      "Epoch 4554/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0310 - acc: 0.9917\n",
      "Epoch 4555/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0308 - acc: 0.9917\n",
      "Epoch 4556/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0323 - acc: 0.9917\n",
      "Epoch 4557/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0310 - acc: 0.9917\n",
      "Epoch 4558/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0312 - acc: 0.9917\n",
      "Epoch 4559/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0302 - acc: 0.9917\n",
      "Epoch 4560/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0311 - acc: 0.9917\n",
      "Epoch 4561/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0310 - acc: 0.9917\n",
      "Epoch 4562/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0304 - acc: 0.9917\n",
      "Epoch 4563/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0305 - acc: 0.9917\n",
      "Epoch 4564/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0320 - acc: 0.9917\n",
      "Epoch 4565/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0304 - acc: 0.9917\n",
      "Epoch 4566/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0307 - acc: 0.9917\n",
      "Epoch 4567/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0308 - acc: 0.9917\n",
      "Epoch 4568/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0310 - acc: 0.9917\n",
      "Epoch 4569/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0311 - acc: 0.9917\n",
      "Epoch 4570/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0323 - acc: 0.9917\n",
      "Epoch 4571/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0312 - acc: 0.9917\n",
      "Epoch 4572/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0309 - acc: 0.9917\n",
      "Epoch 4573/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0330 - acc: 0.9917\n",
      "Epoch 4574/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0313 - acc: 0.9917\n",
      "Epoch 4575/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0304 - acc: 0.9917\n",
      "Epoch 4576/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0306 - acc: 0.9917\n",
      "Epoch 4577/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0316 - acc: 0.9917\n",
      "Epoch 4578/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0304 - acc: 0.9917\n",
      "Epoch 4579/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0305 - acc: 0.9917\n",
      "Epoch 4580/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0311 - acc: 0.9917\n",
      "Epoch 4581/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0311 - acc: 0.9917\n",
      "Epoch 4582/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0303 - acc: 0.9917\n",
      "Epoch 4583/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0302 - acc: 0.9917\n",
      "Epoch 4584/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0307 - acc: 0.9917\n",
      "Epoch 4585/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0321 - acc: 0.9917\n",
      "Epoch 4586/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0320 - acc: 0.9917\n",
      "Epoch 4587/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0300 - acc: 0.9917\n",
      "Epoch 4588/8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0306 - acc: 0.9917\n",
      "Epoch 4589/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0315 - acc: 0.9917\n",
      "Epoch 4590/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0316 - acc: 0.9917\n",
      "Epoch 4591/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0308 - acc: 0.9917\n",
      "Epoch 4592/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0309 - acc: 0.9917\n",
      "Epoch 4593/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0322 - acc: 0.9917\n",
      "Epoch 4594/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0316 - acc: 0.9917\n",
      "Epoch 4595/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0314 - acc: 0.9917\n",
      "Epoch 4596/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0308 - acc: 0.9917\n",
      "Epoch 4597/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0329 - acc: 0.9917\n",
      "Epoch 4598/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0303 - acc: 0.9917\n",
      "Epoch 4599/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0303 - acc: 0.9917\n",
      "Epoch 4600/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0318 - acc: 0.9917\n",
      "Epoch 4601/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0329 - acc: 0.9917\n",
      "Epoch 4602/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0315 - acc: 0.9917\n",
      "Epoch 4603/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0313 - acc: 0.9917\n",
      "Epoch 4604/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0309 - acc: 0.9917\n",
      "Epoch 4605/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0317 - acc: 0.9917\n",
      "Epoch 4606/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0333 - acc: 0.9917\n",
      "Epoch 4607/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0311 - acc: 0.9917\n",
      "Epoch 4608/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0319 - acc: 0.9917\n",
      "Epoch 4609/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0312 - acc: 0.9917\n",
      "Epoch 4610/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0304 - acc: 0.9917\n",
      "Epoch 4611/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0319 - acc: 0.9917\n",
      "Epoch 4612/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0310 - acc: 0.9917\n",
      "Epoch 4613/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0312 - acc: 0.9917\n",
      "Epoch 4614/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0303 - acc: 0.9917\n",
      "Epoch 4615/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0307 - acc: 0.9917\n",
      "Epoch 4616/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0312 - acc: 0.9917\n",
      "Epoch 4617/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0324 - acc: 0.9917\n",
      "Epoch 4618/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0309 - acc: 0.9917\n",
      "Epoch 4619/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0304 - acc: 0.9917\n",
      "Epoch 4620/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0305 - acc: 0.9917\n",
      "Epoch 4621/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0046 - acc: 1.000 - 0s 84us/sample - loss: 0.0301 - acc: 0.9917\n",
      "Epoch 4622/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0303 - acc: 0.9917\n",
      "Epoch 4623/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0325 - acc: 0.9917\n",
      "Epoch 4624/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0321 - acc: 0.9917\n",
      "Epoch 4625/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0315 - acc: 0.9917\n",
      "Epoch 4626/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0312 - acc: 0.9917\n",
      "Epoch 4627/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0308 - acc: 0.9917\n",
      "Epoch 4628/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0304 - acc: 0.9917\n",
      "Epoch 4629/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0304 - acc: 0.9917\n",
      "Epoch 4630/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0309 - acc: 0.9917\n",
      "Epoch 4631/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0313 - acc: 0.9917\n",
      "Epoch 4632/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0314 - acc: 0.9917\n",
      "Epoch 4633/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0329 - acc: 0.9917\n",
      "Epoch 4634/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0360 - acc: 0.9917\n",
      "Epoch 4635/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0315 - acc: 0.9917\n",
      "Epoch 4636/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0311 - acc: 0.9917\n",
      "Epoch 4637/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0319 - acc: 0.9917\n",
      "Epoch 4638/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0325 - acc: 0.9917\n",
      "Epoch 4639/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0302 - acc: 0.9917\n",
      "Epoch 4640/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0302 - acc: 0.9917\n",
      "Epoch 4641/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0306 - acc: 0.9917\n",
      "Epoch 4642/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0815 - acc: 0.968 - 0s 92us/sample - loss: 0.0301 - acc: 0.9917\n",
      "Epoch 4643/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0304 - acc: 0.9917\n",
      "Epoch 4644/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0308 - acc: 0.9917\n",
      "Epoch 4645/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0308 - acc: 0.9917\n",
      "Epoch 4646/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0305 - acc: 0.9917\n",
      "Epoch 4647/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0337 - acc: 0.9917\n",
      "Epoch 4648/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0326 - acc: 0.9917\n",
      "Epoch 4649/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0305 - acc: 0.9917\n",
      "Epoch 4650/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0302 - acc: 0.9917\n",
      "Epoch 4651/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0302 - acc: 0.9917\n",
      "Epoch 4652/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0303 - acc: 0.9917\n",
      "Epoch 4653/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0323 - acc: 0.9917\n",
      "Epoch 4654/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0304 - acc: 0.9917\n",
      "Epoch 4655/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0304 - acc: 0.9917\n",
      "Epoch 4656/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0299 - acc: 0.9917\n",
      "Epoch 4657/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0325 - acc: 0.9917\n",
      "Epoch 4658/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0302 - acc: 0.9917\n",
      "Epoch 4659/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0324 - acc: 0.9917\n",
      "Epoch 4660/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0312 - acc: 0.9917\n",
      "Epoch 4661/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0308 - acc: 0.9917\n",
      "Epoch 4662/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0313 - acc: 0.9917\n",
      "Epoch 4663/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0309 - acc: 0.9917\n",
      "Epoch 4664/8000\n",
      "120/120 [==============================] - 0s 50us/sample - loss: 0.0306 - acc: 0.9917\n",
      "Epoch 4665/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0305 - acc: 0.9917\n",
      "Epoch 4666/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0308 - acc: 0.9917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4667/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0310 - acc: 0.9917\n",
      "Epoch 4668/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0314 - acc: 0.9917\n",
      "Epoch 4669/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0318 - acc: 0.9917\n",
      "Epoch 4670/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0305 - acc: 0.9917\n",
      "Epoch 4671/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0303 - acc: 0.9917\n",
      "Epoch 4672/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0302 - acc: 0.9917\n",
      "Epoch 4673/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0309 - acc: 0.9917\n",
      "Epoch 4674/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0310 - acc: 0.9917\n",
      "Epoch 4675/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0305 - acc: 0.9917\n",
      "Epoch 4676/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0304 - acc: 0.9917\n",
      "Epoch 4677/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0310 - acc: 0.9917\n",
      "Epoch 4678/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0299 - acc: 0.9917\n",
      "Epoch 4679/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0341 - acc: 0.9917\n",
      "Epoch 4680/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0321 - acc: 0.9917\n",
      "Epoch 4681/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0303 - acc: 0.9917\n",
      "Epoch 4682/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0313 - acc: 0.9917\n",
      "Epoch 4683/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0301 - acc: 0.9917\n",
      "Epoch 4684/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0297 - acc: 0.9917\n",
      "Epoch 4685/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0308 - acc: 0.9917\n",
      "Epoch 4686/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0313 - acc: 0.9917\n",
      "Epoch 4687/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0306 - acc: 0.9917\n",
      "Epoch 4688/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0048 - acc: 1.000 - 0s 84us/sample - loss: 0.0305 - acc: 0.9917\n",
      "Epoch 4689/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0307 - acc: 0.9917\n",
      "Epoch 4690/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0305 - acc: 0.9917\n",
      "Epoch 4691/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0311 - acc: 0.9917\n",
      "Epoch 4692/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0299 - acc: 0.9917\n",
      "Epoch 4693/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0313 - acc: 0.9917\n",
      "Epoch 4694/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0305 - acc: 0.9917\n",
      "Epoch 4695/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0306 - acc: 0.9917\n",
      "Epoch 4696/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0302 - acc: 0.9917\n",
      "Epoch 4697/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0301 - acc: 0.9917\n",
      "Epoch 4698/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0310 - acc: 0.9917\n",
      "Epoch 4699/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0312 - acc: 0.9917\n",
      "Epoch 4700/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0307 - acc: 0.9917\n",
      "Epoch 4701/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0309 - acc: 0.9917\n",
      "Epoch 4702/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0313 - acc: 0.9917\n",
      "Epoch 4703/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0301 - acc: 0.9917\n",
      "Epoch 4704/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0300 - acc: 0.9917\n",
      "Epoch 4705/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0299 - acc: 0.9917\n",
      "Epoch 4706/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0312 - acc: 0.9917\n",
      "Epoch 4707/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0317 - acc: 0.9917\n",
      "Epoch 4708/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0325 - acc: 0.9917\n",
      "Epoch 4709/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0346 - acc: 0.9917\n",
      "Epoch 4710/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0306 - acc: 0.9917\n",
      "Epoch 4711/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0358 - acc: 0.9917\n",
      "Epoch 4712/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0321 - acc: 0.9917\n",
      "Epoch 4713/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0301 - acc: 0.9917\n",
      "Epoch 4714/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0305 - acc: 0.9917\n",
      "Epoch 4715/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0314 - acc: 0.9917\n",
      "Epoch 4716/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0304 - acc: 0.9917\n",
      "Epoch 4717/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0307 - acc: 0.9917\n",
      "Epoch 4718/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0308 - acc: 0.9917\n",
      "Epoch 4719/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0301 - acc: 0.9917\n",
      "Epoch 4720/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0304 - acc: 0.9917\n",
      "Epoch 4721/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0304 - acc: 0.9917\n",
      "Epoch 4722/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0301 - acc: 0.9917\n",
      "Epoch 4723/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0304 - acc: 0.9917\n",
      "Epoch 4724/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0304 - acc: 0.9917\n",
      "Epoch 4725/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0302 - acc: 0.9917\n",
      "Epoch 4726/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0299 - acc: 0.9917\n",
      "Epoch 4727/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0302 - acc: 0.9917\n",
      "Epoch 4728/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0304 - acc: 0.9917\n",
      "Epoch 4729/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0306 - acc: 0.9917\n",
      "Epoch 4730/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0316 - acc: 0.9917\n",
      "Epoch 4731/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0304 - acc: 0.9917\n",
      "Epoch 4732/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0301 - acc: 0.9917\n",
      "Epoch 4733/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0303 - acc: 0.9917\n",
      "Epoch 4734/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0300 - acc: 0.9917\n",
      "Epoch 4735/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0317 - acc: 0.9917\n",
      "Epoch 4736/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0327 - acc: 0.9917\n",
      "Epoch 4737/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0300 - acc: 0.9917\n",
      "Epoch 4738/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0305 - acc: 0.9917\n",
      "Epoch 4739/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0298 - acc: 0.9917\n",
      "Epoch 4740/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0306 - acc: 0.9917\n",
      "Epoch 4741/8000\n",
      "120/120 [==============================] - 0s 59us/sample - loss: 0.0307 - acc: 0.9917\n",
      "Epoch 4742/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0309 - acc: 0.9917\n",
      "Epoch 4743/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0308 - acc: 0.9917\n",
      "Epoch 4744/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0301 - acc: 0.9917\n",
      "Epoch 4745/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0306 - acc: 0.9917\n",
      "Epoch 4746/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0308 - acc: 0.9917\n",
      "Epoch 4747/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0303 - acc: 0.9917\n",
      "Epoch 4748/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0301 - acc: 0.9917\n",
      "Epoch 4749/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0305 - acc: 0.9917\n",
      "Epoch 4750/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0307 - acc: 0.9917\n",
      "Epoch 4751/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0310 - acc: 0.9917\n",
      "Epoch 4752/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0295 - acc: 0.9917\n",
      "Epoch 4753/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0330 - acc: 0.9917\n",
      "Epoch 4754/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0326 - acc: 0.9833\n",
      "Epoch 4755/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0291 - acc: 0.9917\n",
      "Epoch 4756/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0311 - acc: 0.9917\n",
      "Epoch 4757/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0324 - acc: 0.9917\n",
      "Epoch 4758/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0307 - acc: 0.9917\n",
      "Epoch 4759/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0331 - acc: 0.9917\n",
      "Epoch 4760/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0314 - acc: 0.9917\n",
      "Epoch 4761/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0359 - acc: 0.9917\n",
      "Epoch 4762/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0301 - acc: 0.9917\n",
      "Epoch 4763/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0291 - acc: 0.9917\n",
      "Epoch 4764/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0318 - acc: 0.9917\n",
      "Epoch 4765/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0306 - acc: 0.9917\n",
      "Epoch 4766/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0297 - acc: 0.9917\n",
      "Epoch 4767/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0299 - acc: 0.9917\n",
      "Epoch 4768/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0303 - acc: 0.9917\n",
      "Epoch 4769/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0327 - acc: 0.9917\n",
      "Epoch 4770/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0318 - acc: 0.9917\n",
      "Epoch 4771/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0303 - acc: 0.9917\n",
      "Epoch 4772/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0308 - acc: 0.9917\n",
      "Epoch 4773/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0299 - acc: 0.9917\n",
      "Epoch 4774/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0298 - acc: 0.9917\n",
      "Epoch 4775/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0306 - acc: 0.9917\n",
      "Epoch 4776/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0313 - acc: 0.9917\n",
      "Epoch 4777/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0326 - acc: 0.9917\n",
      "Epoch 4778/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0302 - acc: 0.9917\n",
      "Epoch 4779/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0299 - acc: 0.9917\n",
      "Epoch 4780/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0298 - acc: 0.9917\n",
      "Epoch 4781/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0301 - acc: 0.9917\n",
      "Epoch 4782/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0305 - acc: 0.9917\n",
      "Epoch 4783/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0325 - acc: 0.9917\n",
      "Epoch 4784/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0301 - acc: 0.9917\n",
      "Epoch 4785/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0302 - acc: 0.9917\n",
      "Epoch 4786/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0313 - acc: 0.9917\n",
      "Epoch 4787/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0331 - acc: 0.9917\n",
      "Epoch 4788/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0298 - acc: 0.9917\n",
      "Epoch 4789/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0306 - acc: 0.9917\n",
      "Epoch 4790/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0305 - acc: 0.9917\n",
      "Epoch 4791/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0303 - acc: 0.9917\n",
      "Epoch 4792/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0298 - acc: 0.9917\n",
      "Epoch 4793/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0303 - acc: 0.9917\n",
      "Epoch 4794/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0304 - acc: 0.9917\n",
      "Epoch 4795/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0312 - acc: 0.9917\n",
      "Epoch 4796/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0319 - acc: 0.9917\n",
      "Epoch 4797/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0310 - acc: 0.9917\n",
      "Epoch 4798/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0300 - acc: 0.9917\n",
      "Epoch 4799/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0307 - acc: 0.9917\n",
      "Epoch 4800/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0326 - acc: 0.9917\n",
      "Epoch 4801/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0330 - acc: 0.9917\n",
      "Epoch 4802/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0317 - acc: 0.9917\n",
      "Epoch 4803/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0315 - acc: 0.9917\n",
      "Epoch 4804/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0301 - acc: 0.9917\n",
      "Epoch 4805/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0300 - acc: 0.9917\n",
      "Epoch 4806/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0304 - acc: 0.9917\n",
      "Epoch 4807/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0300 - acc: 0.9917\n",
      "Epoch 4808/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0303 - acc: 0.9917\n",
      "Epoch 4809/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0312 - acc: 0.9917\n",
      "Epoch 4810/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0299 - acc: 0.9917\n",
      "Epoch 4811/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0299 - acc: 0.9917\n",
      "Epoch 4812/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0303 - acc: 0.9917\n",
      "Epoch 4813/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0298 - acc: 0.9917\n",
      "Epoch 4814/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0300 - acc: 0.9917\n",
      "Epoch 4815/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0298 - acc: 0.9917\n",
      "Epoch 4816/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0298 - acc: 0.9917\n",
      "Epoch 4817/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0298 - acc: 0.9917\n",
      "Epoch 4818/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0308 - acc: 0.9917\n",
      "Epoch 4819/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0317 - acc: 0.9917\n",
      "Epoch 4820/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0313 - acc: 0.9917\n",
      "Epoch 4821/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0315 - acc: 0.9917\n",
      "Epoch 4822/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0299 - acc: 0.9917\n",
      "Epoch 4823/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0302 - acc: 0.9917\n",
      "Epoch 4824/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0304 - acc: 0.9917\n",
      "Epoch 4825/8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0299 - acc: 0.9917\n",
      "Epoch 4826/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0306 - acc: 0.9917\n",
      "Epoch 4827/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0331 - acc: 0.9917\n",
      "Epoch 4828/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0329 - acc: 0.9917\n",
      "Epoch 4829/8000\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.0306 - acc: 0.9917\n",
      "Epoch 4830/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0303 - acc: 0.9917\n",
      "Epoch 4831/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0300 - acc: 0.9917\n",
      "Epoch 4832/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0318 - acc: 0.9917\n",
      "Epoch 4833/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0303 - acc: 0.9917\n",
      "Epoch 4834/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0295 - acc: 0.9917\n",
      "Epoch 4835/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0296 - acc: 0.9917\n",
      "Epoch 4836/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0319 - acc: 0.9917\n",
      "Epoch 4837/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0317 - acc: 0.9917\n",
      "Epoch 4838/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0297 - acc: 0.9917\n",
      "Epoch 4839/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0343 - acc: 0.9917\n",
      "Epoch 4840/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0323 - acc: 0.9917\n",
      "Epoch 4841/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0298 - acc: 0.9917\n",
      "Epoch 4842/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0306 - acc: 0.9917\n",
      "Epoch 4843/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0312 - acc: 0.9917\n",
      "Epoch 4844/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0305 - acc: 0.9917\n",
      "Epoch 4845/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0307 - acc: 0.9917\n",
      "Epoch 4846/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0294 - acc: 0.9917\n",
      "Epoch 4847/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0321 - acc: 0.9917\n",
      "Epoch 4848/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0307 - acc: 0.9917\n",
      "Epoch 4849/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0299 - acc: 0.9917\n",
      "Epoch 4850/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0301 - acc: 0.9917\n",
      "Epoch 4851/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0303 - acc: 0.9917\n",
      "Epoch 4852/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0296 - acc: 0.9917\n",
      "Epoch 4853/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0300 - acc: 0.9917\n",
      "Epoch 4854/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0302 - acc: 0.9917\n",
      "Epoch 4855/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0296 - acc: 0.9917\n",
      "Epoch 4856/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0303 - acc: 0.9917\n",
      "Epoch 4857/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0298 - acc: 0.9917\n",
      "Epoch 4858/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0307 - acc: 0.9917\n",
      "Epoch 4859/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0303 - acc: 0.9917\n",
      "Epoch 4860/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0296 - acc: 0.9917\n",
      "Epoch 4861/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0309 - acc: 0.9917\n",
      "Epoch 4862/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0296 - acc: 0.9917\n",
      "Epoch 4863/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0295 - acc: 0.9917\n",
      "Epoch 4864/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0312 - acc: 0.9917\n",
      "Epoch 4865/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0322 - acc: 0.9917\n",
      "Epoch 4866/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0309 - acc: 0.9917\n",
      "Epoch 4867/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0297 - acc: 0.9917\n",
      "Epoch 4868/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0307 - acc: 0.9917\n",
      "Epoch 4869/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0323 - acc: 0.9917\n",
      "Epoch 4870/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0306 - acc: 0.9917\n",
      "Epoch 4871/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0298 - acc: 0.9917\n",
      "Epoch 4872/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0309 - acc: 0.9917\n",
      "Epoch 4873/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0300 - acc: 0.9917\n",
      "Epoch 4874/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0316 - acc: 0.9917\n",
      "Epoch 4875/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0302 - acc: 0.9917\n",
      "Epoch 4876/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0347 - acc: 0.9917\n",
      "Epoch 4877/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0306 - acc: 0.9917\n",
      "Epoch 4878/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0305 - acc: 0.9917\n",
      "Epoch 4879/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0306 - acc: 0.9917\n",
      "Epoch 4880/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0308 - acc: 0.9917\n",
      "Epoch 4881/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0297 - acc: 0.9917\n",
      "Epoch 4882/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0297 - acc: 0.9917\n",
      "Epoch 4883/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0306 - acc: 0.9917\n",
      "Epoch 4884/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0305 - acc: 0.9917\n",
      "Epoch 4885/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0299 - acc: 0.9917\n",
      "Epoch 4886/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0300 - acc: 0.9917\n",
      "Epoch 4887/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0297 - acc: 0.9917\n",
      "Epoch 4888/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0293 - acc: 0.9917\n",
      "Epoch 4889/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0297 - acc: 0.9917\n",
      "Epoch 4890/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0300 - acc: 0.9917\n",
      "Epoch 4891/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0303 - acc: 0.9917\n",
      "Epoch 4892/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0318 - acc: 0.9917\n",
      "Epoch 4893/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0300 - acc: 0.9917\n",
      "Epoch 4894/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0296 - acc: 0.9917\n",
      "Epoch 4895/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0308 - acc: 0.9917\n",
      "Epoch 4896/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0296 - acc: 0.9917\n",
      "Epoch 4897/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0293 - acc: 0.9917\n",
      "Epoch 4898/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0296 - acc: 0.9917\n",
      "Epoch 4899/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0298 - acc: 0.9917\n",
      "Epoch 4900/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0306 - acc: 0.9917\n",
      "Epoch 4901/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0301 - acc: 0.9917\n",
      "Epoch 4902/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0306 - acc: 0.9917\n",
      "Epoch 4903/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0310 - acc: 0.9917\n",
      "Epoch 4904/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0293 - acc: 0.9917\n",
      "Epoch 4905/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0305 - acc: 0.9917\n",
      "Epoch 4906/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0305 - acc: 0.9917\n",
      "Epoch 4907/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0306 - acc: 0.9917\n",
      "Epoch 4908/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0302 - acc: 0.9917\n",
      "Epoch 4909/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0294 - acc: 0.9917\n",
      "Epoch 4910/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0308 - acc: 0.9917\n",
      "Epoch 4911/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0301 - acc: 0.9917\n",
      "Epoch 4912/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0305 - acc: 0.9917\n",
      "Epoch 4913/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0316 - acc: 0.9917\n",
      "Epoch 4914/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0315 - acc: 0.9917\n",
      "Epoch 4915/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0300 - acc: 0.9917\n",
      "Epoch 4916/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0297 - acc: 0.9917\n",
      "Epoch 4917/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0312 - acc: 0.9917\n",
      "Epoch 4918/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0295 - acc: 0.9917\n",
      "Epoch 4919/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0307 - acc: 0.9917\n",
      "Epoch 4920/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0311 - acc: 0.9917\n",
      "Epoch 4921/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0294 - acc: 0.9917\n",
      "Epoch 4922/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0302 - acc: 0.9917\n",
      "Epoch 4923/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0306 - acc: 0.9917\n",
      "Epoch 4924/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0297 - acc: 0.9917\n",
      "Epoch 4925/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0308 - acc: 0.9917\n",
      "Epoch 4926/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0301 - acc: 0.9917\n",
      "Epoch 4927/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0305 - acc: 0.9917\n",
      "Epoch 4928/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0291 - acc: 0.9917\n",
      "Epoch 4929/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0304 - acc: 0.9917\n",
      "Epoch 4930/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0304 - acc: 0.9917\n",
      "Epoch 4931/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0324 - acc: 0.9917\n",
      "Epoch 4932/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0321 - acc: 0.9917\n",
      "Epoch 4933/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0298 - acc: 0.9917\n",
      "Epoch 4934/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0304 - acc: 0.9917\n",
      "Epoch 4935/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0294 - acc: 0.9917\n",
      "Epoch 4936/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0308 - acc: 0.9917\n",
      "Epoch 4937/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0320 - acc: 0.9917\n",
      "Epoch 4938/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0285 - acc: 0.9917\n",
      "Epoch 4939/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0292 - acc: 0.9917\n",
      "Epoch 4940/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0316 - acc: 0.9917\n",
      "Epoch 4941/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0308 - acc: 0.9917\n",
      "Epoch 4942/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0314 - acc: 0.9917\n",
      "Epoch 4943/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0301 - acc: 0.9917\n",
      "Epoch 4944/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0296 - acc: 0.9917\n",
      "Epoch 4945/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0304 - acc: 0.9917\n",
      "Epoch 4946/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0322 - acc: 0.9917\n",
      "Epoch 4947/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0302 - acc: 0.9917\n",
      "Epoch 4948/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0317 - acc: 0.9917\n",
      "Epoch 4949/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0308 - acc: 0.9917\n",
      "Epoch 4950/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0288 - acc: 0.9917\n",
      "Epoch 4951/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0311 - acc: 0.9917\n",
      "Epoch 4952/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0310 - acc: 0.9917\n",
      "Epoch 4953/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0151 - acc: 1.000 - 0s 75us/sample - loss: 0.0304 - acc: 0.9917\n",
      "Epoch 4954/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0296 - acc: 0.9917\n",
      "Epoch 4955/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0299 - acc: 0.9917\n",
      "Epoch 4956/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0301 - acc: 0.9917\n",
      "Epoch 4957/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0300 - acc: 0.9917\n",
      "Epoch 4958/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0310 - acc: 0.9917\n",
      "Epoch 4959/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0294 - acc: 0.9917\n",
      "Epoch 4960/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0294 - acc: 0.9917\n",
      "Epoch 4961/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0301 - acc: 0.9917\n",
      "Epoch 4962/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0293 - acc: 0.9917\n",
      "Epoch 4963/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0320 - acc: 0.9917\n",
      "Epoch 4964/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0316 - acc: 0.9917\n",
      "Epoch 4965/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0296 - acc: 0.9917\n",
      "Epoch 4966/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0296 - acc: 0.9917\n",
      "Epoch 4967/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0295 - acc: 0.9917\n",
      "Epoch 4968/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0291 - acc: 0.9917\n",
      "Epoch 4969/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0298 - acc: 0.9917\n",
      "Epoch 4970/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0309 - acc: 0.9917\n",
      "Epoch 4971/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0300 - acc: 0.9917\n",
      "Epoch 4972/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0300 - acc: 0.9917\n",
      "Epoch 4973/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0298 - acc: 0.9917\n",
      "Epoch 4974/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0304 - acc: 0.9917\n",
      "Epoch 4975/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0295 - acc: 0.9917\n",
      "Epoch 4976/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0299 - acc: 0.9917\n",
      "Epoch 4977/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0301 - acc: 0.9917\n",
      "Epoch 4978/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0297 - acc: 0.9917\n",
      "Epoch 4979/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0292 - acc: 0.9917\n",
      "Epoch 4980/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0297 - acc: 0.9917\n",
      "Epoch 4981/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0302 - acc: 0.9917\n",
      "Epoch 4982/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0299 - acc: 0.9917\n",
      "Epoch 4983/8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 134us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 4984/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0292 - acc: 0.9917\n",
      "Epoch 4985/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0310 - acc: 0.9917\n",
      "Epoch 4986/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0294 - acc: 0.9917\n",
      "Epoch 4987/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0295 - acc: 0.9917\n",
      "Epoch 4988/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0301 - acc: 0.9917\n",
      "Epoch 4989/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0306 - acc: 0.9917\n",
      "Epoch 4990/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0291 - acc: 0.9917\n",
      "Epoch 4991/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0323 - acc: 0.9917\n",
      "Epoch 4992/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0317 - acc: 0.9917\n",
      "Epoch 4993/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0310 - acc: 0.9917\n",
      "Epoch 4994/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0305 - acc: 0.9917\n",
      "Epoch 4995/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0299 - acc: 0.9917\n",
      "Epoch 4996/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0324 - acc: 0.9833\n",
      "Epoch 4997/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0308 - acc: 0.9917\n",
      "Epoch 4998/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0325 - acc: 0.9917\n",
      "Epoch 4999/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0307 - acc: 0.9917\n",
      "Epoch 5000/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0303 - acc: 0.9917\n",
      "Epoch 5001/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0288 - acc: 0.9917\n",
      "Epoch 5002/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0305 - acc: 0.9917\n",
      "Epoch 5003/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0304 - acc: 0.9917\n",
      "Epoch 5004/8000\n",
      "120/120 [==============================] - 0s 83us/sample - loss: 0.0306 - acc: 0.9917\n",
      "Epoch 5005/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0304 - acc: 0.9917\n",
      "Epoch 5006/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0299 - acc: 0.9917\n",
      "Epoch 5007/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0303 - acc: 0.9917\n",
      "Epoch 5008/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0293 - acc: 0.9917\n",
      "Epoch 5009/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0318 - acc: 0.9917\n",
      "Epoch 5010/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0313 - acc: 0.9917\n",
      "Epoch 5011/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0301 - acc: 0.9917\n",
      "Epoch 5012/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0291 - acc: 0.9917\n",
      "Epoch 5013/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0302 - acc: 0.9917\n",
      "Epoch 5014/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0304 - acc: 0.9917\n",
      "Epoch 5015/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0302 - acc: 0.9917\n",
      "Epoch 5016/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0305 - acc: 0.9917\n",
      "Epoch 5017/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0307 - acc: 0.9917\n",
      "Epoch 5018/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0294 - acc: 0.9917\n",
      "Epoch 5019/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0304 - acc: 0.9917\n",
      "Epoch 5020/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0299 - acc: 0.9917\n",
      "Epoch 5021/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0297 - acc: 0.9917\n",
      "Epoch 5022/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0292 - acc: 0.9917\n",
      "Epoch 5023/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0293 - acc: 0.9917\n",
      "Epoch 5024/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0313 - acc: 0.9917\n",
      "Epoch 5025/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0303 - acc: 0.9917\n",
      "Epoch 5026/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0296 - acc: 0.9917\n",
      "Epoch 5027/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0297 - acc: 0.9917\n",
      "Epoch 5028/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0297 - acc: 0.9917\n",
      "Epoch 5029/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0294 - acc: 0.9917\n",
      "Epoch 5030/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0301 - acc: 0.9917\n",
      "Epoch 5031/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0291 - acc: 0.9917\n",
      "Epoch 5032/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0323 - acc: 0.9917\n",
      "Epoch 5033/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0310 - acc: 0.9917\n",
      "Epoch 5034/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0285 - acc: 0.9917\n",
      "Epoch 5035/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0301 - acc: 0.9917\n",
      "Epoch 5036/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0312 - acc: 0.9917\n",
      "Epoch 5037/8000\n",
      "120/120 [==============================] - 0s 83us/sample - loss: 0.0298 - acc: 0.9917\n",
      "Epoch 5038/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0300 - acc: 0.9917\n",
      "Epoch 5039/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0664 - acc: 0.968 - 0s 75us/sample - loss: 0.0297 - acc: 0.9917\n",
      "Epoch 5040/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0748 - acc: 0.968 - 0s 75us/sample - loss: 0.0291 - acc: 0.9917\n",
      "Epoch 5041/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0307 - acc: 0.9917\n",
      "Epoch 5042/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0300 - acc: 0.9917\n",
      "Epoch 5043/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0291 - acc: 0.9917\n",
      "Epoch 5044/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0294 - acc: 0.9917\n",
      "Epoch 5045/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0296 - acc: 0.9917\n",
      "Epoch 5046/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0296 - acc: 0.9917\n",
      "Epoch 5047/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0291 - acc: 0.9917\n",
      "Epoch 5048/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0310 - acc: 0.9917\n",
      "Epoch 5049/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0300 - acc: 0.9917\n",
      "Epoch 5050/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0288 - acc: 0.9917\n",
      "Epoch 5051/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0296 - acc: 0.9917\n",
      "Epoch 5052/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0311 - acc: 0.9917\n",
      "Epoch 5053/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0295 - acc: 0.9917\n",
      "Epoch 5054/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0316 - acc: 0.9917\n",
      "Epoch 5055/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0303 - acc: 0.9917\n",
      "Epoch 5056/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0294 - acc: 0.9917\n",
      "Epoch 5057/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0290 - acc: 0.9917\n",
      "Epoch 5058/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0291 - acc: 0.9917\n",
      "Epoch 5059/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0301 - acc: 0.9917\n",
      "Epoch 5060/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0302 - acc: 0.9917\n",
      "Epoch 5061/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0293 - acc: 0.9917\n",
      "Epoch 5062/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0301 - acc: 0.9917\n",
      "Epoch 5063/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0295 - acc: 0.9917\n",
      "Epoch 5064/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0294 - acc: 0.9917\n",
      "Epoch 5065/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0310 - acc: 0.9917\n",
      "Epoch 5066/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0290 - acc: 0.9917\n",
      "Epoch 5067/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0296 - acc: 0.9917\n",
      "Epoch 5068/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 5069/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0297 - acc: 0.9917\n",
      "Epoch 5070/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0294 - acc: 0.9917\n",
      "Epoch 5071/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0292 - acc: 0.9917\n",
      "Epoch 5072/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0293 - acc: 0.9917\n",
      "Epoch 5073/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0312 - acc: 0.9917\n",
      "Epoch 5074/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0297 - acc: 0.9917\n",
      "Epoch 5075/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0323 - acc: 0.9917\n",
      "Epoch 5076/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0295 - acc: 0.9917\n",
      "Epoch 5077/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0296 - acc: 0.9917\n",
      "Epoch 5078/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0293 - acc: 0.9917\n",
      "Epoch 5079/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0299 - acc: 0.9917\n",
      "Epoch 5080/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0294 - acc: 0.9917\n",
      "Epoch 5081/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0318 - acc: 0.9917\n",
      "Epoch 5082/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0302 - acc: 0.9917\n",
      "Epoch 5083/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0297 - acc: 0.9917\n",
      "Epoch 5084/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0306 - acc: 0.9917\n",
      "Epoch 5085/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0296 - acc: 0.9917\n",
      "Epoch 5086/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0290 - acc: 0.9917\n",
      "Epoch 5087/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0293 - acc: 0.9917\n",
      "Epoch 5088/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0298 - acc: 0.9917\n",
      "Epoch 5089/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0292 - acc: 0.9917\n",
      "Epoch 5090/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0291 - acc: 0.9917\n",
      "Epoch 5091/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0293 - acc: 0.9917\n",
      "Epoch 5092/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0295 - acc: 0.9917\n",
      "Epoch 5093/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0306 - acc: 0.9917\n",
      "Epoch 5094/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0294 - acc: 0.9917\n",
      "Epoch 5095/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0284 - acc: 0.9917\n",
      "Epoch 5096/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0363 - acc: 0.9833\n",
      "Epoch 5097/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0307 - acc: 0.9917\n",
      "Epoch 5098/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0300 - acc: 0.9917\n",
      "Epoch 5099/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0304 - acc: 0.9917\n",
      "Epoch 5100/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 5101/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0321 - acc: 0.9917\n",
      "Epoch 5102/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0317 - acc: 0.9833\n",
      "Epoch 5103/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 5104/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0293 - acc: 0.9917\n",
      "Epoch 5105/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0307 - acc: 0.9917\n",
      "Epoch 5106/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0299 - acc: 0.9917\n",
      "Epoch 5107/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0291 - acc: 0.9917\n",
      "Epoch 5108/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0291 - acc: 0.9917\n",
      "Epoch 5109/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0294 - acc: 0.9917\n",
      "Epoch 5110/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0292 - acc: 0.9917\n",
      "Epoch 5111/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0303 - acc: 0.9917\n",
      "Epoch 5112/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0297 - acc: 0.9917\n",
      "Epoch 5113/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0293 - acc: 0.9917\n",
      "Epoch 5114/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 5115/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0300 - acc: 0.9917\n",
      "Epoch 5116/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0295 - acc: 0.9917\n",
      "Epoch 5117/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0310 - acc: 0.9917\n",
      "Epoch 5118/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0312 - acc: 0.9917\n",
      "Epoch 5119/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0292 - acc: 0.9917\n",
      "Epoch 5120/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0306 - acc: 0.9917\n",
      "Epoch 5121/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 5122/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0298 - acc: 0.9917\n",
      "Epoch 5123/8000\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.0294 - acc: 0.9917\n",
      "Epoch 5124/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0307 - acc: 0.9917\n",
      "Epoch 5125/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 5126/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0298 - acc: 0.9917\n",
      "Epoch 5127/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0292 - acc: 0.9917\n",
      "Epoch 5128/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0298 - acc: 0.9917\n",
      "Epoch 5129/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0290 - acc: 0.9917\n",
      "Epoch 5130/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0287 - acc: 0.9917\n",
      "Epoch 5131/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0299 - acc: 0.9917\n",
      "Epoch 5132/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0305 - acc: 0.9917\n",
      "Epoch 5133/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0300 - acc: 0.9917\n",
      "Epoch 5134/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0306 - acc: 0.9917\n",
      "Epoch 5135/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0301 - acc: 0.9917\n",
      "Epoch 5136/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0317 - acc: 0.9917\n",
      "Epoch 5137/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0303 - acc: 0.9917\n",
      "Epoch 5138/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 5139/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0296 - acc: 0.9917\n",
      "Epoch 5140/8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0300 - acc: 0.9917\n",
      "Epoch 5141/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0287 - acc: 0.9917\n",
      "Epoch 5142/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0318 - acc: 0.9917\n",
      "Epoch 5143/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0302 - acc: 0.9917\n",
      "Epoch 5144/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0294 - acc: 0.9917\n",
      "Epoch 5145/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0310 - acc: 0.9917\n",
      "Epoch 5146/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0304 - acc: 0.9917\n",
      "Epoch 5147/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0302 - acc: 0.9917\n",
      "Epoch 5148/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0304 - acc: 0.9917\n",
      "Epoch 5149/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0291 - acc: 0.9917\n",
      "Epoch 5150/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0295 - acc: 0.9917\n",
      "Epoch 5151/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0288 - acc: 0.9917\n",
      "Epoch 5152/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0291 - acc: 0.9917\n",
      "Epoch 5153/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0295 - acc: 0.9917\n",
      "Epoch 5154/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0292 - acc: 0.9917\n",
      "Epoch 5155/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0294 - acc: 0.9917\n",
      "Epoch 5156/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0303 - acc: 0.9917\n",
      "Epoch 5157/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0296 - acc: 0.9917\n",
      "Epoch 5158/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0315 - acc: 0.9917\n",
      "Epoch 5159/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0305 - acc: 0.9917\n",
      "Epoch 5160/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0319 - acc: 0.9917\n",
      "Epoch 5161/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0301 - acc: 0.9917\n",
      "Epoch 5162/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0291 - acc: 0.9917\n",
      "Epoch 5163/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0292 - acc: 0.9917\n",
      "Epoch 5164/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0298 - acc: 0.9917\n",
      "Epoch 5165/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0293 - acc: 0.9917\n",
      "Epoch 5166/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0295 - acc: 0.9917\n",
      "Epoch 5167/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0293 - acc: 0.9917\n",
      "Epoch 5168/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0287 - acc: 0.9917\n",
      "Epoch 5169/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0294 - acc: 0.9917\n",
      "Epoch 5170/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0292 - acc: 0.9917\n",
      "Epoch 5171/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0305 - acc: 0.9917\n",
      "Epoch 5172/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0291 - acc: 0.9917\n",
      "Epoch 5173/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 5174/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0293 - acc: 0.9917\n",
      "Epoch 5175/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0296 - acc: 0.9917\n",
      "Epoch 5176/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0292 - acc: 0.9917\n",
      "Epoch 5177/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0306 - acc: 0.9917\n",
      "Epoch 5178/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0242 - acc: 1.000 - 0s 84us/sample - loss: 0.0292 - acc: 0.9917\n",
      "Epoch 5179/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0285 - acc: 0.9917\n",
      "Epoch 5180/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0294 - acc: 0.9917\n",
      "Epoch 5181/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 5182/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0308 - acc: 0.9917\n",
      "Epoch 5183/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0290 - acc: 0.9917\n",
      "Epoch 5184/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0287 - acc: 0.9917\n",
      "Epoch 5185/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0290 - acc: 0.9917\n",
      "Epoch 5186/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0291 - acc: 0.9917\n",
      "Epoch 5187/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0299 - acc: 0.9917\n",
      "Epoch 5188/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0290 - acc: 0.9917\n",
      "Epoch 5189/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0301 - acc: 0.9917\n",
      "Epoch 5190/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0287 - acc: 0.9917\n",
      "Epoch 5191/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0288 - acc: 0.9917\n",
      "Epoch 5192/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0295 - acc: 0.9917\n",
      "Epoch 5193/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 5194/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0297 - acc: 0.9917\n",
      "Epoch 5195/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0295 - acc: 0.9917\n",
      "Epoch 5196/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0295 - acc: 0.9917\n",
      "Epoch 5197/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0288 - acc: 0.9917\n",
      "Epoch 5198/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0299 - acc: 0.9917\n",
      "Epoch 5199/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0301 - acc: 0.9917\n",
      "Epoch 5200/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0058 - acc: 1.000 - 0s 92us/sample - loss: 0.0294 - acc: 0.9917\n",
      "Epoch 5201/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0293 - acc: 0.9917\n",
      "Epoch 5202/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0301 - acc: 0.9917\n",
      "Epoch 5203/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 5204/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0296 - acc: 0.9917\n",
      "Epoch 5205/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0314 - acc: 0.9917\n",
      "Epoch 5206/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0332 - acc: 0.9917\n",
      "Epoch 5207/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0295 - acc: 0.9917\n",
      "Epoch 5208/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0290 - acc: 0.9917\n",
      "Epoch 5209/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0290 - acc: 0.9917\n",
      "Epoch 5210/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 5211/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0296 - acc: 0.9917\n",
      "Epoch 5212/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0299 - acc: 0.9917\n",
      "Epoch 5213/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0288 - acc: 0.9917\n",
      "Epoch 5214/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0291 - acc: 0.9917\n",
      "Epoch 5215/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0293 - acc: 0.9917\n",
      "Epoch 5216/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0295 - acc: 0.9917\n",
      "Epoch 5217/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0286 - acc: 0.9917\n",
      "Epoch 5218/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0300 - acc: 0.9917\n",
      "Epoch 5219/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0293 - acc: 0.9917\n",
      "Epoch 5220/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0290 - acc: 0.9917\n",
      "Epoch 5221/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0301 - acc: 0.9917\n",
      "Epoch 5222/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0301 - acc: 0.9917\n",
      "Epoch 5223/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0301 - acc: 0.9917\n",
      "Epoch 5224/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0288 - acc: 0.9917\n",
      "Epoch 5225/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0290 - acc: 0.9917\n",
      "Epoch 5226/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0298 - acc: 0.9917\n",
      "Epoch 5227/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0303 - acc: 0.9917\n",
      "Epoch 5228/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0313 - acc: 0.9917\n",
      "Epoch 5229/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0299 - acc: 0.9917\n",
      "Epoch 5230/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0292 - acc: 0.9917\n",
      "Epoch 5231/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0309 - acc: 0.9917\n",
      "Epoch 5232/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0300 - acc: 0.9917\n",
      "Epoch 5233/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0300 - acc: 0.9917\n",
      "Epoch 5234/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0284 - acc: 0.9917\n",
      "Epoch 5235/8000\n",
      "120/120 [==============================] - 0s 83us/sample - loss: 0.0304 - acc: 0.9917\n",
      "Epoch 5236/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0299 - acc: 0.9917\n",
      "Epoch 5237/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0300 - acc: 0.9917\n",
      "Epoch 5238/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0296 - acc: 0.9917\n",
      "Epoch 5239/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 5240/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0286 - acc: 0.9917\n",
      "Epoch 5241/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0292 - acc: 0.9917\n",
      "Epoch 5242/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0295 - acc: 0.9917\n",
      "Epoch 5243/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0291 - acc: 0.9917\n",
      "Epoch 5244/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0292 - acc: 0.9917\n",
      "Epoch 5245/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0292 - acc: 0.9917\n",
      "Epoch 5246/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0231 - acc: 1.000 - 0s 75us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 5247/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0291 - acc: 0.9917\n",
      "Epoch 5248/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0065 - acc: 1.000 - 0s 75us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 5249/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0291 - acc: 0.9917\n",
      "Epoch 5250/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0292 - acc: 0.9917\n",
      "Epoch 5251/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0295 - acc: 0.9917\n",
      "Epoch 5252/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 5253/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0288 - acc: 0.9917\n",
      "Epoch 5254/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0296 - acc: 0.9917\n",
      "Epoch 5255/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0313 - acc: 0.9917\n",
      "Epoch 5256/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0288 - acc: 0.9917\n",
      "Epoch 5257/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0287 - acc: 0.9917\n",
      "Epoch 5258/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 5259/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0291 - acc: 0.9917\n",
      "Epoch 5260/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0285 - acc: 0.9917\n",
      "Epoch 5261/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0291 - acc: 0.9917\n",
      "Epoch 5262/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0291 - acc: 0.9917\n",
      "Epoch 5263/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0322 - acc: 0.9917\n",
      "Epoch 5264/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0297 - acc: 0.9917\n",
      "Epoch 5265/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0326 - acc: 0.9917\n",
      "Epoch 5266/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0296 - acc: 0.9917\n",
      "Epoch 5267/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0280 - acc: 0.9917\n",
      "Epoch 5268/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 5269/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0297 - acc: 0.9917\n",
      "Epoch 5270/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0307 - acc: 0.9917\n",
      "Epoch 5271/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0286 - acc: 0.9917\n",
      "Epoch 5272/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0288 - acc: 0.9917\n",
      "Epoch 5273/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0308 - acc: 0.9917\n",
      "Epoch 5274/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0288 - acc: 0.9917\n",
      "Epoch 5275/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0284 - acc: 0.9917\n",
      "Epoch 5276/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0294 - acc: 0.9917\n",
      "Epoch 5277/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 5278/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0287 - acc: 0.9917\n",
      "Epoch 5279/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0287 - acc: 0.9917\n",
      "Epoch 5280/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0287 - acc: 0.9917\n",
      "Epoch 5281/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0283 - acc: 0.9917\n",
      "Epoch 5282/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0312 - acc: 0.9917\n",
      "Epoch 5283/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0290 - acc: 0.9917\n",
      "Epoch 5284/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0280 - acc: 0.9917\n",
      "Epoch 5285/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0293 - acc: 0.9917\n",
      "Epoch 5286/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0298 - acc: 0.9917\n",
      "Epoch 5287/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0296 - acc: 0.9917\n",
      "Epoch 5288/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0291 - acc: 0.9917\n",
      "Epoch 5289/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0295 - acc: 0.9917\n",
      "Epoch 5290/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0293 - acc: 0.9917\n",
      "Epoch 5291/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 5292/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0286 - acc: 0.9917\n",
      "Epoch 5293/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0288 - acc: 0.9917\n",
      "Epoch 5294/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0286 - acc: 0.9917\n",
      "Epoch 5295/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0307 - acc: 0.9917\n",
      "Epoch 5296/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0280 - acc: 0.9917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5297/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0287 - acc: 0.9917\n",
      "Epoch 5298/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0299 - acc: 0.9917\n",
      "Epoch 5299/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0287 - acc: 0.9917\n",
      "Epoch 5300/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0304 - acc: 0.9917\n",
      "Epoch 5301/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0294 - acc: 0.9917\n",
      "Epoch 5302/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0303 - acc: 0.9917\n",
      "Epoch 5303/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0318 - acc: 0.9917\n",
      "Epoch 5304/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0287 - acc: 0.9917\n",
      "Epoch 5305/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0282 - acc: 0.9917\n",
      "Epoch 5306/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0292 - acc: 0.9917\n",
      "Epoch 5307/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0291 - acc: 0.9917\n",
      "Epoch 5308/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0280 - acc: 0.9917\n",
      "Epoch 5309/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0284 - acc: 0.9917\n",
      "Epoch 5310/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0292 - acc: 0.9917\n",
      "Epoch 5311/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0322 - acc: 0.9917\n",
      "Epoch 5312/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0286 - acc: 0.9917\n",
      "Epoch 5313/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0307 - acc: 0.9917\n",
      "Epoch 5314/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0292 - acc: 0.9917\n",
      "Epoch 5315/8000\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.0328 - acc: 0.9917\n",
      "Epoch 5316/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0286 - acc: 0.9917\n",
      "Epoch 5317/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0381 - acc: 1.000 - 0s 84us/sample - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 5318/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0310 - acc: 0.9833\n",
      "Epoch 5319/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0301 - acc: 0.9917\n",
      "Epoch 5320/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0279 - acc: 0.9917\n",
      "Epoch 5321/8000\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.0291 - acc: 0.9917\n",
      "Epoch 5322/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0296 - acc: 0.9917\n",
      "Epoch 5323/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0290 - acc: 0.9917\n",
      "Epoch 5324/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0286 - acc: 0.9917\n",
      "Epoch 5325/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0300 - acc: 0.9917\n",
      "Epoch 5326/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0287 - acc: 0.9917\n",
      "Epoch 5327/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0294 - acc: 0.9917\n",
      "Epoch 5328/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0288 - acc: 0.9917\n",
      "Epoch 5329/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0295 - acc: 0.9917\n",
      "Epoch 5330/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0306 - acc: 0.9917\n",
      "Epoch 5331/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0299 - acc: 0.9917\n",
      "Epoch 5332/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0293 - acc: 0.9917\n",
      "Epoch 5333/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0283 - acc: 0.9917\n",
      "Epoch 5334/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0293 - acc: 0.9917\n",
      "Epoch 5335/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0290 - acc: 0.9917\n",
      "Epoch 5336/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0288 - acc: 0.9917\n",
      "Epoch 5337/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0294 - acc: 0.9917\n",
      "Epoch 5338/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0305 - acc: 0.9917\n",
      "Epoch 5339/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0284 - acc: 0.9917\n",
      "Epoch 5340/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0291 - acc: 0.9917\n",
      "Epoch 5341/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0288 - acc: 0.9917\n",
      "Epoch 5342/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0295 - acc: 0.9917\n",
      "Epoch 5343/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0297 - acc: 0.9917\n",
      "Epoch 5344/8000\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.0307 - acc: 0.9917\n",
      "Epoch 5345/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0303 - acc: 0.9917\n",
      "Epoch 5346/8000\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.0285 - acc: 0.9917\n",
      "Epoch 5347/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0284 - acc: 0.9917\n",
      "Epoch 5348/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 5349/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0294 - acc: 0.9917\n",
      "Epoch 5350/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0294 - acc: 0.9917\n",
      "Epoch 5351/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 5352/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 5353/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 5354/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0284 - acc: 0.9917\n",
      "Epoch 5355/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0282 - acc: 0.9917\n",
      "Epoch 5356/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0292 - acc: 0.9917\n",
      "Epoch 5357/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0285 - acc: 0.9917\n",
      "Epoch 5358/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0291 - acc: 0.9917\n",
      "Epoch 5359/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0287 - acc: 0.9917\n",
      "Epoch 5360/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0285 - acc: 0.9917\n",
      "Epoch 5361/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0279 - acc: 0.9917\n",
      "Epoch 5362/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0282 - acc: 0.9917\n",
      "Epoch 5363/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0296 - acc: 0.9917\n",
      "Epoch 5364/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0286 - acc: 0.9917\n",
      "Epoch 5365/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0514 - acc: 0.968 - 0s 75us/sample - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 5366/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0295 - acc: 0.9917\n",
      "Epoch 5367/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0299 - acc: 0.9917\n",
      "Epoch 5368/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0304 - acc: 0.9917\n",
      "Epoch 5369/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0284 - acc: 0.9917\n",
      "Epoch 5370/8000\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.0284 - acc: 0.9917\n",
      "Epoch 5371/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0296 - acc: 0.9917\n",
      "Epoch 5372/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0302 - acc: 0.9917\n",
      "Epoch 5373/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0301 - acc: 0.9917\n",
      "Epoch 5374/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0284 - acc: 0.9917\n",
      "Epoch 5375/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0286 - acc: 0.9917\n",
      "Epoch 5376/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 5377/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0307 - acc: 0.9917\n",
      "Epoch 5378/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0299 - acc: 0.9917\n",
      "Epoch 5379/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0293 - acc: 0.9917\n",
      "Epoch 5380/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0284 - acc: 0.9917\n",
      "Epoch 5381/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0293 - acc: 0.9917\n",
      "Epoch 5382/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0292 - acc: 0.9917\n",
      "Epoch 5383/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 5384/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0298 - acc: 0.9917\n",
      "Epoch 5385/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0302 - acc: 0.9917\n",
      "Epoch 5386/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0316 - acc: 0.9917\n",
      "Epoch 5387/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0293 - acc: 0.9917\n",
      "Epoch 5388/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0284 - acc: 0.9917\n",
      "Epoch 5389/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 5390/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0285 - acc: 0.9917\n",
      "Epoch 5391/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0316 - acc: 0.9917\n",
      "Epoch 5392/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0298 - acc: 0.9917\n",
      "Epoch 5393/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0285 - acc: 0.9917\n",
      "Epoch 5394/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0292 - acc: 0.9917\n",
      "Epoch 5395/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0282 - acc: 0.9917\n",
      "Epoch 5396/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0285 - acc: 0.9917\n",
      "Epoch 5397/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 5398/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0710 - acc: 0.968 - 0s 67us/sample - loss: 0.0282 - acc: 0.9917\n",
      "Epoch 5399/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 5400/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0306 - acc: 0.9917\n",
      "Epoch 5401/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 5402/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0299 - acc: 0.9917\n",
      "Epoch 5403/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0307 - acc: 0.9917\n",
      "Epoch 5404/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0302 - acc: 0.9917\n",
      "Epoch 5405/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0286 - acc: 0.9917\n",
      "Epoch 5406/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0296 - acc: 0.9917\n",
      "Epoch 5407/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0284 - acc: 0.9917\n",
      "Epoch 5408/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0293 - acc: 0.9917\n",
      "Epoch 5409/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0296 - acc: 0.9917\n",
      "Epoch 5410/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 5411/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0297 - acc: 0.9917\n",
      "Epoch 5412/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0309 - acc: 0.9917\n",
      "Epoch 5413/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0285 - acc: 0.9917\n",
      "Epoch 5414/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0300 - acc: 0.9917\n",
      "Epoch 5415/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0310 - acc: 0.9917\n",
      "Epoch 5416/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0284 - acc: 0.9917\n",
      "Epoch 5417/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0284 - acc: 0.9917\n",
      "Epoch 5418/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0287 - acc: 0.9917\n",
      "Epoch 5419/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0285 - acc: 0.9917\n",
      "Epoch 5420/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0284 - acc: 0.9917\n",
      "Epoch 5421/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0294 - acc: 0.9917\n",
      "Epoch 5422/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 5423/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 5424/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 5425/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0290 - acc: 0.9917\n",
      "Epoch 5426/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0288 - acc: 0.9917\n",
      "Epoch 5427/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0283 - acc: 0.9917\n",
      "Epoch 5428/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 5429/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0284 - acc: 0.9917\n",
      "Epoch 5430/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0309 - acc: 0.9917\n",
      "Epoch 5431/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0308 - acc: 0.9917\n",
      "Epoch 5432/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0293 - acc: 0.9917\n",
      "Epoch 5433/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0320 - acc: 0.9917\n",
      "Epoch 5434/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0294 - acc: 0.9917\n",
      "Epoch 5435/8000\n",
      "120/120 [==============================] - 0s 83us/sample - loss: 0.0307 - acc: 0.9917\n",
      "Epoch 5436/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0283 - acc: 0.9917\n",
      "Epoch 5437/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0297 - acc: 0.9917\n",
      "Epoch 5438/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0291 - acc: 0.9917\n",
      "Epoch 5439/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0293 - acc: 0.9917\n",
      "Epoch 5440/8000\n",
      "120/120 [==============================] - 0s 59us/sample - loss: 0.0302 - acc: 0.9917\n",
      "Epoch 5441/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0292 - acc: 0.9917\n",
      "Epoch 5442/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0288 - acc: 0.9917\n",
      "Epoch 5443/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 5444/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0290 - acc: 0.9917\n",
      "Epoch 5445/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0299 - acc: 0.9917\n",
      "Epoch 5446/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0296 - acc: 0.9917\n",
      "Epoch 5447/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0277 - acc: 0.9917\n",
      "Epoch 5448/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 5449/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0298 - acc: 0.9917\n",
      "Epoch 5450/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0290 - acc: 0.9917\n",
      "Epoch 5451/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0293 - acc: 0.9917\n",
      "Epoch 5452/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0299 - acc: 0.9917\n",
      "Epoch 5453/8000\n",
      "120/120 [==============================] - 0s 59us/sample - loss: 0.0285 - acc: 0.9917\n",
      "Epoch 5454/8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0287 - acc: 0.9917\n",
      "Epoch 5455/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0285 - acc: 0.9917\n",
      "Epoch 5456/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 5457/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0290 - acc: 0.9917\n",
      "Epoch 5458/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0282 - acc: 0.9917\n",
      "Epoch 5459/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0290 - acc: 0.9917\n",
      "Epoch 5460/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0282 - acc: 0.9917\n",
      "Epoch 5461/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0287 - acc: 0.9917\n",
      "Epoch 5462/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0297 - acc: 0.9917\n",
      "Epoch 5463/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 5464/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0282 - acc: 0.9917\n",
      "Epoch 5465/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0285 - acc: 0.9917\n",
      "Epoch 5466/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0308 - acc: 0.9917\n",
      "Epoch 5467/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 5468/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0306 - acc: 0.9917\n",
      "Epoch 5469/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0288 - acc: 0.9917\n",
      "Epoch 5470/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0283 - acc: 0.9917\n",
      "Epoch 5471/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0287 - acc: 0.9917\n",
      "Epoch 5472/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 5473/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0287 - acc: 0.9917\n",
      "Epoch 5474/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0285 - acc: 0.9917\n",
      "Epoch 5475/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0306 - acc: 0.9917\n",
      "Epoch 5476/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0283 - acc: 0.9917\n",
      "Epoch 5477/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0285 - acc: 0.9917\n",
      "Epoch 5478/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0280 - acc: 0.9917\n",
      "Epoch 5479/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0293 - acc: 0.9917\n",
      "Epoch 5480/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 5481/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0307 - acc: 0.9917\n",
      "Epoch 5482/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0285 - acc: 0.9917\n",
      "Epoch 5483/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 5484/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 5485/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0284 - acc: 0.9917\n",
      "Epoch 5486/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0291 - acc: 0.9917\n",
      "Epoch 5487/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 5488/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0284 - acc: 0.9917\n",
      "Epoch 5489/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0283 - acc: 0.9917\n",
      "Epoch 5490/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0285 - acc: 0.9917\n",
      "Epoch 5491/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0290 - acc: 0.9917\n",
      "Epoch 5492/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 5493/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0276 - acc: 0.9917\n",
      "Epoch 5494/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0293 - acc: 0.9917\n",
      "Epoch 5495/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0286 - acc: 0.9917\n",
      "Epoch 5496/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0287 - acc: 0.9917\n",
      "Epoch 5497/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0277 - acc: 0.9917\n",
      "Epoch 5498/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0292 - acc: 0.9917\n",
      "Epoch 5499/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0294 - acc: 0.9917\n",
      "Epoch 5500/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0279 - acc: 0.9917\n",
      "Epoch 5501/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0306 - acc: 0.9917\n",
      "Epoch 5502/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 5503/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 5504/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0288 - acc: 0.9917\n",
      "Epoch 5505/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0299 - acc: 0.9917\n",
      "Epoch 5506/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0284 - acc: 0.9917\n",
      "Epoch 5507/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0292 - acc: 0.9917\n",
      "Epoch 5508/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0292 - acc: 0.9917\n",
      "Epoch 5509/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 5510/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0312 - acc: 0.9917\n",
      "Epoch 5511/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0309 - acc: 0.9917\n",
      "Epoch 5512/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0296 - acc: 0.9917\n",
      "Epoch 5513/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0297 - acc: 0.9917\n",
      "Epoch 5514/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0303 - acc: 0.9917\n",
      "Epoch 5515/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0280 - acc: 0.9917\n",
      "Epoch 5516/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0288 - acc: 0.9917\n",
      "Epoch 5517/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0283 - acc: 0.9917\n",
      "Epoch 5518/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0311 - acc: 0.9917\n",
      "Epoch 5519/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0285 - acc: 0.9917\n",
      "Epoch 5520/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0279 - acc: 0.9917\n",
      "Epoch 5521/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 5522/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0290 - acc: 0.9917\n",
      "Epoch 5523/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0286 - acc: 0.9917\n",
      "Epoch 5524/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0287 - acc: 0.9917\n",
      "Epoch 5525/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0287 - acc: 0.9917\n",
      "Epoch 5526/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0288 - acc: 0.9917\n",
      "Epoch 5527/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0286 - acc: 0.9917\n",
      "Epoch 5528/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0282 - acc: 0.9917\n",
      "Epoch 5529/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0284 - acc: 0.9917\n",
      "Epoch 5530/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0296 - acc: 0.9917\n",
      "Epoch 5531/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0285 - acc: 0.9917\n",
      "Epoch 5532/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 5533/8000\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.0282 - acc: 0.9917\n",
      "Epoch 5534/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0297 - acc: 0.9917\n",
      "Epoch 5535/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0283 - acc: 0.9917\n",
      "Epoch 5536/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 5537/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0277 - acc: 0.9917\n",
      "Epoch 5538/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0294 - acc: 0.9917\n",
      "Epoch 5539/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0283 - acc: 0.9917\n",
      "Epoch 5540/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0282 - acc: 0.9917\n",
      "Epoch 5541/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0296 - acc: 0.9917\n",
      "Epoch 5542/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0294 - acc: 0.9917\n",
      "Epoch 5543/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 5544/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 5545/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0302 - acc: 0.9917\n",
      "Epoch 5546/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0298 - acc: 0.9917\n",
      "Epoch 5547/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0283 - acc: 0.9917\n",
      "Epoch 5548/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0121 - acc: 1.000 - 0s 75us/sample - loss: 0.0285 - acc: 0.9917\n",
      "Epoch 5549/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0298 - acc: 0.9917\n",
      "Epoch 5550/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0290 - acc: 0.9917\n",
      "Epoch 5551/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0283 - acc: 0.9917\n",
      "Epoch 5552/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0284 - acc: 0.9917\n",
      "Epoch 5553/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 5554/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0280 - acc: 0.9917\n",
      "Epoch 5555/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0277 - acc: 0.9917\n",
      "Epoch 5556/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0299 - acc: 0.9917\n",
      "Epoch 5557/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0286 - acc: 0.9917\n",
      "Epoch 5558/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0288 - acc: 0.9917\n",
      "Epoch 5559/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0312 - acc: 0.9917\n",
      "Epoch 5560/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 5561/8000\n",
      "120/120 [==============================] - 0s 83us/sample - loss: 0.0272 - acc: 0.9917\n",
      "Epoch 5562/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0296 - acc: 0.9917\n",
      "Epoch 5563/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0290 - acc: 0.9917\n",
      "Epoch 5564/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0284 - acc: 0.9917\n",
      "Epoch 5565/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0280 - acc: 0.9917\n",
      "Epoch 5566/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0285 - acc: 0.9917\n",
      "Epoch 5567/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0283 - acc: 0.9917\n",
      "Epoch 5568/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0301 - acc: 0.9917\n",
      "Epoch 5569/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 5570/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0292 - acc: 0.9917\n",
      "Epoch 5571/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0294 - acc: 0.9917\n",
      "Epoch 5572/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0287 - acc: 0.9917\n",
      "Epoch 5573/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0280 - acc: 0.9917\n",
      "Epoch 5574/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0280 - acc: 0.9917\n",
      "Epoch 5575/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0286 - acc: 0.9917\n",
      "Epoch 5576/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0290 - acc: 0.9917\n",
      "Epoch 5577/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0284 - acc: 0.9917\n",
      "Epoch 5578/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0277 - acc: 0.9917\n",
      "Epoch 5579/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0292 - acc: 0.9917\n",
      "Epoch 5580/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0157 - acc: 1.000 - 0s 67us/sample - loss: 0.0288 - acc: 0.9917\n",
      "Epoch 5581/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0279 - acc: 0.9917\n",
      "Epoch 5582/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0284 - acc: 0.9917\n",
      "Epoch 5583/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0285 - acc: 0.9917\n",
      "Epoch 5584/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0307 - acc: 0.9917\n",
      "Epoch 5585/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0290 - acc: 0.9917\n",
      "Epoch 5586/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0287 - acc: 0.9917\n",
      "Epoch 5587/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0290 - acc: 0.9917\n",
      "Epoch 5588/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0283 - acc: 0.9917\n",
      "Epoch 5589/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 5590/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0282 - acc: 0.9917\n",
      "Epoch 5591/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0285 - acc: 0.9917\n",
      "Epoch 5592/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0258 - acc: 1.000 - 0s 84us/sample - loss: 0.0283 - acc: 0.9917\n",
      "Epoch 5593/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0276 - acc: 0.9917\n",
      "Epoch 5594/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 5595/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0284 - acc: 0.9917\n",
      "Epoch 5596/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0295 - acc: 0.9917\n",
      "Epoch 5597/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0277 - acc: 0.9917\n",
      "Epoch 5598/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0279 - acc: 0.9917\n",
      "Epoch 5599/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0294 - acc: 0.9917\n",
      "Epoch 5600/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0290 - acc: 0.9917\n",
      "Epoch 5601/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0311 - acc: 0.9917\n",
      "Epoch 5602/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0299 - acc: 0.9917\n",
      "Epoch 5603/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0298 - acc: 0.9917\n",
      "Epoch 5604/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 5605/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0280 - acc: 0.9917\n",
      "Epoch 5606/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0276 - acc: 0.9917\n",
      "Epoch 5607/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 5608/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0282 - acc: 0.9917\n",
      "Epoch 5609/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0291 - acc: 0.9917\n",
      "Epoch 5610/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0283 - acc: 0.9917\n",
      "Epoch 5611/8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0280 - acc: 0.9917\n",
      "Epoch 5612/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0276 - acc: 0.9917\n",
      "Epoch 5613/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0286 - acc: 0.9917\n",
      "Epoch 5614/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0282 - acc: 0.9917\n",
      "Epoch 5615/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 5616/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0313 - acc: 0.9917\n",
      "Epoch 5617/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0068 - acc: 1.000 - 0s 75us/sample - loss: 0.0282 - acc: 0.9917\n",
      "Epoch 5618/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0316 - acc: 0.9917\n",
      "Epoch 5619/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0315 - acc: 0.9917\n",
      "Epoch 5620/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0295 - acc: 0.9917\n",
      "Epoch 5621/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0276 - acc: 0.9917\n",
      "Epoch 5622/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0279 - acc: 0.9917\n",
      "Epoch 5623/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 5624/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0300 - acc: 0.9917\n",
      "Epoch 5625/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0284 - acc: 0.9917\n",
      "Epoch 5626/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0306 - acc: 0.9917\n",
      "Epoch 5627/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0280 - acc: 0.9917\n",
      "Epoch 5628/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 5629/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 5630/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0280 - acc: 0.9917\n",
      "Epoch 5631/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 5632/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0291 - acc: 0.9917\n",
      "Epoch 5633/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0288 - acc: 0.9917\n",
      "Epoch 5634/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 5635/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0280 - acc: 0.9917\n",
      "Epoch 5636/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0287 - acc: 0.9917\n",
      "Epoch 5637/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 5638/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0283 - acc: 0.9917\n",
      "Epoch 5639/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 5640/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0291 - acc: 0.9917\n",
      "Epoch 5641/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 5642/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 5643/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 5644/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0306 - acc: 0.9917\n",
      "Epoch 5645/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0291 - acc: 0.9917\n",
      "Epoch 5646/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0286 - acc: 0.9917\n",
      "Epoch 5647/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0283 - acc: 0.9917\n",
      "Epoch 5648/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0294 - acc: 0.9917\n",
      "Epoch 5649/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0286 - acc: 0.9917\n",
      "Epoch 5650/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0280 - acc: 0.9917\n",
      "Epoch 5651/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 5652/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0290 - acc: 0.9917\n",
      "Epoch 5653/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0293 - acc: 0.9917\n",
      "Epoch 5654/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0269 - acc: 0.9917\n",
      "Epoch 5655/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 5656/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0301 - acc: 0.9917\n",
      "Epoch 5657/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 5658/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0269 - acc: 0.9917\n",
      "Epoch 5659/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0304 - acc: 0.9833\n",
      "Epoch 5660/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0287 - acc: 0.9917\n",
      "Epoch 5661/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0287 - acc: 0.9917\n",
      "Epoch 5662/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0293 - acc: 0.9917\n",
      "Epoch 5663/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0298 - acc: 0.9917\n",
      "Epoch 5664/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0283 - acc: 0.9917\n",
      "Epoch 5665/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 5666/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 5667/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0296 - acc: 0.9917\n",
      "Epoch 5668/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 5669/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 5670/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0285 - acc: 0.9917\n",
      "Epoch 5671/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0282 - acc: 0.9917\n",
      "Epoch 5672/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 5673/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 5674/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 5675/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 5676/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0293 - acc: 0.9917\n",
      "Epoch 5677/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 5678/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0280 - acc: 0.9917\n",
      "Epoch 5679/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0277 - acc: 0.9917\n",
      "Epoch 5680/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 5681/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0286 - acc: 0.9917\n",
      "Epoch 5682/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0279 - acc: 0.9917\n",
      "Epoch 5683/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0296 - acc: 0.9917\n",
      "Epoch 5684/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0299 - acc: 0.9917\n",
      "Epoch 5685/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0282 - acc: 0.9917\n",
      "Epoch 5686/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0296 - acc: 0.9917\n",
      "Epoch 5687/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 5688/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 5689/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 5690/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0288 - acc: 0.9917\n",
      "Epoch 5691/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0277 - acc: 0.9917\n",
      "Epoch 5692/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0291 - acc: 0.9917\n",
      "Epoch 5693/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 5694/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0276 - acc: 0.9917\n",
      "Epoch 5695/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0307 - acc: 0.9917\n",
      "Epoch 5696/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 5697/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 5698/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0323 - acc: 0.9917\n",
      "Epoch 5699/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0315 - acc: 0.9917\n",
      "Epoch 5700/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0279 - acc: 0.9917\n",
      "Epoch 5701/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0288 - acc: 0.9917\n",
      "Epoch 5702/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0283 - acc: 0.9917\n",
      "Epoch 5703/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0286 - acc: 0.9917\n",
      "Epoch 5704/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0296 - acc: 0.9917\n",
      "Epoch 5705/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0304 - acc: 0.9917\n",
      "Epoch 5706/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0277 - acc: 0.9917\n",
      "Epoch 5707/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 5708/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0279 - acc: 0.9917\n",
      "Epoch 5709/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0301 - acc: 0.9917\n",
      "Epoch 5710/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 5711/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0302 - acc: 0.9917\n",
      "Epoch 5712/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0276 - acc: 0.9917\n",
      "Epoch 5713/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0304 - acc: 0.9917\n",
      "Epoch 5714/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0287 - acc: 0.9917\n",
      "Epoch 5715/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0268 - acc: 0.9917\n",
      "Epoch 5716/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0292 - acc: 0.9917\n",
      "Epoch 5717/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0321 - acc: 0.9917\n",
      "Epoch 5718/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0277 - acc: 0.9917\n",
      "Epoch 5719/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0285 - acc: 0.9917\n",
      "Epoch 5720/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0277 - acc: 0.9917\n",
      "Epoch 5721/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 5722/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0277 - acc: 0.9917\n",
      "Epoch 5723/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0301 - acc: 0.9917\n",
      "Epoch 5724/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 5725/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 5726/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0284 - acc: 0.9917\n",
      "Epoch 5727/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0284 - acc: 0.9917\n",
      "Epoch 5728/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0272 - acc: 0.9917\n",
      "Epoch 5729/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0285 - acc: 0.9917\n",
      "Epoch 5730/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 5731/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 5732/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0299 - acc: 0.9917\n",
      "Epoch 5733/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0336 - acc: 0.9917\n",
      "Epoch 5734/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0276 - acc: 0.9917\n",
      "Epoch 5735/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 5736/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0285 - acc: 0.9917\n",
      "Epoch 5737/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 5738/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 5739/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0276 - acc: 0.9917\n",
      "Epoch 5740/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0277 - acc: 0.9917\n",
      "Epoch 5741/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 5742/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 5743/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 5744/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 5745/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0277 - acc: 0.9917\n",
      "Epoch 5746/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0272 - acc: 0.9917\n",
      "Epoch 5747/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0286 - acc: 0.9917\n",
      "Epoch 5748/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0277 - acc: 0.9917\n",
      "Epoch 5749/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0284 - acc: 0.9917\n",
      "Epoch 5750/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0285 - acc: 0.9917\n",
      "Epoch 5751/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0286 - acc: 0.9917\n",
      "Epoch 5752/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0277 - acc: 0.9917\n",
      "Epoch 5753/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 5754/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0276 - acc: 0.9917\n",
      "Epoch 5755/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0290 - acc: 0.9917\n",
      "Epoch 5756/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 5757/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0283 - acc: 0.9917\n",
      "Epoch 5758/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0277 - acc: 0.9917\n",
      "Epoch 5759/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0279 - acc: 0.9917\n",
      "Epoch 5760/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 5761/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 5762/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0282 - acc: 0.9917\n",
      "Epoch 5763/8000\n",
      "120/120 [==============================] - 0s 59us/sample - loss: 0.0283 - acc: 0.9917\n",
      "Epoch 5764/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0285 - acc: 0.9917\n",
      "Epoch 5765/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 5766/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0279 - acc: 0.9917\n",
      "Epoch 5767/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 5768/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0284 - acc: 0.9917\n",
      "Epoch 5769/8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0277 - acc: 0.9917\n",
      "Epoch 5770/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 5771/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 5772/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0285 - acc: 0.9917\n",
      "Epoch 5773/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0282 - acc: 0.9917\n",
      "Epoch 5774/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0277 - acc: 0.9917\n",
      "Epoch 5775/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 5776/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0118 - acc: 1.000 - 0s 75us/sample - loss: 0.0272 - acc: 0.9917\n",
      "Epoch 5777/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 5778/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0286 - acc: 0.9917\n",
      "Epoch 5779/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 5780/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0301 - acc: 0.9917\n",
      "Epoch 5781/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0290 - acc: 0.9917\n",
      "Epoch 5782/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 5783/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 5784/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0285 - acc: 0.9917\n",
      "Epoch 5785/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0288 - acc: 0.9917\n",
      "Epoch 5786/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0293 - acc: 0.9917\n",
      "Epoch 5787/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0288 - acc: 0.9917\n",
      "Epoch 5788/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0286 - acc: 0.9917\n",
      "Epoch 5789/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0282 - acc: 0.9917\n",
      "Epoch 5790/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0277 - acc: 0.9917\n",
      "Epoch 5791/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0293 - acc: 0.9917\n",
      "Epoch 5792/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0293 - acc: 0.9917\n",
      "Epoch 5793/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 5794/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0282 - acc: 0.9917\n",
      "Epoch 5795/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0293 - acc: 0.9917\n",
      "Epoch 5796/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0277 - acc: 0.9917\n",
      "Epoch 5797/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0280 - acc: 0.9917\n",
      "Epoch 5798/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 5799/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 5800/8000\n",
      "120/120 [==============================] - 0s 83us/sample - loss: 0.0295 - acc: 0.9917\n",
      "Epoch 5801/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0291 - acc: 0.9917\n",
      "Epoch 5802/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 5803/8000\n",
      "120/120 [==============================] - 0s 59us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 5804/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0279 - acc: 0.9917\n",
      "Epoch 5805/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0279 - acc: 0.9917\n",
      "Epoch 5806/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 5807/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0283 - acc: 0.9917\n",
      "Epoch 5808/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0280 - acc: 0.9917\n",
      "Epoch 5809/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 5810/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 5811/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0280 - acc: 0.9917\n",
      "Epoch 5812/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0272 - acc: 0.9917\n",
      "Epoch 5813/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0279 - acc: 0.9917\n",
      "Epoch 5814/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0288 - acc: 0.9917\n",
      "Epoch 5815/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0287 - acc: 0.9917\n",
      "Epoch 5816/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 5817/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0314 - acc: 0.9917\n",
      "Epoch 5818/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0303 - acc: 0.9917\n",
      "Epoch 5819/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 5820/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0297 - acc: 0.9917\n",
      "Epoch 5821/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0285 - acc: 0.9917\n",
      "Epoch 5822/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 5823/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0284 - acc: 0.9917\n",
      "Epoch 5824/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0293 - acc: 0.9917\n",
      "Epoch 5825/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 5826/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0272 - acc: 0.9917\n",
      "Epoch 5827/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 5828/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0276 - acc: 0.9917\n",
      "Epoch 5829/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0288 - acc: 0.9917\n",
      "Epoch 5830/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 5831/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 5832/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0171 - acc: 1.000 - 0s 67us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 5833/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 5834/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0269 - acc: 0.9917\n",
      "Epoch 5835/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 5836/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 5837/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 5838/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0276 - acc: 0.9917\n",
      "Epoch 5839/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 5840/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0276 - acc: 0.9917\n",
      "Epoch 5841/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 5842/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 5843/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 5844/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 5845/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 5846/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 5847/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0298 - acc: 0.9917\n",
      "Epoch 5848/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 5849/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0280 - acc: 0.9917\n",
      "Epoch 5850/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 5851/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 5852/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0272 - acc: 0.9917\n",
      "Epoch 5853/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0287 - acc: 0.9917\n",
      "Epoch 5854/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 5855/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0283 - acc: 0.9917\n",
      "Epoch 5856/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0294 - acc: 0.9917\n",
      "Epoch 5857/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 5858/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 5859/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 5860/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0282 - acc: 0.9917\n",
      "Epoch 5861/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 5862/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0272 - acc: 0.9917\n",
      "Epoch 5863/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0280 - acc: 0.9917\n",
      "Epoch 5864/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 5865/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0614 - acc: 0.968 - 0s 75us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 5866/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0291 - acc: 0.9917\n",
      "Epoch 5867/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0285 - acc: 0.9917\n",
      "Epoch 5868/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0280 - acc: 0.9917\n",
      "Epoch 5869/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0280 - acc: 0.9917\n",
      "Epoch 5870/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0268 - acc: 0.9917\n",
      "Epoch 5871/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 5872/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0286 - acc: 0.9917\n",
      "Epoch 5873/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0295 - acc: 0.9917\n",
      "Epoch 5874/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0286 - acc: 0.9917\n",
      "Epoch 5875/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 5876/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0283 - acc: 0.9917\n",
      "Epoch 5877/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0304 - acc: 0.9917\n",
      "Epoch 5878/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 5879/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 5880/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0292 - acc: 0.9917\n",
      "Epoch 5881/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 5882/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0280 - acc: 0.9917\n",
      "Epoch 5883/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0292 - acc: 0.9917\n",
      "Epoch 5884/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0293 - acc: 0.9917\n",
      "Epoch 5885/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0277 - acc: 0.9917\n",
      "Epoch 5886/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 5887/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0284 - acc: 0.9917\n",
      "Epoch 5888/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 5889/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0295 - acc: 0.9917\n",
      "Epoch 5890/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0295 - acc: 0.9917\n",
      "Epoch 5891/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0284 - acc: 0.9917\n",
      "Epoch 5892/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0294 - acc: 0.9917\n",
      "Epoch 5893/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0265 - acc: 1.000 - 0s 84us/sample - loss: 0.0280 - acc: 0.9917\n",
      "Epoch 5894/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0267 - acc: 0.9917\n",
      "Epoch 5895/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 5896/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0296 - acc: 0.9917\n",
      "Epoch 5897/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0285 - acc: 0.9917\n",
      "Epoch 5898/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0272 - acc: 0.9917\n",
      "Epoch 5899/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0277 - acc: 0.9917\n",
      "Epoch 5900/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0287 - acc: 0.9917\n",
      "Epoch 5901/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 5902/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0284 - acc: 0.9917\n",
      "Epoch 5903/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0309 - acc: 0.9917\n",
      "Epoch 5904/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0297 - acc: 0.9917\n",
      "Epoch 5905/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 5906/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 5907/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 5908/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0302 - acc: 0.9917\n",
      "Epoch 5909/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0272 - acc: 0.9917\n",
      "Epoch 5910/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0287 - acc: 0.9917\n",
      "Epoch 5911/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0288 - acc: 0.9917\n",
      "Epoch 5912/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0283 - acc: 0.9917\n",
      "Epoch 5913/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0287 - acc: 0.9917\n",
      "Epoch 5914/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0272 - acc: 0.9917\n",
      "Epoch 5915/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0303 - acc: 0.9917\n",
      "Epoch 5916/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 5917/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 5918/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 5919/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0284 - acc: 0.9917\n",
      "Epoch 5920/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 5921/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 5922/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0286 - acc: 0.9917\n",
      "Epoch 5923/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 5924/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 5925/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0271 - acc: 0.9917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5926/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0286 - acc: 0.9917\n",
      "Epoch 5927/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 5928/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 5929/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0280 - acc: 0.9917\n",
      "Epoch 5930/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0288 - acc: 0.9917\n",
      "Epoch 5931/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 5932/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 5933/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0298 - acc: 0.9917\n",
      "Epoch 5934/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0282 - acc: 0.9917\n",
      "Epoch 5935/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0266 - acc: 0.9917\n",
      "Epoch 5936/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0277 - acc: 0.9917\n",
      "Epoch 5937/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0290 - acc: 0.9917\n",
      "Epoch 5938/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0282 - acc: 0.9917\n",
      "Epoch 5939/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 5940/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 5941/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0284 - acc: 0.9917\n",
      "Epoch 5942/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 5943/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 5944/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0303 - acc: 0.9917\n",
      "Epoch 5945/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0276 - acc: 0.9917\n",
      "Epoch 5946/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0283 - acc: 0.9917\n",
      "Epoch 5947/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0283 - acc: 0.9917\n",
      "Epoch 5948/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0266 - acc: 0.9917\n",
      "Epoch 5949/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 5950/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0291 - acc: 0.9917\n",
      "Epoch 5951/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 5952/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0304 - acc: 0.9917\n",
      "Epoch 5953/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0323 - acc: 0.9917\n",
      "Epoch 5954/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0279 - acc: 0.9917\n",
      "Epoch 5955/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 5956/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0282 - acc: 0.9917\n",
      "Epoch 5957/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0268 - acc: 0.9917\n",
      "Epoch 5958/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0284 - acc: 0.9917\n",
      "Epoch 5959/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 5960/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0266 - acc: 0.9917\n",
      "Epoch 5961/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 5962/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0283 - acc: 0.9917\n",
      "Epoch 5963/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0272 - acc: 0.9917\n",
      "Epoch 5964/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 5965/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0280 - acc: 0.9917\n",
      "Epoch 5966/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 5967/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 5968/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0299 - acc: 0.9917\n",
      "Epoch 5969/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 5970/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0284 - acc: 0.9917\n",
      "Epoch 5971/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 5972/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0272 - acc: 0.9917\n",
      "Epoch 5973/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 5974/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0685 - acc: 0.968 - 0s 92us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 5975/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0277 - acc: 0.9917\n",
      "Epoch 5976/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 5977/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0287 - acc: 0.9917\n",
      "Epoch 5978/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0282 - acc: 0.9917\n",
      "Epoch 5979/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0283 - acc: 0.9917\n",
      "Epoch 5980/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0279 - acc: 0.9917\n",
      "Epoch 5981/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 5982/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 5983/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0272 - acc: 0.9917\n",
      "Epoch 5984/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0272 - acc: 0.9917\n",
      "Epoch 5985/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0276 - acc: 0.9917\n",
      "Epoch 5986/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0287 - acc: 0.9917\n",
      "Epoch 5987/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 5988/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0279 - acc: 0.9917\n",
      "Epoch 5989/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 5990/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0283 - acc: 0.9917\n",
      "Epoch 5991/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 5992/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 5993/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0277 - acc: 0.9917\n",
      "Epoch 5994/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0279 - acc: 0.9917\n",
      "Epoch 5995/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0276 - acc: 0.9917\n",
      "Epoch 5996/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 5997/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 5998/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0280 - acc: 0.9917\n",
      "Epoch 5999/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 6000/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 6001/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 6002/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 6003/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0267 - acc: 0.9917\n",
      "Epoch 6004/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0284 - acc: 0.9917\n",
      "Epoch 6005/8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 6006/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0280 - acc: 0.9917\n",
      "Epoch 6007/8000\n",
      "120/120 [==============================] - 0s 59us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 6008/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 6009/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0269 - acc: 0.9917\n",
      "Epoch 6010/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 6011/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 6012/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0272 - acc: 0.9917\n",
      "Epoch 6013/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0272 - acc: 0.9917\n",
      "Epoch 6014/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0305 - acc: 0.9917\n",
      "Epoch 6015/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 6016/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0277 - acc: 0.9917\n",
      "Epoch 6017/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0282 - acc: 0.9917\n",
      "Epoch 6018/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 6019/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 6020/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0269 - acc: 0.9917\n",
      "Epoch 6021/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0280 - acc: 0.9917\n",
      "Epoch 6022/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 6023/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0269 - acc: 0.9917\n",
      "Epoch 6024/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0303 - acc: 0.9917\n",
      "Epoch 6025/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 6026/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0269 - acc: 0.9917\n",
      "Epoch 6027/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0295 - acc: 0.9917\n",
      "Epoch 6028/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0293 - acc: 0.9917\n",
      "Epoch 6029/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0314 - acc: 0.9833\n",
      "Epoch 6030/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 6031/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0276 - acc: 0.9917\n",
      "Epoch 6032/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0306 - acc: 0.9917\n",
      "Epoch 6033/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0285 - acc: 0.9917\n",
      "Epoch 6034/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 6035/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 6036/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0267 - acc: 0.9917\n",
      "Epoch 6037/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0291 - acc: 0.9917\n",
      "Epoch 6038/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 6039/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 6040/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 6041/8000\n",
      "120/120 [==============================] - 0s 50us/sample - loss: 0.0285 - acc: 0.9917\n",
      "Epoch 6042/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0269 - acc: 0.9917\n",
      "Epoch 6043/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0268 - acc: 0.9917\n",
      "Epoch 6044/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0299 - acc: 0.9917\n",
      "Epoch 6045/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 6046/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 6047/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0286 - acc: 0.9917\n",
      "Epoch 6048/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0298 - acc: 0.9917\n",
      "Epoch 6049/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 6050/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0267 - acc: 0.9917\n",
      "Epoch 6051/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0277 - acc: 0.9917\n",
      "Epoch 6052/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0293 - acc: 0.9917\n",
      "Epoch 6053/8000\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.0293 - acc: 0.9917\n",
      "Epoch 6054/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0269 - acc: 0.9917\n",
      "Epoch 6055/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 6056/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0269 - acc: 0.9917\n",
      "Epoch 6057/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 6058/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 6059/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0055 - acc: 1.000 - 0s 92us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 6060/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 6061/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 6062/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0282 - acc: 0.9917\n",
      "Epoch 6063/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0272 - acc: 0.9917\n",
      "Epoch 6064/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 6065/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 6066/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0282 - acc: 0.9917\n",
      "Epoch 6067/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 6068/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0287 - acc: 0.9917\n",
      "Epoch 6069/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0286 - acc: 0.9917\n",
      "Epoch 6070/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0272 - acc: 0.9917\n",
      "Epoch 6071/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0267 - acc: 0.9917\n",
      "Epoch 6072/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 6073/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 6074/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0285 - acc: 0.9917\n",
      "Epoch 6075/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 6076/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0272 - acc: 0.9917\n",
      "Epoch 6077/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 6078/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0280 - acc: 0.9917\n",
      "Epoch 6079/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0266 - acc: 0.9917\n",
      "Epoch 6080/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 6081/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 6082/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0267 - acc: 0.9917\n",
      "Epoch 6083/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0267 - acc: 0.9917\n",
      "Epoch 6084/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0269 - acc: 0.9917\n",
      "Epoch 6085/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0268 - acc: 0.9917\n",
      "Epoch 6086/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0283 - acc: 0.9917\n",
      "Epoch 6087/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0267 - acc: 0.9917\n",
      "Epoch 6088/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0268 - acc: 0.9917\n",
      "Epoch 6089/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0272 - acc: 0.9917\n",
      "Epoch 6090/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 6091/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0267 - acc: 0.9917\n",
      "Epoch 6092/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0268 - acc: 0.9917\n",
      "Epoch 6093/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 6094/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0267 - acc: 0.9917\n",
      "Epoch 6095/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0279 - acc: 0.9917\n",
      "Epoch 6096/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0282 - acc: 0.9917\n",
      "Epoch 6097/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0288 - acc: 0.9917\n",
      "Epoch 6098/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 6099/8000\n",
      "120/120 [==============================] - 0s 59us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 6100/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0292 - acc: 0.9917\n",
      "Epoch 6101/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 6102/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0279 - acc: 0.9917\n",
      "Epoch 6103/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0287 - acc: 0.9917\n",
      "Epoch 6104/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0266 - acc: 0.9917\n",
      "Epoch 6105/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0301 - acc: 0.9917\n",
      "Epoch 6106/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0276 - acc: 0.9917\n",
      "Epoch 6107/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0285 - acc: 0.9917\n",
      "Epoch 6108/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 6109/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 6110/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 6111/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 6112/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 6113/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 6114/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0269 - acc: 0.9917\n",
      "Epoch 6115/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 6116/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0272 - acc: 0.9917\n",
      "Epoch 6117/8000\n",
      "120/120 [==============================] - 0s 150us/sample - loss: 0.0276 - acc: 0.9917\n",
      "Epoch 6118/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0297 - acc: 0.9917\n",
      "Epoch 6119/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0268 - acc: 0.9917\n",
      "Epoch 6120/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0272 - acc: 0.9917\n",
      "Epoch 6121/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0272 - acc: 0.9917\n",
      "Epoch 6122/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 6123/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0269 - acc: 0.9917\n",
      "Epoch 6124/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 6125/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 6126/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 6127/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 6128/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0272 - acc: 0.9917\n",
      "Epoch 6129/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 6130/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0291 - acc: 0.9917\n",
      "Epoch 6131/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0272 - acc: 0.9917\n",
      "Epoch 6132/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 6133/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0269 - acc: 0.9917\n",
      "Epoch 6134/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0277 - acc: 0.9917\n",
      "Epoch 6135/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 6136/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0280 - acc: 0.9917\n",
      "Epoch 6137/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 6138/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0291 - acc: 0.9917\n",
      "Epoch 6139/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0269 - acc: 0.9917\n",
      "Epoch 6140/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 6141/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 6142/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 6143/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 6144/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0208 - acc: 1.000 - 0s 67us/sample - loss: 0.0272 - acc: 0.9917\n",
      "Epoch 6145/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0259 - acc: 0.9917\n",
      "Epoch 6146/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 6147/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0308 - acc: 0.9833\n",
      "Epoch 6148/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0291 - acc: 0.9917\n",
      "Epoch 6149/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0269 - acc: 0.9917\n",
      "Epoch 6150/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 6151/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0283 - acc: 0.9917\n",
      "Epoch 6152/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0294 - acc: 0.9917\n",
      "Epoch 6153/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0294 - acc: 0.9917\n",
      "Epoch 6154/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 6155/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 6156/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 6157/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0301 - acc: 0.9917\n",
      "Epoch 6158/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0266 - acc: 0.9917\n",
      "Epoch 6159/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0297 - acc: 0.9917\n",
      "Epoch 6160/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0308 - acc: 0.9917\n",
      "Epoch 6161/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0269 - acc: 0.9917\n",
      "Epoch 6162/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 6163/8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 6164/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 6165/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 6166/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 6167/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 6168/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0292 - acc: 0.9917\n",
      "Epoch 6169/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 6170/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0268 - acc: 0.9917\n",
      "Epoch 6171/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0300 - acc: 0.9833\n",
      "Epoch 6172/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0276 - acc: 0.9917\n",
      "Epoch 6173/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0232 - acc: 1.000 - 0s 75us/sample - loss: 0.0267 - acc: 0.9917\n",
      "Epoch 6174/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0282 - acc: 0.9917\n",
      "Epoch 6175/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 6176/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0287 - acc: 0.9917\n",
      "Epoch 6177/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0309 - acc: 0.9833\n",
      "Epoch 6178/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0280 - acc: 0.9917\n",
      "Epoch 6179/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0287 - acc: 0.9917\n",
      "Epoch 6180/8000\n",
      "120/120 [==============================] - 0s 83us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 6181/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 6182/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0302 - acc: 0.9833\n",
      "Epoch 6183/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 6184/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0291 - acc: 0.9917\n",
      "Epoch 6185/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 6186/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 6187/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0279 - acc: 0.9917\n",
      "Epoch 6188/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0285 - acc: 0.9917\n",
      "Epoch 6189/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0276 - acc: 0.9917\n",
      "Epoch 6190/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0269 - acc: 0.9917\n",
      "Epoch 6191/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 6192/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0266 - acc: 0.9917\n",
      "Epoch 6193/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 6194/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 6195/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 6196/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0280 - acc: 0.9917\n",
      "Epoch 6197/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0277 - acc: 0.9917\n",
      "Epoch 6198/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 6199/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0266 - acc: 0.9917\n",
      "Epoch 6200/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 6201/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0269 - acc: 0.9917\n",
      "Epoch 6202/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0263 - acc: 0.9917\n",
      "Epoch 6203/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0268 - acc: 0.9917\n",
      "Epoch 6204/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 6205/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0293 - acc: 0.9917\n",
      "Epoch 6206/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0283 - acc: 0.9917\n",
      "Epoch 6207/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0282 - acc: 0.9917\n",
      "Epoch 6208/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0272 - acc: 0.9917\n",
      "Epoch 6209/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 6210/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0295 - acc: 0.9917\n",
      "Epoch 6211/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 6212/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 6213/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0280 - acc: 0.9917\n",
      "Epoch 6214/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0280 - acc: 0.9917\n",
      "Epoch 6215/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0284 - acc: 0.9917\n",
      "Epoch 6216/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 6217/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0269 - acc: 0.9917\n",
      "Epoch 6218/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0268 - acc: 0.9917\n",
      "Epoch 6219/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 6220/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0267 - acc: 0.9917\n",
      "Epoch 6221/8000\n",
      "120/120 [==============================] - 0s 83us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 6222/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0276 - acc: 0.9917\n",
      "Epoch 6223/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 6224/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 6225/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 6226/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0283 - acc: 0.9917\n",
      "Epoch 6227/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0299 - acc: 0.9917\n",
      "Epoch 6228/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0266 - acc: 0.9917\n",
      "Epoch 6229/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0285 - acc: 0.9917\n",
      "Epoch 6230/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 6231/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 6232/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 6233/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0269 - acc: 0.9917\n",
      "Epoch 6234/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0267 - acc: 0.9917\n",
      "Epoch 6235/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0292 - acc: 0.9917\n",
      "Epoch 6236/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0268 - acc: 0.9917\n",
      "Epoch 6237/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0290 - acc: 0.9917\n",
      "Epoch 6238/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0290 - acc: 0.9833\n",
      "Epoch 6239/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 6240/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0279 - acc: 0.9917\n",
      "Epoch 6241/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0279 - acc: 0.9917\n",
      "Epoch 6242/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 6243/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0285 - acc: 0.9917\n",
      "Epoch 6244/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 6245/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 6246/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0299 - acc: 0.9917\n",
      "Epoch 6247/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 6248/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0338 - acc: 0.9833\n",
      "Epoch 6249/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0298 - acc: 0.9833\n",
      "Epoch 6250/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0280 - acc: 0.9917\n",
      "Epoch 6251/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0280 - acc: 0.9917\n",
      "Epoch 6252/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 6253/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0268 - acc: 0.9917\n",
      "Epoch 6254/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0269 - acc: 0.9917\n",
      "Epoch 6255/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 6256/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 6257/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0267 - acc: 0.9917\n",
      "Epoch 6258/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0276 - acc: 0.9917\n",
      "Epoch 6259/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0276 - acc: 0.9917\n",
      "Epoch 6260/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 6261/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0268 - acc: 0.9917\n",
      "Epoch 6262/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0291 - acc: 0.9917\n",
      "Epoch 6263/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0266 - acc: 0.9917\n",
      "Epoch 6264/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0268 - acc: 0.9917\n",
      "Epoch 6265/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0263 - acc: 0.9917\n",
      "Epoch 6266/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0266 - acc: 0.9917\n",
      "Epoch 6267/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0268 - acc: 0.9917\n",
      "Epoch 6268/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0266 - acc: 0.9917\n",
      "Epoch 6269/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 6270/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 6271/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0259 - acc: 0.9917\n",
      "Epoch 6272/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 6273/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0280 - acc: 0.9917\n",
      "Epoch 6274/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0268 - acc: 0.9917\n",
      "Epoch 6275/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 6276/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0282 - acc: 0.9917\n",
      "Epoch 6277/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0282 - acc: 0.9917\n",
      "Epoch 6278/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 6279/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 6280/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0279 - acc: 0.9917\n",
      "Epoch 6281/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 6282/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0263 - acc: 0.9917\n",
      "Epoch 6283/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 6284/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0266 - acc: 0.9917\n",
      "Epoch 6285/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0272 - acc: 0.9917\n",
      "Epoch 6286/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 6287/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 6288/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 6289/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0269 - acc: 0.9917\n",
      "Epoch 6290/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0290 - acc: 0.9917\n",
      "Epoch 6291/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 6292/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0259 - acc: 0.9917\n",
      "Epoch 6293/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0269 - acc: 0.9917\n",
      "Epoch 6294/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 6295/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0263 - acc: 0.9917\n",
      "Epoch 6296/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0267 - acc: 0.9917\n",
      "Epoch 6297/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 6298/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0267 - acc: 0.9917\n",
      "Epoch 6299/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 6300/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 6301/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0312 - acc: 0.9917\n",
      "Epoch 6302/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0287 - acc: 0.9917\n",
      "Epoch 6303/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 6304/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 6305/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 6306/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 6307/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0286 - acc: 0.9917\n",
      "Epoch 6308/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0263 - acc: 0.9917\n",
      "Epoch 6309/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 6310/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 6311/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 6312/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 6313/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 6314/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0279 - acc: 0.9917\n",
      "Epoch 6315/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 6316/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0268 - acc: 0.9917\n",
      "Epoch 6317/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 6318/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 6319/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0268 - acc: 0.9917\n",
      "Epoch 6320/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0263 - acc: 0.9917\n",
      "Epoch 6321/8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0291 - acc: 0.9917\n",
      "Epoch 6322/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 6323/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0277 - acc: 0.9917\n",
      "Epoch 6324/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0286 - acc: 0.9917\n",
      "Epoch 6325/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 6326/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 6327/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 6328/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 6329/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0286 - acc: 0.9917\n",
      "Epoch 6330/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 6331/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 6332/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0272 - acc: 0.9917\n",
      "Epoch 6333/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0308 - acc: 0.9917\n",
      "Epoch 6334/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 6335/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0263 - acc: 0.9917\n",
      "Epoch 6336/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 6337/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 6338/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0276 - acc: 0.9917\n",
      "Epoch 6339/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 6340/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 6341/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 6342/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0263 - acc: 0.9917\n",
      "Epoch 6343/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 6344/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 6345/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 6346/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 6347/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 6348/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0266 - acc: 0.9917\n",
      "Epoch 6349/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0279 - acc: 0.9917\n",
      "Epoch 6350/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0263 - acc: 0.9917\n",
      "Epoch 6351/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 6352/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0267 - acc: 0.9917\n",
      "Epoch 6353/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0267 - acc: 0.9917\n",
      "Epoch 6354/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0263 - acc: 0.9917\n",
      "Epoch 6355/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 6356/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 6357/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0263 - acc: 0.9917\n",
      "Epoch 6358/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 6359/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0263 - acc: 0.9917\n",
      "Epoch 6360/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0268 - acc: 0.9917\n",
      "Epoch 6361/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0280 - acc: 0.9917\n",
      "Epoch 6362/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0284 - acc: 0.9917\n",
      "Epoch 6363/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 6364/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0263 - acc: 0.9917\n",
      "Epoch 6365/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0292 - acc: 0.9917\n",
      "Epoch 6366/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 6367/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0284 - acc: 0.9917\n",
      "Epoch 6368/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0267 - acc: 0.9917\n",
      "Epoch 6369/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 6370/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 6371/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 6372/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 6373/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 6374/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 6375/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 6376/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 6377/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 6378/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 6379/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0276 - acc: 0.9917\n",
      "Epoch 6380/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 6381/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0267 - acc: 0.9917\n",
      "Epoch 6382/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 6383/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 6384/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0286 - acc: 0.9917\n",
      "Epoch 6385/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0266 - acc: 0.9917\n",
      "Epoch 6386/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 6387/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0272 - acc: 0.9917\n",
      "Epoch 6388/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 6389/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0277 - acc: 0.9917\n",
      "Epoch 6390/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 6391/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0266 - acc: 0.9917\n",
      "Epoch 6392/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 6393/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 6394/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0282 - acc: 0.9917\n",
      "Epoch 6395/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 6396/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0267 - acc: 0.9917\n",
      "Epoch 6397/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 6398/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 6399/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 6400/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0290 - acc: 0.9917\n",
      "Epoch 6401/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0283 - acc: 0.9917\n",
      "Epoch 6402/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0302 - acc: 0.9917\n",
      "Epoch 6403/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 6404/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0311 - acc: 0.9917\n",
      "Epoch 6405/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 6406/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 6407/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0276 - acc: 0.9917\n",
      "Epoch 6408/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0034 - acc: 1.000 - 0s 75us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 6409/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0276 - acc: 0.9917\n",
      "Epoch 6410/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 6411/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 6412/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 6413/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 6414/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 6415/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 6416/8000\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.0294 - acc: 0.9917\n",
      "Epoch 6417/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 6418/8000\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 6419/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0284 - acc: 0.9917\n",
      "Epoch 6420/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0269 - acc: 0.9917\n",
      "Epoch 6421/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0268 - acc: 0.9917\n",
      "Epoch 6422/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 6423/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0268 - acc: 0.9917\n",
      "Epoch 6424/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 6425/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 6426/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 6427/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0269 - acc: 0.9917\n",
      "Epoch 6428/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0313 - acc: 0.9917\n",
      "Epoch 6429/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 6430/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 6431/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0272 - acc: 0.9917\n",
      "Epoch 6432/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0061 - acc: 1.000 - 0s 75us/sample - loss: 0.0255 - acc: 0.9917\n",
      "Epoch 6433/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0287 - acc: 0.9917\n",
      "Epoch 6434/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 6435/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0258 - acc: 0.9917\n",
      "Epoch 6436/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 6437/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0268 - acc: 0.9917\n",
      "Epoch 6438/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 6439/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 6440/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0282 - acc: 0.9917\n",
      "Epoch 6441/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 6442/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0277 - acc: 0.9917\n",
      "Epoch 6443/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 6444/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 6445/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 6446/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 6447/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0263 - acc: 0.9917\n",
      "Epoch 6448/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0268 - acc: 0.9917\n",
      "Epoch 6449/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0266 - acc: 0.9917\n",
      "Epoch 6450/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0267 - acc: 0.9917\n",
      "Epoch 6451/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0259 - acc: 0.9917\n",
      "Epoch 6452/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 6453/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0266 - acc: 0.9917\n",
      "Epoch 6454/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 6455/8000\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.0272 - acc: 0.9917\n",
      "Epoch 6456/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 6457/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 6458/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 6459/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 6460/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 6461/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0267 - acc: 0.9917\n",
      "Epoch 6462/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 6463/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 6464/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0313 - acc: 0.9833\n",
      "Epoch 6465/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0296 - acc: 0.9917\n",
      "Epoch 6466/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0266 - acc: 0.9917\n",
      "Epoch 6467/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0288 - acc: 0.9917\n",
      "Epoch 6468/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 6469/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 6470/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0294 - acc: 0.9917\n",
      "Epoch 6471/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 6472/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 6473/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 6474/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0279 - acc: 0.9917\n",
      "Epoch 6475/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 6476/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 6477/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 6478/8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0267 - acc: 0.9917\n",
      "Epoch 6479/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0266 - acc: 0.9917\n",
      "Epoch 6480/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0283 - acc: 0.9917\n",
      "Epoch 6481/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0255 - acc: 0.9917\n",
      "Epoch 6482/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0266 - acc: 0.9917\n",
      "Epoch 6483/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 6484/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 6485/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0266 - acc: 0.9917\n",
      "Epoch 6486/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 6487/8000\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.0287 - acc: 0.9917\n",
      "Epoch 6488/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0269 - acc: 0.9917\n",
      "Epoch 6489/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0276 - acc: 0.9917\n",
      "Epoch 6490/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 6491/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0284 - acc: 0.9917\n",
      "Epoch 6492/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 6493/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 6494/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0280 - acc: 0.9917\n",
      "Epoch 6495/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0266 - acc: 0.9917\n",
      "Epoch 6496/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0280 - acc: 0.9917\n",
      "Epoch 6497/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0310 - acc: 0.9833\n",
      "Epoch 6498/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0300 - acc: 0.9917\n",
      "Epoch 6499/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0263 - acc: 0.9917\n",
      "Epoch 6500/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0287 - acc: 0.9917\n",
      "Epoch 6501/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 6502/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0263 - acc: 0.9917\n",
      "Epoch 6503/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0277 - acc: 0.9917\n",
      "Epoch 6504/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0282 - acc: 0.9917\n",
      "Epoch 6505/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 6506/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 6507/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 6508/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0263 - acc: 0.9917\n",
      "Epoch 6509/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0259 - acc: 0.9917\n",
      "Epoch 6510/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0267 - acc: 0.9917\n",
      "Epoch 6511/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0267 - acc: 0.9917\n",
      "Epoch 6512/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 6513/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0267 - acc: 0.9917\n",
      "Epoch 6514/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 6515/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0263 - acc: 0.9917\n",
      "Epoch 6516/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 6517/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0268 - acc: 0.9917\n",
      "Epoch 6518/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 6519/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0279 - acc: 0.9917\n",
      "Epoch 6520/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 6521/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0267 - acc: 0.9917\n",
      "Epoch 6522/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 6523/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 6524/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0259 - acc: 0.9917\n",
      "Epoch 6525/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 6526/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 6527/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 6528/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0269 - acc: 0.9917\n",
      "Epoch 6529/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 6530/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0287 - acc: 0.9917\n",
      "Epoch 6531/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0287 - acc: 0.9917\n",
      "Epoch 6532/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0269 - acc: 0.9917\n",
      "Epoch 6533/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 6534/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 6535/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0266 - acc: 0.9917\n",
      "Epoch 6536/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0266 - acc: 0.9917\n",
      "Epoch 6537/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 6538/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 6539/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0279 - acc: 0.9917\n",
      "Epoch 6540/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 6541/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0268 - acc: 0.9917\n",
      "Epoch 6542/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0263 - acc: 0.9917\n",
      "Epoch 6543/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 6544/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 6545/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 6546/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0283 - acc: 0.9917\n",
      "Epoch 6547/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 6548/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 6549/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 6550/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 6551/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0259 - acc: 0.9917\n",
      "Epoch 6552/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 6553/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0259 - acc: 0.9917\n",
      "Epoch 6554/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0277 - acc: 0.9917\n",
      "Epoch 6555/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 6556/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 6557/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 6558/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 6559/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0268 - acc: 0.9917\n",
      "Epoch 6560/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0071 - acc: 1.000 - 0s 58us/sample - loss: 0.0268 - acc: 0.9917\n",
      "Epoch 6561/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 6562/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 6563/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0283 - acc: 0.9917\n",
      "Epoch 6564/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 6565/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 6566/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 6567/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 6568/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 6569/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0267 - acc: 0.9917\n",
      "Epoch 6570/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0258 - acc: 0.9917\n",
      "Epoch 6571/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 6572/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 6573/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0267 - acc: 0.9917\n",
      "Epoch 6574/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0258 - acc: 0.9917\n",
      "Epoch 6575/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0280 - acc: 0.9917\n",
      "Epoch 6576/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0258 - acc: 0.9917\n",
      "Epoch 6577/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 6578/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 6579/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0266 - acc: 0.9917\n",
      "Epoch 6580/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0280 - acc: 0.9917\n",
      "Epoch 6581/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0284 - acc: 0.9917\n",
      "Epoch 6582/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 6583/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 6584/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 6585/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0255 - acc: 0.9917\n",
      "Epoch 6586/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0276 - acc: 0.9917\n",
      "Epoch 6587/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 6588/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 6589/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 6590/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 6591/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 6592/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 6593/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0259 - acc: 0.9917\n",
      "Epoch 6594/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0269 - acc: 0.9917\n",
      "Epoch 6595/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 6596/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0268 - acc: 0.9917\n",
      "Epoch 6597/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 6598/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 6599/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 6600/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0310 - acc: 0.9917\n",
      "Epoch 6601/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 6602/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 6603/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 6604/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0266 - acc: 0.9917\n",
      "Epoch 6605/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0258 - acc: 0.9917\n",
      "Epoch 6606/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0279 - acc: 0.9917\n",
      "Epoch 6607/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0267 - acc: 0.9917\n",
      "Epoch 6608/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0294 - acc: 0.9917\n",
      "Epoch 6609/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0267 - acc: 0.9917\n",
      "Epoch 6610/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 6611/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0268 - acc: 0.9917\n",
      "Epoch 6612/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0250 - acc: 0.9917\n",
      "Epoch 6613/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0263 - acc: 0.9917\n",
      "Epoch 6614/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 6615/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0284 - acc: 0.9917\n",
      "Epoch 6616/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0291 - acc: 0.9833\n",
      "Epoch 6617/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 6618/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 6619/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 6620/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0272 - acc: 0.9917\n",
      "Epoch 6621/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0269 - acc: 0.9917\n",
      "Epoch 6622/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 6623/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 6624/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0267 - acc: 0.9917\n",
      "Epoch 6625/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 6626/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 6627/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 6628/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 6629/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 6630/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 6631/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 6632/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0263 - acc: 0.9917\n",
      "Epoch 6633/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 6634/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 6635/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 6636/8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 6637/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0268 - acc: 0.9917\n",
      "Epoch 6638/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 6639/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 6640/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0266 - acc: 0.9917\n",
      "Epoch 6641/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 6642/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0279 - acc: 0.9917\n",
      "Epoch 6643/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0259 - acc: 0.9917\n",
      "Epoch 6644/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 6645/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0259 - acc: 0.9917\n",
      "Epoch 6646/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 6647/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 6648/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 6649/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0253 - acc: 0.9917\n",
      "Epoch 6650/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0287 - acc: 0.9917\n",
      "Epoch 6651/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0267 - acc: 0.9917\n",
      "Epoch 6652/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0297 - acc: 0.9917\n",
      "Epoch 6653/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0269 - acc: 0.9917\n",
      "Epoch 6654/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0266 - acc: 0.9917\n",
      "Epoch 6655/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0277 - acc: 0.9917\n",
      "Epoch 6656/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 6657/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 6658/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0258 - acc: 0.9917\n",
      "Epoch 6659/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0269 - acc: 0.9917\n",
      "Epoch 6660/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 6661/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 6662/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0266 - acc: 0.9917\n",
      "Epoch 6663/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0272 - acc: 0.9917\n",
      "Epoch 6664/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 6665/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0260 - acc: 1.000 - 0s 67us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 6666/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0288 - acc: 0.9917\n",
      "Epoch 6667/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0306 - acc: 0.9917\n",
      "Epoch 6668/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0259 - acc: 0.9917\n",
      "Epoch 6669/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0276 - acc: 0.9917\n",
      "Epoch 6670/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 6671/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 6672/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0277 - acc: 0.9917\n",
      "Epoch 6673/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0258 - acc: 0.9917\n",
      "Epoch 6674/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0259 - acc: 0.9917\n",
      "Epoch 6675/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0263 - acc: 0.9917\n",
      "Epoch 6676/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 6677/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 6678/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 6679/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0258 - acc: 0.9917\n",
      "Epoch 6680/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 6681/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 6682/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0276 - acc: 0.9917\n",
      "Epoch 6683/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 6684/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 6685/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0266 - acc: 0.9917\n",
      "Epoch 6686/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 6687/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0279 - acc: 0.9917\n",
      "Epoch 6688/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0258 - acc: 0.9917\n",
      "Epoch 6689/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 6690/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0263 - acc: 0.9917\n",
      "Epoch 6691/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 6692/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 6693/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 6694/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0259 - acc: 0.9917\n",
      "Epoch 6695/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 6696/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 6697/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 6698/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 6699/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 6700/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0263 - acc: 0.9917\n",
      "Epoch 6701/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 6702/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0284 - acc: 0.9917\n",
      "Epoch 6703/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 6704/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 6705/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 6706/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 6707/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0267 - acc: 0.9917\n",
      "Epoch 6708/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 6709/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 6710/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 6711/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0266 - acc: 0.9917\n",
      "Epoch 6712/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0255 - acc: 0.9917\n",
      "Epoch 6713/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 6714/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0276 - acc: 0.9917\n",
      "Epoch 6715/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 6716/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0258 - acc: 0.9917\n",
      "Epoch 6717/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 6718/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 6719/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0263 - acc: 0.9917\n",
      "Epoch 6720/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 6721/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0285 - acc: 0.9917\n",
      "Epoch 6722/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 6723/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 6724/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0268 - acc: 0.9917\n",
      "Epoch 6725/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0255 - acc: 0.9917\n",
      "Epoch 6726/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0266 - acc: 0.9917\n",
      "Epoch 6727/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 6728/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 6729/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0252 - acc: 0.9917\n",
      "Epoch 6730/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0253 - acc: 0.9917\n",
      "Epoch 6731/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 6732/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 6733/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 6734/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 6735/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0263 - acc: 0.9917\n",
      "Epoch 6736/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0272 - acc: 0.9917\n",
      "Epoch 6737/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0294 - acc: 0.9917\n",
      "Epoch 6738/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0263 - acc: 0.9917\n",
      "Epoch 6739/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0267 - acc: 0.9917\n",
      "Epoch 6740/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0272 - acc: 0.9917\n",
      "Epoch 6741/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 6742/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0277 - acc: 0.9917\n",
      "Epoch 6743/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 6744/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 6745/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0237 - acc: 1.000 - 0s 75us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 6746/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 6747/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0269 - acc: 0.9917\n",
      "Epoch 6748/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 6749/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 6750/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0276 - acc: 0.9917\n",
      "Epoch 6751/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 6752/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 6753/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0267 - acc: 0.9917\n",
      "Epoch 6754/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0259 - acc: 0.9917\n",
      "Epoch 6755/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 6756/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 6757/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 6758/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0259 - acc: 0.9917\n",
      "Epoch 6759/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 6760/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0258 - acc: 0.9917\n",
      "Epoch 6761/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0263 - acc: 0.9917\n",
      "Epoch 6762/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 6763/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 6764/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 6765/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 6766/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 6767/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 6768/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 6769/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 6770/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 6771/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 6772/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 6773/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 6774/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 6775/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0283 - acc: 0.9917\n",
      "Epoch 6776/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0269 - acc: 0.9917\n",
      "Epoch 6777/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 6778/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 6779/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 6780/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0255 - acc: 0.9917\n",
      "Epoch 6781/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 6782/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 6783/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 6784/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 6785/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0266 - acc: 0.9917\n",
      "Epoch 6786/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0276 - acc: 0.9917\n",
      "Epoch 6787/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0251 - acc: 0.9917\n",
      "Epoch 6788/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0283 - acc: 0.9917\n",
      "Epoch 6789/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0277 - acc: 0.9917\n",
      "Epoch 6790/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0259 - acc: 0.9917\n",
      "Epoch 6791/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0288 - acc: 0.9917\n",
      "Epoch 6792/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0277 - acc: 0.9917\n",
      "Epoch 6793/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 6794/8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 6795/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 6796/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0255 - acc: 0.9917\n",
      "Epoch 6797/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 6798/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0258 - acc: 0.9917\n",
      "Epoch 6799/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0276 - acc: 0.9917\n",
      "Epoch 6800/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 6801/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 6802/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0255 - acc: 0.9917\n",
      "Epoch 6803/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0253 - acc: 0.9917\n",
      "Epoch 6804/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 6805/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 6806/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 6807/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 6808/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 6809/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 6810/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0259 - acc: 0.9917\n",
      "Epoch 6811/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0272 - acc: 0.9917\n",
      "Epoch 6812/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 6813/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 6814/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 6815/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0253 - acc: 0.9917\n",
      "Epoch 6816/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 6817/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0255 - acc: 0.9917\n",
      "Epoch 6818/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0252 - acc: 0.9917\n",
      "Epoch 6819/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0259 - acc: 0.9917\n",
      "Epoch 6820/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 6821/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0269 - acc: 0.9917\n",
      "Epoch 6822/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0269 - acc: 0.9917\n",
      "Epoch 6823/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0137 - acc: 1.000 - 0s 67us/sample - loss: 0.0268 - acc: 0.9917\n",
      "Epoch 6824/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0268 - acc: 0.9917\n",
      "Epoch 6825/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0258 - acc: 0.9917\n",
      "Epoch 6826/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0284 - acc: 0.9917\n",
      "Epoch 6827/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 6828/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0253 - acc: 0.9917\n",
      "Epoch 6829/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 6830/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 6831/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0285 - acc: 0.9917\n",
      "Epoch 6832/8000\n",
      "120/120 [==============================] - 0s 59us/sample - loss: 0.0267 - acc: 0.9917\n",
      "Epoch 6833/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0258 - acc: 0.9917\n",
      "Epoch 6834/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0124 - acc: 1.000 - 0s 75us/sample - loss: 0.0253 - acc: 0.9917\n",
      "Epoch 6835/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 6836/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 6837/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 6838/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 6839/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 6840/8000\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.0268 - acc: 0.9917\n",
      "Epoch 6841/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 6842/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 6843/8000\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 6844/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0251 - acc: 0.9917\n",
      "Epoch 6845/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 6846/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 6847/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0295 - acc: 0.9833\n",
      "Epoch 6848/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 6849/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 6850/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0255 - acc: 0.9917\n",
      "Epoch 6851/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0263 - acc: 0.9917\n",
      "Epoch 6852/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0287 - acc: 0.9917\n",
      "Epoch 6853/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0287 - acc: 0.9917\n",
      "Epoch 6854/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0258 - acc: 0.9917\n",
      "Epoch 6855/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0252 - acc: 0.9917\n",
      "Epoch 6856/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 6857/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0258 - acc: 0.9917\n",
      "Epoch 6858/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0252 - acc: 0.9917\n",
      "Epoch 6859/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0471 - acc: 0.968 - 0s 67us/sample - loss: 0.0285 - acc: 0.9917\n",
      "Epoch 6860/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 6861/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0255 - acc: 0.9917\n",
      "Epoch 6862/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 6863/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 6864/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 6865/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0268 - acc: 0.9917\n",
      "Epoch 6866/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 6867/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 6868/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0269 - acc: 0.9917\n",
      "Epoch 6869/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0286 - acc: 0.9917\n",
      "Epoch 6870/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 6871/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0248 - acc: 0.9917\n",
      "Epoch 6872/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 6873/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0266 - acc: 0.9917\n",
      "Epoch 6874/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 6875/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 6876/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0298 - acc: 0.9917\n",
      "Epoch 6877/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0255 - acc: 0.9917\n",
      "Epoch 6878/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 6879/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0277 - acc: 0.9917\n",
      "Epoch 6880/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 6881/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0285 - acc: 0.9917\n",
      "Epoch 6882/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 6883/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 6884/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0259 - acc: 0.9917\n",
      "Epoch 6885/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0258 - acc: 0.9917\n",
      "Epoch 6886/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 6887/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 6888/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0253 - acc: 0.9917\n",
      "Epoch 6889/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 6890/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0258 - acc: 0.9917\n",
      "Epoch 6891/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0330 - acc: 0.9833\n",
      "Epoch 6892/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0274 - acc: 0.9833\n",
      "Epoch 6893/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0244 - acc: 0.9917\n",
      "Epoch 6894/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 6895/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0299 - acc: 0.9917\n",
      "Epoch 6896/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0267 - acc: 0.9917\n",
      "Epoch 6897/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0546 - acc: 0.968 - 0s 67us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 6898/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 6899/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0266 - acc: 0.9917\n",
      "Epoch 6900/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 6901/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0258 - acc: 0.9917\n",
      "Epoch 6902/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0266 - acc: 0.9917\n",
      "Epoch 6903/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0279 - acc: 0.9917\n",
      "Epoch 6904/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 6905/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 6906/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 6907/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0259 - acc: 0.9917\n",
      "Epoch 6908/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0268 - acc: 0.9917\n",
      "Epoch 6909/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 6910/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 6911/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0267 - acc: 0.9917\n",
      "Epoch 6912/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 6913/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 6914/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 6915/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 6916/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0272 - acc: 0.9917\n",
      "Epoch 6917/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0263 - acc: 0.9917\n",
      "Epoch 6918/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0259 - acc: 0.9917\n",
      "Epoch 6919/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 6920/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 6921/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0259 - acc: 0.9917\n",
      "Epoch 6922/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0251 - acc: 0.9917\n",
      "Epoch 6923/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 6924/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 6925/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 6926/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 6927/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 6928/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 6929/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 6930/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0247 - acc: 0.9917\n",
      "Epoch 6931/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 6932/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 6933/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0266 - acc: 0.9917\n",
      "Epoch 6934/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 6935/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 6936/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 6937/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 6938/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 6939/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0259 - acc: 0.9917\n",
      "Epoch 6940/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 6941/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0279 - acc: 0.9917\n",
      "Epoch 6942/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0259 - acc: 0.9917\n",
      "Epoch 6943/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 6944/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0263 - acc: 0.9917\n",
      "Epoch 6945/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 6946/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0253 - acc: 0.9917\n",
      "Epoch 6947/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0263 - acc: 0.9917\n",
      "Epoch 6948/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 6949/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 6950/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 6951/8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0266 - acc: 0.9917\n",
      "Epoch 6952/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0255 - acc: 0.9917\n",
      "Epoch 6953/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 6954/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 6955/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0266 - acc: 0.9917\n",
      "Epoch 6956/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 6957/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0253 - acc: 0.9917\n",
      "Epoch 6958/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0253 - acc: 0.9917\n",
      "Epoch 6959/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 6960/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0267 - acc: 0.9917\n",
      "Epoch 6961/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 6962/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0255 - acc: 0.9917\n",
      "Epoch 6963/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 6964/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0253 - acc: 0.9917\n",
      "Epoch 6965/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 6966/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 6967/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 6968/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 6969/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0255 - acc: 0.9917\n",
      "Epoch 6970/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 6971/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 6972/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0253 - acc: 0.9917\n",
      "Epoch 6973/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0258 - acc: 0.9917\n",
      "Epoch 6974/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0253 - acc: 0.9917\n",
      "Epoch 6975/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0252 - acc: 0.9917\n",
      "Epoch 6976/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0252 - acc: 0.9917\n",
      "Epoch 6977/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0263 - acc: 0.9917\n",
      "Epoch 6978/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0293 - acc: 0.9917\n",
      "Epoch 6979/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 6980/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0253 - acc: 0.9917\n",
      "Epoch 6981/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 6982/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0266 - acc: 0.9917\n",
      "Epoch 6983/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0253 - acc: 0.9917\n",
      "Epoch 6984/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0249 - acc: 0.9917\n",
      "Epoch 6985/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0255 - acc: 0.9917\n",
      "Epoch 6986/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 6987/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0255 - acc: 0.9917\n",
      "Epoch 6988/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 6989/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 6990/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0282 - acc: 0.9917\n",
      "Epoch 6991/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0266 - acc: 0.9917\n",
      "Epoch 6992/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0245 - acc: 0.9917\n",
      "Epoch 6993/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0272 - acc: 0.9917\n",
      "Epoch 6994/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 6995/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0251 - acc: 0.9917\n",
      "Epoch 6996/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 6997/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0268 - acc: 0.9917\n",
      "Epoch 6998/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 6999/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 7000/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 7001/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0263 - acc: 0.9917\n",
      "Epoch 7002/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 7003/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0255 - acc: 0.9917\n",
      "Epoch 7004/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0267 - acc: 0.9917\n",
      "Epoch 7005/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0205 - acc: 1.000 - 0s 84us/sample - loss: 0.0259 - acc: 0.9917\n",
      "Epoch 7006/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0263 - acc: 0.9917\n",
      "Epoch 7007/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0253 - acc: 0.9917\n",
      "Epoch 7008/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 7009/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0266 - acc: 0.9917\n",
      "Epoch 7010/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0251 - acc: 0.9917\n",
      "Epoch 7011/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0248 - acc: 0.9917\n",
      "Epoch 7012/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0255 - acc: 0.9917\n",
      "Epoch 7013/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0253 - acc: 0.9917\n",
      "Epoch 7014/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 7015/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 7016/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 7017/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0249 - acc: 0.9917\n",
      "Epoch 7018/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 7019/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0263 - acc: 0.9917\n",
      "Epoch 7020/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0266 - acc: 0.9917\n",
      "Epoch 7021/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0276 - acc: 0.9917\n",
      "Epoch 7022/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 7023/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0255 - acc: 0.9917\n",
      "Epoch 7024/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 7025/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 7026/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 7027/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0258 - acc: 0.9917\n",
      "Epoch 7028/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0255 - acc: 0.9917\n",
      "Epoch 7029/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0248 - acc: 0.9917\n",
      "Epoch 7030/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 7031/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 7032/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0251 - acc: 0.9917\n",
      "Epoch 7033/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 7034/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0266 - acc: 0.9917\n",
      "Epoch 7035/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0249 - acc: 0.9917\n",
      "Epoch 7036/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0252 - acc: 0.9917\n",
      "Epoch 7037/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 7038/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0282 - acc: 0.9917\n",
      "Epoch 7039/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0263 - acc: 0.9917\n",
      "Epoch 7040/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0259 - acc: 0.9917\n",
      "Epoch 7041/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0252 - acc: 0.9917\n",
      "Epoch 7042/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0255 - acc: 0.9917\n",
      "Epoch 7043/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0255 - acc: 0.9917\n",
      "Epoch 7044/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 7045/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0259 - acc: 0.9917\n",
      "Epoch 7046/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0248 - acc: 0.9917\n",
      "Epoch 7047/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 7048/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0252 - acc: 0.9917\n",
      "Epoch 7049/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0268 - acc: 0.9917\n",
      "Epoch 7050/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0259 - acc: 0.9917\n",
      "Epoch 7051/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0267 - acc: 0.9917\n",
      "Epoch 7052/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 7053/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 7054/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0253 - acc: 0.9917\n",
      "Epoch 7055/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 7056/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0263 - acc: 0.9917\n",
      "Epoch 7057/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0268 - acc: 0.9917\n",
      "Epoch 7058/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0258 - acc: 0.9917\n",
      "Epoch 7059/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0269 - acc: 0.9917\n",
      "Epoch 7060/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 7061/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 7062/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0249 - acc: 0.9917\n",
      "Epoch 7063/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0269 - acc: 0.9917\n",
      "Epoch 7064/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0266 - acc: 0.9917\n",
      "Epoch 7065/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0282 - acc: 0.9917\n",
      "Epoch 7066/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0251 - acc: 0.9917\n",
      "Epoch 7067/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 7068/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0263 - acc: 0.9917\n",
      "Epoch 7069/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0253 - acc: 0.9917\n",
      "Epoch 7070/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0253 - acc: 0.9917\n",
      "Epoch 7071/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 7072/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0258 - acc: 0.9917\n",
      "Epoch 7073/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0250 - acc: 0.9917\n",
      "Epoch 7074/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0249 - acc: 0.9917\n",
      "Epoch 7075/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0253 - acc: 0.9917\n",
      "Epoch 7076/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 7077/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 7078/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0259 - acc: 0.9917\n",
      "Epoch 7079/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 7080/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0259 - acc: 0.9917\n",
      "Epoch 7081/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0247 - acc: 0.9917\n",
      "Epoch 7082/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0263 - acc: 0.9917\n",
      "Epoch 7083/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0267 - acc: 0.9917\n",
      "Epoch 7084/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0315 - acc: 0.9917\n",
      "Epoch 7085/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0258 - acc: 0.9917\n",
      "Epoch 7086/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0248 - acc: 0.9917\n",
      "Epoch 7087/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 7088/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 7089/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0253 - acc: 0.9917\n",
      "Epoch 7090/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0263 - acc: 0.9917\n",
      "Epoch 7091/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 7092/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0251 - acc: 0.9917\n",
      "Epoch 7093/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0252 - acc: 0.9917\n",
      "Epoch 7094/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 7095/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 7096/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 7097/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 7098/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 7099/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0249 - acc: 0.9917\n",
      "Epoch 7100/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0255 - acc: 0.9917\n",
      "Epoch 7101/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 7102/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0252 - acc: 0.9917\n",
      "Epoch 7103/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0272 - acc: 0.9917\n",
      "Epoch 7104/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0280 - acc: 0.9917\n",
      "Epoch 7105/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0258 - acc: 0.9917\n",
      "Epoch 7106/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 7107/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 7108/8000\n",
      "120/120 [==============================] - 0s 59us/sample - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 7109/8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0258 - acc: 0.9917\n",
      "Epoch 7110/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0244 - acc: 0.9917\n",
      "Epoch 7111/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0258 - acc: 0.9917\n",
      "Epoch 7112/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0263 - acc: 0.9917\n",
      "Epoch 7113/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 7114/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0258 - acc: 0.9917\n",
      "Epoch 7115/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 7116/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 7117/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 7118/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 7119/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0269 - acc: 0.9917\n",
      "Epoch 7120/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 7121/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 7122/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 7123/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0248 - acc: 0.9917\n",
      "Epoch 7124/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 7125/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 7126/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0615 - acc: 0.968 - 0s 100us/sample - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 7127/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0181 - acc: 1.000 - 0s 84us/sample - loss: 0.0255 - acc: 0.9917\n",
      "Epoch 7128/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0279 - acc: 0.9917\n",
      "Epoch 7129/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0291 - acc: 0.9833\n",
      "Epoch 7130/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0242 - acc: 0.9917\n",
      "Epoch 7131/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 7132/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0290 - acc: 0.9917\n",
      "Epoch 7133/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0290 - acc: 0.9917\n",
      "Epoch 7134/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0252 - acc: 0.9917\n",
      "Epoch 7135/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 7136/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0255 - acc: 0.9917\n",
      "Epoch 7137/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 7138/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0284 - acc: 0.9917\n",
      "Epoch 7139/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 7140/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 7141/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0200 - acc: 1.000 - 0s 75us/sample - loss: 0.0248 - acc: 0.9917\n",
      "Epoch 7142/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0243 - acc: 0.9917\n",
      "Epoch 7143/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 7144/8000\n",
      "120/120 [==============================] - 0s 83us/sample - loss: 0.0259 - acc: 0.9917\n",
      "Epoch 7145/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0283 - acc: 0.9917\n",
      "Epoch 7146/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0199 - acc: 1.000 - 0s 100us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 7147/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0258 - acc: 0.9917\n",
      "Epoch 7148/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0258 - acc: 0.9917\n",
      "Epoch 7149/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 7150/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0250 - acc: 0.9917\n",
      "Epoch 7151/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 7152/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0282 - acc: 0.9917\n",
      "Epoch 7153/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0263 - acc: 0.9917\n",
      "Epoch 7154/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 7155/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0247 - acc: 0.9917\n",
      "Epoch 7156/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 7157/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0259 - acc: 0.9917\n",
      "Epoch 7158/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 7159/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0249 - acc: 0.9917\n",
      "Epoch 7160/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0258 - acc: 0.9917\n",
      "Epoch 7161/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0247 - acc: 0.9917\n",
      "Epoch 7162/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0259 - acc: 0.9917\n",
      "Epoch 7163/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0252 - acc: 0.9917\n",
      "Epoch 7164/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0259 - acc: 0.9917\n",
      "Epoch 7165/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0266 - acc: 0.9917\n",
      "Epoch 7166/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0253 - acc: 0.9917\n",
      "Epoch 7167/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0253 - acc: 0.9917\n",
      "Epoch 7168/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0251 - acc: 0.9917\n",
      "Epoch 7169/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0253 - acc: 0.9917\n",
      "Epoch 7170/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 7171/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 7172/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 7173/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 7174/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 7175/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0268 - acc: 0.9917\n",
      "Epoch 7176/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0248 - acc: 0.9917\n",
      "Epoch 7177/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0251 - acc: 0.9917\n",
      "Epoch 7178/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 7179/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 7180/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 7181/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0259 - acc: 0.9917\n",
      "Epoch 7182/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0267 - acc: 0.9917\n",
      "Epoch 7183/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 7184/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0253 - acc: 0.9917\n",
      "Epoch 7185/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0250 - acc: 0.9917\n",
      "Epoch 7186/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0246 - acc: 0.9917\n",
      "Epoch 7187/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 7188/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0276 - acc: 0.9917\n",
      "Epoch 7189/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0247 - acc: 0.9917\n",
      "Epoch 7190/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0302 - acc: 0.9917\n",
      "Epoch 7191/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0286 - acc: 0.9917\n",
      "Epoch 7192/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0272 - acc: 0.9917\n",
      "Epoch 7193/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0269 - acc: 0.9917\n",
      "Epoch 7194/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 7195/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0267 - acc: 0.9917\n",
      "Epoch 7196/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0250 - acc: 0.9917\n",
      "Epoch 7197/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0267 - acc: 0.9917\n",
      "Epoch 7198/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 7199/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0246 - acc: 0.9917\n",
      "Epoch 7200/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0258 - acc: 0.9917\n",
      "Epoch 7201/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0246 - acc: 0.9917\n",
      "Epoch 7202/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0251 - acc: 0.9917\n",
      "Epoch 7203/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0248 - acc: 0.9917\n",
      "Epoch 7204/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0253 - acc: 0.9917\n",
      "Epoch 7205/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 7206/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0246 - acc: 0.9917\n",
      "Epoch 7207/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0263 - acc: 0.9917\n",
      "Epoch 7208/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 7209/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0255 - acc: 0.9917\n",
      "Epoch 7210/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0247 - acc: 0.9917\n",
      "Epoch 7211/8000\n",
      "120/120 [==============================] - 0s 83us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 7212/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 7213/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0248 - acc: 0.9917\n",
      "Epoch 7214/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 7215/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 7216/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 7217/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0250 - acc: 0.9917\n",
      "Epoch 7218/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 7219/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 7220/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 7221/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0249 - acc: 0.9917\n",
      "Epoch 7222/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 7223/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 7224/8000\n",
      "120/120 [==============================] - 0s 59us/sample - loss: 0.0250 - acc: 0.9917\n",
      "Epoch 7225/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0266 - acc: 0.9917\n",
      "Epoch 7226/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0248 - acc: 0.9917\n",
      "Epoch 7227/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 7228/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0279 - acc: 0.9917\n",
      "Epoch 7229/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0277 - acc: 0.9917\n",
      "Epoch 7230/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 7231/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0248 - acc: 0.9917\n",
      "Epoch 7232/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0269 - acc: 0.9917\n",
      "Epoch 7233/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0272 - acc: 0.9917\n",
      "Epoch 7234/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0247 - acc: 0.9917\n",
      "Epoch 7235/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0252 - acc: 0.9917\n",
      "Epoch 7236/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 7237/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0251 - acc: 0.9917\n",
      "Epoch 7238/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0267 - acc: 0.9917\n",
      "Epoch 7239/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 7240/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0253 - acc: 0.9917\n",
      "Epoch 7241/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 7242/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 7243/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0252 - acc: 0.9917\n",
      "Epoch 7244/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 7245/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0250 - acc: 0.9917\n",
      "Epoch 7246/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0255 - acc: 0.9917\n",
      "Epoch 7247/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0267 - acc: 0.9917\n",
      "Epoch 7248/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0250 - acc: 0.9917\n",
      "Epoch 7249/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0243 - acc: 0.9917\n",
      "Epoch 7250/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0295 - acc: 0.9833\n",
      "Epoch 7251/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0291 - acc: 0.9917\n",
      "Epoch 7252/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0255 - acc: 0.9917\n",
      "Epoch 7253/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0249 - acc: 0.9917\n",
      "Epoch 7254/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0249 - acc: 0.9917\n",
      "Epoch 7255/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0250 - acc: 0.9917\n",
      "Epoch 7256/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 7257/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0252 - acc: 0.9917\n",
      "Epoch 7258/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0277 - acc: 0.9917\n",
      "Epoch 7259/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0245 - acc: 0.9917\n",
      "Epoch 7260/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0238 - acc: 0.9917\n",
      "Epoch 7261/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0268 - acc: 0.9917\n",
      "Epoch 7262/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 7263/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0249 - acc: 0.9917\n",
      "Epoch 7264/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 7265/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0250 - acc: 0.9917\n",
      "Epoch 7266/8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0259 - acc: 0.9917\n",
      "Epoch 7267/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0243 - acc: 0.9917\n",
      "Epoch 7268/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0269 - acc: 0.9833\n",
      "Epoch 7269/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0274 - acc: 0.9833\n",
      "Epoch 7270/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0250 - acc: 0.9917\n",
      "Epoch 7271/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 7272/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 7273/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0268 - acc: 0.9917\n",
      "Epoch 7274/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0248 - acc: 0.9917\n",
      "Epoch 7275/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0304 - acc: 0.9833\n",
      "Epoch 7276/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0312 - acc: 0.9833\n",
      "Epoch 7277/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 7278/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 7279/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0277 - acc: 0.9917\n",
      "Epoch 7280/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 7281/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0267 - acc: 0.9917\n",
      "Epoch 7282/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 7283/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 7284/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0245 - acc: 0.9917\n",
      "Epoch 7285/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0243 - acc: 0.9917\n",
      "Epoch 7286/8000\n",
      "120/120 [==============================] - 0s 83us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 7287/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0277 - acc: 0.9917\n",
      "Epoch 7288/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0279 - acc: 0.9917\n",
      "Epoch 7289/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 7290/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0272 - acc: 0.9917\n",
      "Epoch 7291/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0251 - acc: 0.9917\n",
      "Epoch 7292/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0248 - acc: 0.9917\n",
      "Epoch 7293/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 7294/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0266 - acc: 0.9917\n",
      "Epoch 7295/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0293 - acc: 0.9917\n",
      "Epoch 7296/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 7297/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 7298/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0268 - acc: 0.9917\n",
      "Epoch 7299/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0255 - acc: 0.9917\n",
      "Epoch 7300/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 7301/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0250 - acc: 0.9917\n",
      "Epoch 7302/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0276 - acc: 0.9917\n",
      "Epoch 7303/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0253 - acc: 0.9917\n",
      "Epoch 7304/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0240 - acc: 0.9917\n",
      "Epoch 7305/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0258 - acc: 0.9917\n",
      "Epoch 7306/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 7307/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 7308/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0253 - acc: 0.9917\n",
      "Epoch 7309/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0259 - acc: 0.9917\n",
      "Epoch 7310/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0251 - acc: 0.9917\n",
      "Epoch 7311/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0243 - acc: 0.9917\n",
      "Epoch 7312/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 7313/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0284 - acc: 0.9917\n",
      "Epoch 7314/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0247 - acc: 0.9917\n",
      "Epoch 7315/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0252 - acc: 0.9917\n",
      "Epoch 7316/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 7317/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0258 - acc: 0.9917\n",
      "Epoch 7318/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0252 - acc: 0.9917\n",
      "Epoch 7319/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 7320/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0266 - acc: 0.9917\n",
      "Epoch 7321/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 7322/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0255 - acc: 0.9917\n",
      "Epoch 7323/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 7324/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 7325/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0255 - acc: 0.9917\n",
      "Epoch 7326/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 7327/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0247 - acc: 0.9917\n",
      "Epoch 7328/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 7329/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0251 - acc: 0.9917\n",
      "Epoch 7330/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0257 - acc: 1.000 - 0s 75us/sample - loss: 0.0250 - acc: 0.9917\n",
      "Epoch 7331/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0263 - acc: 0.9917\n",
      "Epoch 7332/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0258 - acc: 0.9917\n",
      "Epoch 7333/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0251 - acc: 0.9917\n",
      "Epoch 7334/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0258 - acc: 0.9917\n",
      "Epoch 7335/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 7336/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0253 - acc: 0.9917\n",
      "Epoch 7337/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0258 - acc: 0.9917\n",
      "Epoch 7338/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0255 - acc: 0.9917\n",
      "Epoch 7339/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0249 - acc: 0.9917\n",
      "Epoch 7340/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0252 - acc: 0.9917\n",
      "Epoch 7341/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0266 - acc: 0.9917\n",
      "Epoch 7342/8000\n",
      "120/120 [==============================] - 0s 83us/sample - loss: 0.0251 - acc: 0.9917\n",
      "Epoch 7343/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0248 - acc: 0.9917\n",
      "Epoch 7344/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0242 - acc: 0.9917\n",
      "Epoch 7345/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0255 - acc: 0.9917\n",
      "Epoch 7346/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0258 - acc: 0.9917\n",
      "Epoch 7347/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0248 - acc: 0.9917\n",
      "Epoch 7348/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0253 - acc: 0.9917\n",
      "Epoch 7349/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 7350/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 7351/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0253 - acc: 0.9917\n",
      "Epoch 7352/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 7353/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0255 - acc: 0.9917\n",
      "Epoch 7354/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 7355/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 7356/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 7357/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0305 - acc: 0.9917\n",
      "Epoch 7358/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 7359/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0255 - acc: 0.9917\n",
      "Epoch 7360/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 7361/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0252 - acc: 0.9917\n",
      "Epoch 7362/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 7363/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0253 - acc: 0.9917\n",
      "Epoch 7364/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 7365/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 7366/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0247 - acc: 0.9917\n",
      "Epoch 7367/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0255 - acc: 0.9917\n",
      "Epoch 7368/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0252 - acc: 0.9917\n",
      "Epoch 7369/8000\n",
      "120/120 [==============================] - 0s 83us/sample - loss: 0.0252 - acc: 0.9917\n",
      "Epoch 7370/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0252 - acc: 0.9917\n",
      "Epoch 7371/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0252 - acc: 0.9917\n",
      "Epoch 7372/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0259 - acc: 0.9917\n",
      "Epoch 7373/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0252 - acc: 0.9917\n",
      "Epoch 7374/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 7375/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0249 - acc: 0.9917\n",
      "Epoch 7376/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0251 - acc: 0.9917\n",
      "Epoch 7377/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0250 - acc: 0.9917\n",
      "Epoch 7378/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0248 - acc: 0.9917\n",
      "Epoch 7379/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0245 - acc: 0.9917\n",
      "Epoch 7380/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0244 - acc: 0.9917\n",
      "Epoch 7381/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 7382/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 7383/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0269 - acc: 0.9917\n",
      "Epoch 7384/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 7385/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0250 - acc: 0.9917\n",
      "Epoch 7386/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 7387/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0249 - acc: 0.9917\n",
      "Epoch 7388/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0258 - acc: 0.9917\n",
      "Epoch 7389/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0252 - acc: 0.9917\n",
      "Epoch 7390/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0248 - acc: 0.9917\n",
      "Epoch 7391/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0246 - acc: 0.9917\n",
      "Epoch 7392/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0248 - acc: 0.9917\n",
      "Epoch 7393/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0251 - acc: 0.9917\n",
      "Epoch 7394/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 7395/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 7396/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0249 - acc: 0.9917\n",
      "Epoch 7397/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0248 - acc: 1.000 - 0s 92us/sample - loss: 0.0268 - acc: 0.9917\n",
      "Epoch 7398/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0251 - acc: 0.9917\n",
      "Epoch 7399/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0249 - acc: 0.9917\n",
      "Epoch 7400/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0253 - acc: 0.9917\n",
      "Epoch 7401/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0247 - acc: 0.9917\n",
      "Epoch 7402/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0252 - acc: 0.9917\n",
      "Epoch 7403/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0251 - acc: 0.9917\n",
      "Epoch 7404/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0255 - acc: 0.9917\n",
      "Epoch 7405/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 7406/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 7407/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0250 - acc: 0.9917\n",
      "Epoch 7408/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0250 - acc: 0.9917\n",
      "Epoch 7409/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0244 - acc: 0.9917\n",
      "Epoch 7410/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0267 - acc: 0.9917\n",
      "Epoch 7411/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 7412/8000\n",
      "120/120 [==============================] - 0s 59us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 7413/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0247 - acc: 0.9917\n",
      "Epoch 7414/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0249 - acc: 0.9917\n",
      "Epoch 7415/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 7416/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0259 - acc: 0.9917\n",
      "Epoch 7417/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0244 - acc: 0.9917\n",
      "Epoch 7418/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0246 - acc: 0.9917\n",
      "Epoch 7419/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 7420/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0279 - acc: 0.9917\n",
      "Epoch 7421/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0263 - acc: 0.9917\n",
      "Epoch 7422/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 7423/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 7424/8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0251 - acc: 0.9917\n",
      "Epoch 7425/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 7426/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0247 - acc: 0.9917\n",
      "Epoch 7427/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0246 - acc: 0.9917\n",
      "Epoch 7428/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0252 - acc: 0.9917\n",
      "Epoch 7429/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 7430/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0250 - acc: 0.9917\n",
      "Epoch 7431/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0251 - acc: 0.9917\n",
      "Epoch 7432/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0246 - acc: 0.9917\n",
      "Epoch 7433/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0268 - acc: 0.9917\n",
      "Epoch 7434/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0268 - acc: 0.9917\n",
      "Epoch 7435/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 7436/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0245 - acc: 0.9917\n",
      "Epoch 7437/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0246 - acc: 0.9917\n",
      "Epoch 7438/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0245 - acc: 0.9917\n",
      "Epoch 7439/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0249 - acc: 0.9917\n",
      "Epoch 7440/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0250 - acc: 0.9917\n",
      "Epoch 7441/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0250 - acc: 0.9917\n",
      "Epoch 7442/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0251 - acc: 0.9917\n",
      "Epoch 7443/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0251 - acc: 0.9917\n",
      "Epoch 7444/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 7445/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0258 - acc: 0.9917\n",
      "Epoch 7446/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0255 - acc: 0.9917\n",
      "Epoch 7447/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0251 - acc: 0.9917\n",
      "Epoch 7448/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0258 - acc: 0.9917\n",
      "Epoch 7449/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0246 - acc: 0.9917\n",
      "Epoch 7450/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0253 - acc: 0.9917\n",
      "Epoch 7451/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0255 - acc: 0.9917\n",
      "Epoch 7452/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0245 - acc: 0.9917\n",
      "Epoch 7453/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0244 - acc: 0.9917\n",
      "Epoch 7454/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 7455/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0252 - acc: 0.9917\n",
      "Epoch 7456/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 7457/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 7458/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0237 - acc: 0.9917\n",
      "Epoch 7459/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 7460/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 7461/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0249 - acc: 0.9917\n",
      "Epoch 7462/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 7463/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 7464/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0255 - acc: 0.9917\n",
      "Epoch 7465/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0246 - acc: 0.9917\n",
      "Epoch 7466/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0248 - acc: 0.9917\n",
      "Epoch 7467/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0258 - acc: 0.9917\n",
      "Epoch 7468/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0249 - acc: 0.9917\n",
      "Epoch 7469/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 7470/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0267 - acc: 0.9917\n",
      "Epoch 7471/8000\n",
      "120/120 [==============================] - 0s 50us/sample - loss: 0.0248 - acc: 0.9917\n",
      "Epoch 7472/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0245 - acc: 0.9917\n",
      "Epoch 7473/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 7474/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0250 - acc: 0.9917\n",
      "Epoch 7475/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 7476/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0251 - acc: 0.9917\n",
      "Epoch 7477/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0243 - acc: 0.9917\n",
      "Epoch 7478/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0252 - acc: 0.9917\n",
      "Epoch 7479/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0244 - acc: 0.9917\n",
      "Epoch 7480/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0247 - acc: 0.9917\n",
      "Epoch 7481/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0253 - acc: 0.9917\n",
      "Epoch 7482/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0253 - acc: 0.9917\n",
      "Epoch 7483/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0248 - acc: 0.9917\n",
      "Epoch 7484/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0245 - acc: 0.9917\n",
      "Epoch 7485/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0252 - acc: 0.9917\n",
      "Epoch 7486/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0251 - acc: 0.9917\n",
      "Epoch 7487/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 7488/8000\n",
      "120/120 [==============================] - 0s 59us/sample - loss: 0.0267 - acc: 0.9917\n",
      "Epoch 7489/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0283 - acc: 0.9917\n",
      "Epoch 7490/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0239 - acc: 0.9917\n",
      "Epoch 7491/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 7492/8000\n",
      "120/120 [==============================] - 0s 59us/sample - loss: 0.0282 - acc: 0.9917\n",
      "Epoch 7493/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 7494/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0240 - acc: 0.9917\n",
      "Epoch 7495/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0253 - acc: 0.9917\n",
      "Epoch 7496/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 7497/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0245 - acc: 0.9917\n",
      "Epoch 7498/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0277 - acc: 0.9917\n",
      "Epoch 7499/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 7500/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0252 - acc: 0.9917\n",
      "Epoch 7501/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0258 - acc: 0.9917\n",
      "Epoch 7502/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0250 - acc: 0.9917\n",
      "Epoch 7503/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0244 - acc: 0.9917\n",
      "Epoch 7504/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0267 - acc: 0.9917\n",
      "Epoch 7505/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0246 - acc: 0.9917\n",
      "Epoch 7506/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 7507/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 7508/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0238 - acc: 0.9917\n",
      "Epoch 7509/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0250 - acc: 0.9917\n",
      "Epoch 7510/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 7511/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0245 - acc: 0.9917\n",
      "Epoch 7512/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0247 - acc: 0.9917\n",
      "Epoch 7513/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0250 - acc: 0.9917\n",
      "Epoch 7514/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0245 - acc: 0.9917\n",
      "Epoch 7515/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 7516/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0251 - acc: 0.9917\n",
      "Epoch 7517/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0249 - acc: 0.9917\n",
      "Epoch 7518/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 7519/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 7520/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0235 - acc: 0.9917\n",
      "Epoch 7521/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 7522/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0280 - acc: 0.9917\n",
      "Epoch 7523/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0267 - acc: 0.9917\n",
      "Epoch 7524/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 7525/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 7526/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0240 - acc: 0.9917\n",
      "Epoch 7527/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0251 - acc: 0.9917\n",
      "Epoch 7528/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0266 - acc: 0.9917\n",
      "Epoch 7529/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0250 - acc: 0.9917\n",
      "Epoch 7530/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0252 - acc: 0.9917\n",
      "Epoch 7531/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0247 - acc: 0.9917\n",
      "Epoch 7532/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0246 - acc: 0.9917\n",
      "Epoch 7533/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0253 - acc: 0.9917\n",
      "Epoch 7534/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0249 - acc: 0.9917\n",
      "Epoch 7535/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 7536/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0252 - acc: 0.9917\n",
      "Epoch 7537/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 7538/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0269 - acc: 0.9917\n",
      "Epoch 7539/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0243 - acc: 0.9917\n",
      "Epoch 7540/8000\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.0245 - acc: 0.9917\n",
      "Epoch 7541/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0268 - acc: 0.9917\n",
      "Epoch 7542/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0248 - acc: 0.9917\n",
      "Epoch 7543/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0250 - acc: 0.9917\n",
      "Epoch 7544/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0248 - acc: 0.9917\n",
      "Epoch 7545/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 7546/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 7547/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 7548/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0251 - acc: 0.9917\n",
      "Epoch 7549/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0286 - acc: 0.9917\n",
      "Epoch 7550/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0240 - acc: 0.9917\n",
      "Epoch 7551/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 7552/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 7553/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 7554/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0248 - acc: 0.9917\n",
      "Epoch 7555/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0250 - acc: 0.9917\n",
      "Epoch 7556/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0251 - acc: 0.9917\n",
      "Epoch 7557/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0253 - acc: 0.9917\n",
      "Epoch 7558/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0249 - acc: 0.9917\n",
      "Epoch 7559/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 7560/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0255 - acc: 0.9917\n",
      "Epoch 7561/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0248 - acc: 0.9917\n",
      "Epoch 7562/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0252 - acc: 0.9917\n",
      "Epoch 7563/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0248 - acc: 0.9917\n",
      "Epoch 7564/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0247 - acc: 0.9917\n",
      "Epoch 7565/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0245 - acc: 0.9917\n",
      "Epoch 7566/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0252 - acc: 0.9917\n",
      "Epoch 7567/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0239 - acc: 0.9917\n",
      "Epoch 7568/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 7569/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0255 - acc: 0.9917\n",
      "Epoch 7570/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0243 - acc: 0.9917\n",
      "Epoch 7571/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0244 - acc: 0.9917\n",
      "Epoch 7572/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0247 - acc: 0.9917\n",
      "Epoch 7573/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 7574/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 7575/8000\n",
      "120/120 [==============================] - 0s 134us/sample - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 7576/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0252 - acc: 0.9917\n",
      "Epoch 7577/8000\n",
      "120/120 [==============================] - 0s 134us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 7578/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0248 - acc: 0.9917\n",
      "Epoch 7579/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 7580/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 7581/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0237 - acc: 0.9917\n",
      "Epoch 7582/8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0310 - acc: 0.9917\n",
      "Epoch 7583/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0304 - acc: 0.9917\n",
      "Epoch 7584/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0079 - acc: 1.000 - 0s 84us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 7585/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0258 - acc: 0.9917\n",
      "Epoch 7586/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0239 - acc: 0.9917\n",
      "Epoch 7587/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 7588/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0263 - acc: 0.9917\n",
      "Epoch 7589/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0234 - acc: 0.9917\n",
      "Epoch 7590/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 7591/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0272 - acc: 0.968 - 0s 84us/sample - loss: 0.0275 - acc: 0.9833\n",
      "Epoch 7592/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0249 - acc: 0.9917\n",
      "Epoch 7593/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0247 - acc: 0.9917\n",
      "Epoch 7594/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0259 - acc: 0.9917\n",
      "Epoch 7595/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0244 - acc: 0.9917\n",
      "Epoch 7596/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0263 - acc: 0.9917\n",
      "Epoch 7597/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0241 - acc: 0.9917\n",
      "Epoch 7598/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0266 - acc: 0.9917\n",
      "Epoch 7599/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0252 - acc: 0.9917\n",
      "Epoch 7600/8000\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.0240 - acc: 0.9917\n",
      "Epoch 7601/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0259 - acc: 0.9917\n",
      "Epoch 7602/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 7603/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0245 - acc: 0.9917\n",
      "Epoch 7604/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0263 - acc: 0.9917\n",
      "Epoch 7605/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0276 - acc: 0.9917\n",
      "Epoch 7606/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0245 - acc: 0.9917\n",
      "Epoch 7607/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0247 - acc: 0.9917\n",
      "Epoch 7608/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0618 - acc: 0.968 - 0s 84us/sample - loss: 0.0243 - acc: 0.9917\n",
      "Epoch 7609/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0251 - acc: 0.9917\n",
      "Epoch 7610/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0248 - acc: 0.9917\n",
      "Epoch 7611/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0248 - acc: 0.9917\n",
      "Epoch 7612/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0241 - acc: 0.9917\n",
      "Epoch 7613/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0539 - acc: 0.968 - 0s 109us/sample - loss: 0.0244 - acc: 0.9917\n",
      "Epoch 7614/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0243 - acc: 0.9917\n",
      "Epoch 7615/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0249 - acc: 0.9917\n",
      "Epoch 7616/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0249 - acc: 0.9917\n",
      "Epoch 7617/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0246 - acc: 0.9917\n",
      "Epoch 7618/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0240 - acc: 0.9917\n",
      "Epoch 7619/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 7620/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0244 - acc: 0.9917\n",
      "Epoch 7621/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 7622/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0279 - acc: 0.9917\n",
      "Epoch 7623/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0252 - acc: 0.9917\n",
      "Epoch 7624/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0247 - acc: 0.9917\n",
      "Epoch 7625/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0247 - acc: 0.9917\n",
      "Epoch 7626/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 7627/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 7628/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0259 - acc: 0.9917\n",
      "Epoch 7629/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0248 - acc: 0.9917\n",
      "Epoch 7630/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0244 - acc: 0.9917\n",
      "Epoch 7631/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0247 - acc: 0.9917\n",
      "Epoch 7632/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0243 - acc: 0.9917\n",
      "Epoch 7633/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0240 - acc: 0.9917\n",
      "Epoch 7634/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0268 - acc: 0.9917\n",
      "Epoch 7635/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 7636/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0248 - acc: 0.9917\n",
      "Epoch 7637/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0250 - acc: 0.9917\n",
      "Epoch 7638/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0250 - acc: 0.9917\n",
      "Epoch 7639/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0244 - acc: 0.9917\n",
      "Epoch 7640/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0263 - acc: 0.9917\n",
      "Epoch 7641/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0252 - acc: 0.9917\n",
      "Epoch 7642/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0284 - acc: 0.9917\n",
      "Epoch 7643/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 7644/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0246 - acc: 0.9917\n",
      "Epoch 7645/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0255 - acc: 0.9917\n",
      "Epoch 7646/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0241 - acc: 0.9917\n",
      "Epoch 7647/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0244 - acc: 0.9917\n",
      "Epoch 7648/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0248 - acc: 0.9917\n",
      "Epoch 7649/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0244 - acc: 0.9917\n",
      "Epoch 7650/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0251 - acc: 0.9917\n",
      "Epoch 7651/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0251 - acc: 0.9917\n",
      "Epoch 7652/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 7653/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0253 - acc: 0.9917\n",
      "Epoch 7654/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0242 - acc: 0.9917\n",
      "Epoch 7655/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 7656/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0242 - acc: 0.9917\n",
      "Epoch 7657/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 7658/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0283 - acc: 0.9917\n",
      "Epoch 7659/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0258 - acc: 0.9917\n",
      "Epoch 7660/8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0247 - acc: 0.9917\n",
      "Epoch 7661/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0263 - acc: 0.9917\n",
      "Epoch 7662/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0250 - acc: 0.9917\n",
      "Epoch 7663/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0248 - acc: 0.9917\n",
      "Epoch 7664/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0244 - acc: 0.9917\n",
      "Epoch 7665/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0251 - acc: 0.9917\n",
      "Epoch 7666/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0251 - acc: 0.9917\n",
      "Epoch 7667/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0242 - acc: 0.9917\n",
      "Epoch 7668/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0246 - acc: 0.9917\n",
      "Epoch 7669/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0241 - acc: 0.9917\n",
      "Epoch 7670/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0248 - acc: 0.9917\n",
      "Epoch 7671/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0248 - acc: 0.9917\n",
      "Epoch 7672/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 7673/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0247 - acc: 0.9917\n",
      "Epoch 7674/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0239 - acc: 0.9917\n",
      "Epoch 7675/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0180 - acc: 1.000 - 0s 84us/sample - loss: 0.0243 - acc: 0.9917\n",
      "Epoch 7676/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0246 - acc: 0.9917\n",
      "Epoch 7677/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0242 - acc: 0.9917\n",
      "Epoch 7678/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0248 - acc: 0.9917\n",
      "Epoch 7679/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 7680/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0239 - acc: 0.9917\n",
      "Epoch 7681/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0248 - acc: 0.9917\n",
      "Epoch 7682/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0253 - acc: 0.9917\n",
      "Epoch 7683/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 7684/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0249 - acc: 0.9917\n",
      "Epoch 7685/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0244 - acc: 0.9917\n",
      "Epoch 7686/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0246 - acc: 0.9917\n",
      "Epoch 7687/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0240 - acc: 0.9917\n",
      "Epoch 7688/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0240 - acc: 0.9917\n",
      "Epoch 7689/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 7690/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0241 - acc: 0.9917\n",
      "Epoch 7691/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0238 - acc: 0.9917\n",
      "Epoch 7692/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0299 - acc: 0.9833\n",
      "Epoch 7693/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0243 - acc: 0.9917\n",
      "Epoch 7694/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0243 - acc: 0.9917\n",
      "Epoch 7695/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 7696/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0169 - acc: 1.000 - 0s 92us/sample - loss: 0.0250 - acc: 0.9917\n",
      "Epoch 7697/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0250 - acc: 0.9917\n",
      "Epoch 7698/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0277 - acc: 0.9833\n",
      "Epoch 7699/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0242 - acc: 0.9917\n",
      "Epoch 7700/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0242 - acc: 0.9917\n",
      "Epoch 7701/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0259 - acc: 0.9917\n",
      "Epoch 7702/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0248 - acc: 0.9917\n",
      "Epoch 7703/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0240 - acc: 0.9917\n",
      "Epoch 7704/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0248 - acc: 0.9917\n",
      "Epoch 7705/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 7706/8000\n",
      "120/120 [==============================] - 0s 59us/sample - loss: 0.0243 - acc: 0.9917\n",
      "Epoch 7707/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 7708/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0247 - acc: 0.9917\n",
      "Epoch 7709/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0240 - acc: 0.9917\n",
      "Epoch 7710/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0250 - acc: 0.9917\n",
      "Epoch 7711/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 7712/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0243 - acc: 0.9917\n",
      "Epoch 7713/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0247 - acc: 0.9917\n",
      "Epoch 7714/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0247 - acc: 0.9917\n",
      "Epoch 7715/8000\n",
      "120/120 [==============================] - 0s 59us/sample - loss: 0.0245 - acc: 0.9917\n",
      "Epoch 7716/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0244 - acc: 0.9917\n",
      "Epoch 7717/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0268 - acc: 0.9917\n",
      "Epoch 7718/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0259 - acc: 0.9917\n",
      "Epoch 7719/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0258 - acc: 0.9917\n",
      "Epoch 7720/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0249 - acc: 0.9917\n",
      "Epoch 7721/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 7722/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0238 - acc: 0.9917\n",
      "Epoch 7723/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 7724/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 7725/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0249 - acc: 0.9917\n",
      "Epoch 7726/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0241 - acc: 0.9917\n",
      "Epoch 7727/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0248 - acc: 0.9917\n",
      "Epoch 7728/8000\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.0263 - acc: 0.9917\n",
      "Epoch 7729/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0244 - acc: 0.9917\n",
      "Epoch 7730/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0284 - acc: 0.9917\n",
      "Epoch 7731/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0255 - acc: 0.9917\n",
      "Epoch 7732/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0245 - acc: 0.9917\n",
      "Epoch 7733/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0269 - acc: 0.9833\n",
      "Epoch 7734/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 7735/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0249 - acc: 0.9917\n",
      "Epoch 7736/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0246 - acc: 0.9917\n",
      "Epoch 7737/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0251 - acc: 0.9917\n",
      "Epoch 7738/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0239 - acc: 0.9917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7739/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0255 - acc: 0.9917\n",
      "Epoch 7740/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0259 - acc: 0.9917\n",
      "Epoch 7741/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 7742/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0244 - acc: 0.9917\n",
      "Epoch 7743/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0244 - acc: 0.9917\n",
      "Epoch 7744/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0248 - acc: 0.9917\n",
      "Epoch 7745/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0242 - acc: 0.9917\n",
      "Epoch 7746/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0243 - acc: 0.9917\n",
      "Epoch 7747/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0244 - acc: 0.9917\n",
      "Epoch 7748/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 7749/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0243 - acc: 0.9917\n",
      "Epoch 7750/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 7751/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0246 - acc: 0.9917\n",
      "Epoch 7752/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0245 - acc: 0.9917\n",
      "Epoch 7753/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0244 - acc: 0.9917\n",
      "Epoch 7754/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0268 - acc: 0.9917\n",
      "Epoch 7755/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0269 - acc: 0.9917\n",
      "Epoch 7756/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0246 - acc: 0.9917\n",
      "Epoch 7757/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0279 - acc: 0.9833\n",
      "Epoch 7758/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 7759/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0249 - acc: 0.9917\n",
      "Epoch 7760/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0240 - acc: 0.9917\n",
      "Epoch 7761/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 7762/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0245 - acc: 0.9917\n",
      "Epoch 7763/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0248 - acc: 0.9917\n",
      "Epoch 7764/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0249 - acc: 0.9917\n",
      "Epoch 7765/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0246 - acc: 0.9917\n",
      "Epoch 7766/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0250 - acc: 0.9917\n",
      "Epoch 7767/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0238 - acc: 0.9917\n",
      "Epoch 7768/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 7769/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0244 - acc: 0.9917\n",
      "Epoch 7770/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0244 - acc: 0.9917\n",
      "Epoch 7771/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0249 - acc: 0.9917\n",
      "Epoch 7772/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0246 - acc: 0.9917\n",
      "Epoch 7773/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0240 - acc: 0.9917\n",
      "Epoch 7774/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0241 - acc: 0.9917\n",
      "Epoch 7775/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0267 - acc: 0.9917\n",
      "Epoch 7776/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0247 - acc: 0.9917\n",
      "Epoch 7777/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 7778/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0245 - acc: 0.9917\n",
      "Epoch 7779/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0294 - acc: 0.9917\n",
      "Epoch 7780/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0252 - acc: 0.9917\n",
      "Epoch 7781/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0238 - acc: 0.9917\n",
      "Epoch 7782/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0245 - acc: 0.9917\n",
      "Epoch 7783/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 7784/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 7785/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0245 - acc: 0.9917\n",
      "Epoch 7786/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0244 - acc: 0.9917\n",
      "Epoch 7787/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0244 - acc: 0.9917\n",
      "Epoch 7788/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0244 - acc: 0.9917\n",
      "Epoch 7789/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0247 - acc: 0.9917\n",
      "Epoch 7790/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0269 - acc: 0.9917\n",
      "Epoch 7791/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0250 - acc: 0.9917\n",
      "Epoch 7792/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0249 - acc: 0.9917\n",
      "Epoch 7793/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0237 - acc: 0.9917\n",
      "Epoch 7794/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0255 - acc: 0.9917\n",
      "Epoch 7795/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0247 - acc: 0.9917\n",
      "Epoch 7796/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0241 - acc: 0.9917\n",
      "Epoch 7797/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0251 - acc: 0.9917\n",
      "Epoch 7798/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0248 - acc: 0.9917\n",
      "Epoch 7799/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0246 - acc: 0.9917\n",
      "Epoch 7800/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 7801/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 7802/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0250 - acc: 0.9917\n",
      "Epoch 7803/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0245 - acc: 0.9917\n",
      "Epoch 7804/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0240 - acc: 0.9917\n",
      "Epoch 7805/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 7806/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0252 - acc: 0.9917\n",
      "Epoch 7807/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0249 - acc: 0.9917\n",
      "Epoch 7808/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 7809/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0249 - acc: 0.9917\n",
      "Epoch 7810/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0251 - acc: 0.9917\n",
      "Epoch 7811/8000\n",
      "120/120 [==============================] - 0s 59us/sample - loss: 0.0247 - acc: 0.9917\n",
      "Epoch 7812/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0240 - acc: 0.9917\n",
      "Epoch 7813/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0239 - acc: 0.9917\n",
      "Epoch 7814/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 7815/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0238 - acc: 0.9917\n",
      "Epoch 7816/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0233 - acc: 0.9917\n",
      "Epoch 7817/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0610 - acc: 0.968 - 0s 67us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 7818/8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 7819/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0239 - acc: 0.9917\n",
      "Epoch 7820/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 7821/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0266 - acc: 0.9833\n",
      "Epoch 7822/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0280 - acc: 0.9917\n",
      "Epoch 7823/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 7824/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0294 - acc: 0.9917\n",
      "Epoch 7825/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0246 - acc: 0.9917\n",
      "Epoch 7826/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0243 - acc: 0.9917\n",
      "Epoch 7827/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0247 - acc: 0.9917\n",
      "Epoch 7828/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0245 - acc: 0.9917\n",
      "Epoch 7829/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 7830/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0241 - acc: 0.9917\n",
      "Epoch 7831/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0238 - acc: 0.9917\n",
      "Epoch 7832/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0250 - acc: 0.9917\n",
      "Epoch 7833/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 7834/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0250 - acc: 0.9917\n",
      "Epoch 7835/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0246 - acc: 0.9917\n",
      "Epoch 7836/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0248 - acc: 0.9917\n",
      "Epoch 7837/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 7838/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0251 - acc: 0.9917\n",
      "Epoch 7839/8000\n",
      "120/120 [==============================] - 0s 83us/sample - loss: 0.0236 - acc: 0.9917\n",
      "Epoch 7840/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 7841/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 7842/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0243 - acc: 0.9917\n",
      "Epoch 7843/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0250 - acc: 0.9917\n",
      "Epoch 7844/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0236 - acc: 0.9917\n",
      "Epoch 7845/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0236 - acc: 0.9917\n",
      "Epoch 7846/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0261 - acc: 0.9833\n",
      "Epoch 7847/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0251 - acc: 0.9917\n",
      "Epoch 7848/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0263 - acc: 0.9917\n",
      "Epoch 7849/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 7850/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0259 - acc: 0.9917\n",
      "Epoch 7851/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0263 - acc: 0.9917\n",
      "Epoch 7852/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0280 - acc: 0.9917\n",
      "Epoch 7853/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0243 - acc: 0.9917\n",
      "Epoch 7854/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0312 - acc: 0.9833\n",
      "Epoch 7855/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0272 - acc: 0.9917\n",
      "Epoch 7856/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0241 - acc: 0.9917\n",
      "Epoch 7857/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0259 - acc: 0.9917\n",
      "Epoch 7858/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0099 - acc: 1.000 - 0s 84us/sample - loss: 0.0255 - acc: 0.9917\n",
      "Epoch 7859/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 7860/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0250 - acc: 0.9917\n",
      "Epoch 7861/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0243 - acc: 0.9917\n",
      "Epoch 7862/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0240 - acc: 0.9917\n",
      "Epoch 7863/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0259 - acc: 0.9917\n",
      "Epoch 7864/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0245 - acc: 0.9917\n",
      "Epoch 7865/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 7866/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 7867/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0249 - acc: 0.9917\n",
      "Epoch 7868/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0248 - acc: 0.9917\n",
      "Epoch 7869/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0250 - acc: 0.9917\n",
      "Epoch 7870/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0252 - acc: 0.9917\n",
      "Epoch 7871/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0239 - acc: 0.9917\n",
      "Epoch 7872/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0243 - acc: 0.9917\n",
      "Epoch 7873/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0247 - acc: 0.9917\n",
      "Epoch 7874/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0245 - acc: 0.9917\n",
      "Epoch 7875/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 7876/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0238 - acc: 0.9917\n",
      "Epoch 7877/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0239 - acc: 0.9917\n",
      "Epoch 7878/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0267 - acc: 0.9833\n",
      "Epoch 7879/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0244 - acc: 0.9917\n",
      "Epoch 7880/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0233 - acc: 0.9917\n",
      "Epoch 7881/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0255 - acc: 0.9917\n",
      "Epoch 7882/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 7883/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0232 - acc: 0.9917\n",
      "Epoch 7884/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0231 - acc: 0.9917\n",
      "Epoch 7885/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0318 - acc: 0.9833\n",
      "Epoch 7886/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 7887/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0246 - acc: 0.9917\n",
      "Epoch 7888/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0251 - acc: 0.9917\n",
      "Epoch 7889/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0252 - acc: 0.9917\n",
      "Epoch 7890/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0250 - acc: 0.9917\n",
      "Epoch 7891/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0269 - acc: 0.9917\n",
      "Epoch 7892/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0252 - acc: 0.9917\n",
      "Epoch 7893/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0255 - acc: 0.9917\n",
      "Epoch 7894/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0251 - acc: 0.9917\n",
      "Epoch 7895/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0249 - acc: 0.9917\n",
      "Epoch 7896/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0255 - acc: 0.9917\n",
      "Epoch 7897/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0250 - acc: 0.9917\n",
      "Epoch 7898/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 7899/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0251 - acc: 0.9917\n",
      "Epoch 7900/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0244 - acc: 0.9917\n",
      "Epoch 7901/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 7902/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 7903/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0248 - acc: 0.9917\n",
      "Epoch 7904/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0248 - acc: 0.9917\n",
      "Epoch 7905/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0236 - acc: 0.9917\n",
      "Epoch 7906/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0250 - acc: 0.9917\n",
      "Epoch 7907/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0245 - acc: 0.9917\n",
      "Epoch 7908/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0237 - acc: 0.9917\n",
      "Epoch 7909/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 7910/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 7911/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 7912/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0240 - acc: 0.9917\n",
      "Epoch 7913/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 7914/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0239 - acc: 0.9917\n",
      "Epoch 7915/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0246 - acc: 0.9917\n",
      "Epoch 7916/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0266 - acc: 0.9917\n",
      "Epoch 7917/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0247 - acc: 0.9917\n",
      "Epoch 7918/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0243 - acc: 0.9917\n",
      "Epoch 7919/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0236 - acc: 0.9917\n",
      "Epoch 7920/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0240 - acc: 0.9917\n",
      "Epoch 7921/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0247 - acc: 0.9917\n",
      "Epoch 7922/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0250 - acc: 0.9917\n",
      "Epoch 7923/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0244 - acc: 0.9917\n",
      "Epoch 7924/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0248 - acc: 0.9917\n",
      "Epoch 7925/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 7926/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0249 - acc: 0.9917\n",
      "Epoch 7927/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0247 - acc: 0.9917\n",
      "Epoch 7928/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0247 - acc: 0.9917\n",
      "Epoch 7929/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0269 - acc: 0.9917\n",
      "Epoch 7930/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0241 - acc: 0.9917\n",
      "Epoch 7931/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0244 - acc: 0.9917\n",
      "Epoch 7932/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0240 - acc: 0.9917\n",
      "Epoch 7933/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0239 - acc: 0.9917\n",
      "Epoch 7934/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0245 - acc: 0.9917\n",
      "Epoch 7935/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0248 - acc: 0.9917\n",
      "Epoch 7936/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0242 - acc: 0.9917\n",
      "Epoch 7937/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 7938/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 7939/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0238 - acc: 0.9917\n",
      "Epoch 7940/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0241 - acc: 0.9917\n",
      "Epoch 7941/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0245 - acc: 0.9917\n",
      "Epoch 7942/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0244 - acc: 0.9917\n",
      "Epoch 7943/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0244 - acc: 0.9917\n",
      "Epoch 7944/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0241 - acc: 0.9917\n",
      "Epoch 7945/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0248 - acc: 0.9917\n",
      "Epoch 7946/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0238 - acc: 0.9917\n",
      "Epoch 7947/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0244 - acc: 0.9917\n",
      "Epoch 7948/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0251 - acc: 0.9917\n",
      "Epoch 7949/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0245 - acc: 0.9917\n",
      "Epoch 7950/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0247 - acc: 0.9917\n",
      "Epoch 7951/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0244 - acc: 0.9917\n",
      "Epoch 7952/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0274 - acc: 0.9917\n",
      "Epoch 7953/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0245 - acc: 0.9917\n",
      "Epoch 7954/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0303 - acc: 0.9917\n",
      "Epoch 7955/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0252 - acc: 0.9917\n",
      "Epoch 7956/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 7957/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0245 - acc: 0.9917\n",
      "Epoch 7958/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0263 - acc: 0.9917\n",
      "Epoch 7959/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0222 - acc: 0.9917\n",
      "Epoch 7960/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 7961/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0270 - acc: 0.9917\n",
      "Epoch 7962/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0238 - acc: 0.9917\n",
      "Epoch 7963/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0243 - acc: 0.9917\n",
      "Epoch 7964/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0252 - acc: 0.9917\n",
      "Epoch 7965/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0249 - acc: 0.9917\n",
      "Epoch 7966/8000\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.0246 - acc: 0.9917\n",
      "Epoch 7967/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0244 - acc: 0.9917\n",
      "Epoch 7968/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0244 - acc: 0.9917\n",
      "Epoch 7969/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0244 - acc: 0.9917\n",
      "Epoch 7970/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0239 - acc: 0.9917\n",
      "Epoch 7971/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0245 - acc: 0.9917\n",
      "Epoch 7972/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0268 - acc: 0.9917\n",
      "Epoch 7973/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 7974/8000\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0246 - acc: 0.9917\n",
      "Epoch 7975/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0253 - acc: 0.9917\n",
      "Epoch 7976/8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 75us/sample - loss: 0.0263 - acc: 0.9917\n",
      "Epoch 7977/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0244 - acc: 0.9917\n",
      "Epoch 7978/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0258 - acc: 0.9917\n",
      "Epoch 7979/8000\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.0249 - acc: 0.9917\n",
      "Epoch 7980/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0241 - acc: 0.9917\n",
      "Epoch 7981/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0238 - acc: 0.9917\n",
      "Epoch 7982/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0240 - acc: 0.9917\n",
      "Epoch 7983/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0247 - acc: 0.9917\n",
      "Epoch 7984/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0242 - acc: 0.9917\n",
      "Epoch 7985/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0242 - acc: 0.9917\n",
      "Epoch 7986/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0239 - acc: 0.9917\n",
      "Epoch 7987/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0276 - acc: 0.9833\n",
      "Epoch 7988/8000\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0350 - acc: 1.000 - 0s 92us/sample - loss: 0.0276 - acc: 0.9917\n",
      "Epoch 7989/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0276 - acc: 0.9917\n",
      "Epoch 7990/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0276 - acc: 0.9917\n",
      "Epoch 7991/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0246 - acc: 0.9917\n",
      "Epoch 7992/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0244 - acc: 0.9917\n",
      "Epoch 7993/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0244 - acc: 0.9917\n",
      "Epoch 7994/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0250 - acc: 0.9917\n",
      "Epoch 7995/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 7996/8000\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 7997/8000\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.0246 - acc: 0.9917\n",
      "Epoch 7998/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0245 - acc: 0.9917\n",
      "Epoch 7999/8000\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.0243 - acc: 0.9917\n",
      "Epoch 8000/8000\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.0254 - acc: 0.9917\n",
      "30/30 [==============================] - 0s 3ms/sample - loss: 0.1693 - acc: 0.9667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.16926170885562897, 0.96666664]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(10, input_dim=4, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.relu),\n",
    "  #tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam', # you can also use other optimizers such as SGD.\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_feature, train_label, epochs=8000)\n",
    "model.evaluate(test_feature, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 Loss:  1.1182212 accurracy:  0.26666668\n",
      "Epoch:  1 Loss:  1.1244656 accurracy:  0.26666668\n",
      "Epoch:  2 Loss:  1.1160067 accurracy:  0.26666668\n",
      "Epoch:  3 Loss:  1.1037937 accurracy:  0.26666668\n",
      "Epoch:  4 Loss:  1.0936826 accurracy:  0.26666668\n",
      "Epoch:  5 Loss:  1.0874685 accurracy:  0.2777778\n",
      "Epoch:  6 Loss:  1.0841833 accurracy:  0.31428573\n",
      "Epoch:  7 Loss:  1.0824592 accurracy:  0.34166667\n",
      "Epoch:  8 Loss:  1.0814034 accurracy:  0.36296296\n",
      "Epoch:  9 Loss:  1.0801345 accurracy:  0.38\n",
      "Epoch:  10 Loss:  1.0775838 accurracy:  0.3939394\n",
      "Epoch:  11 Loss:  1.073086 accurracy:  0.40555555\n",
      "Epoch:  12 Loss:  1.066775 accurracy:  0.41538462\n",
      "Epoch:  13 Loss:  1.0594246 accurracy:  0.42380953\n",
      "Epoch:  14 Loss:  1.0519246 accurracy:  0.4311111\n",
      "Epoch:  15 Loss:  1.0449829 accurracy:  0.4375\n",
      "Epoch:  16 Loss:  1.0388255 accurracy:  0.44313726\n",
      "Epoch:  17 Loss:  1.0334795 accurracy:  0.44814816\n",
      "Epoch:  18 Loss:  1.0288829 accurracy:  0.4526316\n",
      "Epoch:  19 Loss:  1.0248569 accurracy:  0.45666668\n",
      "Epoch:  20 Loss:  1.0211425 accurracy:  0.46031746\n",
      "Epoch:  21 Loss:  1.01748 accurracy:  0.46363637\n",
      "Epoch:  22 Loss:  1.013719 accurracy:  0.46666667\n",
      "Epoch:  23 Loss:  1.0098684 accurracy:  0.46944445\n",
      "Epoch:  24 Loss:  1.0060691 accurracy:  0.472\n",
      "Epoch:  25 Loss:  1.0025431 accurracy:  0.47435898\n",
      "Epoch:  26 Loss:  0.99950165 accurracy:  0.47654322\n",
      "Epoch:  27 Loss:  0.9970625 accurracy:  0.47857141\n",
      "Epoch:  28 Loss:  0.9952313 accurracy:  0.48045978\n",
      "Epoch:  29 Loss:  0.9939444 accurracy:  0.48222223\n",
      "Epoch:  30 Loss:  0.99310946 accurracy:  0.48387095\n",
      "Epoch:  31 Loss:  0.9925867 accurracy:  0.48541668\n",
      "Epoch:  32 Loss:  0.992175 accurracy:  0.48686868\n",
      "Epoch:  33 Loss:  0.9916688 accurracy:  0.4882353\n",
      "Epoch:  34 Loss:  0.99095154 accurracy:  0.4895238\n",
      "Epoch:  35 Loss:  0.990049 accurracy:  0.49074075\n",
      "Epoch:  36 Loss:  0.9891059 accurracy:  0.4918919\n",
      "Epoch:  37 Loss:  0.98829895 accurracy:  0.49298245\n",
      "Epoch:  38 Loss:  0.98773396 accurracy:  0.4940171\n",
      "Epoch:  39 Loss:  0.9874203 accurracy:  0.495\n",
      "Epoch:  40 Loss:  0.9873178 accurracy:  0.49593496\n",
      "Epoch:  41 Loss:  0.9873425 accurracy:  0.4968254\n",
      "Epoch:  42 Loss:  0.9873523 accurracy:  0.4976744\n",
      "Epoch:  43 Loss:  0.9872106 accurracy:  0.49848485\n",
      "Epoch:  44 Loss:  0.9868801 accurracy:  0.49925926\n",
      "Epoch:  45 Loss:  0.9864493 accurracy:  0.5\n",
      "Epoch:  46 Loss:  0.9860567 accurracy:  0.50070924\n",
      "Epoch:  47 Loss:  0.9857947 accurracy:  0.5013889\n",
      "Epoch:  48 Loss:  0.98568034 accurracy:  0.5020408\n",
      "Epoch:  49 Loss:  0.9856871 accurracy:  0.50266665\n",
      "Epoch:  50 Loss:  0.98575044 accurracy:  0.503268\n",
      "Epoch:  51 Loss:  0.98577106 accurracy:  0.50384617\n",
      "Epoch:  52 Loss:  0.98567426 accurracy:  0.5044025\n",
      "Epoch:  53 Loss:  0.9854689 accurracy:  0.50493824\n",
      "Epoch:  54 Loss:  0.98523545 accurracy:  0.50545454\n",
      "Epoch:  55 Loss:  0.9850558 accurracy:  0.50595236\n",
      "Epoch:  56 Loss:  0.98496497 accurracy:  0.5064328\n",
      "Epoch:  57 Loss:  0.98495644 accurracy:  0.50689656\n",
      "Epoch:  58 Loss:  0.9849949 accurracy:  0.5073446\n",
      "Epoch:  59 Loss:  0.98501956 accurracy:  0.50777775\n",
      "Epoch:  60 Loss:  0.98497516 accurracy:  0.5081967\n",
      "Epoch:  61 Loss:  0.9848559 accurracy:  0.50860214\n",
      "Epoch:  62 Loss:  0.9847072 accurracy:  0.5089947\n",
      "Epoch:  63 Loss:  0.9845835 accurracy:  0.509375\n",
      "Epoch:  64 Loss:  0.98451227 accurracy:  0.5097436\n",
      "Epoch:  65 Loss:  0.9844919 accurracy:  0.510101\n",
      "Epoch:  66 Loss:  0.98449826 accurracy:  0.51044774\n",
      "Epoch:  67 Loss:  0.98449165 accurracy:  0.5107843\n",
      "Epoch:  68 Loss:  0.9844378 accurracy:  0.51111114\n",
      "Epoch:  69 Loss:  0.9843347 accurracy:  0.5114286\n",
      "Epoch:  70 Loss:  0.98421127 accurracy:  0.5117371\n",
      "Epoch:  71 Loss:  0.984101 accurracy:  0.51203704\n",
      "Epoch:  72 Loss:  0.98401994 accurracy:  0.51232874\n",
      "Epoch:  73 Loss:  0.9839647 accurracy:  0.51261264\n",
      "Epoch:  74 Loss:  0.98391575 accurracy:  0.5128889\n",
      "Epoch:  75 Loss:  0.9838453 accurracy:  0.5131579\n",
      "Epoch:  76 Loss:  0.9837335 accurracy:  0.5134199\n",
      "Epoch:  77 Loss:  0.98358244 accurracy:  0.5136752\n",
      "Epoch:  78 Loss:  0.9834104 accurracy:  0.51392406\n",
      "Epoch:  79 Loss:  0.98323506 accurracy:  0.51416665\n",
      "Epoch:  80 Loss:  0.98306066 accurracy:  0.5144033\n",
      "Epoch:  81 Loss:  0.9828775 accurracy:  0.51463413\n",
      "Epoch:  82 Loss:  0.9826645 accurracy:  0.51485944\n",
      "Epoch:  83 Loss:  0.98239684 accurracy:  0.5150794\n",
      "Epoch:  84 Loss:  0.98205656 accurracy:  0.51529413\n",
      "Epoch:  85 Loss:  0.98163706 accurracy:  0.5155039\n",
      "Epoch:  86 Loss:  0.98113436 accurracy:  0.5157088\n",
      "Epoch:  87 Loss:  0.9805345 accurracy:  0.5159091\n",
      "Epoch:  88 Loss:  0.97980416 accurracy:  0.5161049\n",
      "Epoch:  89 Loss:  0.97888625 accurracy:  0.51629627\n",
      "Epoch:  90 Loss:  0.9776964 accurracy:  0.51648355\n",
      "Epoch:  91 Loss:  0.9761182 accurracy:  0.51666665\n",
      "Epoch:  92 Loss:  0.9739908 accurracy:  0.5168459\n",
      "Epoch:  93 Loss:  0.9710773 accurracy:  0.5170213\n",
      "Epoch:  94 Loss:  0.96700794 accurracy:  0.51719296\n",
      "Epoch:  95 Loss:  0.9611981 accurracy:  0.5173611\n",
      "Epoch:  96 Loss:  0.95274204 accurracy:  0.5175258\n",
      "Epoch:  97 Loss:  0.940313 accurracy:  0.5176871\n",
      "Epoch:  98 Loss:  0.92217433 accurracy:  0.5178451\n",
      "Epoch:  99 Loss:  0.8965593 accurracy:  0.518\n",
      "Epoch:  100 Loss:  0.8626877 accurracy:  0.5181518\n",
      "Epoch:  101 Loss:  0.8223679 accurracy:  0.52026147\n",
      "Epoch:  102 Loss:  0.78088135 accurracy:  0.5236246\n",
      "Epoch:  103 Loss:  0.74515426 accurracy:  0.5278846\n",
      "Epoch:  104 Loss:  0.72413534 accurracy:  0.5320635\n",
      "Epoch:  105 Loss:  0.72012585 accurracy:  0.5361635\n",
      "Epoch:  106 Loss:  0.7150441 accurracy:  0.54018694\n",
      "Epoch:  107 Loss:  0.70561427 accurracy:  0.5441358\n",
      "Epoch:  108 Loss:  0.6976734 accurracy:  0.54801226\n",
      "Epoch:  109 Loss:  0.6928631 accurracy:  0.5518182\n",
      "Epoch:  110 Loss:  0.68979424 accurracy:  0.5555556\n",
      "Epoch:  111 Loss:  0.684389 accurracy:  0.5592262\n",
      "Epoch:  112 Loss:  0.67556393 accurracy:  0.5628319\n",
      "Epoch:  113 Loss:  0.66676 accurracy:  0.56637424\n",
      "Epoch:  114 Loss:  0.6605942 accurracy:  0.5698551\n",
      "Epoch:  115 Loss:  0.6563854 accurracy:  0.57327586\n",
      "Epoch:  116 Loss:  0.6516442 accurracy:  0.57663816\n",
      "Epoch:  117 Loss:  0.6451839 accurracy:  0.5799435\n",
      "Epoch:  118 Loss:  0.63909805 accurracy:  0.5831933\n",
      "Epoch:  119 Loss:  0.6349732 accurracy:  0.5863889\n",
      "Epoch:  120 Loss:  0.6322146 accurracy:  0.58953166\n",
      "Epoch:  121 Loss:  0.6289652 accurracy:  0.59262294\n",
      "Epoch:  122 Loss:  0.6247093 accurracy:  0.59566396\n",
      "Epoch:  123 Loss:  0.62094283 accurracy:  0.59865594\n",
      "Epoch:  124 Loss:  0.6185163 accurracy:  0.6016\n",
      "Epoch:  125 Loss:  0.6167452 accurracy:  0.6044974\n",
      "Epoch:  126 Loss:  0.6143764 accurracy:  0.6073491\n",
      "Epoch:  127 Loss:  0.6114682 accurracy:  0.61015624\n",
      "Epoch:  128 Loss:  0.60910094 accurracy:  0.61291987\n",
      "Epoch:  129 Loss:  0.60759646 accurracy:  0.615641\n",
      "Epoch:  130 Loss:  0.606271 accurracy:  0.6183206\n",
      "Epoch:  131 Loss:  0.60442454 accurracy:  0.6209596\n",
      "Epoch:  132 Loss:  0.6024429 accurracy:  0.6235589\n",
      "Epoch:  133 Loss:  0.60102206 accurracy:  0.6261194\n",
      "Epoch:  134 Loss:  0.60012907 accurracy:  0.62864196\n",
      "Epoch:  135 Loss:  0.5991476 accurracy:  0.6311275\n",
      "Epoch:  136 Loss:  0.5978136 accurracy:  0.63357663\n",
      "Epoch:  137 Loss:  0.5965976 accurracy:  0.6359903\n",
      "Epoch:  138 Loss:  0.59584993 accurracy:  0.6383693\n",
      "Epoch:  139 Loss:  0.59532535 accurracy:  0.6407143\n",
      "Epoch:  140 Loss:  0.59458053 accurracy:  0.643026\n",
      "Epoch:  141 Loss:  0.5936719 accurracy:  0.64530516\n",
      "Epoch:  142 Loss:  0.5929935 accurracy:  0.64755243\n",
      "Epoch:  143 Loss:  0.5926183 accurracy:  0.64976853\n",
      "Epoch:  144 Loss:  0.5922336 accurracy:  0.651954\n",
      "Epoch:  145 Loss:  0.5916382 accurracy:  0.6541096\n",
      "Epoch:  146 Loss:  0.5910498 accurracy:  0.6562358\n",
      "Epoch:  147 Loss:  0.5906939 accurracy:  0.65833336\n",
      "Epoch:  148 Loss:  0.59046346 accurracy:  0.66040266\n",
      "Epoch:  149 Loss:  0.59011286 accurracy:  0.6624445\n",
      "Epoch:  150 Loss:  0.58965427 accurracy:  0.66445917\n",
      "Epoch:  151 Loss:  0.58930373 accurracy:  0.66644734\n",
      "Epoch:  152 Loss:  0.58911157 accurracy:  0.6684096\n",
      "Epoch:  153 Loss:  0.5889063 accurracy:  0.6703463\n",
      "Epoch:  154 Loss:  0.58858263 accurracy:  0.6722581\n",
      "Epoch:  155 Loss:  0.5882629 accurracy:  0.6741453\n",
      "Epoch:  156 Loss:  0.588068 accurracy:  0.67600846\n",
      "Epoch:  157 Loss:  0.58792824 accurracy:  0.6778481\n",
      "Epoch:  158 Loss:  0.5877128 accurracy:  0.67966455\n",
      "Epoch:  159 Loss:  0.58744663 accurracy:  0.68145835\n",
      "Epoch:  160 Loss:  0.58724934 accurracy:  0.6832298\n",
      "Epoch:  161 Loss:  0.58712965 accurracy:  0.68497944\n",
      "Epoch:  162 Loss:  0.5869849 accurracy:  0.68670756\n",
      "Epoch:  163 Loss:  0.5867781 accurracy:  0.68841463\n",
      "Epoch:  164 Loss:  0.5865908 accurracy:  0.690101\n",
      "Epoch:  165 Loss:  0.58647335 accurracy:  0.6917671\n",
      "Epoch:  166 Loss:  0.586367 accurracy:  0.6934132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  167 Loss:  0.5862115 accurracy:  0.6950397\n",
      "Epoch:  168 Loss:  0.58604455 accurracy:  0.6966469\n",
      "Epoch:  169 Loss:  0.58592695 accurracy:  0.6982353\n",
      "Epoch:  170 Loss:  0.5858382 accurracy:  0.6998051\n",
      "Epoch:  171 Loss:  0.5857199 accurracy:  0.7013566\n",
      "Epoch:  172 Loss:  0.58557695 accurracy:  0.70289016\n",
      "Epoch:  173 Loss:  0.5854623 accurracy:  0.70440614\n",
      "Epoch:  174 Loss:  0.58538055 accurracy:  0.7059048\n",
      "Epoch:  175 Loss:  0.5852864 accurracy:  0.7073864\n",
      "Epoch:  176 Loss:  0.5851661 accurracy:  0.7088512\n",
      "Epoch:  177 Loss:  0.58505756 accurracy:  0.7102996\n",
      "Epoch:  178 Loss:  0.5849789 accurracy:  0.71173185\n",
      "Epoch:  179 Loss:  0.58489984 accurracy:  0.7131482\n",
      "Epoch:  180 Loss:  0.5847984 accurracy:  0.7145488\n",
      "Epoch:  181 Loss:  0.5846981 accurracy:  0.71593404\n",
      "Epoch:  182 Loss:  0.5846217 accurracy:  0.71730417\n",
      "Epoch:  183 Loss:  0.58455163 accurracy:  0.7186594\n",
      "Epoch:  184 Loss:  0.5844648 accurracy:  0.72\n",
      "Epoch:  185 Loss:  0.5843738 accurracy:  0.7213262\n",
      "Epoch:  186 Loss:  0.5843004 accurracy:  0.72263813\n",
      "Epoch:  187 Loss:  0.5842359 accurracy:  0.72393614\n",
      "Epoch:  188 Loss:  0.58415985 accurracy:  0.72522044\n",
      "Epoch:  189 Loss:  0.5840777 accurracy:  0.7264912\n",
      "Epoch:  190 Loss:  0.5840081 accurracy:  0.7277487\n",
      "Epoch:  191 Loss:  0.5839478 accurracy:  0.72899306\n",
      "Epoch:  192 Loss:  0.5838797 accurracy:  0.73022455\n",
      "Epoch:  193 Loss:  0.5838056 accurracy:  0.7314433\n",
      "Epoch:  194 Loss:  0.5837403 accurracy:  0.73264956\n",
      "Epoch:  195 Loss:  0.58368355 accurracy:  0.73384356\n",
      "Epoch:  196 Loss:  0.5836218 accurracy:  0.7350254\n",
      "Epoch:  197 Loss:  0.5835545 accurracy:  0.73619527\n",
      "Epoch:  198 Loss:  0.58349395 accurracy:  0.73735344\n",
      "Epoch:  199 Loss:  0.58344054 accurracy:  0.7385\n",
      "Epoch:  200 Loss:  0.5833838 accurracy:  0.73963517\n",
      "Epoch:  201 Loss:  0.58332264 accurracy:  0.7407591\n",
      "Epoch:  202 Loss:  0.5832667 accurracy:  0.7418719\n",
      "Epoch:  203 Loss:  0.5832166 accurracy:  0.74297386\n",
      "Epoch:  204 Loss:  0.58316416 accurracy:  0.74406505\n",
      "Epoch:  205 Loss:  0.58310837 accurracy:  0.7451456\n",
      "Epoch:  206 Loss:  0.58305687 accurracy:  0.74621576\n",
      "Epoch:  207 Loss:  0.58301014 accurracy:  0.74727565\n",
      "Epoch:  208 Loss:  0.58296144 accurracy:  0.74832535\n",
      "Epoch:  209 Loss:  0.58291054 accurracy:  0.7493651\n",
      "Epoch:  210 Loss:  0.5828634 accurracy:  0.75039494\n",
      "Epoch:  211 Loss:  0.5828198 accurracy:  0.7514151\n",
      "Epoch:  212 Loss:  0.58277446 accurracy:  0.7524257\n",
      "Epoch:  213 Loss:  0.5827278 accurracy:  0.7534268\n",
      "Epoch:  214 Loss:  0.5826846 accurracy:  0.7544186\n",
      "Epoch:  215 Loss:  0.58264405 accurracy:  0.75540125\n",
      "Epoch:  216 Loss:  0.5826019 accurracy:  0.75637484\n",
      "Epoch:  217 Loss:  0.58255935 accurracy:  0.7573395\n",
      "Epoch:  218 Loss:  0.5825199 accurracy:  0.7582953\n",
      "Epoch:  219 Loss:  0.5824822 accurracy:  0.7592424\n",
      "Epoch:  220 Loss:  0.58244324 accurracy:  0.760181\n",
      "Epoch:  221 Loss:  0.58240443 accurracy:  0.76111114\n",
      "Epoch:  222 Loss:  0.5823683 accurracy:  0.76203287\n",
      "Epoch:  223 Loss:  0.58233345 accurracy:  0.7629464\n",
      "Epoch:  224 Loss:  0.58229756 accurracy:  0.7638519\n",
      "Epoch:  225 Loss:  0.5822623 accurracy:  0.7647493\n",
      "Epoch:  226 Loss:  0.5822295 accurracy:  0.76563877\n",
      "Epoch:  227 Loss:  0.5821972 accurracy:  0.76652044\n",
      "Epoch:  228 Loss:  0.5821642 accurracy:  0.7673945\n",
      "Epoch:  229 Loss:  0.5821324 accurracy:  0.7682609\n",
      "Epoch:  230 Loss:  0.5821025 accurracy:  0.76911974\n",
      "Epoch:  231 Loss:  0.5820726 accurracy:  0.76997125\n",
      "Epoch:  232 Loss:  0.5820427 accurracy:  0.77081543\n",
      "Epoch:  233 Loss:  0.5820141 accurracy:  0.7716524\n",
      "Epoch:  234 Loss:  0.5819867 accurracy:  0.7724823\n",
      "Epoch:  235 Loss:  0.5819594 accurracy:  0.77330506\n",
      "Epoch:  236 Loss:  0.5819326 accurracy:  0.7741209\n",
      "Epoch:  237 Loss:  0.58190674 accurracy:  0.77493\n",
      "Epoch:  238 Loss:  0.58188176 accurracy:  0.7757322\n",
      "Epoch:  239 Loss:  0.58185697 accurracy:  0.77652776\n",
      "Epoch:  240 Loss:  0.5818328 accurracy:  0.77731675\n",
      "Epoch:  241 Loss:  0.58180964 accurracy:  0.7780992\n",
      "Epoch:  242 Loss:  0.581787 accurracy:  0.7788752\n",
      "Epoch:  243 Loss:  0.5817646 accurracy:  0.7796448\n",
      "Epoch:  244 Loss:  0.58174306 accurracy:  0.78040814\n",
      "Epoch:  245 Loss:  0.5817223 accurracy:  0.7811653\n",
      "Epoch:  246 Loss:  0.58170193 accurracy:  0.7819163\n",
      "Epoch:  247 Loss:  0.581682 accurracy:  0.7826613\n",
      "Epoch:  248 Loss:  0.5816629 accurracy:  0.7834003\n",
      "Epoch:  249 Loss:  0.5816444 accurracy:  0.7841333\n",
      "Epoch:  250 Loss:  0.58162624 accurracy:  0.78486055\n",
      "Epoch:  251 Loss:  0.5816088 accurracy:  0.785582\n",
      "Epoch:  252 Loss:  0.5815919 accurracy:  0.78629774\n",
      "Epoch:  253 Loss:  0.58157563 accurracy:  0.78700787\n",
      "Epoch:  254 Loss:  0.5815597 accurracy:  0.7877124\n",
      "Epoch:  255 Loss:  0.58154446 accurracy:  0.78841144\n",
      "Epoch:  256 Loss:  0.58152974 accurracy:  0.78910506\n",
      "Epoch:  257 Loss:  0.58151543 accurracy:  0.78979325\n",
      "Epoch:  258 Loss:  0.5815017 accurracy:  0.7904762\n",
      "Epoch:  259 Loss:  0.58148855 accurracy:  0.79115385\n",
      "Epoch:  260 Loss:  0.58147585 accurracy:  0.7918263\n",
      "Epoch:  261 Loss:  0.58146363 accurracy:  0.79249364\n",
      "Epoch:  262 Loss:  0.58145183 accurracy:  0.7931559\n",
      "Epoch:  263 Loss:  0.58144075 accurracy:  0.7938131\n",
      "Epoch:  264 Loss:  0.58143 accurracy:  0.7944654\n",
      "Epoch:  265 Loss:  0.5814195 accurracy:  0.7951128\n",
      "Epoch:  266 Loss:  0.5814098 accurracy:  0.7957553\n",
      "Epoch:  267 Loss:  0.58140045 accurracy:  0.79639304\n",
      "Epoch:  268 Loss:  0.5813915 accurracy:  0.79702604\n",
      "Epoch:  269 Loss:  0.58138305 accurracy:  0.79765433\n",
      "Epoch:  270 Loss:  0.5813751 accurracy:  0.798278\n",
      "Epoch:  271 Loss:  0.5813675 accurracy:  0.7988971\n",
      "Epoch:  272 Loss:  0.5813602 accurracy:  0.7995116\n",
      "Epoch:  273 Loss:  0.5813535 accurracy:  0.80012167\n",
      "Epoch:  274 Loss:  0.5813473 accurracy:  0.80072725\n",
      "Epoch:  275 Loss:  0.5813414 accurracy:  0.8013285\n",
      "Epoch:  276 Loss:  0.58133584 accurracy:  0.8019254\n",
      "Epoch:  277 Loss:  0.58133066 accurracy:  0.802518\n",
      "Epoch:  278 Loss:  0.58132595 accurracy:  0.8031063\n",
      "Epoch:  279 Loss:  0.5813217 accurracy:  0.8036905\n",
      "Epoch:  280 Loss:  0.58131766 accurracy:  0.80427045\n",
      "Epoch:  281 Loss:  0.58131397 accurracy:  0.80484635\n",
      "Epoch:  282 Loss:  0.5813108 accurracy:  0.80541813\n",
      "Epoch:  283 Loss:  0.581308 accurracy:  0.8059859\n",
      "Epoch:  284 Loss:  0.5813054 accurracy:  0.8065497\n",
      "Epoch:  285 Loss:  0.5813032 accurracy:  0.80710953\n",
      "Epoch:  286 Loss:  0.5813014 accurracy:  0.8076655\n",
      "Epoch:  287 Loss:  0.5812997 accurracy:  0.8082176\n",
      "Epoch:  288 Loss:  0.5812986 accurracy:  0.8087659\n",
      "Epoch:  289 Loss:  0.5812977 accurracy:  0.8093103\n",
      "Epoch:  290 Loss:  0.5812971 accurracy:  0.8098511\n",
      "Epoch:  291 Loss:  0.58129686 accurracy:  0.81038815\n",
      "Epoch:  292 Loss:  0.581297 accurracy:  0.8109215\n",
      "Epoch:  293 Loss:  0.58129746 accurracy:  0.81145126\n",
      "Epoch:  294 Loss:  0.58129805 accurracy:  0.8119774\n",
      "Epoch:  295 Loss:  0.58129907 accurracy:  0.8125\n",
      "Epoch:  296 Loss:  0.58130044 accurracy:  0.8130191\n",
      "Epoch:  297 Loss:  0.5813018 accurracy:  0.8135347\n",
      "Epoch:  298 Loss:  0.5813037 accurracy:  0.8140468\n",
      "Epoch:  299 Loss:  0.58130586 accurracy:  0.8145555\n",
      "Epoch:  300 Loss:  0.5813083 accurracy:  0.8150609\n",
      "Epoch:  301 Loss:  0.581311 accurracy:  0.8155629\n",
      "Epoch:  302 Loss:  0.581314 accurracy:  0.8160616\n",
      "Epoch:  303 Loss:  0.5813172 accurracy:  0.816557\n",
      "Epoch:  304 Loss:  0.58132064 accurracy:  0.8170492\n",
      "Epoch:  305 Loss:  0.58132434 accurracy:  0.81753814\n",
      "Epoch:  306 Loss:  0.5813284 accurracy:  0.81802386\n",
      "Epoch:  307 Loss:  0.5813325 accurracy:  0.8185065\n",
      "Epoch:  308 Loss:  0.58133703 accurracy:  0.818986\n",
      "Epoch:  309 Loss:  0.5813418 accurracy:  0.81946236\n",
      "Epoch:  310 Loss:  0.5813467 accurracy:  0.8199357\n",
      "Epoch:  311 Loss:  0.58135194 accurracy:  0.82040596\n",
      "Epoch:  312 Loss:  0.58135724 accurracy:  0.82087326\n",
      "Epoch:  313 Loss:  0.5813629 accurracy:  0.8213376\n",
      "Epoch:  314 Loss:  0.58136874 accurracy:  0.8217989\n",
      "Epoch:  315 Loss:  0.5813748 accurracy:  0.8222574\n",
      "Epoch:  316 Loss:  0.581381 accurracy:  0.82271296\n",
      "Epoch:  317 Loss:  0.5813875 accurracy:  0.8231656\n",
      "Epoch:  318 Loss:  0.5813942 accurracy:  0.8236155\n",
      "Epoch:  319 Loss:  0.58140105 accurracy:  0.8240625\n",
      "Epoch:  320 Loss:  0.5814082 accurracy:  0.82450676\n",
      "Epoch:  321 Loss:  0.5814154 accurracy:  0.82494825\n",
      "Epoch:  322 Loss:  0.5814229 accurracy:  0.825387\n",
      "Epoch:  323 Loss:  0.5814306 accurracy:  0.82582307\n",
      "Epoch:  324 Loss:  0.5814384 accurracy:  0.8262564\n",
      "Epoch:  325 Loss:  0.5814464 accurracy:  0.8266871\n",
      "Epoch:  326 Loss:  0.5814547 accurracy:  0.8271152\n",
      "Epoch:  327 Loss:  0.581463 accurracy:  0.82754064\n",
      "Epoch:  328 Loss:  0.5814715 accurracy:  0.82796353\n",
      "Epoch:  329 Loss:  0.58148026 accurracy:  0.82838386\n",
      "Epoch:  330 Loss:  0.5814892 accurracy:  0.82880163\n",
      "Epoch:  331 Loss:  0.58149827 accurracy:  0.82921684\n",
      "Epoch:  332 Loss:  0.5815075 accurracy:  0.8296296\n",
      "Epoch:  333 Loss:  0.58151686 accurracy:  0.8300399\n",
      "Epoch:  334 Loss:  0.5815264 accurracy:  0.83044773\n",
      "Epoch:  335 Loss:  0.581536 accurracy:  0.83085316\n",
      "Epoch:  336 Loss:  0.5815459 accurracy:  0.8312562\n",
      "Epoch:  337 Loss:  0.581556 accurracy:  0.8316568\n",
      "Epoch:  338 Loss:  0.5815661 accurracy:  0.8320551\n",
      "Epoch:  339 Loss:  0.5815764 accurracy:  0.832451\n",
      "Epoch:  340 Loss:  0.5815868 accurracy:  0.83284456\n",
      "Epoch:  341 Loss:  0.58159745 accurracy:  0.83323586\n",
      "Epoch:  342 Loss:  0.5816081 accurracy:  0.8336249\n",
      "Epoch:  343 Loss:  0.58161896 accurracy:  0.8340116\n",
      "Epoch:  344 Loss:  0.58163 accurracy:  0.8343961\n",
      "Epoch:  345 Loss:  0.58164114 accurracy:  0.8347784\n",
      "Epoch:  346 Loss:  0.5816524 accurracy:  0.8351585\n",
      "Epoch:  347 Loss:  0.58166385 accurracy:  0.8355364\n",
      "Epoch:  348 Loss:  0.5816754 accurracy:  0.8359121\n",
      "Epoch:  349 Loss:  0.5816871 accurracy:  0.8362857\n",
      "Epoch:  350 Loss:  0.5816988 accurracy:  0.83665717\n",
      "Epoch:  351 Loss:  0.5817108 accurracy:  0.83702654\n",
      "Epoch:  352 Loss:  0.581723 accurracy:  0.83739376\n",
      "Epoch:  353 Loss:  0.581735 accurracy:  0.83775896\n",
      "Epoch:  354 Loss:  0.58174735 accurracy:  0.83812207\n",
      "Epoch:  355 Loss:  0.5817598 accurracy:  0.83848315\n",
      "Epoch:  356 Loss:  0.58177227 accurracy:  0.8388422\n",
      "Epoch:  357 Loss:  0.5817851 accurracy:  0.83919924\n",
      "Epoch:  358 Loss:  0.58179784 accurracy:  0.8395543\n",
      "Epoch:  359 Loss:  0.5818107 accurracy:  0.8399074\n",
      "Epoch:  360 Loss:  0.5818237 accurracy:  0.84025854\n",
      "Epoch:  361 Loss:  0.5818369 accurracy:  0.84060776\n",
      "Epoch:  362 Loss:  0.5818501 accurracy:  0.840955\n",
      "Epoch:  363 Loss:  0.5818634 accurracy:  0.84130037\n",
      "Epoch:  364 Loss:  0.5818769 accurracy:  0.8416438\n",
      "Epoch:  365 Loss:  0.5818904 accurracy:  0.8419854\n",
      "Epoch:  366 Loss:  0.58190405 accurracy:  0.84232515\n",
      "Epoch:  367 Loss:  0.58191776 accurracy:  0.84266305\n",
      "Epoch:  368 Loss:  0.58193177 accurracy:  0.8429991\n",
      "Epoch:  369 Loss:  0.5819456 accurracy:  0.8433333\n",
      "Epoch:  370 Loss:  0.5819597 accurracy:  0.8436658\n",
      "Epoch:  371 Loss:  0.58197397 accurracy:  0.8439964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  372 Loss:  0.5819882 accurracy:  0.8443253\n",
      "Epoch:  373 Loss:  0.5820025 accurracy:  0.8446524\n",
      "Epoch:  374 Loss:  0.582017 accurracy:  0.8449778\n",
      "Epoch:  375 Loss:  0.58203155 accurracy:  0.8453014\n",
      "Epoch:  376 Loss:  0.5820463 accurracy:  0.8456233\n",
      "Epoch:  377 Loss:  0.58206105 accurracy:  0.84594357\n",
      "Epoch:  378 Loss:  0.5820759 accurracy:  0.8462621\n",
      "Epoch:  379 Loss:  0.58209074 accurracy:  0.84657896\n",
      "Epoch:  380 Loss:  0.5821059 accurracy:  0.84689415\n",
      "Epoch:  381 Loss:  0.582121 accurracy:  0.84720767\n",
      "Epoch:  382 Loss:  0.5821363 accurracy:  0.8475196\n",
      "Epoch:  383 Loss:  0.58215153 accurracy:  0.8478299\n",
      "Epoch:  384 Loss:  0.58216697 accurracy:  0.8481385\n",
      "Epoch:  385 Loss:  0.5821825 accurracy:  0.8484456\n",
      "Epoch:  386 Loss:  0.58219814 accurracy:  0.84875107\n",
      "Epoch:  387 Loss:  0.58221376 accurracy:  0.849055\n",
      "Epoch:  388 Loss:  0.58222955 accurracy:  0.8493573\n",
      "Epoch:  389 Loss:  0.58224547 accurracy:  0.84965813\n",
      "Epoch:  390 Loss:  0.58226126 accurracy:  0.84995735\n",
      "Epoch:  391 Loss:  0.58227736 accurracy:  0.85025513\n",
      "Epoch:  392 Loss:  0.58229345 accurracy:  0.8505513\n",
      "Epoch:  393 Loss:  0.5823097 accurracy:  0.85084605\n",
      "Epoch:  394 Loss:  0.58232594 accurracy:  0.85113925\n",
      "Epoch:  395 Loss:  0.5823424 accurracy:  0.85143095\n",
      "Epoch:  396 Loss:  0.5823588 accurracy:  0.8517212\n",
      "Epoch:  397 Loss:  0.58237535 accurracy:  0.8520101\n",
      "Epoch:  398 Loss:  0.582392 accurracy:  0.8522974\n",
      "Epoch:  399 Loss:  0.5824087 accurracy:  0.8525\n",
      "Epoch:  400 Loss:  0.58242553 accurracy:  0.8527016\n",
      "Epoch:  401 Loss:  0.58244234 accurracy:  0.8529022\n",
      "Epoch:  402 Loss:  0.5824593 accurracy:  0.85310173\n",
      "Epoch:  403 Loss:  0.5824764 accurracy:  0.85330033\n",
      "Epoch:  404 Loss:  0.5824935 accurracy:  0.8534979\n",
      "Epoch:  405 Loss:  0.5825106 accurracy:  0.85369456\n",
      "Epoch:  406 Loss:  0.58252794 accurracy:  0.85389024\n",
      "Epoch:  407 Loss:  0.5825452 accurracy:  0.85408497\n",
      "Epoch:  408 Loss:  0.58256257 accurracy:  0.85427874\n",
      "Epoch:  409 Loss:  0.58258003 accurracy:  0.85447156\n",
      "Epoch:  410 Loss:  0.5825977 accurracy:  0.85466343\n",
      "Epoch:  411 Loss:  0.58261544 accurracy:  0.85485435\n",
      "Epoch:  412 Loss:  0.5826331 accurracy:  0.85504436\n",
      "Epoch:  413 Loss:  0.58265084 accurracy:  0.8552335\n",
      "Epoch:  414 Loss:  0.58266866 accurracy:  0.85542166\n",
      "Epoch:  415 Loss:  0.5826866 accurracy:  0.855609\n",
      "Epoch:  416 Loss:  0.58270466 accurracy:  0.8557954\n",
      "Epoch:  417 Loss:  0.5827228 accurracy:  0.8559809\n",
      "Epoch:  418 Loss:  0.582741 accurracy:  0.85616547\n",
      "Epoch:  419 Loss:  0.58275914 accurracy:  0.85634923\n",
      "Epoch:  420 Loss:  0.58277744 accurracy:  0.85653204\n",
      "Epoch:  421 Loss:  0.58279586 accurracy:  0.85671407\n",
      "Epoch:  422 Loss:  0.58281434 accurracy:  0.8568952\n",
      "Epoch:  423 Loss:  0.58283275 accurracy:  0.85707545\n",
      "Epoch:  424 Loss:  0.58285147 accurracy:  0.8572549\n",
      "Epoch:  425 Loss:  0.5828702 accurracy:  0.8574335\n",
      "Epoch:  426 Loss:  0.5828888 accurracy:  0.85761124\n",
      "Epoch:  427 Loss:  0.58290774 accurracy:  0.85778815\n",
      "Epoch:  428 Loss:  0.5829265 accurracy:  0.8579643\n",
      "Epoch:  429 Loss:  0.5829455 accurracy:  0.8581395\n",
      "Epoch:  430 Loss:  0.5829645 accurracy:  0.858314\n",
      "Epoch:  431 Loss:  0.5829837 accurracy:  0.85848767\n",
      "Epoch:  432 Loss:  0.5830026 accurracy:  0.8586605\n",
      "Epoch:  433 Loss:  0.58302206 accurracy:  0.85883254\n",
      "Epoch:  434 Loss:  0.58304095 accurracy:  0.85900384\n",
      "Epoch:  435 Loss:  0.583061 accurracy:  0.8591743\n",
      "Epoch:  436 Loss:  0.58307934 accurracy:  0.859344\n",
      "Epoch:  437 Loss:  0.5831004 accurracy:  0.8595129\n",
      "Epoch:  438 Loss:  0.5831176 accurracy:  0.85968107\n",
      "Epoch:  439 Loss:  0.5831416 accurracy:  0.8598485\n",
      "Epoch:  440 Loss:  0.5831554 accurracy:  0.8600151\n",
      "Epoch:  441 Loss:  0.5831878 accurracy:  0.860181\n",
      "Epoch:  442 Loss:  0.5831947 accurracy:  0.86042136\n",
      "Epoch:  443 Loss:  0.58325523 accurracy:  0.8605856\n",
      "Epoch:  444 Loss:  0.58326215 accurracy:  0.860824\n",
      "Epoch:  445 Loss:  0.58339214 accurracy:  0.8610613\n",
      "Epoch:  446 Loss:  0.5834401 accurracy:  0.86129755\n",
      "Epoch:  447 Loss:  0.5834493 accurracy:  0.86153275\n",
      "Epoch:  448 Loss:  0.58331764 accurracy:  0.8617669\n",
      "Epoch:  449 Loss:  0.5833155 accurracy:  0.8619259\n",
      "Epoch:  450 Loss:  0.5833781 accurracy:  0.86208427\n",
      "Epoch:  451 Loss:  0.58338106 accurracy:  0.86231565\n",
      "Epoch:  452 Loss:  0.5834512 accurracy:  0.8624724\n",
      "Epoch:  453 Loss:  0.5833521 accurracy:  0.8627019\n",
      "Epoch:  454 Loss:  0.5833677 accurracy:  0.86285716\n",
      "Epoch:  455 Loss:  0.58344734 accurracy:  0.8630117\n",
      "Epoch:  456 Loss:  0.5834115 accurracy:  0.8632385\n",
      "Epoch:  457 Loss:  0.58347315 accurracy:  0.8633916\n",
      "Epoch:  458 Loss:  0.58342516 accurracy:  0.8635439\n",
      "Epoch:  459 Loss:  0.58343333 accurracy:  0.8637681\n",
      "Epoch:  460 Loss:  0.5835261 accurracy:  0.863919\n",
      "Epoch:  461 Loss:  0.5834679 accurracy:  0.8641414\n",
      "Epoch:  462 Loss:  0.5835196 accurracy:  0.86429083\n",
      "Epoch:  463 Loss:  0.58352906 accurracy:  0.86443967\n",
      "Epoch:  464 Loss:  0.5835174 accurracy:  0.8646595\n",
      "Epoch:  465 Loss:  0.5836038 accurracy:  0.8648069\n",
      "Epoch:  466 Loss:  0.5835568 accurracy:  0.865025\n",
      "Epoch:  467 Loss:  0.5835942 accurracy:  0.86517096\n",
      "Epoch:  468 Loss:  0.5836395 accurracy:  0.8653163\n",
      "Epoch:  469 Loss:  0.58361423 accurracy:  0.8655319\n",
      "Epoch:  470 Loss:  0.5836894 accurracy:  0.86567587\n",
      "Epoch:  471 Loss:  0.5836683 accurracy:  0.8658192\n",
      "Epoch:  472 Loss:  0.5836909 accurracy:  0.86596197\n",
      "Epoch:  473 Loss:  0.58374983 accurracy:  0.86610407\n",
      "Epoch:  474 Loss:  0.5837232 accurracy:  0.8662456\n",
      "Epoch:  475 Loss:  0.5837879 accurracy:  0.86638653\n",
      "Epoch:  476 Loss:  0.5837873 accurracy:  0.8665269\n",
      "Epoch:  477 Loss:  0.5838012 accurracy:  0.8666667\n",
      "Epoch:  478 Loss:  0.58386123 accurracy:  0.86680585\n",
      "Epoch:  479 Loss:  0.5838408 accurracy:  0.86694443\n",
      "Epoch:  480 Loss:  0.5838974 accurracy:  0.8670825\n",
      "Epoch:  481 Loss:  0.5839071 accurracy:  0.8672199\n",
      "Epoch:  482 Loss:  0.5839193 accurracy:  0.8673568\n",
      "Epoch:  483 Loss:  0.5839749 accurracy:  0.8674931\n",
      "Epoch:  484 Loss:  0.5839613 accurracy:  0.8676289\n",
      "Epoch:  485 Loss:  0.5840139 accurracy:  0.86776406\n",
      "Epoch:  486 Loss:  0.58402485 accurracy:  0.8678987\n",
      "Epoch:  487 Loss:  0.584041 accurracy:  0.8680328\n",
      "Epoch:  488 Loss:  0.5840894 accurracy:  0.8681663\n",
      "Epoch:  489 Loss:  0.58408225 accurracy:  0.8682993\n",
      "Epoch:  490 Loss:  0.58413327 accurracy:  0.86843175\n",
      "Epoch:  491 Loss:  0.5841406 accurracy:  0.8685637\n",
      "Epoch:  492 Loss:  0.5841646 accurracy:  0.8686951\n",
      "Epoch:  493 Loss:  0.58420247 accurracy:  0.8688259\n",
      "Epoch:  494 Loss:  0.58420277 accurracy:  0.8689562\n",
      "Epoch:  495 Loss:  0.5842518 accurracy:  0.869086\n",
      "Epoch:  496 Loss:  0.5842543 accurracy:  0.8692153\n",
      "Epoch:  497 Loss:  0.58428824 accurracy:  0.86934406\n",
      "Epoch:  498 Loss:  0.584313 accurracy:  0.86947227\n",
      "Epoch:  499 Loss:  0.58432424 accurracy:  0.8696\n",
      "Epoch:  500 Loss:  0.58436626 accurracy:  0.8697272\n",
      "Epoch:  501 Loss:  0.5843684 accurracy:  0.8698539\n",
      "Epoch:  502 Loss:  0.58440953 accurracy:  0.8699801\n",
      "Epoch:  503 Loss:  0.5844208 accurracy:  0.8701058\n",
      "Epoch:  504 Loss:  0.58444697 accurracy:  0.87023103\n",
      "Epoch:  505 Loss:  0.5844748 accurracy:  0.8703557\n",
      "Epoch:  506 Loss:  0.584486 accurracy:  0.87047994\n",
      "Epoch:  507 Loss:  0.5845242 accurracy:  0.8706037\n",
      "Epoch:  508 Loss:  0.5845303 accurracy:  0.87072694\n",
      "Epoch:  509 Loss:  0.5845676 accurracy:  0.87084967\n",
      "Epoch:  510 Loss:  0.5845796 accurracy:  0.870972\n",
      "Epoch:  511 Loss:  0.58460724 accurracy:  0.87109375\n",
      "Epoch:  512 Loss:  0.58463013 accurracy:  0.87121505\n",
      "Epoch:  513 Loss:  0.58464706 accurracy:  0.8713359\n",
      "Epoch:  514 Loss:  0.58467895 accurracy:  0.8714563\n",
      "Epoch:  515 Loss:  0.5846894 accurracy:  0.87157625\n",
      "Epoch:  516 Loss:  0.5847245 accurracy:  0.8716957\n",
      "Epoch:  517 Loss:  0.58473456 accurracy:  0.87181467\n",
      "Epoch:  518 Loss:  0.58476746 accurracy:  0.8719332\n",
      "Epoch:  519 Loss:  0.58478177 accurracy:  0.8720513\n",
      "Epoch:  520 Loss:  0.5848093 accurracy:  0.8721689\n",
      "Epoch:  521 Loss:  0.58482957 accurracy:  0.8722861\n",
      "Epoch:  522 Loss:  0.58485085 accurracy:  0.8724028\n",
      "Epoch:  523 Loss:  0.5848768 accurracy:  0.8725191\n",
      "Epoch:  524 Loss:  0.5848932 accurracy:  0.87263495\n",
      "Epoch:  525 Loss:  0.5849234 accurracy:  0.87275034\n",
      "Epoch:  526 Loss:  0.58493656 accurracy:  0.87286526\n",
      "Epoch:  527 Loss:  0.5849688 accurracy:  0.8729798\n",
      "Epoch:  528 Loss:  0.5849808 accurracy:  0.8730939\n",
      "Epoch:  529 Loss:  0.58501405 accurracy:  0.87320757\n",
      "Epoch:  530 Loss:  0.58502525 accurracy:  0.87332076\n",
      "Epoch:  531 Loss:  0.5850591 accurracy:  0.8734336\n",
      "Epoch:  532 Loss:  0.5850699 accurracy:  0.87354594\n",
      "Epoch:  533 Loss:  0.5851045 accurracy:  0.87365794\n",
      "Epoch:  534 Loss:  0.58511454 accurracy:  0.87376946\n",
      "Epoch:  535 Loss:  0.5851506 accurracy:  0.8738806\n",
      "Epoch:  536 Loss:  0.5851584 accurracy:  0.8739913\n",
      "Epoch:  537 Loss:  0.58519745 accurracy:  0.87410164\n",
      "Epoch:  538 Loss:  0.5852012 accurracy:  0.8742115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  539 Loss:  0.5852457 accurracy:  0.874321\n",
      "Epoch:  540 Loss:  0.5852422 accurracy:  0.87443006\n",
      "Epoch:  541 Loss:  0.5852964 accurracy:  0.8745387\n",
      "Epoch:  542 Loss:  0.5852792 accurracy:  0.874647\n",
      "Epoch:  543 Loss:  0.5853501 accurracy:  0.8747549\n",
      "Epoch:  544 Loss:  0.5853092 accurracy:  0.8748624\n",
      "Epoch:  545 Loss:  0.58540803 accurracy:  0.8749695\n",
      "Epoch:  546 Loss:  0.5853247 accurracy:  0.8750762\n",
      "Epoch:  547 Loss:  0.58546805 accurracy:  0.8751825\n",
      "Epoch:  548 Loss:  0.5853157 accurracy:  0.8753491\n",
      "Epoch:  549 Loss:  0.5855208 accurracy:  0.87545455\n",
      "Epoch:  550 Loss:  0.5852919 accurracy:  0.87562007\n",
      "Epoch:  551 Loss:  0.5855594 accurracy:  0.87578505\n",
      "Epoch:  552 Loss:  0.5853378 accurracy:  0.8759494\n",
      "Epoch:  553 Loss:  0.5855909 accurracy:  0.876053\n",
      "Epoch:  554 Loss:  0.5854949 accurracy:  0.87615615\n",
      "Epoch:  555 Loss:  0.5855783 accurracy:  0.87625897\n",
      "Epoch:  556 Loss:  0.5856226 accurracy:  0.8763615\n",
      "Epoch:  557 Loss:  0.5855216 accurracy:  0.87646353\n",
      "Epoch:  558 Loss:  0.5856794 accurracy:  0.8765653\n",
      "Epoch:  559 Loss:  0.5855307 accurracy:  0.87666667\n",
      "Epoch:  560 Loss:  0.58571297 accurracy:  0.8767677\n",
      "Epoch:  561 Loss:  0.58564657 accurracy:  0.8768683\n",
      "Epoch:  562 Loss:  0.58571446 accurracy:  0.8769686\n",
      "Epoch:  563 Loss:  0.58575416 accurracy:  0.8770686\n",
      "Epoch:  564 Loss:  0.5856887 accurracy:  0.8771681\n",
      "Epoch:  565 Loss:  0.5858111 accurracy:  0.87726736\n",
      "Epoch:  566 Loss:  0.58571786 accurracy:  0.87736624\n",
      "Epoch:  567 Loss:  0.5858476 accurracy:  0.8774648\n",
      "Epoch:  568 Loss:  0.5858143 accurracy:  0.877563\n",
      "Epoch:  569 Loss:  0.5858602 accurracy:  0.8776608\n",
      "Epoch:  570 Loss:  0.58590215 accurracy:  0.8777583\n",
      "Epoch:  571 Loss:  0.58586174 accurracy:  0.8778555\n",
      "Epoch:  572 Loss:  0.5859583 accurracy:  0.8779523\n",
      "Epoch:  573 Loss:  0.58590156 accurracy:  0.8780488\n",
      "Epoch:  574 Loss:  0.5859991 accurracy:  0.8781449\n",
      "Epoch:  575 Loss:  0.58598167 accurracy:  0.87824076\n",
      "Epoch:  576 Loss:  0.5860248 accurracy:  0.87833625\n",
      "Epoch:  577 Loss:  0.5860587 accurracy:  0.8784314\n",
      "Epoch:  578 Loss:  0.5860443 accurracy:  0.8785262\n",
      "Epoch:  579 Loss:  0.58611614 accurracy:  0.8786207\n",
      "Epoch:  580 Loss:  0.58608377 accurracy:  0.87871486\n",
      "Epoch:  581 Loss:  0.58616257 accurracy:  0.8788087\n",
      "Epoch:  582 Loss:  0.58614856 accurracy:  0.87890226\n",
      "Epoch:  583 Loss:  0.5862001 accurracy:  0.8789954\n",
      "Epoch:  584 Loss:  0.5862182 accurracy:  0.87908834\n",
      "Epoch:  585 Loss:  0.58623207 accurracy:  0.8791809\n",
      "Epoch:  586 Loss:  0.5862783 accurracy:  0.8792731\n",
      "Epoch:  587 Loss:  0.5862687 accurracy:  0.8793651\n",
      "Epoch:  588 Loss:  0.58632976 accurracy:  0.8794567\n",
      "Epoch:  589 Loss:  0.5863184 accurracy:  0.879548\n",
      "Epoch:  590 Loss:  0.58637565 accurracy:  0.879639\n",
      "Epoch:  591 Loss:  0.5863775 accurracy:  0.87972975\n",
      "Epoch:  592 Loss:  0.58641773 accurracy:  0.8798201\n",
      "Epoch:  593 Loss:  0.58643734 accurracy:  0.87991023\n",
      "Epoch:  594 Loss:  0.58645755 accurracy:  0.88\n",
      "Epoch:  595 Loss:  0.5864927 accurracy:  0.88008946\n",
      "Epoch:  596 Loss:  0.5864992 accurracy:  0.8801787\n",
      "Epoch:  597 Loss:  0.58654386 accurracy:  0.88026756\n",
      "Epoch:  598 Loss:  0.5865451 accurracy:  0.88035613\n",
      "Epoch:  599 Loss:  0.58659214 accurracy:  0.88044447\n",
      "Epoch:  600 Loss:  0.586595 accurracy:  0.88053244\n",
      "Epoch:  601 Loss:  0.5866386 accurracy:  0.8806202\n",
      "Epoch:  602 Loss:  0.5866473 accurracy:  0.88070756\n",
      "Epoch:  603 Loss:  0.58668417 accurracy:  0.8807947\n",
      "Epoch:  604 Loss:  0.5866995 accurracy:  0.88088155\n",
      "Epoch:  605 Loss:  0.58672905 accurracy:  0.8809681\n",
      "Epoch:  606 Loss:  0.5867508 accurracy:  0.88105434\n",
      "Epoch:  607 Loss:  0.5867739 accurracy:  0.88114035\n",
      "Epoch:  608 Loss:  0.58680063 accurracy:  0.88122606\n",
      "Epoch:  609 Loss:  0.58681905 accurracy:  0.8813115\n",
      "Epoch:  610 Loss:  0.58684945 accurracy:  0.8813966\n",
      "Epoch:  611 Loss:  0.58686453 accurracy:  0.88148147\n",
      "Epoch:  612 Loss:  0.5868976 accurracy:  0.88156605\n",
      "Epoch:  613 Loss:  0.5869102 accurracy:  0.8816504\n",
      "Epoch:  614 Loss:  0.5869452 accurracy:  0.88173443\n",
      "Epoch:  615 Loss:  0.5869555 accurracy:  0.8818182\n",
      "Epoch:  616 Loss:  0.5869924 accurracy:  0.8819017\n",
      "Epoch:  617 Loss:  0.587 accurracy:  0.8819849\n",
      "Epoch:  618 Loss:  0.58703905 accurracy:  0.88206786\n",
      "Epoch:  619 Loss:  0.58704317 accurracy:  0.88215053\n",
      "Epoch:  620 Loss:  0.5870849 accurracy:  0.88223296\n",
      "Epoch:  621 Loss:  0.5870833 accurracy:  0.8823151\n",
      "Epoch:  622 Loss:  0.5871284 accurracy:  0.882397\n",
      "Epoch:  623 Loss:  0.5871175 accurracy:  0.88247865\n",
      "Epoch:  624 Loss:  0.5871666 accurracy:  0.88256\n",
      "Epoch:  625 Loss:  0.5871404 accurracy:  0.88264114\n",
      "Epoch:  626 Loss:  0.5871929 accurracy:  0.88272196\n",
      "Epoch:  627 Loss:  0.5871432 accurracy:  0.88280255\n",
      "Epoch:  628 Loss:  0.5872007 accurracy:  0.8828829\n",
      "Epoch:  629 Loss:  0.5871245 accurracy:  0.88296294\n",
      "Epoch:  630 Loss:  0.58719903 accurracy:  0.8830956\n",
      "Epoch:  631 Loss:  0.58712566 accurracy:  0.88317513\n",
      "Epoch:  632 Loss:  0.5872352 accurracy:  0.883307\n",
      "Epoch:  633 Loss:  0.5872254 accurracy:  0.8833859\n",
      "Epoch:  634 Loss:  0.58733904 accurracy:  0.8834646\n",
      "Epoch:  635 Loss:  0.5873785 accurracy:  0.88354295\n",
      "Epoch:  636 Loss:  0.5874284 accurracy:  0.88362116\n",
      "Epoch:  637 Loss:  0.58744526 accurracy:  0.88369906\n",
      "Epoch:  638 Loss:  0.5874351 accurracy:  0.8837767\n",
      "Epoch:  639 Loss:  0.58744466 accurracy:  0.88385415\n",
      "Epoch:  640 Loss:  0.5874358 accurracy:  0.88393134\n",
      "Epoch:  641 Loss:  0.58747476 accurracy:  0.8840083\n",
      "Epoch:  642 Loss:  0.5875053 accurracy:  0.884085\n",
      "Epoch:  643 Loss:  0.5875538 accurracy:  0.8841615\n",
      "Epoch:  644 Loss:  0.5875922 accurracy:  0.8842377\n",
      "Epoch:  645 Loss:  0.5876178 accurracy:  0.8843137\n",
      "Epoch:  646 Loss:  0.58763045 accurracy:  0.8843895\n",
      "Epoch:  647 Loss:  0.5876442 accurracy:  0.88446504\n",
      "Epoch:  648 Loss:  0.5876501 accurracy:  0.8845403\n",
      "Epoch:  649 Loss:  0.5876793 accurracy:  0.88461536\n",
      "Epoch:  650 Loss:  0.58769745 accurracy:  0.8846902\n",
      "Epoch:  651 Loss:  0.5877415 accurracy:  0.88476485\n",
      "Epoch:  652 Loss:  0.5877654 accurracy:  0.8848392\n",
      "Epoch:  653 Loss:  0.58779854 accurracy:  0.8849133\n",
      "Epoch:  654 Loss:  0.58782184 accurracy:  0.8849873\n",
      "Epoch:  655 Loss:  0.5878336 accurracy:  0.88506097\n",
      "Epoch:  656 Loss:  0.5878637 accurracy:  0.88513446\n",
      "Epoch:  657 Loss:  0.5878665 accurracy:  0.8852077\n",
      "Epoch:  658 Loss:  0.5879085 accurracy:  0.8852807\n",
      "Epoch:  659 Loss:  0.5879149 accurracy:  0.8853535\n",
      "Epoch:  660 Loss:  0.5879611 accurracy:  0.8854261\n",
      "Epoch:  661 Loss:  0.5879744 accurracy:  0.88549846\n",
      "Epoch:  662 Loss:  0.5880102 accurracy:  0.88557065\n",
      "Epoch:  663 Loss:  0.5880318 accurracy:  0.8856426\n",
      "Epoch:  664 Loss:  0.5880502 accurracy:  0.8857143\n",
      "Epoch:  665 Loss:  0.5880823 accurracy:  0.88578576\n",
      "Epoch:  666 Loss:  0.5880876 accurracy:  0.88585705\n",
      "Epoch:  667 Loss:  0.58812976 accurracy:  0.88592815\n",
      "Epoch:  668 Loss:  0.58813035 accurracy:  0.885999\n",
      "Epoch:  669 Loss:  0.5881776 accurracy:  0.88606966\n",
      "Epoch:  670 Loss:  0.58818036 accurracy:  0.8861401\n",
      "Epoch:  671 Loss:  0.58822525 accurracy:  0.8862103\n",
      "Epoch:  672 Loss:  0.5882342 accurracy:  0.88628036\n",
      "Epoch:  673 Loss:  0.5882702 accurracy:  0.88635015\n",
      "Epoch:  674 Loss:  0.5882879 accurracy:  0.8864198\n",
      "Epoch:  675 Loss:  0.58831203 accurracy:  0.88648915\n",
      "Epoch:  676 Loss:  0.58833945 accurracy:  0.88655835\n",
      "Epoch:  677 Loss:  0.58835256 accurracy:  0.8866273\n",
      "Epoch:  678 Loss:  0.58838886 accurracy:  0.8866961\n",
      "Epoch:  679 Loss:  0.5883939 accurracy:  0.8867647\n",
      "Epoch:  680 Loss:  0.58843696 accurracy:  0.8868331\n",
      "Epoch:  681 Loss:  0.5884371 accurracy:  0.88690126\n",
      "Epoch:  682 Loss:  0.5884841 accurracy:  0.88696927\n",
      "Epoch:  683 Loss:  0.58848196 accurracy:  0.88703704\n",
      "Epoch:  684 Loss:  0.58853036 accurracy:  0.88710463\n",
      "Epoch:  685 Loss:  0.5885279 accurracy:  0.887172\n",
      "Epoch:  686 Loss:  0.58857596 accurracy:  0.8872392\n",
      "Epoch:  687 Loss:  0.5885744 accurracy:  0.8873062\n",
      "Epoch:  688 Loss:  0.58862114 accurracy:  0.88737303\n",
      "Epoch:  689 Loss:  0.5886207 accurracy:  0.8874396\n",
      "Epoch:  690 Loss:  0.5886661 accurracy:  0.887506\n",
      "Epoch:  691 Loss:  0.5886666 accurracy:  0.8875722\n",
      "Epoch:  692 Loss:  0.588711 accurracy:  0.8876383\n",
      "Epoch:  693 Loss:  0.58871156 accurracy:  0.88770413\n",
      "Epoch:  694 Loss:  0.5887563 accurracy:  0.88776976\n",
      "Epoch:  695 Loss:  0.5887555 accurracy:  0.88783526\n",
      "Epoch:  696 Loss:  0.5888019 accurracy:  0.88790053\n",
      "Epoch:  697 Loss:  0.5887979 accurracy:  0.8879656\n",
      "Epoch:  698 Loss:  0.58884835 accurracy:  0.8880305\n",
      "Epoch:  699 Loss:  0.58883834 accurracy:  0.88809526\n",
      "Epoch:  700 Loss:  0.5888959 accurracy:  0.88815975\n",
      "Epoch:  701 Loss:  0.58887565 accurracy:  0.8882241\n",
      "Epoch:  702 Loss:  0.5889445 accurracy:  0.88828826\n",
      "Epoch:  703 Loss:  0.5889078 accurracy:  0.8883523\n",
      "Epoch:  704 Loss:  0.5889944 accurracy:  0.88841605\n",
      "Epoch:  705 Loss:  0.58893126 accurracy:  0.8884797\n",
      "Epoch:  706 Loss:  0.5890446 accurracy:  0.8885431\n",
      "Epoch:  707 Loss:  0.58893865 accurracy:  0.8886064\n",
      "Epoch:  708 Loss:  0.5890907 accurracy:  0.8886695\n",
      "Epoch:  709 Loss:  0.5889174 accurracy:  0.8887324\n",
      "Epoch:  710 Loss:  0.5891214 accurracy:  0.88879514\n",
      "Epoch:  711 Loss:  0.58884805 accurracy:  0.88885766\n",
      "Epoch:  712 Loss:  0.58911383 accurracy:  0.88892007\n",
      "Epoch:  713 Loss:  0.5887219 accurracy:  0.88902897\n",
      "Epoch:  714 Loss:  0.58905655 accurracy:  0.8890909\n",
      "Epoch:  715 Loss:  0.5886007 accurracy:  0.88919926\n",
      "Epoch:  716 Loss:  0.58904266 accurracy:  0.8892608\n",
      "Epoch:  717 Loss:  0.5886762 accurracy:  0.8893686\n",
      "Epoch:  718 Loss:  0.5892233 accurracy:  0.88942975\n",
      "Epoch:  719 Loss:  0.58904713 accurracy:  0.8894907\n",
      "Epoch:  720 Loss:  0.5893258 accurracy:  0.8895515\n",
      "Epoch:  721 Loss:  0.5893521 accurracy:  0.8896122\n",
      "Epoch:  722 Loss:  0.5891122 accurracy:  0.88967264\n",
      "Epoch:  723 Loss:  0.5893768 accurracy:  0.88973296\n",
      "Epoch:  724 Loss:  0.58900636 accurracy:  0.88983905\n",
      "Epoch:  725 Loss:  0.58942926 accurracy:  0.889899\n",
      "Epoch:  726 Loss:  0.5892216 accurracy:  0.88995874\n",
      "Epoch:  727 Loss:  0.5894598 accurracy:  0.89001834\n",
      "Epoch:  728 Loss:  0.58947545 accurracy:  0.8900777\n",
      "Epoch:  729 Loss:  0.58931184 accurracy:  0.89013696\n",
      "Epoch:  730 Loss:  0.58955234 accurracy:  0.8901961\n",
      "Epoch:  731 Loss:  0.5892612 accurracy:  0.89025503\n",
      "Epoch:  732 Loss:  0.5895968 accurracy:  0.8903138\n",
      "Epoch:  733 Loss:  0.58943504 accurracy:  0.8903724\n",
      "Epoch:  734 Loss:  0.58957934 accurracy:  0.89043087\n",
      "Epoch:  735 Loss:  0.5896235 accurracy:  0.8904891\n",
      "Epoch:  736 Loss:  0.5894789 accurracy:  0.8905473\n",
      "Epoch:  737 Loss:  0.5897045 accurracy:  0.8906052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  738 Loss:  0.5894818 accurracy:  0.8906631\n",
      "Epoch:  739 Loss:  0.5897385 accurracy:  0.8907207\n",
      "Epoch:  740 Loss:  0.5896275 accurracy:  0.89077824\n",
      "Epoch:  741 Loss:  0.5897097 accurracy:  0.8908356\n",
      "Epoch:  742 Loss:  0.5897728 accurracy:  0.8908928\n",
      "Epoch:  743 Loss:  0.5896524 accurracy:  0.89094985\n",
      "Epoch:  744 Loss:  0.58984864 accurracy:  0.8910067\n",
      "Epoch:  745 Loss:  0.5896803 accurracy:  0.89106345\n",
      "Epoch:  746 Loss:  0.58987606 accurracy:  0.89112\n",
      "Epoch:  747 Loss:  0.58979833 accurracy:  0.89117646\n",
      "Epoch:  748 Loss:  0.5898559 accurracy:  0.8912327\n",
      "Epoch:  749 Loss:  0.5899166 accurracy:  0.8912889\n",
      "Epoch:  750 Loss:  0.58982855 accurracy:  0.89134485\n",
      "Epoch:  751 Loss:  0.58998793 accurracy:  0.8914007\n",
      "Epoch:  752 Loss:  0.5898611 accurracy:  0.8914564\n",
      "Epoch:  753 Loss:  0.59001696 accurracy:  0.8915119\n",
      "Epoch:  754 Loss:  0.58995414 accurracy:  0.89156735\n",
      "Epoch:  755 Loss:  0.5900115 accurracy:  0.8916226\n",
      "Epoch:  756 Loss:  0.59005356 accurracy:  0.8916777\n",
      "Epoch:  757 Loss:  0.5900018 accurracy:  0.89173263\n",
      "Epoch:  758 Loss:  0.5901234 accurracy:  0.89178747\n",
      "Epoch:  759 Loss:  0.5900294 accurracy:  0.8918421\n",
      "Epoch:  760 Loss:  0.59015924 accurracy:  0.8918966\n",
      "Epoch:  761 Loss:  0.5901 accurracy:  0.891951\n",
      "Epoch:  762 Loss:  0.59016865 accurracy:  0.89200526\n",
      "Epoch:  763 Loss:  0.59018415 accurracy:  0.8920593\n",
      "Epoch:  764 Loss:  0.59017056 accurracy:  0.89211327\n",
      "Epoch:  765 Loss:  0.5902537 accurracy:  0.8921671\n",
      "Epoch:  766 Loss:  0.59019154 accurracy:  0.8922208\n",
      "Epoch:  767 Loss:  0.59029865 accurracy:  0.8922743\n",
      "Epoch:  768 Loss:  0.5902424 accurracy:  0.8923277\n",
      "Epoch:  769 Loss:  0.5903219 accurracy:  0.89238095\n",
      "Epoch:  770 Loss:  0.5903107 accurracy:  0.89243406\n",
      "Epoch:  771 Loss:  0.59033424 accurracy:  0.89248705\n",
      "Epoch:  772 Loss:  0.5903774 accurracy:  0.89253986\n",
      "Epoch:  773 Loss:  0.59035164 accurracy:  0.8925926\n",
      "Epoch:  774 Loss:  0.5904302 accurracy:  0.8926452\n",
      "Epoch:  775 Loss:  0.5903862 accurracy:  0.8926976\n",
      "Epoch:  776 Loss:  0.5904663 accurracy:  0.8927499\n",
      "Epoch:  777 Loss:  0.5904375 accurracy:  0.89280206\n",
      "Epoch:  778 Loss:  0.5904902 accurracy:  0.8928541\n",
      "Epoch:  779 Loss:  0.5904964 accurracy:  0.892906\n",
      "Epoch:  780 Loss:  0.59051025 accurracy:  0.89295775\n",
      "Epoch:  781 Loss:  0.5905523 accurracy:  0.89300936\n",
      "Epoch:  782 Loss:  0.59053576 accurracy:  0.89306086\n",
      "Epoch:  783 Loss:  0.5905984 accurracy:  0.89311224\n",
      "Epoch:  784 Loss:  0.5905718 accurracy:  0.8931635\n",
      "Epoch:  785 Loss:  0.5906344 accurracy:  0.8932146\n",
      "Epoch:  786 Loss:  0.5906179 accurracy:  0.89326555\n",
      "Epoch:  787 Loss:  0.5906627 accurracy:  0.8933164\n",
      "Epoch:  788 Loss:  0.5906685 accurracy:  0.8933671\n",
      "Epoch:  789 Loss:  0.5906885 accurracy:  0.8934177\n",
      "Epoch:  790 Loss:  0.590718 accurracy:  0.8934682\n",
      "Epoch:  791 Loss:  0.59071666 accurracy:  0.8935185\n",
      "Epoch:  792 Loss:  0.59076273 accurracy:  0.89356875\n",
      "Epoch:  793 Loss:  0.5907504 accurracy:  0.8936188\n",
      "Epoch:  794 Loss:  0.59080124 accurracy:  0.8936688\n",
      "Epoch:  795 Loss:  0.59079003 accurracy:  0.8937186\n",
      "Epoch:  796 Loss:  0.59083444 accurracy:  0.8937683\n",
      "Epoch:  797 Loss:  0.59083366 accurracy:  0.8938179\n",
      "Epoch:  798 Loss:  0.5908647 accurracy:  0.8938673\n",
      "Epoch:  799 Loss:  0.5908788 accurracy:  0.89391667\n",
      "Epoch:  800 Loss:  0.59089464 accurracy:  0.8939659\n",
      "Epoch:  801 Loss:  0.5909225 accurracy:  0.89401495\n",
      "Epoch:  802 Loss:  0.59092623 accurracy:  0.89406395\n",
      "Epoch:  803 Loss:  0.5909633 accurracy:  0.89411277\n",
      "Epoch:  804 Loss:  0.59096086 accurracy:  0.89416146\n",
      "Epoch:  805 Loss:  0.59100074 accurracy:  0.8942101\n",
      "Epoch:  806 Loss:  0.59099686 accurracy:  0.89425856\n",
      "Epoch:  807 Loss:  0.5910308 accurracy:  0.89430696\n",
      "Epoch:  808 Loss:  0.5910291 accurracy:  0.8943552\n",
      "Epoch:  809 Loss:  0.5910555 accurracy:  0.8944033\n",
      "Epoch:  810 Loss:  0.5910679 accurracy:  0.8944513\n",
      "Epoch:  811 Loss:  0.59109443 accurracy:  0.8944992\n",
      "Epoch:  812 Loss:  0.591097 accurracy:  0.8945469\n",
      "Epoch:  813 Loss:  0.59112346 accurracy:  0.8945946\n",
      "Epoch:  814 Loss:  0.5911373 accurracy:  0.8946421\n",
      "Epoch:  815 Loss:  0.591155 accurracy:  0.89468956\n",
      "Epoch:  816 Loss:  0.59117645 accurracy:  0.8947368\n",
      "Epoch:  817 Loss:  0.59118694 accurracy:  0.89478403\n",
      "Epoch:  818 Loss:  0.59121436 accurracy:  0.8948311\n",
      "Epoch:  819 Loss:  0.5912197 accurracy:  0.89487803\n",
      "Epoch:  820 Loss:  0.59125084 accurracy:  0.8949249\n",
      "Epoch:  821 Loss:  0.59125406 accurracy:  0.8949716\n",
      "Epoch:  822 Loss:  0.5912865 accurracy:  0.8950182\n",
      "Epoch:  823 Loss:  0.59128964 accurracy:  0.8950647\n",
      "Epoch:  824 Loss:  0.5913213 accurracy:  0.8951111\n",
      "Epoch:  825 Loss:  0.59132606 accurracy:  0.8951574\n",
      "Epoch:  826 Loss:  0.5913556 accurracy:  0.89520353\n",
      "Epoch:  827 Loss:  0.5913632 accurracy:  0.8952496\n",
      "Epoch:  828 Loss:  0.5913902 accurracy:  0.89529556\n",
      "Epoch:  829 Loss:  0.5914007 accurracy:  0.89534134\n",
      "Epoch:  830 Loss:  0.5914245 accurracy:  0.8953871\n",
      "Epoch:  831 Loss:  0.59143823 accurracy:  0.8954327\n",
      "Epoch:  832 Loss:  0.5914589 accurracy:  0.8954782\n",
      "Epoch:  833 Loss:  0.59147584 accurracy:  0.8955236\n",
      "Epoch:  834 Loss:  0.59149396 accurracy:  0.89556885\n",
      "Epoch:  835 Loss:  0.59151345 accurracy:  0.895614\n",
      "Epoch:  836 Loss:  0.5915292 accurracy:  0.8956591\n",
      "Epoch:  837 Loss:  0.59155095 accurracy:  0.89570403\n",
      "Epoch:  838 Loss:  0.5915649 accurracy:  0.8957489\n",
      "Epoch:  839 Loss:  0.5915882 accurracy:  0.8957937\n",
      "Epoch:  840 Loss:  0.59160095 accurracy:  0.89583826\n",
      "Epoch:  841 Loss:  0.5916254 accurracy:  0.89588284\n",
      "Epoch:  842 Loss:  0.591637 accurracy:  0.89592725\n",
      "Epoch:  843 Loss:  0.59166247 accurracy:  0.89597154\n",
      "Epoch:  844 Loss:  0.59167343 accurracy:  0.89601576\n",
      "Epoch:  845 Loss:  0.59169984 accurracy:  0.8960599\n",
      "Epoch:  846 Loss:  0.5917097 accurracy:  0.8961039\n",
      "Epoch:  847 Loss:  0.5917371 accurracy:  0.8961478\n",
      "Epoch:  848 Loss:  0.5917458 accurracy:  0.8961916\n",
      "Epoch:  849 Loss:  0.5917741 accurracy:  0.8962353\n",
      "Epoch:  850 Loss:  0.5917823 accurracy:  0.89627886\n",
      "Epoch:  851 Loss:  0.59181136 accurracy:  0.89632237\n",
      "Epoch:  852 Loss:  0.5918184 accurracy:  0.89636576\n",
      "Epoch:  853 Loss:  0.5918486 accurracy:  0.89640903\n",
      "Epoch:  854 Loss:  0.59185445 accurracy:  0.89645225\n",
      "Epoch:  855 Loss:  0.591886 accurracy:  0.89649534\n",
      "Epoch:  856 Loss:  0.5918901 accurracy:  0.8965383\n",
      "Epoch:  857 Loss:  0.59192365 accurracy:  0.8965812\n",
      "Epoch:  858 Loss:  0.5919252 accurracy:  0.89662397\n",
      "Epoch:  859 Loss:  0.59196144 accurracy:  0.89666665\n",
      "Epoch:  860 Loss:  0.59195995 accurracy:  0.89670926\n",
      "Epoch:  861 Loss:  0.5919997 accurracy:  0.89675176\n",
      "Epoch:  862 Loss:  0.5919941 accurracy:  0.89679414\n",
      "Epoch:  863 Loss:  0.5920382 accurracy:  0.8968364\n",
      "Epoch:  864 Loss:  0.59202725 accurracy:  0.8968786\n",
      "Epoch:  865 Loss:  0.59207743 accurracy:  0.8969207\n",
      "Epoch:  866 Loss:  0.59205943 accurracy:  0.8969627\n",
      "Epoch:  867 Loss:  0.59211755 accurracy:  0.8970046\n",
      "Epoch:  868 Loss:  0.5920901 accurracy:  0.8970464\n",
      "Epoch:  869 Loss:  0.59215903 accurracy:  0.8970881\n",
      "Epoch:  870 Loss:  0.5921185 accurracy:  0.8971297\n",
      "Epoch:  871 Loss:  0.59220237 accurracy:  0.89717126\n",
      "Epoch:  872 Loss:  0.59214467 accurracy:  0.8972127\n",
      "Epoch:  873 Loss:  0.59224814 accurracy:  0.897254\n",
      "Epoch:  874 Loss:  0.5921671 accurracy:  0.89729524\n",
      "Epoch:  875 Loss:  0.59229755 accurracy:  0.89733636\n",
      "Epoch:  876 Loss:  0.59218407 accurracy:  0.89737743\n",
      "Epoch:  877 Loss:  0.59235173 accurracy:  0.8974184\n",
      "Epoch:  878 Loss:  0.5921942 accurracy:  0.8974592\n",
      "Epoch:  879 Loss:  0.5924129 accurracy:  0.8975\n",
      "Epoch:  880 Loss:  0.5921942 accurracy:  0.8975407\n",
      "Epoch:  881 Loss:  0.5924832 accurracy:  0.8975813\n",
      "Epoch:  882 Loss:  0.5921796 accurracy:  0.89762175\n",
      "Epoch:  883 Loss:  0.59256583 accurracy:  0.89766216\n",
      "Epoch:  884 Loss:  0.5921441 accurracy:  0.89770246\n",
      "Epoch:  885 Loss:  0.59266514 accurracy:  0.8977427\n",
      "Epoch:  886 Loss:  0.5920774 accurracy:  0.8977828\n",
      "Epoch:  887 Loss:  0.592785 accurracy:  0.8978228\n",
      "Epoch:  888 Loss:  0.59196484 accurracy:  0.8978628\n",
      "Epoch:  889 Loss:  0.59292877 accurracy:  0.8979026\n",
      "Epoch:  890 Loss:  0.59178424 accurracy:  0.8979798\n",
      "Epoch:  891 Loss:  0.5930936 accurracy:  0.89801943\n",
      "Epoch:  892 Loss:  0.5915048 accurracy:  0.8980963\n",
      "Epoch:  893 Loss:  0.59326243 accurracy:  0.8981357\n",
      "Epoch:  894 Loss:  0.59108776 accurracy:  0.8982123\n",
      "Epoch:  895 Loss:  0.5933847 accurracy:  0.8982515\n",
      "Epoch:  896 Loss:  0.5905087 accurracy:  0.89832777\n",
      "Epoch:  897 Loss:  0.5933641 accurracy:  0.89836675\n",
      "Epoch:  898 Loss:  0.5898391 accurracy:  0.8984427\n",
      "Epoch:  899 Loss:  0.59317654 accurracy:  0.8984815\n",
      "Epoch:  900 Loss:  0.58948517 accurracy:  0.8985572\n",
      "Epoch:  901 Loss:  0.59330297 accurracy:  0.8985957\n",
      "Epoch:  902 Loss:  0.5905492 accurracy:  0.8986711\n",
      "Epoch:  903 Loss:  0.59321296 accurracy:  0.8987094\n",
      "Epoch:  904 Loss:  0.5931752 accurracy:  0.8987477\n",
      "Epoch:  905 Loss:  0.59092265 accurracy:  0.89882267\n",
      "Epoch:  906 Loss:  0.59361243 accurracy:  0.8988607\n",
      "Epoch:  907 Loss:  0.5910237 accurracy:  0.8989354\n",
      "Epoch:  908 Loss:  0.5931891 accurracy:  0.8989732\n",
      "Epoch:  909 Loss:  0.59318215 accurracy:  0.899011\n",
      "Epoch:  910 Loss:  0.5913084 accurracy:  0.8990853\n",
      "Epoch:  911 Loss:  0.5936629 accurracy:  0.89912283\n",
      "Epoch:  912 Loss:  0.59177357 accurracy:  0.8991968\n",
      "Epoch:  913 Loss:  0.59280556 accurracy:  0.8992341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  914 Loss:  0.5934265 accurracy:  0.8992714\n",
      "Epoch:  915 Loss:  0.5915407 accurracy:  0.899345\n",
      "Epoch:  916 Loss:  0.59354997 accurracy:  0.89938205\n",
      "Epoch:  917 Loss:  0.5925372 accurracy:  0.899419\n",
      "Epoch:  918 Loss:  0.59238625 accurracy:  0.8994559\n",
      "Epoch:  919 Loss:  0.59357095 accurracy:  0.89949274\n",
      "Epoch:  920 Loss:  0.59196484 accurracy:  0.8995657\n",
      "Epoch:  921 Loss:  0.5932392 accurracy:  0.8996023\n",
      "Epoch:  922 Loss:  0.5931246 accurracy:  0.89963883\n",
      "Epoch:  923 Loss:  0.59220827 accurracy:  0.8997114\n",
      "Epoch:  924 Loss:  0.5935511 accurracy:  0.8997477\n",
      "Epoch:  925 Loss:  0.59253824 accurracy:  0.899784\n",
      "Epoch:  926 Loss:  0.5928661 accurracy:  0.8998202\n",
      "Epoch:  927 Loss:  0.5934369 accurracy:  0.8998563\n",
      "Epoch:  928 Loss:  0.5923583 accurracy:  0.8999282\n",
      "Epoch:  929 Loss:  0.5933676 accurracy:  0.89996415\n",
      "Epoch:  930 Loss:  0.5930538 accurracy:  0.9\n",
      "Epoch:  931 Loss:  0.59265643 accurracy:  0.90003574\n",
      "Epoch:  932 Loss:  0.593516 accurracy:  0.90007144\n",
      "Epoch:  933 Loss:  0.5927188 accurracy:  0.9001071\n",
      "Epoch:  934 Loss:  0.5931204 accurracy:  0.9001426\n",
      "Epoch:  935 Loss:  0.59337527 accurracy:  0.9001781\n",
      "Epoch:  936 Loss:  0.59269965 accurracy:  0.9002134\n",
      "Epoch:  937 Loss:  0.59343415 accurracy:  0.90024877\n",
      "Epoch:  938 Loss:  0.5931015 accurracy:  0.900284\n",
      "Epoch:  939 Loss:  0.5929636 accurracy:  0.90031916\n",
      "Epoch:  940 Loss:  0.59350115 accurracy:  0.9003542\n",
      "Epoch:  941 Loss:  0.59292346 accurracy:  0.90038925\n",
      "Epoch:  942 Loss:  0.59328914 accurracy:  0.9004242\n",
      "Epoch:  943 Loss:  0.5933765 accurracy:  0.90045905\n",
      "Epoch:  944 Loss:  0.5929721 accurracy:  0.9004938\n",
      "Epoch:  945 Loss:  0.5934894 accurracy:  0.90052855\n",
      "Epoch:  946 Loss:  0.5931963 accurracy:  0.9005632\n",
      "Epoch:  947 Loss:  0.59318835 accurracy:  0.90059775\n",
      "Epoch:  948 Loss:  0.5935143 accurracy:  0.90063226\n",
      "Epoch:  949 Loss:  0.59311426 accurracy:  0.90066665\n",
      "Epoch:  950 Loss:  0.59341735 accurracy:  0.90070105\n",
      "Epoch:  951 Loss:  0.5934174 accurracy:  0.9007353\n",
      "Epoch:  952 Loss:  0.5931896 accurracy:  0.9007695\n",
      "Epoch:  953 Loss:  0.5935451 accurracy:  0.9008036\n",
      "Epoch:  954 Loss:  0.59330785 accurracy:  0.9008377\n",
      "Epoch:  955 Loss:  0.59336126 accurracy:  0.9008717\n",
      "Epoch:  956 Loss:  0.5935496 accurracy:  0.9009056\n",
      "Epoch:  957 Loss:  0.5932837 accurracy:  0.90093946\n",
      "Epoch:  958 Loss:  0.5935228 accurracy:  0.90097326\n",
      "Epoch:  959 Loss:  0.5934818 accurracy:  0.90100694\n",
      "Epoch:  960 Loss:  0.59336597 accurracy:  0.90104055\n",
      "Epoch:  961 Loss:  0.59360427 accurracy:  0.9010742\n",
      "Epoch:  962 Loss:  0.59342325 accurracy:  0.90110767\n",
      "Epoch:  963 Loss:  0.5935002 accurracy:  0.9011411\n",
      "Epoch:  964 Loss:  0.59360176 accurracy:  0.9011744\n",
      "Epoch:  965 Loss:  0.5934328 accurracy:  0.90120775\n",
      "Epoch:  966 Loss:  0.59361446 accurracy:  0.90124094\n",
      "Epoch:  967 Loss:  0.5935598 accurracy:  0.9012741\n",
      "Epoch:  968 Loss:  0.5935121 accurracy:  0.90130717\n",
      "Epoch:  969 Loss:  0.59366727 accurracy:  0.9013402\n",
      "Epoch:  970 Loss:  0.59353656 accurracy:  0.90137315\n",
      "Epoch:  971 Loss:  0.59361637 accurracy:  0.90140605\n",
      "Epoch:  972 Loss:  0.5936658 accurracy:  0.90143883\n",
      "Epoch:  973 Loss:  0.5935644 accurracy:  0.9014716\n",
      "Epoch:  974 Loss:  0.5936984 accurracy:  0.9015043\n",
      "Epoch:  975 Loss:  0.59364516 accurracy:  0.9015369\n",
      "Epoch:  976 Loss:  0.59363616 accurracy:  0.9015694\n",
      "Epoch:  977 Loss:  0.59373516 accurracy:  0.9016019\n",
      "Epoch:  978 Loss:  0.593645 accurracy:  0.90163434\n",
      "Epoch:  979 Loss:  0.5937177 accurracy:  0.90166664\n",
      "Epoch:  980 Loss:  0.59373754 accurracy:  0.90169895\n",
      "Epoch:  981 Loss:  0.593682 accurracy:  0.90173113\n",
      "Epoch:  982 Loss:  0.5937778 accurracy:  0.9017633\n",
      "Epoch:  983 Loss:  0.59373367 accurracy:  0.9017954\n",
      "Epoch:  984 Loss:  0.593745 accurracy:  0.9018274\n",
      "Epoch:  985 Loss:  0.5938064 accurracy:  0.90185934\n",
      "Epoch:  986 Loss:  0.5937482 accurracy:  0.90189123\n",
      "Epoch:  987 Loss:  0.59380937 accurracy:  0.90192306\n",
      "Epoch:  988 Loss:  0.5938145 accurracy:  0.9019548\n",
      "Epoch:  989 Loss:  0.59378844 accurracy:  0.90198654\n",
      "Epoch:  990 Loss:  0.5938559 accurracy:  0.9020182\n",
      "Epoch:  991 Loss:  0.5938226 accurracy:  0.9020497\n",
      "Epoch:  992 Loss:  0.5938431 accurracy:  0.90208125\n",
      "Epoch:  993 Loss:  0.59388065 accurracy:  0.90211266\n",
      "Epoch:  994 Loss:  0.59384567 accurracy:  0.9021441\n",
      "Epoch:  995 Loss:  0.5938952 accurracy:  0.90217537\n",
      "Epoch:  996 Loss:  0.593894 accurracy:  0.9022066\n",
      "Epoch:  997 Loss:  0.59388554 accurracy:  0.90223783\n",
      "Epoch:  998 Loss:  0.59393334 accurracy:  0.90226895\n",
      "Epoch:  999 Loss:  0.5939099 accurracy:  0.9023\n",
      "Epoch:  1000 Loss:  0.59393364 accurracy:  0.902331\n",
      "Epoch:  1001 Loss:  0.59395665 accurracy:  0.9023619\n",
      "Epoch:  1002 Loss:  0.5939379 accurracy:  0.9023928\n",
      "Epoch:  1003 Loss:  0.59397715 accurracy:  0.9024236\n",
      "Epoch:  1004 Loss:  0.5939741 accurracy:  0.9024544\n",
      "Epoch:  1005 Loss:  0.5939768 accurracy:  0.9024851\n",
      "Epoch:  1006 Loss:  0.59400994 accurracy:  0.9025157\n",
      "Epoch:  1007 Loss:  0.59399545 accurracy:  0.9025463\n",
      "Epoch:  1008 Loss:  0.5940189 accurracy:  0.9025768\n",
      "Epoch:  1009 Loss:  0.5940331 accurracy:  0.90260726\n",
      "Epoch:  1010 Loss:  0.59402555 accurracy:  0.90263766\n",
      "Epoch:  1011 Loss:  0.5940563 accurracy:  0.902668\n",
      "Epoch:  1012 Loss:  0.59405416 accurracy:  0.9026983\n",
      "Epoch:  1013 Loss:  0.594062 accurracy:  0.90272844\n",
      "Epoch:  1014 Loss:  0.59408575 accurracy:  0.9027586\n",
      "Epoch:  1015 Loss:  0.59407836 accurracy:  0.9027887\n",
      "Epoch:  1016 Loss:  0.5940994 accurracy:  0.90281874\n",
      "Epoch:  1017 Loss:  0.59410954 accurracy:  0.9028487\n",
      "Epoch:  1018 Loss:  0.5941089 accurracy:  0.90287864\n",
      "Epoch:  1019 Loss:  0.5941325 accurracy:  0.9029085\n",
      "Epoch:  1020 Loss:  0.59413254 accurracy:  0.9029383\n",
      "Epoch:  1021 Loss:  0.59414315 accurracy:  0.90296805\n",
      "Epoch:  1022 Loss:  0.5941604 accurracy:  0.90299773\n",
      "Epoch:  1023 Loss:  0.5941588 accurracy:  0.90302736\n",
      "Epoch:  1024 Loss:  0.59417653 accurracy:  0.9030569\n",
      "Epoch:  1025 Loss:  0.5941849 accurracy:  0.9030864\n",
      "Epoch:  1026 Loss:  0.59418863 accurracy:  0.90311587\n",
      "Epoch:  1027 Loss:  0.59420717 accurracy:  0.90314525\n",
      "Epoch:  1028 Loss:  0.59420913 accurracy:  0.9031746\n",
      "Epoch:  1029 Loss:  0.59422004 accurracy:  0.9032039\n",
      "Epoch:  1030 Loss:  0.59423393 accurracy:  0.9032331\n",
      "Epoch:  1031 Loss:  0.5942355 accurracy:  0.90326226\n",
      "Epoch:  1032 Loss:  0.594251 accurracy:  0.9032914\n",
      "Epoch:  1033 Loss:  0.59425855 accurracy:  0.90332043\n",
      "Epoch:  1034 Loss:  0.59426415 accurracy:  0.90334946\n",
      "Epoch:  1035 Loss:  0.5942793 accurracy:  0.90337837\n",
      "Epoch:  1036 Loss:  0.5942834 accurracy:  0.9034073\n",
      "Epoch:  1037 Loss:  0.59429353 accurracy:  0.9034361\n",
      "Epoch:  1038 Loss:  0.5943056 accurracy:  0.90346485\n",
      "Epoch:  1039 Loss:  0.59430915 accurracy:  0.9034936\n",
      "Epoch:  1040 Loss:  0.59432274 accurracy:  0.90352225\n",
      "Epoch:  1041 Loss:  0.59432995 accurracy:  0.90355086\n",
      "Epoch:  1042 Loss:  0.5943366 accurracy:  0.9035794\n",
      "Epoch:  1043 Loss:  0.5943497 accurracy:  0.9036079\n",
      "Epoch:  1044 Loss:  0.59435445 accurracy:  0.90363634\n",
      "Epoch:  1045 Loss:  0.5943645 accurracy:  0.90366477\n",
      "Epoch:  1046 Loss:  0.5943747 accurracy:  0.9036931\n",
      "Epoch:  1047 Loss:  0.5943798 accurracy:  0.9037214\n",
      "Epoch:  1048 Loss:  0.5943918 accurracy:  0.9037496\n",
      "Epoch:  1049 Loss:  0.5943988 accurracy:  0.9037778\n",
      "Epoch:  1050 Loss:  0.5944062 accurracy:  0.9038059\n",
      "Epoch:  1051 Loss:  0.5944175 accurracy:  0.903834\n",
      "Epoch:  1052 Loss:  0.59442294 accurracy:  0.903862\n",
      "Epoch:  1053 Loss:  0.5944326 accurracy:  0.90388995\n",
      "Epoch:  1054 Loss:  0.5944415 accurracy:  0.90391785\n",
      "Epoch:  1055 Loss:  0.5944475 accurracy:  0.9039457\n",
      "Epoch:  1056 Loss:  0.5944583 accurracy:  0.9039735\n",
      "Epoch:  1057 Loss:  0.594469 accurracy:  0.90400124\n",
      "Epoch:  1058 Loss:  0.5944674 accurracy:  0.90402895\n",
      "Epoch:  1059 Loss:  0.59448606 accurracy:  0.9040566\n",
      "Epoch:  1060 Loss:  0.5944885 accurracy:  0.9040842\n",
      "Epoch:  1061 Loss:  0.5944943 accurracy:  0.90411174\n",
      "Epoch:  1062 Loss:  0.5945102 accurracy:  0.9041392\n",
      "Epoch:  1063 Loss:  0.5945094 accurracy:  0.90416664\n",
      "Epoch:  1064 Loss:  0.59452194 accurracy:  0.90419406\n",
      "Epoch:  1065 Loss:  0.5945313 accurracy:  0.9042214\n",
      "Epoch:  1066 Loss:  0.5945328 accurracy:  0.90424865\n",
      "Epoch:  1067 Loss:  0.5945477 accurracy:  0.9042759\n",
      "Epoch:  1068 Loss:  0.59455127 accurracy:  0.9043031\n",
      "Epoch:  1069 Loss:  0.5945581 accurracy:  0.9043302\n",
      "Epoch:  1070 Loss:  0.5945707 accurracy:  0.9043573\n",
      "Epoch:  1071 Loss:  0.5945723 accurracy:  0.9043843\n",
      "Epoch:  1072 Loss:  0.5945836 accurracy:  0.9044113\n",
      "Epoch:  1073 Loss:  0.5945913 accurracy:  0.90443826\n",
      "Epoch:  1074 Loss:  0.5945949 accurracy:  0.90446514\n",
      "Epoch:  1075 Loss:  0.59460735 accurracy:  0.90449196\n",
      "Epoch:  1076 Loss:  0.5946114 accurracy:  0.9045187\n",
      "Epoch:  1077 Loss:  0.5946185 accurracy:  0.9045454\n",
      "Epoch:  1078 Loss:  0.5946291 accurracy:  0.9045721\n",
      "Epoch:  1079 Loss:  0.59463197 accurracy:  0.9045988\n",
      "Epoch:  1080 Loss:  0.5946423 accurracy:  0.90462536\n",
      "Epoch:  1081 Loss:  0.59464914 accurracy:  0.9046519\n",
      "Epoch:  1082 Loss:  0.5946539 accurracy:  0.90467834\n",
      "Epoch:  1083 Loss:  0.5946646 accurracy:  0.9047048\n",
      "Epoch:  1084 Loss:  0.59466875 accurracy:  0.90473115\n",
      "Epoch:  1085 Loss:  0.5946763 accurracy:  0.9047575\n",
      "Epoch:  1086 Loss:  0.59468514 accurracy:  0.9047838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1087 Loss:  0.59468913 accurracy:  0.9048101\n",
      "Epoch:  1088 Loss:  0.59469813 accurracy:  0.90483624\n",
      "Epoch:  1089 Loss:  0.59470475 accurracy:  0.9048624\n",
      "Epoch:  1090 Loss:  0.5947098 accurracy:  0.9048885\n",
      "Epoch:  1091 Loss:  0.594719 accurracy:  0.90491456\n",
      "Epoch:  1092 Loss:  0.59472424 accurracy:  0.90494055\n",
      "Epoch:  1093 Loss:  0.5947306 accurracy:  0.9049665\n",
      "Epoch:  1094 Loss:  0.594739 accurracy:  0.9049924\n",
      "Epoch:  1095 Loss:  0.5947438 accurracy:  0.90501827\n",
      "Epoch:  1096 Loss:  0.5947512 accurracy:  0.9050441\n",
      "Epoch:  1097 Loss:  0.594758 accurracy:  0.9050698\n",
      "Epoch:  1098 Loss:  0.5947631 accurracy:  0.9050955\n",
      "Epoch:  1099 Loss:  0.5947711 accurracy:  0.9051212\n",
      "Epoch:  1100 Loss:  0.5947766 accurracy:  0.90514684\n",
      "Epoch:  1101 Loss:  0.5947828 accurracy:  0.9051724\n",
      "Epoch:  1102 Loss:  0.59479016 accurracy:  0.9051979\n",
      "Epoch:  1103 Loss:  0.59479517 accurracy:  0.9052234\n",
      "Epoch:  1104 Loss:  0.59480226 accurracy:  0.9052489\n",
      "Epoch:  1105 Loss:  0.5948084 accurracy:  0.9052743\n",
      "Epoch:  1106 Loss:  0.5948137 accurracy:  0.9052996\n",
      "Epoch:  1107 Loss:  0.59482116 accurracy:  0.90532494\n",
      "Epoch:  1108 Loss:  0.59482604 accurracy:  0.90535015\n",
      "Epoch:  1109 Loss:  0.59483266 accurracy:  0.90537536\n",
      "Epoch:  1110 Loss:  0.59483874 accurracy:  0.9054005\n",
      "Epoch:  1111 Loss:  0.5948443 accurracy:  0.90542567\n",
      "Epoch:  1112 Loss:  0.59485054 accurracy:  0.90545076\n",
      "Epoch:  1113 Loss:  0.5948563 accurracy:  0.90547574\n",
      "Epoch:  1114 Loss:  0.5948618 accurracy:  0.90550077\n",
      "Epoch:  1115 Loss:  0.59486806 accurracy:  0.9055257\n",
      "Epoch:  1116 Loss:  0.5948736 accurracy:  0.9055506\n",
      "Epoch:  1117 Loss:  0.59487903 accurracy:  0.90557545\n",
      "Epoch:  1118 Loss:  0.59488547 accurracy:  0.90560025\n",
      "Epoch:  1119 Loss:  0.5948905 accurracy:  0.905625\n",
      "Epoch:  1120 Loss:  0.5948964 accurracy:  0.9056497\n",
      "Epoch:  1121 Loss:  0.5949019 accurracy:  0.9056744\n",
      "Epoch:  1122 Loss:  0.5949076 accurracy:  0.905699\n",
      "Epoch:  1123 Loss:  0.5949129 accurracy:  0.90572363\n",
      "Epoch:  1124 Loss:  0.59491825 accurracy:  0.9057481\n",
      "Epoch:  1125 Loss:  0.5949236 accurracy:  0.9057726\n",
      "Epoch:  1126 Loss:  0.5949294 accurracy:  0.9057971\n",
      "Epoch:  1127 Loss:  0.5949346 accurracy:  0.9058215\n",
      "Epoch:  1128 Loss:  0.59493965 accurracy:  0.9058459\n",
      "Epoch:  1129 Loss:  0.5949452 accurracy:  0.9058702\n",
      "Epoch:  1130 Loss:  0.5949503 accurracy:  0.9058945\n",
      "Epoch:  1131 Loss:  0.5949554 accurracy:  0.9059187\n",
      "Epoch:  1132 Loss:  0.59496087 accurracy:  0.9059429\n",
      "Epoch:  1133 Loss:  0.59496593 accurracy:  0.90596706\n",
      "Epoch:  1134 Loss:  0.59497076 accurracy:  0.9059912\n",
      "Epoch:  1135 Loss:  0.594976 accurracy:  0.9060153\n",
      "Epoch:  1136 Loss:  0.59498113 accurracy:  0.9060393\n",
      "Epoch:  1137 Loss:  0.59498566 accurracy:  0.90606326\n",
      "Epoch:  1138 Loss:  0.5949913 accurracy:  0.9060872\n",
      "Epoch:  1139 Loss:  0.59499556 accurracy:  0.9061111\n",
      "Epoch:  1140 Loss:  0.5950007 accurracy:  0.90613496\n",
      "Epoch:  1141 Loss:  0.5950059 accurracy:  0.9061588\n",
      "Epoch:  1142 Loss:  0.59501 accurracy:  0.9061826\n",
      "Epoch:  1143 Loss:  0.5950153 accurracy:  0.9062063\n",
      "Epoch:  1144 Loss:  0.5950197 accurracy:  0.90623\n",
      "Epoch:  1145 Loss:  0.59502435 accurracy:  0.90625364\n",
      "Epoch:  1146 Loss:  0.5950293 accurracy:  0.90627724\n",
      "Epoch:  1147 Loss:  0.59503347 accurracy:  0.90630084\n",
      "Epoch:  1148 Loss:  0.5950386 accurracy:  0.9063243\n",
      "Epoch:  1149 Loss:  0.5950429 accurracy:  0.9063478\n",
      "Epoch:  1150 Loss:  0.59504706 accurracy:  0.9063713\n",
      "Epoch:  1151 Loss:  0.59505254 accurracy:  0.90639466\n",
      "Epoch:  1152 Loss:  0.5950559 accurracy:  0.906418\n",
      "Epoch:  1153 Loss:  0.5950605 accurracy:  0.9064414\n",
      "Epoch:  1154 Loss:  0.5950655 accurracy:  0.90646464\n",
      "Epoch:  1155 Loss:  0.59506875 accurracy:  0.9064879\n",
      "Epoch:  1156 Loss:  0.59507394 accurracy:  0.90651107\n",
      "Epoch:  1157 Loss:  0.59507793 accurracy:  0.90653425\n",
      "Epoch:  1158 Loss:  0.5950819 accurracy:  0.9065574\n",
      "Epoch:  1159 Loss:  0.59508646 accurracy:  0.90658045\n",
      "Epoch:  1160 Loss:  0.5950909 accurracy:  0.9066035\n",
      "Epoch:  1161 Loss:  0.5950943 accurracy:  0.9066265\n",
      "Epoch:  1162 Loss:  0.59509903 accurracy:  0.9066495\n",
      "Epoch:  1163 Loss:  0.5951026 accurracy:  0.9066724\n",
      "Epoch:  1164 Loss:  0.5951067 accurracy:  0.9066953\n",
      "Epoch:  1165 Loss:  0.59511095 accurracy:  0.90671813\n",
      "Epoch:  1166 Loss:  0.5951144 accurracy:  0.9067409\n",
      "Epoch:  1167 Loss:  0.59511876 accurracy:  0.9067637\n",
      "Epoch:  1168 Loss:  0.59512246 accurracy:  0.90678644\n",
      "Epoch:  1169 Loss:  0.59512615 accurracy:  0.9068091\n",
      "Epoch:  1170 Loss:  0.5951302 accurracy:  0.90683174\n",
      "Epoch:  1171 Loss:  0.5951339 accurracy:  0.9068544\n",
      "Epoch:  1172 Loss:  0.59513766 accurracy:  0.906877\n",
      "Epoch:  1173 Loss:  0.5951417 accurracy:  0.9068995\n",
      "Epoch:  1174 Loss:  0.59514487 accurracy:  0.906922\n",
      "Epoch:  1175 Loss:  0.59514904 accurracy:  0.90697277\n",
      "Epoch:  1176 Loss:  0.59515256 accurracy:  0.9070235\n",
      "Epoch:  1177 Loss:  0.5951551 accurracy:  0.90707415\n",
      "Epoch:  1178 Loss:  0.5951602 accurracy:  0.9071247\n",
      "Epoch:  1179 Loss:  0.5951625 accurracy:  0.9071751\n",
      "Epoch:  1180 Loss:  0.59517086 accurracy:  0.9072255\n",
      "Epoch:  1181 Loss:  0.5951641 accurracy:  0.9072758\n",
      "Epoch:  1182 Loss:  0.59517634 accurracy:  0.907326\n",
      "Epoch:  1183 Loss:  0.5951775 accurracy:  0.9073761\n",
      "Epoch:  1184 Loss:  0.59517574 accurracy:  0.9074262\n",
      "Epoch:  1185 Loss:  0.5951874 accurracy:  0.9074761\n",
      "Epoch:  1186 Loss:  0.5951845 accurracy:  0.90752596\n",
      "Epoch:  1187 Loss:  0.5951885 accurracy:  0.9075758\n",
      "Epoch:  1188 Loss:  0.595196 accurracy:  0.90762544\n",
      "Epoch:  1189 Loss:  0.5951929 accurracy:  0.9076751\n",
      "Epoch:  1190 Loss:  0.5952002 accurracy:  0.9077246\n",
      "Epoch:  1191 Loss:  0.5952037 accurracy:  0.90777403\n",
      "Epoch:  1192 Loss:  0.5952026 accurracy:  0.90782344\n",
      "Epoch:  1193 Loss:  0.59521073 accurracy:  0.9078727\n",
      "Epoch:  1194 Loss:  0.5952111 accurracy:  0.9079219\n",
      "Epoch:  1195 Loss:  0.5952129 accurracy:  0.907971\n",
      "Epoch:  1196 Loss:  0.5952199 accurracy:  0.9080201\n",
      "Epoch:  1197 Loss:  0.5952187 accurracy:  0.908069\n",
      "Epoch:  1198 Loss:  0.59522325 accurracy:  0.9081179\n",
      "Epoch:  1199 Loss:  0.59522754 accurracy:  0.90816665\n",
      "Epoch:  1200 Loss:  0.5952269 accurracy:  0.9082154\n",
      "Epoch:  1201 Loss:  0.5952326 accurracy:  0.908264\n",
      "Epoch:  1202 Loss:  0.59523493 accurracy:  0.90831256\n",
      "Epoch:  1203 Loss:  0.59523547 accurracy:  0.908361\n",
      "Epoch:  1204 Loss:  0.5952414 accurracy:  0.9084094\n",
      "Epoch:  1205 Loss:  0.5952423 accurracy:  0.9084577\n",
      "Epoch:  1206 Loss:  0.5952442 accurracy:  0.9085059\n",
      "Epoch:  1207 Loss:  0.5952497 accurracy:  0.9085541\n",
      "Epoch:  1208 Loss:  0.5952491 accurracy:  0.9086022\n",
      "Epoch:  1209 Loss:  0.5952527 accurracy:  0.90865016\n",
      "Epoch:  1210 Loss:  0.59525645 accurracy:  0.908698\n",
      "Epoch:  1211 Loss:  0.59525657 accurracy:  0.9087459\n",
      "Epoch:  1212 Loss:  0.59526116 accurracy:  0.9087936\n",
      "Epoch:  1213 Loss:  0.59526336 accurracy:  0.9088413\n",
      "Epoch:  1214 Loss:  0.5952637 accurracy:  0.9088889\n",
      "Epoch:  1215 Loss:  0.59526896 accurracy:  0.9089364\n",
      "Epoch:  1216 Loss:  0.59526944 accurracy:  0.9089838\n",
      "Epoch:  1217 Loss:  0.59527117 accurracy:  0.9090312\n",
      "Epoch:  1218 Loss:  0.595276 accurracy:  0.9090785\n",
      "Epoch:  1219 Loss:  0.5952757 accurracy:  0.9091257\n",
      "Epoch:  1220 Loss:  0.5952788 accurracy:  0.90917283\n",
      "Epoch:  1221 Loss:  0.59528184 accurracy:  0.90921986\n",
      "Epoch:  1222 Loss:  0.59528214 accurracy:  0.9092668\n",
      "Epoch:  1223 Loss:  0.59528583 accurracy:  0.90931374\n",
      "Epoch:  1224 Loss:  0.59528726 accurracy:  0.9093605\n",
      "Epoch:  1225 Loss:  0.5952887 accurracy:  0.90940726\n",
      "Epoch:  1226 Loss:  0.5952927 accurracy:  0.9094539\n",
      "Epoch:  1227 Loss:  0.59529275 accurracy:  0.90950054\n",
      "Epoch:  1228 Loss:  0.59529513 accurracy:  0.90954703\n",
      "Epoch:  1229 Loss:  0.5952984 accurracy:  0.9095935\n",
      "Epoch:  1230 Loss:  0.5952985 accurracy:  0.90963984\n",
      "Epoch:  1231 Loss:  0.5953016 accurracy:  0.90968615\n",
      "Epoch:  1232 Loss:  0.5953034 accurracy:  0.90973234\n",
      "Epoch:  1233 Loss:  0.59530383 accurracy:  0.9097785\n",
      "Epoch:  1234 Loss:  0.5953072 accurracy:  0.90982455\n",
      "Epoch:  1235 Loss:  0.5953087 accurracy:  0.90987056\n",
      "Epoch:  1236 Loss:  0.5953092 accurracy:  0.90991646\n",
      "Epoch:  1237 Loss:  0.59531265 accurracy:  0.9099623\n",
      "Epoch:  1238 Loss:  0.5953133 accurracy:  0.9100081\n",
      "Epoch:  1239 Loss:  0.59531486 accurracy:  0.9100538\n",
      "Epoch:  1240 Loss:  0.5953174 accurracy:  0.9100994\n",
      "Epoch:  1241 Loss:  0.59531784 accurracy:  0.9101449\n",
      "Epoch:  1242 Loss:  0.59531975 accurracy:  0.9101904\n",
      "Epoch:  1243 Loss:  0.5953219 accurracy:  0.9102358\n",
      "Epoch:  1244 Loss:  0.5953229 accurracy:  0.9102811\n",
      "Epoch:  1245 Loss:  0.5953245 accurracy:  0.91032636\n",
      "Epoch:  1246 Loss:  0.59532577 accurracy:  0.91037154\n",
      "Epoch:  1247 Loss:  0.5953276 accurracy:  0.91041666\n",
      "Epoch:  1248 Loss:  0.59532857 accurracy:  0.9104617\n",
      "Epoch:  1249 Loss:  0.59533024 accurracy:  0.91050667\n",
      "Epoch:  1250 Loss:  0.5953315 accurracy:  0.91055155\n",
      "Epoch:  1251 Loss:  0.5953324 accurracy:  0.9105964\n",
      "Epoch:  1252 Loss:  0.59533465 accurracy:  0.91064113\n",
      "Epoch:  1253 Loss:  0.59533507 accurracy:  0.9106858\n",
      "Epoch:  1254 Loss:  0.59533685 accurracy:  0.9107304\n",
      "Epoch:  1255 Loss:  0.5953383 accurracy:  0.91077495\n",
      "Epoch:  1256 Loss:  0.5953383 accurracy:  0.9108194\n",
      "Epoch:  1257 Loss:  0.5953406 accurracy:  0.9108638\n",
      "Epoch:  1258 Loss:  0.59534144 accurracy:  0.9109081\n",
      "Epoch:  1259 Loss:  0.5953417 accurracy:  0.9109524\n",
      "Epoch:  1260 Loss:  0.5953445 accurracy:  0.91099656\n",
      "Epoch:  1261 Loss:  0.5953441 accurracy:  0.91104066\n",
      "Epoch:  1262 Loss:  0.5953452 accurracy:  0.9110847\n",
      "Epoch:  1263 Loss:  0.5953475 accurracy:  0.9111287\n",
      "Epoch:  1264 Loss:  0.595347 accurracy:  0.91117257\n",
      "Epoch:  1265 Loss:  0.5953484 accurracy:  0.91121644\n",
      "Epoch:  1266 Loss:  0.5953501 accurracy:  0.9112602\n",
      "Epoch:  1267 Loss:  0.59534955 accurracy:  0.9113039\n",
      "Epoch:  1268 Loss:  0.59535134 accurracy:  0.9113475\n",
      "Epoch:  1269 Loss:  0.5953526 accurracy:  0.9113911\n",
      "Epoch:  1270 Loss:  0.5953523 accurracy:  0.9114346\n",
      "Epoch:  1271 Loss:  0.59535384 accurracy:  0.911478\n",
      "Epoch:  1272 Loss:  0.5953548 accurracy:  0.9115213\n",
      "Epoch:  1273 Loss:  0.5953545 accurracy:  0.91156465\n",
      "Epoch:  1274 Loss:  0.5953565 accurracy:  0.91160786\n",
      "Epoch:  1275 Loss:  0.59535635 accurracy:  0.911651\n",
      "Epoch:  1276 Loss:  0.5953569 accurracy:  0.91169405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1277 Loss:  0.5953585 accurracy:  0.9117371\n",
      "Epoch:  1278 Loss:  0.59535813 accurracy:  0.91178006\n",
      "Epoch:  1279 Loss:  0.59535885 accurracy:  0.9118229\n",
      "Epoch:  1280 Loss:  0.5953601 accurracy:  0.9118657\n",
      "Epoch:  1281 Loss:  0.59536 accurracy:  0.91190845\n",
      "Epoch:  1282 Loss:  0.5953605 accurracy:  0.9119512\n",
      "Epoch:  1283 Loss:  0.5953619 accurracy:  0.91199374\n",
      "Epoch:  1284 Loss:  0.5953615 accurracy:  0.9120363\n",
      "Epoch:  1285 Loss:  0.5953617 accurracy:  0.9120788\n",
      "Epoch:  1286 Loss:  0.5953633 accurracy:  0.91212124\n",
      "Epoch:  1287 Loss:  0.5953624 accurracy:  0.91216356\n",
      "Epoch:  1288 Loss:  0.5953637 accurracy:  0.9122058\n",
      "Epoch:  1289 Loss:  0.5953642 accurracy:  0.9122481\n",
      "Epoch:  1290 Loss:  0.5953635 accurracy:  0.9122902\n",
      "Epoch:  1291 Loss:  0.5953645 accurracy:  0.9123323\n",
      "Epoch:  1292 Loss:  0.5953648 accurracy:  0.9123743\n",
      "Epoch:  1293 Loss:  0.59536445 accurracy:  0.9124163\n",
      "Epoch:  1294 Loss:  0.59536546 accurracy:  0.9124582\n",
      "Epoch:  1295 Loss:  0.59536546 accurracy:  0.9125\n",
      "Epoch:  1296 Loss:  0.5953697 accurracy:  0.91254175\n",
      "Epoch:  1297 Loss:  0.59536064 accurracy:  0.9125835\n",
      "Epoch:  1298 Loss:  0.59536827 accurracy:  0.9126251\n",
      "Epoch:  1299 Loss:  0.5953675 accurracy:  0.9126667\n",
      "Epoch:  1300 Loss:  0.595362 accurracy:  0.91270816\n",
      "Epoch:  1301 Loss:  0.59536916 accurracy:  0.9127496\n",
      "Epoch:  1302 Loss:  0.59536564 accurracy:  0.912791\n",
      "Epoch:  1303 Loss:  0.5953634 accurracy:  0.9128323\n",
      "Epoch:  1304 Loss:  0.59537005 accurracy:  0.91287357\n",
      "Epoch:  1305 Loss:  0.5953643 accurracy:  0.91291475\n",
      "Epoch:  1306 Loss:  0.595365 accurracy:  0.9129559\n",
      "Epoch:  1307 Loss:  0.5953693 accurracy:  0.91299695\n",
      "Epoch:  1308 Loss:  0.5953631 accurracy:  0.91303796\n",
      "Epoch:  1309 Loss:  0.59536624 accurracy:  0.9130789\n",
      "Epoch:  1310 Loss:  0.59536785 accurracy:  0.91311973\n",
      "Epoch:  1311 Loss:  0.59536266 accurracy:  0.91316056\n",
      "Epoch:  1312 Loss:  0.59536684 accurracy:  0.91320133\n",
      "Epoch:  1313 Loss:  0.5953662 accurracy:  0.913242\n",
      "Epoch:  1314 Loss:  0.5953627 accurracy:  0.91328263\n",
      "Epoch:  1315 Loss:  0.5953664 accurracy:  0.9133232\n",
      "Epoch:  1316 Loss:  0.5953644 accurracy:  0.9133637\n",
      "Epoch:  1317 Loss:  0.5953625 accurracy:  0.91340417\n",
      "Epoch:  1318 Loss:  0.5953658 accurracy:  0.9134445\n",
      "Epoch:  1319 Loss:  0.5953626 accurracy:  0.9134849\n",
      "Epoch:  1320 Loss:  0.5953624 accurracy:  0.9135251\n",
      "Epoch:  1321 Loss:  0.5953645 accurracy:  0.9135653\n",
      "Epoch:  1322 Loss:  0.5953614 accurracy:  0.91360545\n",
      "Epoch:  1323 Loss:  0.5953618 accurracy:  0.9136455\n",
      "Epoch:  1324 Loss:  0.5953628 accurracy:  0.91368556\n",
      "Epoch:  1325 Loss:  0.5953601 accurracy:  0.9137255\n",
      "Epoch:  1326 Loss:  0.59536093 accurracy:  0.9137654\n",
      "Epoch:  1327 Loss:  0.5953609 accurracy:  0.91380525\n",
      "Epoch:  1328 Loss:  0.59535897 accurracy:  0.913845\n",
      "Epoch:  1329 Loss:  0.5953594 accurracy:  0.9138847\n",
      "Epoch:  1330 Loss:  0.59535867 accurracy:  0.9139244\n",
      "Epoch:  1331 Loss:  0.5953577 accurracy:  0.913964\n",
      "Epoch:  1332 Loss:  0.5953578 accurracy:  0.9140035\n",
      "Epoch:  1333 Loss:  0.5953567 accurracy:  0.91404295\n",
      "Epoch:  1334 Loss:  0.5953562 accurracy:  0.9140824\n",
      "Epoch:  1335 Loss:  0.5953556 accurracy:  0.91412175\n",
      "Epoch:  1336 Loss:  0.59535474 accurracy:  0.9141611\n",
      "Epoch:  1337 Loss:  0.5953539 accurracy:  0.9142003\n",
      "Epoch:  1338 Loss:  0.59535354 accurracy:  0.91423947\n",
      "Epoch:  1339 Loss:  0.59535205 accurracy:  0.9142786\n",
      "Epoch:  1340 Loss:  0.59535223 accurracy:  0.91431767\n",
      "Epoch:  1341 Loss:  0.5953509 accurracy:  0.9143567\n",
      "Epoch:  1342 Loss:  0.59534985 accurracy:  0.91439563\n",
      "Epoch:  1343 Loss:  0.59534997 accurracy:  0.91443455\n",
      "Epoch:  1344 Loss:  0.59534824 accurracy:  0.91447335\n",
      "Epoch:  1345 Loss:  0.59534806 accurracy:  0.91451216\n",
      "Epoch:  1346 Loss:  0.59534687 accurracy:  0.91455084\n",
      "Epoch:  1347 Loss:  0.5953455 accurracy:  0.9145895\n",
      "Epoch:  1348 Loss:  0.5953455 accurracy:  0.91462815\n",
      "Epoch:  1349 Loss:  0.59534377 accurracy:  0.91466665\n",
      "Epoch:  1350 Loss:  0.59534264 accurracy:  0.91470516\n",
      "Epoch:  1351 Loss:  0.59534276 accurracy:  0.9147436\n",
      "Epoch:  1352 Loss:  0.59534055 accurracy:  0.914782\n",
      "Epoch:  1353 Loss:  0.59534 accurracy:  0.9148203\n",
      "Epoch:  1354 Loss:  0.5953396 accurracy:  0.9148585\n",
      "Epoch:  1355 Loss:  0.5953375 accurracy:  0.9148967\n",
      "Epoch:  1356 Loss:  0.59533674 accurracy:  0.91493493\n",
      "Epoch:  1357 Loss:  0.5953364 accurracy:  0.914973\n",
      "Epoch:  1358 Loss:  0.59533393 accurracy:  0.91501105\n",
      "Epoch:  1359 Loss:  0.5953339 accurracy:  0.915049\n",
      "Epoch:  1360 Loss:  0.5953324 accurracy:  0.9150869\n",
      "Epoch:  1361 Loss:  0.595331 accurracy:  0.91512483\n",
      "Epoch:  1362 Loss:  0.5953301 accurracy:  0.9151626\n",
      "Epoch:  1363 Loss:  0.59532875 accurracy:  0.9152004\n",
      "Epoch:  1364 Loss:  0.5953275 accurracy:  0.9152381\n",
      "Epoch:  1365 Loss:  0.59532636 accurracy:  0.91527575\n",
      "Epoch:  1366 Loss:  0.59532535 accurracy:  0.91531336\n",
      "Epoch:  1367 Loss:  0.5953238 accurracy:  0.91535085\n",
      "Epoch:  1368 Loss:  0.595323 accurracy:  0.91538835\n",
      "Epoch:  1369 Loss:  0.59532136 accurracy:  0.9154258\n",
      "Epoch:  1370 Loss:  0.59531957 accurracy:  0.91546315\n",
      "Epoch:  1371 Loss:  0.59531903 accurracy:  0.91550046\n",
      "Epoch:  1372 Loss:  0.5953169 accurracy:  0.9155378\n",
      "Epoch:  1373 Loss:  0.59531593 accurracy:  0.91557497\n",
      "Epoch:  1374 Loss:  0.595315 accurracy:  0.9156121\n",
      "Epoch:  1375 Loss:  0.5953124 accurracy:  0.91564924\n",
      "Epoch:  1376 Loss:  0.59531194 accurracy:  0.91568625\n",
      "Epoch:  1377 Loss:  0.59531033 accurracy:  0.91572326\n",
      "Epoch:  1378 Loss:  0.59530807 accurracy:  0.9157602\n",
      "Epoch:  1379 Loss:  0.5953077 accurracy:  0.9157971\n",
      "Epoch:  1380 Loss:  0.5953056 accurracy:  0.91583395\n",
      "Epoch:  1381 Loss:  0.5953035 accurracy:  0.9158707\n",
      "Epoch:  1382 Loss:  0.59530336 accurracy:  0.91590744\n",
      "Epoch:  1383 Loss:  0.5953008 accurracy:  0.9159441\n",
      "Epoch:  1384 Loss:  0.5952988 accurracy:  0.91598076\n",
      "Epoch:  1385 Loss:  0.59529877 accurracy:  0.9160173\n",
      "Epoch:  1386 Loss:  0.5952962 accurracy:  0.91605383\n",
      "Epoch:  1387 Loss:  0.5952939 accurracy:  0.9160903\n",
      "Epoch:  1388 Loss:  0.595294 accurracy:  0.9161267\n",
      "Epoch:  1389 Loss:  0.59529114 accurracy:  0.9161631\n",
      "Epoch:  1390 Loss:  0.59528905 accurracy:  0.9161994\n",
      "Epoch:  1391 Loss:  0.5952888 accurracy:  0.9162356\n",
      "Epoch:  1392 Loss:  0.5952861 accurracy:  0.9162718\n",
      "Epoch:  1393 Loss:  0.59528416 accurracy:  0.916308\n",
      "Epoch:  1394 Loss:  0.5952836 accurracy:  0.9163441\n",
      "Epoch:  1395 Loss:  0.5952808 accurracy:  0.9163801\n",
      "Epoch:  1396 Loss:  0.59527934 accurracy:  0.9164161\n",
      "Epoch:  1397 Loss:  0.595278 accurracy:  0.91645205\n",
      "Epoch:  1398 Loss:  0.5952755 accurracy:  0.916488\n",
      "Epoch:  1399 Loss:  0.5952741 accurracy:  0.9165238\n",
      "Epoch:  1400 Loss:  0.59527224 accurracy:  0.9165596\n",
      "Epoch:  1401 Loss:  0.59527016 accurracy:  0.91659534\n",
      "Epoch:  1402 Loss:  0.5952685 accurracy:  0.91663104\n",
      "Epoch:  1403 Loss:  0.5952665 accurracy:  0.9166667\n",
      "Epoch:  1404 Loss:  0.5952645 accurracy:  0.9167023\n",
      "Epoch:  1405 Loss:  0.5952631 accurracy:  0.9167378\n",
      "Epoch:  1406 Loss:  0.59526104 accurracy:  0.91677326\n",
      "Epoch:  1407 Loss:  0.59525853 accurracy:  0.9168087\n",
      "Epoch:  1408 Loss:  0.59525746 accurracy:  0.91684407\n",
      "Epoch:  1409 Loss:  0.595255 accurracy:  0.9168794\n",
      "Epoch:  1410 Loss:  0.59525275 accurracy:  0.9169147\n",
      "Epoch:  1411 Loss:  0.59525615 accurracy:  0.9169499\n",
      "Epoch:  1412 Loss:  0.59524363 accurracy:  0.91698515\n",
      "Epoch:  1413 Loss:  0.59524816 accurracy:  0.91702026\n",
      "Epoch:  1414 Loss:  0.5952485 accurracy:  0.91705537\n",
      "Epoch:  1415 Loss:  0.5952378 accurracy:  0.9170904\n",
      "Epoch:  1416 Loss:  0.5952425 accurracy:  0.9171254\n",
      "Epoch:  1417 Loss:  0.59524137 accurracy:  0.91716033\n",
      "Epoch:  1418 Loss:  0.5952322 accurracy:  0.9171952\n",
      "Epoch:  1419 Loss:  0.5952367 accurracy:  0.91723007\n",
      "Epoch:  1420 Loss:  0.59523433 accurracy:  0.9172648\n",
      "Epoch:  1421 Loss:  0.595226 accurracy:  0.91729957\n",
      "Epoch:  1422 Loss:  0.5952304 accurracy:  0.91733426\n",
      "Epoch:  1423 Loss:  0.5952274 accurracy:  0.9173689\n",
      "Epoch:  1424 Loss:  0.5952204 accurracy:  0.9174035\n",
      "Epoch:  1425 Loss:  0.595224 accurracy:  0.91743803\n",
      "Epoch:  1426 Loss:  0.59522015 accurracy:  0.91747254\n",
      "Epoch:  1427 Loss:  0.5952142 accurracy:  0.917507\n",
      "Epoch:  1428 Loss:  0.59521747 accurracy:  0.9175414\n",
      "Epoch:  1429 Loss:  0.5952127 accurracy:  0.9175758\n",
      "Epoch:  1430 Loss:  0.5952082 accurracy:  0.91761005\n",
      "Epoch:  1431 Loss:  0.5952106 accurracy:  0.9176443\n",
      "Epoch:  1432 Loss:  0.595205 accurracy:  0.91767853\n",
      "Epoch:  1433 Loss:  0.5952019 accurracy:  0.9177127\n",
      "Epoch:  1434 Loss:  0.5952033 accurracy:  0.9177468\n",
      "Epoch:  1435 Loss:  0.5951979 accurracy:  0.9177809\n",
      "Epoch:  1436 Loss:  0.59519535 accurracy:  0.9178149\n",
      "Epoch:  1437 Loss:  0.5951964 accurracy:  0.9178489\n",
      "Epoch:  1438 Loss:  0.59519047 accurracy:  0.9178828\n",
      "Epoch:  1439 Loss:  0.59518874 accurracy:  0.91791666\n",
      "Epoch:  1440 Loss:  0.59518886 accurracy:  0.9179505\n",
      "Epoch:  1441 Loss:  0.5951833 accurracy:  0.9179843\n",
      "Epoch:  1442 Loss:  0.5951819 accurracy:  0.91801804\n",
      "Epoch:  1443 Loss:  0.5951812 accurracy:  0.9180517\n",
      "Epoch:  1444 Loss:  0.595176 accurracy:  0.91808534\n",
      "Epoch:  1445 Loss:  0.5951748 accurracy:  0.91811895\n",
      "Epoch:  1446 Loss:  0.59517366 accurracy:  0.9181525\n",
      "Epoch:  1447 Loss:  0.5951689 accurracy:  0.918186\n",
      "Epoch:  1448 Loss:  0.5951674 accurracy:  0.91821945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1449 Loss:  0.59516597 accurracy:  0.9182529\n",
      "Epoch:  1450 Loss:  0.59516066 accurracy:  0.91828626\n",
      "Epoch:  1451 Loss:  0.5951603 accurracy:  0.9183196\n",
      "Epoch:  1452 Loss:  0.59515846 accurracy:  0.91835284\n",
      "Epoch:  1453 Loss:  0.59515315 accurracy:  0.91838604\n",
      "Epoch:  1454 Loss:  0.5951528 accurracy:  0.91841924\n",
      "Epoch:  1455 Loss:  0.5951506 accurracy:  0.9184524\n",
      "Epoch:  1456 Loss:  0.5951454 accurracy:  0.91848546\n",
      "Epoch:  1457 Loss:  0.59514505 accurracy:  0.91851854\n",
      "Epoch:  1458 Loss:  0.5951425 accurracy:  0.9185515\n",
      "Epoch:  1459 Loss:  0.5951379 accurracy:  0.91858447\n",
      "Epoch:  1460 Loss:  0.59513676 accurracy:  0.91861737\n",
      "Epoch:  1461 Loss:  0.5951342 accurracy:  0.91865027\n",
      "Epoch:  1462 Loss:  0.5951302 accurracy:  0.91868305\n",
      "Epoch:  1463 Loss:  0.5951284 accurracy:  0.91871583\n",
      "Epoch:  1464 Loss:  0.5951263 accurracy:  0.91874856\n",
      "Epoch:  1465 Loss:  0.59512234 accurracy:  0.9187813\n",
      "Epoch:  1466 Loss:  0.5951204 accurracy:  0.9188139\n",
      "Epoch:  1467 Loss:  0.5951185 accurracy:  0.9188465\n",
      "Epoch:  1468 Loss:  0.5951137 accurracy:  0.91887903\n",
      "Epoch:  1469 Loss:  0.5951124 accurracy:  0.9189116\n",
      "Epoch:  1470 Loss:  0.59511 accurracy:  0.918944\n",
      "Epoch:  1471 Loss:  0.59510523 accurracy:  0.9189764\n",
      "Epoch:  1472 Loss:  0.5951042 accurracy:  0.91900885\n",
      "Epoch:  1473 Loss:  0.5951012 accurracy:  0.91904116\n",
      "Epoch:  1474 Loss:  0.5950975 accurracy:  0.91907346\n",
      "Epoch:  1475 Loss:  0.5950959 accurracy:  0.9191057\n",
      "Epoch:  1476 Loss:  0.59509224 accurracy:  0.9191379\n",
      "Epoch:  1477 Loss:  0.59508926 accurracy:  0.91917\n",
      "Epoch:  1478 Loss:  0.59508723 accurracy:  0.91920215\n",
      "Epoch:  1479 Loss:  0.59508353 accurracy:  0.9192342\n",
      "Epoch:  1480 Loss:  0.59508103 accurracy:  0.9192663\n",
      "Epoch:  1481 Loss:  0.5950783 accurracy:  0.91929823\n",
      "Epoch:  1482 Loss:  0.5950751 accurracy:  0.9193302\n",
      "Epoch:  1483 Loss:  0.5950723 accurracy:  0.91936207\n",
      "Epoch:  1484 Loss:  0.59506947 accurracy:  0.91939396\n",
      "Epoch:  1485 Loss:  0.5950667 accurracy:  0.9194257\n",
      "Epoch:  1486 Loss:  0.5950632 accurracy:  0.9194575\n",
      "Epoch:  1487 Loss:  0.59506047 accurracy:  0.91948926\n",
      "Epoch:  1488 Loss:  0.5950578 accurracy:  0.9195209\n",
      "Epoch:  1489 Loss:  0.5950542 accurracy:  0.91955256\n",
      "Epoch:  1490 Loss:  0.59505177 accurracy:  0.91958416\n",
      "Epoch:  1491 Loss:  0.59504884 accurracy:  0.91961575\n",
      "Epoch:  1492 Loss:  0.59504586 accurracy:  0.9196472\n",
      "Epoch:  1493 Loss:  0.59504235 accurracy:  0.9196787\n",
      "Epoch:  1494 Loss:  0.5950401 accurracy:  0.91971016\n",
      "Epoch:  1495 Loss:  0.5950364 accurracy:  0.9197415\n",
      "Epoch:  1496 Loss:  0.5950331 accurracy:  0.91977286\n",
      "Epoch:  1497 Loss:  0.59503084 accurracy:  0.91980416\n",
      "Epoch:  1498 Loss:  0.5950274 accurracy:  0.91983545\n",
      "Epoch:  1499 Loss:  0.595024 accurracy:  0.9198667\n",
      "Epoch:  1500 Loss:  0.59502137 accurracy:  0.91989785\n",
      "Epoch:  1501 Loss:  0.5950184 accurracy:  0.91992897\n",
      "Epoch:  1502 Loss:  0.5950147 accurracy:  0.9199601\n",
      "Epoch:  1503 Loss:  0.5950121 accurracy:  0.91999114\n",
      "Epoch:  1504 Loss:  0.59500897 accurracy:  0.92002213\n",
      "Epoch:  1505 Loss:  0.5950053 accurracy:  0.9200531\n",
      "Epoch:  1506 Loss:  0.595003 accurracy:  0.92008406\n",
      "Epoch:  1507 Loss:  0.59499973 accurracy:  0.92011493\n",
      "Epoch:  1508 Loss:  0.5949955 accurracy:  0.9201458\n",
      "Epoch:  1509 Loss:  0.59499335 accurracy:  0.9201766\n",
      "Epoch:  1510 Loss:  0.59499043 accurracy:  0.9202074\n",
      "Epoch:  1511 Loss:  0.5949859 accurracy:  0.9202381\n",
      "Epoch:  1512 Loss:  0.5949838 accurracy:  0.9202688\n",
      "Epoch:  1513 Loss:  0.59498066 accurracy:  0.9202994\n",
      "Epoch:  1514 Loss:  0.59497625 accurracy:  0.92033005\n",
      "Epoch:  1515 Loss:  0.5949743 accurracy:  0.9203606\n",
      "Epoch:  1516 Loss:  0.59497124 accurracy:  0.92039114\n",
      "Epoch:  1517 Loss:  0.594967 accurracy:  0.9204216\n",
      "Epoch:  1518 Loss:  0.59496385 accurracy:  0.92045206\n",
      "Epoch:  1519 Loss:  0.5949617 accurracy:  0.92048246\n",
      "Epoch:  1520 Loss:  0.5949571 accurracy:  0.9205128\n",
      "Epoch:  1521 Loss:  0.59495825 accurracy:  0.92054313\n",
      "Epoch:  1522 Loss:  0.5949478 accurracy:  0.9205734\n",
      "Epoch:  1523 Loss:  0.59494716 accurracy:  0.9206037\n",
      "Epoch:  1524 Loss:  0.59494835 accurracy:  0.92063385\n",
      "Epoch:  1525 Loss:  0.5949376 accurracy:  0.9206641\n",
      "Epoch:  1526 Loss:  0.5949376 accurracy:  0.9206942\n",
      "Epoch:  1527 Loss:  0.5949376 accurracy:  0.9207243\n",
      "Epoch:  1528 Loss:  0.5949285 accurracy:  0.9207543\n",
      "Epoch:  1529 Loss:  0.59492785 accurracy:  0.9207843\n",
      "Epoch:  1530 Loss:  0.5949269 accurracy:  0.9208143\n",
      "Epoch:  1531 Loss:  0.5949185 accurracy:  0.9208442\n",
      "Epoch:  1532 Loss:  0.59491754 accurracy:  0.9208741\n",
      "Epoch:  1533 Loss:  0.5949166 accurracy:  0.920904\n",
      "Epoch:  1534 Loss:  0.59490913 accurracy:  0.9209338\n",
      "Epoch:  1535 Loss:  0.59490716 accurracy:  0.9209635\n",
      "Epoch:  1536 Loss:  0.5949061 accurracy:  0.92099327\n",
      "Epoch:  1537 Loss:  0.5948989 accurracy:  0.92102295\n",
      "Epoch:  1538 Loss:  0.5948974 accurracy:  0.92105263\n",
      "Epoch:  1539 Loss:  0.5948954 accurracy:  0.92108226\n",
      "Epoch:  1540 Loss:  0.5948892 accurracy:  0.9211118\n",
      "Epoch:  1541 Loss:  0.5948869 accurracy:  0.9211414\n",
      "Epoch:  1542 Loss:  0.59488463 accurracy:  0.9211709\n",
      "Epoch:  1543 Loss:  0.59487957 accurracy:  0.92120034\n",
      "Epoch:  1544 Loss:  0.5948762 accurracy:  0.9212298\n",
      "Epoch:  1545 Loss:  0.5948742 accurracy:  0.92125916\n",
      "Epoch:  1546 Loss:  0.594869 accurracy:  0.9212885\n",
      "Epoch:  1547 Loss:  0.5948657 accurracy:  0.9213178\n",
      "Epoch:  1548 Loss:  0.5948638 accurracy:  0.9213471\n",
      "Epoch:  1549 Loss:  0.5948584 accurracy:  0.92137635\n",
      "Epoch:  1550 Loss:  0.5948553 accurracy:  0.92140555\n",
      "Epoch:  1551 Loss:  0.594853 accurracy:  0.9214347\n",
      "Epoch:  1552 Loss:  0.5948481 accurracy:  0.92146385\n",
      "Epoch:  1553 Loss:  0.5948447 accurracy:  0.92149293\n",
      "Epoch:  1554 Loss:  0.5948427 accurracy:  0.92152196\n",
      "Epoch:  1555 Loss:  0.5948377 accurracy:  0.921551\n",
      "Epoch:  1556 Loss:  0.5948344 accurracy:  0.92157996\n",
      "Epoch:  1557 Loss:  0.5948315 accurracy:  0.9216089\n",
      "Epoch:  1558 Loss:  0.594827 accurracy:  0.9216378\n",
      "Epoch:  1559 Loss:  0.5948238 accurracy:  0.9216667\n",
      "Epoch:  1560 Loss:  0.59482056 accurracy:  0.9216955\n",
      "Epoch:  1561 Loss:  0.59481657 accurracy:  0.92172426\n",
      "Epoch:  1562 Loss:  0.5948129 accurracy:  0.92175305\n",
      "Epoch:  1563 Loss:  0.5948097 accurracy:  0.9217818\n",
      "Epoch:  1564 Loss:  0.59480566 accurracy:  0.92181045\n",
      "Epoch:  1565 Loss:  0.5948023 accurracy:  0.92183906\n",
      "Epoch:  1566 Loss:  0.59479827 accurracy:  0.92186767\n",
      "Epoch:  1567 Loss:  0.5947956 accurracy:  0.9218963\n",
      "Epoch:  1568 Loss:  0.5947913 accurracy:  0.92192477\n",
      "Epoch:  1569 Loss:  0.594787 accurracy:  0.9219533\n",
      "Epoch:  1570 Loss:  0.5947848 accurracy:  0.92198175\n",
      "Epoch:  1571 Loss:  0.59477997 accurracy:  0.9220102\n",
      "Epoch:  1572 Loss:  0.594776 accurracy:  0.92203856\n",
      "Epoch:  1573 Loss:  0.5947739 accurracy:  0.9220669\n",
      "Epoch:  1574 Loss:  0.5947694 accurracy:  0.92209524\n",
      "Epoch:  1575 Loss:  0.5947648 accurracy:  0.9221235\n",
      "Epoch:  1576 Loss:  0.59476256 accurracy:  0.92215174\n",
      "Epoch:  1577 Loss:  0.59475887 accurracy:  0.92218\n",
      "Epoch:  1578 Loss:  0.5947536 accurracy:  0.92220813\n",
      "Epoch:  1579 Loss:  0.5947513 accurracy:  0.92223626\n",
      "Epoch:  1580 Loss:  0.59474784 accurracy:  0.9222644\n",
      "Epoch:  1581 Loss:  0.59474283 accurracy:  0.9222925\n",
      "Epoch:  1582 Loss:  0.5947394 accurracy:  0.9223205\n",
      "Epoch:  1583 Loss:  0.5947372 accurracy:  0.9223485\n",
      "Epoch:  1584 Loss:  0.5947313 accurracy:  0.92237645\n",
      "Epoch:  1585 Loss:  0.5947284 accurracy:  0.92240435\n",
      "Epoch:  1586 Loss:  0.59472597 accurracy:  0.92243224\n",
      "Epoch:  1587 Loss:  0.59472054 accurracy:  0.92246014\n",
      "Epoch:  1588 Loss:  0.59471667 accurracy:  0.9224879\n",
      "Epoch:  1589 Loss:  0.59471434 accurracy:  0.92251575\n",
      "Epoch:  1590 Loss:  0.5947095 accurracy:  0.92254347\n",
      "Epoch:  1591 Loss:  0.59470475 accurracy:  0.9225712\n",
      "Epoch:  1592 Loss:  0.59470326 accurracy:  0.9225989\n",
      "Epoch:  1593 Loss:  0.59469825 accurracy:  0.9226265\n",
      "Epoch:  1594 Loss:  0.5946935 accurracy:  0.92265415\n",
      "Epoch:  1595 Loss:  0.5946915 accurracy:  0.9226817\n",
      "Epoch:  1596 Loss:  0.59468704 accurracy:  0.9227092\n",
      "Epoch:  1597 Loss:  0.59468204 accurracy:  0.92273676\n",
      "Epoch:  1598 Loss:  0.59468 accurracy:  0.92276424\n",
      "Epoch:  1599 Loss:  0.594676 accurracy:  0.92279166\n",
      "Epoch:  1600 Loss:  0.5946703 accurracy:  0.9228191\n",
      "Epoch:  1601 Loss:  0.59466827 accurracy:  0.92284644\n",
      "Epoch:  1602 Loss:  0.5946642 accurracy:  0.9228738\n",
      "Epoch:  1603 Loss:  0.59465957 accurracy:  0.9229011\n",
      "Epoch:  1604 Loss:  0.5946562 accurracy:  0.92292833\n",
      "Epoch:  1605 Loss:  0.5946524 accurracy:  0.9229556\n",
      "Epoch:  1606 Loss:  0.59464806 accurracy:  0.9229828\n",
      "Epoch:  1607 Loss:  0.59464467 accurracy:  0.92300993\n",
      "Epoch:  1608 Loss:  0.59464085 accurracy:  0.9230371\n",
      "Epoch:  1609 Loss:  0.59463656 accurracy:  0.9230642\n",
      "Epoch:  1610 Loss:  0.59463316 accurracy:  0.92309123\n",
      "Epoch:  1611 Loss:  0.59462875 accurracy:  0.9231183\n",
      "Epoch:  1612 Loss:  0.5946253 accurracy:  0.9231453\n",
      "Epoch:  1613 Loss:  0.5946215 accurracy:  0.92317224\n",
      "Epoch:  1614 Loss:  0.5946169 accurracy:  0.9231992\n",
      "Epoch:  1615 Loss:  0.5946137 accurracy:  0.92322606\n",
      "Epoch:  1616 Loss:  0.5946101 accurracy:  0.92325294\n",
      "Epoch:  1617 Loss:  0.59460473 accurracy:  0.92327976\n",
      "Epoch:  1618 Loss:  0.5946019 accurracy:  0.9233066\n",
      "Epoch:  1619 Loss:  0.5945981 accurracy:  0.92333335\n",
      "Epoch:  1620 Loss:  0.5945934 accurracy:  0.92336005\n",
      "Epoch:  1621 Loss:  0.59458995 accurracy:  0.92338675\n",
      "Epoch:  1622 Loss:  0.5945862 accurracy:  0.92341346\n",
      "Epoch:  1623 Loss:  0.5945816 accurracy:  0.92344004\n",
      "Epoch:  1624 Loss:  0.5945779 accurracy:  0.9234667\n",
      "Epoch:  1625 Loss:  0.59457815 accurracy:  0.9234932\n",
      "Epoch:  1626 Loss:  0.5945667 accurracy:  0.9235198\n",
      "Epoch:  1627 Loss:  0.594565 accurracy:  0.92354625\n",
      "Epoch:  1628 Loss:  0.5945656 accurracy:  0.9235727\n",
      "Epoch:  1629 Loss:  0.59455645 accurracy:  0.9235992\n",
      "Epoch:  1630 Loss:  0.59455216 accurracy:  0.9236256\n",
      "Epoch:  1631 Loss:  0.5945532 accurracy:  0.92365193\n",
      "Epoch:  1632 Loss:  0.5945455 accurracy:  0.9236783\n",
      "Epoch:  1633 Loss:  0.5945395 accurracy:  0.9237046\n",
      "Epoch:  1634 Loss:  0.5945409 accurracy:  0.9237309\n",
      "Epoch:  1635 Loss:  0.5945342 accurracy:  0.92375714\n",
      "Epoch:  1636 Loss:  0.5945273 accurracy:  0.92378336\n",
      "Epoch:  1637 Loss:  0.59452784 accurracy:  0.9238095\n",
      "Epoch:  1638 Loss:  0.5945227 accurracy:  0.9238357\n",
      "Epoch:  1639 Loss:  0.59451586 accurracy:  0.9238618\n",
      "Epoch:  1640 Loss:  0.5945155 accurracy:  0.92388785\n",
      "Epoch:  1641 Loss:  0.59451103 accurracy:  0.92391396\n",
      "Epoch:  1642 Loss:  0.59450376 accurracy:  0.92393994\n",
      "Epoch:  1643 Loss:  0.5945027 accurracy:  0.92396593\n",
      "Epoch:  1644 Loss:  0.59449893 accurracy:  0.9239919\n",
      "Epoch:  1645 Loss:  0.5944922 accurracy:  0.92401785\n",
      "Epoch:  1646 Loss:  0.59449035 accurracy:  0.9240437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1647 Loss:  0.59448695 accurracy:  0.9240696\n",
      "Epoch:  1648 Loss:  0.5944803 accurracy:  0.9240954\n",
      "Epoch:  1649 Loss:  0.5944779 accurracy:  0.9241212\n",
      "Epoch:  1650 Loss:  0.5944748 accurracy:  0.924147\n",
      "Epoch:  1651 Loss:  0.5944687 accurracy:  0.9241727\n",
      "Epoch:  1652 Loss:  0.5944649 accurracy:  0.92419845\n",
      "Epoch:  1653 Loss:  0.5944624 accurracy:  0.9242241\n",
      "Epoch:  1654 Loss:  0.5944569 accurracy:  0.92424977\n",
      "Epoch:  1655 Loss:  0.5944527 accurracy:  0.92427534\n",
      "Epoch:  1656 Loss:  0.5944501 accurracy:  0.92430097\n",
      "Epoch:  1657 Loss:  0.5944447 accurracy:  0.9243265\n",
      "Epoch:  1658 Loss:  0.59444064 accurracy:  0.924352\n",
      "Epoch:  1659 Loss:  0.5944374 accurracy:  0.9243775\n",
      "Epoch:  1660 Loss:  0.59443283 accurracy:  0.92440295\n",
      "Epoch:  1661 Loss:  0.59442806 accurracy:  0.9244284\n",
      "Epoch:  1662 Loss:  0.59442466 accurracy:  0.9244538\n",
      "Epoch:  1663 Loss:  0.59442085 accurracy:  0.9244792\n",
      "Epoch:  1664 Loss:  0.594416 accurracy:  0.9245045\n",
      "Epoch:  1665 Loss:  0.59441197 accurracy:  0.9245298\n",
      "Epoch:  1666 Loss:  0.59440863 accurracy:  0.92455506\n",
      "Epoch:  1667 Loss:  0.5944038 accurracy:  0.92458034\n",
      "Epoch:  1668 Loss:  0.5943991 accurracy:  0.92460555\n",
      "Epoch:  1669 Loss:  0.5943965 accurracy:  0.92463076\n",
      "Epoch:  1670 Loss:  0.59439117 accurracy:  0.9246559\n",
      "Epoch:  1671 Loss:  0.5943871 accurracy:  0.924681\n",
      "Epoch:  1672 Loss:  0.5943836 accurracy:  0.9247061\n",
      "Epoch:  1673 Loss:  0.5943787 accurracy:  0.9247312\n",
      "Epoch:  1674 Loss:  0.5943746 accurracy:  0.9247562\n",
      "Epoch:  1675 Loss:  0.59437126 accurracy:  0.9247812\n",
      "Epoch:  1676 Loss:  0.5943664 accurracy:  0.9248062\n",
      "Epoch:  1677 Loss:  0.5943623 accurracy:  0.92483115\n",
      "Epoch:  1678 Loss:  0.59435856 accurracy:  0.92485607\n",
      "Epoch:  1679 Loss:  0.59435385 accurracy:  0.924881\n",
      "Epoch:  1680 Loss:  0.5943499 accurracy:  0.92490584\n",
      "Epoch:  1681 Loss:  0.5943459 accurracy:  0.92493063\n",
      "Epoch:  1682 Loss:  0.59434164 accurracy:  0.9249554\n",
      "Epoch:  1683 Loss:  0.5943372 accurracy:  0.9249802\n",
      "Epoch:  1684 Loss:  0.5943334 accurracy:  0.92500496\n",
      "Epoch:  1685 Loss:  0.59432954 accurracy:  0.92502964\n",
      "Epoch:  1686 Loss:  0.59432465 accurracy:  0.9250543\n",
      "Epoch:  1687 Loss:  0.59432065 accurracy:  0.925079\n",
      "Epoch:  1688 Loss:  0.5943165 accurracy:  0.9251036\n",
      "Epoch:  1689 Loss:  0.5943125 accurracy:  0.9251282\n",
      "Epoch:  1690 Loss:  0.5943077 accurracy:  0.9251528\n",
      "Epoch:  1691 Loss:  0.59430385 accurracy:  0.9251773\n",
      "Epoch:  1692 Loss:  0.5943 accurracy:  0.92520183\n",
      "Epoch:  1693 Loss:  0.5942952 accurracy:  0.9252263\n",
      "Epoch:  1694 Loss:  0.5942911 accurracy:  0.9252507\n",
      "Epoch:  1695 Loss:  0.59428734 accurracy:  0.92527515\n",
      "Epoch:  1696 Loss:  0.5942825 accurracy:  0.9252995\n",
      "Epoch:  1697 Loss:  0.5942786 accurracy:  0.9253239\n",
      "Epoch:  1698 Loss:  0.59427464 accurracy:  0.9253482\n",
      "Epoch:  1699 Loss:  0.59427005 accurracy:  0.92537254\n",
      "Epoch:  1700 Loss:  0.5942657 accurracy:  0.9253968\n",
      "Epoch:  1701 Loss:  0.5942618 accurracy:  0.92542106\n",
      "Epoch:  1702 Loss:  0.5942574 accurracy:  0.9254453\n",
      "Epoch:  1703 Loss:  0.594253 accurracy:  0.92546946\n",
      "Epoch:  1704 Loss:  0.59424907 accurracy:  0.92549366\n",
      "Epoch:  1705 Loss:  0.5942446 accurracy:  0.9255178\n",
      "Epoch:  1706 Loss:  0.5942403 accurracy:  0.9255419\n",
      "Epoch:  1707 Loss:  0.5942367 accurracy:  0.92556596\n",
      "Epoch:  1708 Loss:  0.59423167 accurracy:  0.92559004\n",
      "Epoch:  1709 Loss:  0.5942278 accurracy:  0.92561406\n",
      "Epoch:  1710 Loss:  0.59422386 accurracy:  0.925638\n",
      "Epoch:  1711 Loss:  0.594219 accurracy:  0.925662\n",
      "Epoch:  1712 Loss:  0.59421486 accurracy:  0.92568594\n",
      "Epoch:  1713 Loss:  0.5942108 accurracy:  0.92570984\n",
      "Epoch:  1714 Loss:  0.5942065 accurracy:  0.92573375\n",
      "Epoch:  1715 Loss:  0.594202 accurracy:  0.9257576\n",
      "Epoch:  1716 Loss:  0.59419817 accurracy:  0.9257814\n",
      "Epoch:  1717 Loss:  0.5941941 accurracy:  0.9258052\n",
      "Epoch:  1718 Loss:  0.5941888 accurracy:  0.925829\n",
      "Epoch:  1719 Loss:  0.59418553 accurracy:  0.9258527\n",
      "Epoch:  1720 Loss:  0.5941812 accurracy:  0.92587644\n",
      "Epoch:  1721 Loss:  0.59417593 accurracy:  0.9259001\n",
      "Epoch:  1722 Loss:  0.59417236 accurracy:  0.92592376\n",
      "Epoch:  1723 Loss:  0.5941721 accurracy:  0.9259474\n",
      "Epoch:  1724 Loss:  0.5941605 accurracy:  0.92597103\n",
      "Epoch:  1725 Loss:  0.59415805 accurracy:  0.9259946\n",
      "Epoch:  1726 Loss:  0.59415925 accurracy:  0.9260181\n",
      "Epoch:  1727 Loss:  0.5941493 accurracy:  0.92604166\n",
      "Epoch:  1728 Loss:  0.5941443 accurracy:  0.92606515\n",
      "Epoch:  1729 Loss:  0.59414554 accurracy:  0.92608863\n",
      "Epoch:  1730 Loss:  0.59413755 accurracy:  0.92611206\n",
      "Epoch:  1731 Loss:  0.5941311 accurracy:  0.9261355\n",
      "Epoch:  1732 Loss:  0.5941317 accurracy:  0.9261589\n",
      "Epoch:  1733 Loss:  0.59412587 accurracy:  0.9261822\n",
      "Epoch:  1734 Loss:  0.59411806 accurracy:  0.9262056\n",
      "Epoch:  1735 Loss:  0.59411776 accurracy:  0.9262289\n",
      "Epoch:  1736 Loss:  0.59411395 accurracy:  0.9262522\n",
      "Epoch:  1737 Loss:  0.59410506 accurracy:  0.92627543\n",
      "Epoch:  1738 Loss:  0.59410393 accurracy:  0.9262986\n",
      "Epoch:  1739 Loss:  0.59410155 accurracy:  0.92632186\n",
      "Epoch:  1740 Loss:  0.59409314 accurracy:  0.926345\n",
      "Epoch:  1741 Loss:  0.5940903 accurracy:  0.9263682\n",
      "Epoch:  1742 Loss:  0.594088 accurracy:  0.9263913\n",
      "Epoch:  1743 Loss:  0.59408134 accurracy:  0.9264144\n",
      "Epoch:  1744 Loss:  0.5940764 accurracy:  0.92643744\n",
      "Epoch:  1745 Loss:  0.5940748 accurracy:  0.9264605\n",
      "Epoch:  1746 Loss:  0.5940691 accurracy:  0.9264835\n",
      "Epoch:  1747 Loss:  0.5940636 accurracy:  0.92650646\n",
      "Epoch:  1748 Loss:  0.59406114 accurracy:  0.92652947\n",
      "Epoch:  1749 Loss:  0.59405696 accurracy:  0.92655236\n",
      "Epoch:  1750 Loss:  0.5940505 accurracy:  0.9265753\n",
      "Epoch:  1751 Loss:  0.5940477 accurracy:  0.9265982\n",
      "Epoch:  1752 Loss:  0.5940439 accurracy:  0.926621\n",
      "Epoch:  1753 Loss:  0.5940383 accurracy:  0.92664385\n",
      "Epoch:  1754 Loss:  0.5940341 accurracy:  0.9266667\n",
      "Epoch:  1755 Loss:  0.594031 accurracy:  0.92668945\n",
      "Epoch:  1756 Loss:  0.59402543 accurracy:  0.9267122\n",
      "Epoch:  1757 Loss:  0.5940211 accurracy:  0.9267349\n",
      "Epoch:  1758 Loss:  0.5940177 accurracy:  0.92675763\n",
      "Epoch:  1759 Loss:  0.594013 accurracy:  0.9267803\n",
      "Epoch:  1760 Loss:  0.59400815 accurracy:  0.92680293\n",
      "Epoch:  1761 Loss:  0.59400433 accurracy:  0.9268256\n",
      "Epoch:  1762 Loss:  0.59400004 accurracy:  0.9268482\n",
      "Epoch:  1763 Loss:  0.5939951 accurracy:  0.92687076\n",
      "Epoch:  1764 Loss:  0.59399134 accurracy:  0.9268933\n",
      "Epoch:  1765 Loss:  0.5939871 accurracy:  0.9269158\n",
      "Epoch:  1766 Loss:  0.5939818 accurracy:  0.9269383\n",
      "Epoch:  1767 Loss:  0.59397817 accurracy:  0.92696077\n",
      "Epoch:  1768 Loss:  0.5939743 accurracy:  0.92698324\n",
      "Epoch:  1769 Loss:  0.5939688 accurracy:  0.92700565\n",
      "Epoch:  1770 Loss:  0.59396476 accurracy:  0.92702806\n",
      "Epoch:  1771 Loss:  0.5939612 accurracy:  0.9270504\n",
      "Epoch:  1772 Loss:  0.593956 accurracy:  0.92707276\n",
      "Epoch:  1773 Loss:  0.5939518 accurracy:  0.92709506\n",
      "Epoch:  1774 Loss:  0.5939478 accurracy:  0.92711735\n",
      "Epoch:  1775 Loss:  0.5939432 accurracy:  0.92713964\n",
      "Epoch:  1776 Loss:  0.5939387 accurracy:  0.9271619\n",
      "Epoch:  1777 Loss:  0.59393466 accurracy:  0.9271841\n",
      "Epoch:  1778 Loss:  0.5939302 accurracy:  0.9272063\n",
      "Epoch:  1779 Loss:  0.5939257 accurracy:  0.92722845\n",
      "Epoch:  1780 Loss:  0.5939216 accurracy:  0.9272506\n",
      "Epoch:  1781 Loss:  0.59391725 accurracy:  0.92727274\n",
      "Epoch:  1782 Loss:  0.59391266 accurracy:  0.92729485\n",
      "Epoch:  1783 Loss:  0.59390855 accurracy:  0.9273169\n",
      "Epoch:  1784 Loss:  0.5939043 accurracy:  0.92733896\n",
      "Epoch:  1785 Loss:  0.5938994 accurracy:  0.92736095\n",
      "Epoch:  1786 Loss:  0.5938954 accurracy:  0.92738295\n",
      "Epoch:  1787 Loss:  0.593891 accurracy:  0.92740494\n",
      "Epoch:  1788 Loss:  0.5938864 accurracy:  0.9274269\n",
      "Epoch:  1789 Loss:  0.5938824 accurracy:  0.9274488\n",
      "Epoch:  1790 Loss:  0.5938781 accurracy:  0.9274707\n",
      "Epoch:  1791 Loss:  0.5938731 accurracy:  0.92749256\n",
      "Epoch:  1792 Loss:  0.5938694 accurracy:  0.92751443\n",
      "Epoch:  1793 Loss:  0.5938646 accurracy:  0.92753625\n",
      "Epoch:  1794 Loss:  0.5938601 accurracy:  0.927558\n",
      "Epoch:  1795 Loss:  0.5938565 accurracy:  0.9275798\n",
      "Epoch:  1796 Loss:  0.59385175 accurracy:  0.9276016\n",
      "Epoch:  1797 Loss:  0.59384674 accurracy:  0.9276233\n",
      "Epoch:  1798 Loss:  0.5938431 accurracy:  0.92764497\n",
      "Epoch:  1799 Loss:  0.59383875 accurracy:  0.92766666\n",
      "Epoch:  1800 Loss:  0.5938341 accurracy:  0.9276883\n",
      "Epoch:  1801 Loss:  0.59382945 accurracy:  0.92770994\n",
      "Epoch:  1802 Loss:  0.59382594 accurracy:  0.9277316\n",
      "Epoch:  1803 Loss:  0.5938213 accurracy:  0.92775315\n",
      "Epoch:  1804 Loss:  0.5938162 accurracy:  0.9277747\n",
      "Epoch:  1805 Loss:  0.5938124 accurracy:  0.92779624\n",
      "Epoch:  1806 Loss:  0.5938086 accurracy:  0.92781776\n",
      "Epoch:  1807 Loss:  0.5938027 accurracy:  0.9278392\n",
      "Epoch:  1808 Loss:  0.59379894 accurracy:  0.9278607\n",
      "Epoch:  1809 Loss:  0.593796 accurracy:  0.92788213\n",
      "Epoch:  1810 Loss:  0.5937902 accurracy:  0.92790353\n",
      "Epoch:  1811 Loss:  0.5937853 accurracy:  0.92792493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1812 Loss:  0.59378266 accurracy:  0.9279463\n",
      "Epoch:  1813 Loss:  0.59377706 accurracy:  0.92796767\n",
      "Epoch:  1814 Loss:  0.5937749 accurracy:  0.927989\n",
      "Epoch:  1815 Loss:  0.5937677 accurracy:  0.9280103\n",
      "Epoch:  1816 Loss:  0.5937628 accurracy:  0.92803156\n",
      "Epoch:  1817 Loss:  0.59376144 accurracy:  0.9280528\n",
      "Epoch:  1818 Loss:  0.5937555 accurracy:  0.92807406\n",
      "Epoch:  1819 Loss:  0.5937492 accurracy:  0.9280952\n",
      "Epoch:  1820 Loss:  0.59374756 accurracy:  0.92811644\n",
      "Epoch:  1821 Loss:  0.5937429 accurracy:  0.9281376\n",
      "Epoch:  1822 Loss:  0.5937363 accurracy:  0.9281587\n",
      "Epoch:  1823 Loss:  0.5937338 accurracy:  0.9281798\n",
      "Epoch:  1824 Loss:  0.5937303 accurracy:  0.9282009\n",
      "Epoch:  1825 Loss:  0.59372395 accurracy:  0.928222\n",
      "Epoch:  1826 Loss:  0.5937197 accurracy:  0.92824304\n",
      "Epoch:  1827 Loss:  0.5937167 accurracy:  0.928264\n",
      "Epoch:  1828 Loss:  0.5937112 accurracy:  0.92828506\n",
      "Epoch:  1829 Loss:  0.59370667 accurracy:  0.928306\n",
      "Epoch:  1830 Loss:  0.5937032 accurracy:  0.92832696\n",
      "Epoch:  1831 Loss:  0.59369856 accurracy:  0.9283479\n",
      "Epoch:  1832 Loss:  0.5936934 accurracy:  0.9283688\n",
      "Epoch:  1833 Loss:  0.5936901 accurracy:  0.92838967\n",
      "Epoch:  1834 Loss:  0.5936857 accurracy:  0.92841053\n",
      "Epoch:  1835 Loss:  0.5936802 accurracy:  0.9284314\n",
      "Epoch:  1836 Loss:  0.59367645 accurracy:  0.9284522\n",
      "Epoch:  1837 Loss:  0.59367245 accurracy:  0.928473\n",
      "Epoch:  1838 Loss:  0.59366727 accurracy:  0.92849374\n",
      "Epoch:  1839 Loss:  0.593663 accurracy:  0.9285145\n",
      "Epoch:  1840 Loss:  0.5936593 accurracy:  0.9285352\n",
      "Epoch:  1841 Loss:  0.59365475 accurracy:  0.9285559\n",
      "Epoch:  1842 Loss:  0.59364945 accurracy:  0.9285766\n",
      "Epoch:  1843 Loss:  0.59364635 accurracy:  0.9285973\n",
      "Epoch:  1844 Loss:  0.5936416 accurracy:  0.9286179\n",
      "Epoch:  1845 Loss:  0.59363633 accurracy:  0.9286385\n",
      "Epoch:  1846 Loss:  0.5936323 accurracy:  0.9286591\n",
      "Epoch:  1847 Loss:  0.5936287 accurracy:  0.92867965\n",
      "Epoch:  1848 Loss:  0.5936234 accurracy:  0.9287002\n",
      "Epoch:  1849 Loss:  0.59361905 accurracy:  0.9287207\n",
      "Epoch:  1850 Loss:  0.5936157 accurracy:  0.9287412\n",
      "Epoch:  1851 Loss:  0.593611 accurracy:  0.9287617\n",
      "Epoch:  1852 Loss:  0.59360564 accurracy:  0.92878217\n",
      "Epoch:  1853 Loss:  0.59360176 accurracy:  0.9288026\n",
      "Epoch:  1854 Loss:  0.59359795 accurracy:  0.928823\n",
      "Epoch:  1855 Loss:  0.5935936 accurracy:  0.9288434\n",
      "Epoch:  1856 Loss:  0.5935881 accurracy:  0.92886376\n",
      "Epoch:  1857 Loss:  0.5935847 accurracy:  0.9288841\n",
      "Epoch:  1858 Loss:  0.5935806 accurracy:  0.9289044\n",
      "Epoch:  1859 Loss:  0.5935752 accurracy:  0.92892474\n",
      "Epoch:  1860 Loss:  0.59357077 accurracy:  0.928945\n",
      "Epoch:  1861 Loss:  0.5935677 accurracy:  0.9289653\n",
      "Epoch:  1862 Loss:  0.5935624 accurracy:  0.92898554\n",
      "Epoch:  1863 Loss:  0.5935576 accurracy:  0.92900574\n",
      "Epoch:  1864 Loss:  0.59355444 accurracy:  0.9290259\n",
      "Epoch:  1865 Loss:  0.5935496 accurracy:  0.9290461\n",
      "Epoch:  1866 Loss:  0.59354466 accurracy:  0.92906624\n",
      "Epoch:  1867 Loss:  0.59354025 accurracy:  0.9290864\n",
      "Epoch:  1868 Loss:  0.5935367 accurracy:  0.9291065\n",
      "Epoch:  1869 Loss:  0.5935315 accurracy:  0.92912656\n",
      "Epoch:  1870 Loss:  0.5935267 accurracy:  0.92914665\n",
      "Epoch:  1871 Loss:  0.5935238 accurracy:  0.9291667\n",
      "Epoch:  1872 Loss:  0.5935187 accurracy:  0.9291867\n",
      "Epoch:  1873 Loss:  0.5935134 accurracy:  0.92920667\n",
      "Epoch:  1874 Loss:  0.59351027 accurracy:  0.92922664\n",
      "Epoch:  1875 Loss:  0.59350604 accurracy:  0.9292466\n",
      "Epoch:  1876 Loss:  0.5935007 accurracy:  0.9292666\n",
      "Epoch:  1877 Loss:  0.59349674 accurracy:  0.9292865\n",
      "Epoch:  1878 Loss:  0.5934924 accurracy:  0.9293064\n",
      "Epoch:  1879 Loss:  0.593488 accurracy:  0.92932624\n",
      "Epoch:  1880 Loss:  0.59348357 accurracy:  0.9293461\n",
      "Epoch:  1881 Loss:  0.5934792 accurracy:  0.92936593\n",
      "Epoch:  1882 Loss:  0.59347457 accurracy:  0.9293857\n",
      "Epoch:  1883 Loss:  0.5934709 accurracy:  0.9294055\n",
      "Epoch:  1884 Loss:  0.59346634 accurracy:  0.9294253\n",
      "Epoch:  1885 Loss:  0.59346163 accurracy:  0.929445\n",
      "Epoch:  1886 Loss:  0.59345746 accurracy:  0.92946476\n",
      "Epoch:  1887 Loss:  0.5934533 accurracy:  0.9294845\n",
      "Epoch:  1888 Loss:  0.5934487 accurracy:  0.92950416\n",
      "Epoch:  1889 Loss:  0.59344417 accurracy:  0.9295238\n",
      "Epoch:  1890 Loss:  0.5934401 accurracy:  0.92954344\n",
      "Epoch:  1891 Loss:  0.59343547 accurracy:  0.92956305\n",
      "Epoch:  1892 Loss:  0.5934311 accurracy:  0.92958266\n",
      "Epoch:  1893 Loss:  0.5934273 accurracy:  0.92960227\n",
      "Epoch:  1894 Loss:  0.5934225 accurracy:  0.9296218\n",
      "Epoch:  1895 Loss:  0.5934179 accurracy:  0.92964137\n",
      "Epoch:  1896 Loss:  0.59341407 accurracy:  0.92966086\n",
      "Epoch:  1897 Loss:  0.5934098 accurracy:  0.92968035\n",
      "Epoch:  1898 Loss:  0.59340703 accurracy:  0.92969984\n",
      "Epoch:  1899 Loss:  0.5933993 accurracy:  0.92971927\n",
      "Epoch:  1900 Loss:  0.59339523 accurracy:  0.92973876\n",
      "Epoch:  1901 Loss:  0.5933936 accurracy:  0.92975813\n",
      "Epoch:  1902 Loss:  0.5933878 accurracy:  0.92977756\n",
      "Epoch:  1903 Loss:  0.59338164 accurracy:  0.92979693\n",
      "Epoch:  1904 Loss:  0.59337974 accurracy:  0.92981625\n",
      "Epoch:  1905 Loss:  0.59337544 accurracy:  0.9298356\n",
      "Epoch:  1906 Loss:  0.5933691 accurracy:  0.9298549\n",
      "Epoch:  1907 Loss:  0.59336525 accurracy:  0.92987424\n",
      "Epoch:  1908 Loss:  0.5933629 accurracy:  0.9298935\n",
      "Epoch:  1909 Loss:  0.5933572 accurracy:  0.92991275\n",
      "Epoch:  1910 Loss:  0.5933515 accurracy:  0.929932\n",
      "Epoch:  1911 Loss:  0.59334886 accurracy:  0.9299512\n",
      "Epoch:  1912 Loss:  0.5933448 accurracy:  0.9299704\n",
      "Epoch:  1913 Loss:  0.5933392 accurracy:  0.9299896\n",
      "Epoch:  1914 Loss:  0.593335 accurracy:  0.9300087\n",
      "Epoch:  1915 Loss:  0.5933316 accurracy:  0.93002784\n",
      "Epoch:  1916 Loss:  0.5933265 accurracy:  0.930047\n",
      "Epoch:  1917 Loss:  0.59332174 accurracy:  0.93006605\n",
      "Epoch:  1918 Loss:  0.5933186 accurracy:  0.9300851\n",
      "Epoch:  1919 Loss:  0.5933141 accurracy:  0.9301042\n",
      "Epoch:  1920 Loss:  0.5933083 accurracy:  0.9301232\n",
      "Epoch:  1921 Loss:  0.59330493 accurracy:  0.9301422\n",
      "Epoch:  1922 Loss:  0.59330153 accurracy:  0.9301612\n",
      "Epoch:  1923 Loss:  0.5932959 accurracy:  0.9301802\n",
      "Epoch:  1924 Loss:  0.5932914 accurracy:  0.93019915\n",
      "Epoch:  1925 Loss:  0.5932884 accurracy:  0.93021804\n",
      "Epoch:  1926 Loss:  0.5932835 accurracy:  0.930237\n",
      "Epoch:  1927 Loss:  0.59327817 accurracy:  0.9302559\n",
      "Epoch:  1928 Loss:  0.5932747 accurracy:  0.9302747\n",
      "Epoch:  1929 Loss:  0.5932709 accurracy:  0.9302936\n",
      "Epoch:  1930 Loss:  0.5932657 accurracy:  0.93031245\n",
      "Epoch:  1931 Loss:  0.5932612 accurracy:  0.9303313\n",
      "Epoch:  1932 Loss:  0.5932579 accurracy:  0.93035007\n",
      "Epoch:  1933 Loss:  0.5932533 accurracy:  0.93036884\n",
      "Epoch:  1934 Loss:  0.5932482 accurracy:  0.9303876\n",
      "Epoch:  1935 Loss:  0.5932443 accurracy:  0.93040633\n",
      "Epoch:  1936 Loss:  0.5932407 accurracy:  0.93042505\n",
      "Epoch:  1937 Loss:  0.59323525 accurracy:  0.93044376\n",
      "Epoch:  1938 Loss:  0.59323084 accurracy:  0.9304624\n",
      "Epoch:  1939 Loss:  0.5932275 accurracy:  0.9304811\n",
      "Epoch:  1940 Loss:  0.5932218 accurracy:  0.93049973\n",
      "Epoch:  1941 Loss:  0.5932173 accurracy:  0.9305184\n",
      "Epoch:  1942 Loss:  0.59321415 accurracy:  0.930537\n",
      "Epoch:  1943 Loss:  0.5932091 accurracy:  0.9305556\n",
      "Epoch:  1944 Loss:  0.59320444 accurracy:  0.9305741\n",
      "Epoch:  1945 Loss:  0.5932009 accurracy:  0.93059266\n",
      "Epoch:  1946 Loss:  0.59319663 accurracy:  0.9306112\n",
      "Epoch:  1947 Loss:  0.59319156 accurracy:  0.93062973\n",
      "Epoch:  1948 Loss:  0.5931877 accurracy:  0.9306482\n",
      "Epoch:  1949 Loss:  0.5931834 accurracy:  0.9306667\n",
      "Epoch:  1950 Loss:  0.59317887 accurracy:  0.9306851\n",
      "Epoch:  1951 Loss:  0.59317476 accurracy:  0.9307036\n",
      "Epoch:  1952 Loss:  0.5931707 accurracy:  0.93072194\n",
      "Epoch:  1953 Loss:  0.5931661 accurracy:  0.93074036\n",
      "Epoch:  1954 Loss:  0.5931615 accurracy:  0.9307587\n",
      "Epoch:  1955 Loss:  0.59315753 accurracy:  0.9307771\n",
      "Epoch:  1956 Loss:  0.59315324 accurracy:  0.93079543\n",
      "Epoch:  1957 Loss:  0.5931485 accurracy:  0.9308137\n",
      "Epoch:  1958 Loss:  0.5931446 accurracy:  0.930832\n",
      "Epoch:  1959 Loss:  0.59314007 accurracy:  0.9308503\n",
      "Epoch:  1960 Loss:  0.5931358 accurracy:  0.9308686\n",
      "Epoch:  1961 Loss:  0.5931318 accurracy:  0.93088686\n",
      "Epoch:  1962 Loss:  0.5931273 accurracy:  0.9309051\n",
      "Epoch:  1963 Loss:  0.593123 accurracy:  0.9309233\n",
      "Epoch:  1964 Loss:  0.5931189 accurracy:  0.93094146\n",
      "Epoch:  1965 Loss:  0.5931143 accurracy:  0.93095964\n",
      "Epoch:  1966 Loss:  0.59310997 accurracy:  0.9309778\n",
      "Epoch:  1967 Loss:  0.5931062 accurracy:  0.93099594\n",
      "Epoch:  1968 Loss:  0.5931015 accurracy:  0.93101406\n",
      "Epoch:  1969 Loss:  0.59309685 accurracy:  0.9310321\n",
      "Epoch:  1970 Loss:  0.59309345 accurracy:  0.93105024\n",
      "Epoch:  1971 Loss:  0.59308887 accurracy:  0.9310683\n",
      "Epoch:  1972 Loss:  0.5930841 accurracy:  0.93108636\n",
      "Epoch:  1973 Loss:  0.5930799 accurracy:  0.93110436\n",
      "Epoch:  1974 Loss:  0.59307635 accurracy:  0.93112236\n",
      "Epoch:  1975 Loss:  0.5930736 accurracy:  0.93114036\n",
      "Epoch:  1976 Loss:  0.5930662 accurracy:  0.9311583\n",
      "Epoch:  1977 Loss:  0.59306186 accurracy:  0.93117625\n",
      "Epoch:  1978 Loss:  0.5930602 accurracy:  0.9311942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1979 Loss:  0.59305483 accurracy:  0.9312121\n",
      "Epoch:  1980 Loss:  0.59304875 accurracy:  0.93123\n",
      "Epoch:  1981 Loss:  0.5930469 accurracy:  0.9312479\n",
      "Epoch:  1982 Loss:  0.5930426 accurracy:  0.9312658\n",
      "Epoch:  1983 Loss:  0.5930364 accurracy:  0.9312836\n",
      "Epoch:  1984 Loss:  0.5930331 accurracy:  0.9313014\n",
      "Epoch:  1985 Loss:  0.59303033 accurracy:  0.93131924\n",
      "Epoch:  1986 Loss:  0.5930242 accurracy:  0.931337\n",
      "Epoch:  1987 Loss:  0.5930197 accurracy:  0.9313548\n",
      "Epoch:  1988 Loss:  0.5930173 accurracy:  0.9313725\n",
      "Epoch:  1989 Loss:  0.593012 accurracy:  0.9313903\n",
      "Epoch:  1990 Loss:  0.5930067 accurracy:  0.931408\n",
      "Epoch:  1991 Loss:  0.59300363 accurracy:  0.9314257\n",
      "Epoch:  1992 Loss:  0.5929999 accurracy:  0.9314434\n",
      "Epoch:  1993 Loss:  0.59299415 accurracy:  0.93146104\n",
      "Epoch:  1994 Loss:  0.59299034 accurracy:  0.9314787\n",
      "Epoch:  1995 Loss:  0.59298706 accurracy:  0.9314963\n",
      "Epoch:  1996 Loss:  0.5929819 accurracy:  0.93151397\n",
      "Epoch:  1997 Loss:  0.59297764 accurracy:  0.93153155\n",
      "Epoch:  1998 Loss:  0.59297407 accurracy:  0.93154913\n",
      "Epoch:  1999 Loss:  0.5929698 accurracy:  0.93156666\n",
      "Epoch:  2000 Loss:  0.5929643 accurracy:  0.9315842\n",
      "Epoch:  2001 Loss:  0.5929614 accurracy:  0.9316017\n",
      "Epoch:  2002 Loss:  0.5929575 accurracy:  0.9316192\n",
      "Epoch:  2003 Loss:  0.59295183 accurracy:  0.93163675\n",
      "Epoch:  2004 Loss:  0.59294736 accurracy:  0.9316542\n",
      "Epoch:  2005 Loss:  0.5929449 accurracy:  0.9316717\n",
      "Epoch:  2006 Loss:  0.5929403 accurracy:  0.9316891\n",
      "Epoch:  2007 Loss:  0.59293455 accurracy:  0.9317065\n",
      "Epoch:  2008 Loss:  0.5929315 accurracy:  0.9317239\n",
      "Epoch:  2009 Loss:  0.5929281 accurracy:  0.9317413\n",
      "Epoch:  2010 Loss:  0.5929225 accurracy:  0.93175864\n",
      "Epoch:  2011 Loss:  0.59291804 accurracy:  0.931776\n",
      "Epoch:  2012 Loss:  0.5929157 accurracy:  0.93179333\n",
      "Epoch:  2013 Loss:  0.5929104 accurracy:  0.9318107\n",
      "Epoch:  2014 Loss:  0.5929053 accurracy:  0.93182796\n",
      "Epoch:  2015 Loss:  0.5929025 accurracy:  0.93184525\n",
      "Epoch:  2016 Loss:  0.5928981 accurracy:  0.9318625\n",
      "Epoch:  2017 Loss:  0.59289277 accurracy:  0.93187976\n",
      "Epoch:  2018 Loss:  0.59288937 accurracy:  0.931897\n",
      "Epoch:  2019 Loss:  0.59288603 accurracy:  0.9319142\n",
      "Epoch:  2020 Loss:  0.5928806 accurracy:  0.9319314\n",
      "Epoch:  2021 Loss:  0.5928758 accurracy:  0.93194854\n",
      "Epoch:  2022 Loss:  0.592873 accurracy:  0.9319657\n",
      "Epoch:  2023 Loss:  0.59286904 accurracy:  0.9319829\n",
      "Epoch:  2024 Loss:  0.5928636 accurracy:  0.932\n",
      "Epoch:  2025 Loss:  0.5928594 accurracy:  0.9320171\n",
      "Epoch:  2026 Loss:  0.59285647 accurracy:  0.9320342\n",
      "Epoch:  2027 Loss:  0.592852 accurracy:  0.9320513\n",
      "Epoch:  2028 Loss:  0.59284663 accurracy:  0.93206835\n",
      "Epoch:  2029 Loss:  0.59284276 accurracy:  0.9320854\n",
      "Epoch:  2030 Loss:  0.5928394 accurracy:  0.93210244\n",
      "Epoch:  2031 Loss:  0.59283483 accurracy:  0.9321194\n",
      "Epoch:  2032 Loss:  0.5928301 accurracy:  0.9321364\n",
      "Epoch:  2033 Loss:  0.5928266 accurracy:  0.9321534\n",
      "Epoch:  2034 Loss:  0.5928227 accurracy:  0.93217033\n",
      "Epoch:  2035 Loss:  0.59281796 accurracy:  0.9321873\n",
      "Epoch:  2036 Loss:  0.59281355 accurracy:  0.93220425\n",
      "Epoch:  2037 Loss:  0.59281 accurracy:  0.9322211\n",
      "Epoch:  2038 Loss:  0.59280574 accurracy:  0.93223804\n",
      "Epoch:  2039 Loss:  0.592801 accurracy:  0.9322549\n",
      "Epoch:  2040 Loss:  0.5927973 accurracy:  0.9322718\n",
      "Epoch:  2041 Loss:  0.5927935 accurracy:  0.9322886\n",
      "Epoch:  2042 Loss:  0.5927888 accurracy:  0.93230546\n",
      "Epoch:  2043 Loss:  0.59278613 accurracy:  0.93232226\n",
      "Epoch:  2044 Loss:  0.5927801 accurracy:  0.932339\n",
      "Epoch:  2045 Loss:  0.5927753 accurracy:  0.9323558\n",
      "Epoch:  2046 Loss:  0.5927734 accurracy:  0.93237257\n",
      "Epoch:  2047 Loss:  0.59276855 accurracy:  0.9323893\n",
      "Epoch:  2048 Loss:  0.59276265 accurracy:  0.93240607\n",
      "Epoch:  2049 Loss:  0.59275985 accurracy:  0.93242276\n",
      "Epoch:  2050 Loss:  0.5927565 accurracy:  0.93243945\n",
      "Epoch:  2051 Loss:  0.5927512 accurracy:  0.93245614\n",
      "Epoch:  2052 Loss:  0.59274656 accurracy:  0.9324728\n",
      "Epoch:  2053 Loss:  0.5927436 accurracy:  0.93248945\n",
      "Epoch:  2054 Loss:  0.5927394 accurracy:  0.9325061\n",
      "Epoch:  2055 Loss:  0.5927344 accurracy:  0.9325227\n",
      "Epoch:  2056 Loss:  0.59273076 accurracy:  0.9325393\n",
      "Epoch:  2057 Loss:  0.59272724 accurracy:  0.93255585\n",
      "Epoch:  2058 Loss:  0.5927221 accurracy:  0.9325724\n",
      "Epoch:  2059 Loss:  0.59271795 accurracy:  0.932589\n",
      "Epoch:  2060 Loss:  0.59271467 accurracy:  0.9326055\n",
      "Epoch:  2061 Loss:  0.59271014 accurracy:  0.9326221\n",
      "Epoch:  2062 Loss:  0.5927057 accurracy:  0.9326385\n",
      "Epoch:  2063 Loss:  0.59270203 accurracy:  0.93265504\n",
      "Epoch:  2064 Loss:  0.592698 accurracy:  0.9326715\n",
      "Epoch:  2065 Loss:  0.5926934 accurracy:  0.93268794\n",
      "Epoch:  2066 Loss:  0.5926894 accurracy:  0.9327044\n",
      "Epoch:  2067 Loss:  0.5926857 accurracy:  0.93272084\n",
      "Epoch:  2068 Loss:  0.5926811 accurracy:  0.93273723\n",
      "Epoch:  2069 Loss:  0.59267706 accurracy:  0.9327536\n",
      "Epoch:  2070 Loss:  0.59267294 accurracy:  0.93277\n",
      "Epoch:  2071 Loss:  0.59266895 accurracy:  0.93278635\n",
      "Epoch:  2072 Loss:  0.5926647 accurracy:  0.9328027\n",
      "Epoch:  2073 Loss:  0.59266025 accurracy:  0.932819\n",
      "Epoch:  2074 Loss:  0.5926569 accurracy:  0.93283534\n",
      "Epoch:  2075 Loss:  0.5926524 accurracy:  0.9328516\n",
      "Epoch:  2076 Loss:  0.5926482 accurracy:  0.93286794\n",
      "Epoch:  2077 Loss:  0.59264433 accurracy:  0.93288416\n",
      "Epoch:  2078 Loss:  0.5926405 accurracy:  0.9329004\n",
      "Epoch:  2079 Loss:  0.592636 accurracy:  0.93291664\n",
      "Epoch:  2080 Loss:  0.5926316 accurracy:  0.9329329\n",
      "Epoch:  2081 Loss:  0.5926281 accurracy:  0.93294907\n",
      "Epoch:  2082 Loss:  0.59262383 accurracy:  0.9329653\n",
      "Epoch:  2083 Loss:  0.59261984 accurracy:  0.93298143\n",
      "Epoch:  2084 Loss:  0.5926153 accurracy:  0.9329976\n",
      "Epoch:  2085 Loss:  0.59261155 accurracy:  0.93301374\n",
      "Epoch:  2086 Loss:  0.5926074 accurracy:  0.9330299\n",
      "Epoch:  2087 Loss:  0.59260327 accurracy:  0.933046\n",
      "Epoch:  2088 Loss:  0.5925995 accurracy:  0.9330621\n",
      "Epoch:  2089 Loss:  0.5925949 accurracy:  0.93307817\n",
      "Epoch:  2090 Loss:  0.5925911 accurracy:  0.9330942\n",
      "Epoch:  2091 Loss:  0.59258735 accurracy:  0.93311024\n",
      "Epoch:  2092 Loss:  0.5925828 accurracy:  0.9331263\n",
      "Epoch:  2093 Loss:  0.5925788 accurracy:  0.9331423\n",
      "Epoch:  2094 Loss:  0.59257483 accurracy:  0.93315834\n",
      "Epoch:  2095 Loss:  0.592571 accurracy:  0.9331743\n",
      "Epoch:  2096 Loss:  0.5925668 accurracy:  0.9331903\n",
      "Epoch:  2097 Loss:  0.5925624 accurracy:  0.9332062\n",
      "Epoch:  2098 Loss:  0.5925588 accurracy:  0.9332222\n",
      "Epoch:  2099 Loss:  0.5925548 accurracy:  0.9332381\n",
      "Epoch:  2100 Loss:  0.5925516 accurracy:  0.933254\n",
      "Epoch:  2101 Loss:  0.59254557 accurracy:  0.9332699\n",
      "Epoch:  2102 Loss:  0.5925415 accurracy:  0.9332858\n",
      "Epoch:  2103 Loss:  0.5925397 accurracy:  0.9333016\n",
      "Epoch:  2104 Loss:  0.5925345 accurracy:  0.9333175\n",
      "Epoch:  2105 Loss:  0.59252864 accurracy:  0.93333334\n",
      "Epoch:  2106 Loss:  0.5925263 accurracy:  0.93334913\n",
      "Epoch:  2107 Loss:  0.59252304 accurracy:  0.933365\n",
      "Epoch:  2108 Loss:  0.5925172 accurracy:  0.9333807\n",
      "Epoch:  2109 Loss:  0.59251314 accurracy:  0.9333965\n",
      "Epoch:  2110 Loss:  0.5925109 accurracy:  0.9334123\n",
      "Epoch:  2111 Loss:  0.5925062 accurracy:  0.93342805\n",
      "Epoch:  2112 Loss:  0.5925008 accurracy:  0.9334438\n",
      "Epoch:  2113 Loss:  0.59249765 accurracy:  0.93345946\n",
      "Epoch:  2114 Loss:  0.5924953 accurracy:  0.9334752\n",
      "Epoch:  2115 Loss:  0.5924895 accurracy:  0.9334909\n",
      "Epoch:  2116 Loss:  0.5924849 accurracy:  0.93350655\n",
      "Epoch:  2117 Loss:  0.5924818 accurracy:  0.93352216\n",
      "Epoch:  2118 Loss:  0.5924786 accurracy:  0.93353784\n",
      "Epoch:  2119 Loss:  0.59247315 accurracy:  0.93355346\n",
      "Epoch:  2120 Loss:  0.59246886 accurracy:  0.9335691\n",
      "Epoch:  2121 Loss:  0.5924665 accurracy:  0.9335847\n",
      "Epoch:  2122 Loss:  0.5924618 accurracy:  0.93360025\n",
      "Epoch:  2123 Loss:  0.5924568 accurracy:  0.9336158\n",
      "Epoch:  2124 Loss:  0.5924534 accurracy:  0.93363136\n",
      "Epoch:  2125 Loss:  0.59244996 accurracy:  0.9336469\n",
      "Epoch:  2126 Loss:  0.5924457 accurracy:  0.9336624\n",
      "Epoch:  2127 Loss:  0.5924408 accurracy:  0.933678\n",
      "Epoch:  2128 Loss:  0.59243786 accurracy:  0.93369347\n",
      "Epoch:  2129 Loss:  0.59243417 accurracy:  0.9337089\n",
      "Epoch:  2130 Loss:  0.5924292 accurracy:  0.9337244\n",
      "Epoch:  2131 Loss:  0.5924253 accurracy:  0.93373984\n",
      "Epoch:  2132 Loss:  0.5924217 accurracy:  0.9337553\n",
      "Epoch:  2133 Loss:  0.59241784 accurracy:  0.9337707\n",
      "Epoch:  2134 Loss:  0.5924135 accurracy:  0.9337861\n",
      "Epoch:  2135 Loss:  0.5924091 accurracy:  0.9338015\n",
      "Epoch:  2136 Loss:  0.59240574 accurracy:  0.93381685\n",
      "Epoch:  2137 Loss:  0.59240174 accurracy:  0.9338322\n",
      "Epoch:  2138 Loss:  0.59239715 accurracy:  0.9338476\n",
      "Epoch:  2139 Loss:  0.59239364 accurracy:  0.9338629\n",
      "Epoch:  2140 Loss:  0.5923899 accurracy:  0.93387824\n",
      "Epoch:  2141 Loss:  0.5923856 accurracy:  0.93389356\n",
      "Epoch:  2142 Loss:  0.5923819 accurracy:  0.9339089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2143 Loss:  0.5923778 accurracy:  0.93392414\n",
      "Epoch:  2144 Loss:  0.59237355 accurracy:  0.9339394\n",
      "Epoch:  2145 Loss:  0.5923697 accurracy:  0.93395466\n",
      "Epoch:  2146 Loss:  0.59236604 accurracy:  0.93396986\n",
      "Epoch:  2147 Loss:  0.5923628 accurracy:  0.9339851\n",
      "Epoch:  2148 Loss:  0.5923574 accurracy:  0.9340003\n",
      "Epoch:  2149 Loss:  0.59235346 accurracy:  0.9340155\n",
      "Epoch:  2150 Loss:  0.5923503 accurracy:  0.9340307\n",
      "Epoch:  2151 Loss:  0.5923463 accurracy:  0.93404585\n",
      "Epoch:  2152 Loss:  0.5923415 accurracy:  0.934061\n",
      "Epoch:  2153 Loss:  0.59233814 accurracy:  0.93407613\n",
      "Epoch:  2154 Loss:  0.5923345 accurracy:  0.93409127\n",
      "Epoch:  2155 Loss:  0.5923301 accurracy:  0.93410635\n",
      "Epoch:  2156 Loss:  0.5923258 accurracy:  0.9341215\n",
      "Epoch:  2157 Loss:  0.5923223 accurracy:  0.93413657\n",
      "Epoch:  2158 Loss:  0.5923188 accurracy:  0.9341516\n",
      "Epoch:  2159 Loss:  0.5923141 accurracy:  0.93416667\n",
      "Epoch:  2160 Loss:  0.59231013 accurracy:  0.9341817\n",
      "Epoch:  2161 Loss:  0.5923064 accurracy:  0.9341967\n",
      "Epoch:  2162 Loss:  0.5923029 accurracy:  0.93421173\n",
      "Epoch:  2163 Loss:  0.5922987 accurracy:  0.93422675\n",
      "Epoch:  2164 Loss:  0.5922949 accurracy:  0.9342417\n",
      "Epoch:  2165 Loss:  0.59229064 accurracy:  0.9342567\n",
      "Epoch:  2166 Loss:  0.59228677 accurracy:  0.93427163\n",
      "Epoch:  2167 Loss:  0.59228325 accurracy:  0.9342866\n",
      "Epoch:  2168 Loss:  0.59227914 accurracy:  0.9343015\n",
      "Epoch:  2169 Loss:  0.59227455 accurracy:  0.93431646\n",
      "Epoch:  2170 Loss:  0.59227145 accurracy:  0.93433136\n",
      "Epoch:  2171 Loss:  0.5922679 accurracy:  0.9343462\n",
      "Epoch:  2172 Loss:  0.59226316 accurracy:  0.9343611\n",
      "Epoch:  2173 Loss:  0.592259 accurracy:  0.93437594\n",
      "Epoch:  2174 Loss:  0.59225583 accurracy:  0.9343908\n",
      "Epoch:  2175 Loss:  0.5922522 accurracy:  0.9344056\n",
      "Epoch:  2176 Loss:  0.59224737 accurracy:  0.93442047\n",
      "Epoch:  2177 Loss:  0.59224355 accurracy:  0.93443525\n",
      "Epoch:  2178 Loss:  0.5922405 accurracy:  0.93445003\n",
      "Epoch:  2179 Loss:  0.5922361 accurracy:  0.9344648\n",
      "Epoch:  2180 Loss:  0.59223187 accurracy:  0.9344796\n",
      "Epoch:  2181 Loss:  0.59222835 accurracy:  0.9344944\n",
      "Epoch:  2182 Loss:  0.5922247 accurracy:  0.9345091\n",
      "Epoch:  2183 Loss:  0.59222066 accurracy:  0.9345238\n",
      "Epoch:  2184 Loss:  0.5922166 accurracy:  0.93453854\n",
      "Epoch:  2185 Loss:  0.59221274 accurracy:  0.9345532\n",
      "Epoch:  2186 Loss:  0.59220916 accurracy:  0.9345679\n",
      "Epoch:  2187 Loss:  0.5922048 accurracy:  0.9345826\n",
      "Epoch:  2188 Loss:  0.5922019 accurracy:  0.93459725\n",
      "Epoch:  2189 Loss:  0.59219724 accurracy:  0.93461186\n",
      "Epoch:  2190 Loss:  0.5921928 accurracy:  0.9346265\n",
      "Epoch:  2191 Loss:  0.5921898 accurracy:  0.9346411\n",
      "Epoch:  2192 Loss:  0.59218603 accurracy:  0.9346557\n",
      "Epoch:  2193 Loss:  0.5921812 accurracy:  0.9346703\n",
      "Epoch:  2194 Loss:  0.59217775 accurracy:  0.9346849\n",
      "Epoch:  2195 Loss:  0.5921747 accurracy:  0.9346995\n",
      "Epoch:  2196 Loss:  0.5921699 accurracy:  0.934714\n",
      "Epoch:  2197 Loss:  0.5921658 accurracy:  0.93472856\n",
      "Epoch:  2198 Loss:  0.5921629 accurracy:  0.93474305\n",
      "Epoch:  2199 Loss:  0.59215903 accurracy:  0.9347576\n",
      "Epoch:  2200 Loss:  0.5921545 accurracy:  0.9347721\n",
      "Epoch:  2201 Loss:  0.5921506 accurracy:  0.93478656\n",
      "Epoch:  2202 Loss:  0.59214747 accurracy:  0.93480104\n",
      "Epoch:  2203 Loss:  0.5921433 accurracy:  0.93481547\n",
      "Epoch:  2204 Loss:  0.5921391 accurracy:  0.93482995\n",
      "Epoch:  2205 Loss:  0.5921353 accurracy:  0.9348444\n",
      "Epoch:  2206 Loss:  0.5921318 accurracy:  0.9348588\n",
      "Epoch:  2207 Loss:  0.59212816 accurracy:  0.93487316\n",
      "Epoch:  2208 Loss:  0.5921237 accurracy:  0.9348876\n",
      "Epoch:  2209 Loss:  0.59212005 accurracy:  0.93490195\n",
      "Epoch:  2210 Loss:  0.5921168 accurracy:  0.9349163\n",
      "Epoch:  2211 Loss:  0.59211224 accurracy:  0.9349307\n",
      "Epoch:  2212 Loss:  0.5921085 accurracy:  0.93494505\n",
      "Epoch:  2213 Loss:  0.592105 accurracy:  0.93495935\n",
      "Epoch:  2214 Loss:  0.59210145 accurracy:  0.93497366\n",
      "Epoch:  2215 Loss:  0.5920969 accurracy:  0.93498796\n",
      "Epoch:  2216 Loss:  0.5920933 accurracy:  0.93500227\n",
      "Epoch:  2217 Loss:  0.5920898 accurracy:  0.9350165\n",
      "Epoch:  2218 Loss:  0.59208596 accurracy:  0.9350308\n",
      "Epoch:  2219 Loss:  0.59208184 accurracy:  0.93504506\n",
      "Epoch:  2220 Loss:  0.5920777 accurracy:  0.9350593\n",
      "Epoch:  2221 Loss:  0.5920745 accurracy:  0.9350735\n",
      "Epoch:  2222 Loss:  0.592071 accurracy:  0.93508774\n",
      "Epoch:  2223 Loss:  0.59206635 accurracy:  0.9351019\n",
      "Epoch:  2224 Loss:  0.59206337 accurracy:  0.9351161\n",
      "Epoch:  2225 Loss:  0.5920591 accurracy:  0.9351303\n",
      "Epoch:  2226 Loss:  0.5920548 accurracy:  0.9351444\n",
      "Epoch:  2227 Loss:  0.5920517 accurracy:  0.9351586\n",
      "Epoch:  2228 Loss:  0.5920482 accurracy:  0.93517274\n",
      "Epoch:  2229 Loss:  0.59204394 accurracy:  0.93518686\n",
      "Epoch:  2230 Loss:  0.5920397 accurracy:  0.9352009\n",
      "Epoch:  2231 Loss:  0.592037 accurracy:  0.93521506\n",
      "Epoch:  2232 Loss:  0.59203285 accurracy:  0.9352291\n",
      "Epoch:  2233 Loss:  0.5920281 accurracy:  0.9352432\n",
      "Epoch:  2234 Loss:  0.592025 accurracy:  0.93525726\n",
      "Epoch:  2235 Loss:  0.5920219 accurracy:  0.9352713\n",
      "Epoch:  2236 Loss:  0.59201753 accurracy:  0.93528533\n",
      "Epoch:  2237 Loss:  0.59201294 accurracy:  0.9352994\n",
      "Epoch:  2238 Loss:  0.5920106 accurracy:  0.9353134\n",
      "Epoch:  2239 Loss:  0.5920066 accurracy:  0.9353274\n",
      "Epoch:  2240 Loss:  0.5920019 accurracy:  0.93534136\n",
      "Epoch:  2241 Loss:  0.5919982 accurracy:  0.93535537\n",
      "Epoch:  2242 Loss:  0.5919955 accurracy:  0.9353693\n",
      "Epoch:  2243 Loss:  0.59199136 accurracy:  0.93538326\n",
      "Epoch:  2244 Loss:  0.59198695 accurracy:  0.9353972\n",
      "Epoch:  2245 Loss:  0.5919832 accurracy:  0.9354111\n",
      "Epoch:  2246 Loss:  0.5919804 accurracy:  0.935425\n",
      "Epoch:  2247 Loss:  0.5919765 accurracy:  0.93543893\n",
      "Epoch:  2248 Loss:  0.5919714 accurracy:  0.9354528\n",
      "Epoch:  2249 Loss:  0.59196866 accurracy:  0.93546665\n",
      "Epoch:  2250 Loss:  0.59196585 accurracy:  0.93548054\n",
      "Epoch:  2251 Loss:  0.5919607 accurracy:  0.93549436\n",
      "Epoch:  2252 Loss:  0.59195673 accurracy:  0.9355082\n",
      "Epoch:  2253 Loss:  0.5919542 accurracy:  0.935522\n",
      "Epoch:  2254 Loss:  0.5919505 accurracy:  0.93553585\n",
      "Epoch:  2255 Loss:  0.5919455 accurracy:  0.9355496\n",
      "Epoch:  2256 Loss:  0.5919424 accurracy:  0.93556345\n",
      "Epoch:  2257 Loss:  0.59193903 accurracy:  0.9355772\n",
      "Epoch:  2258 Loss:  0.5919352 accurracy:  0.935591\n",
      "Epoch:  2259 Loss:  0.5919311 accurracy:  0.9356047\n",
      "Epoch:  2260 Loss:  0.5919275 accurracy:  0.93561846\n",
      "Epoch:  2261 Loss:  0.5919243 accurracy:  0.93563217\n",
      "Epoch:  2262 Loss:  0.5919202 accurracy:  0.9356459\n",
      "Epoch:  2263 Loss:  0.59191614 accurracy:  0.9356596\n",
      "Epoch:  2264 Loss:  0.5919126 accurracy:  0.9356733\n",
      "Epoch:  2265 Loss:  0.59190917 accurracy:  0.93568695\n",
      "Epoch:  2266 Loss:  0.5919053 accurracy:  0.93570065\n",
      "Epoch:  2267 Loss:  0.5919014 accurracy:  0.9357143\n",
      "Epoch:  2268 Loss:  0.59189785 accurracy:  0.93572795\n",
      "Epoch:  2269 Loss:  0.5918944 accurracy:  0.93574154\n",
      "Epoch:  2270 Loss:  0.59189045 accurracy:  0.9357552\n",
      "Epoch:  2271 Loss:  0.59188694 accurracy:  0.9357688\n",
      "Epoch:  2272 Loss:  0.591883 accurracy:  0.9357824\n",
      "Epoch:  2273 Loss:  0.5918795 accurracy:  0.93579596\n",
      "Epoch:  2274 Loss:  0.59187573 accurracy:  0.93580955\n",
      "Epoch:  2275 Loss:  0.59187204 accurracy:  0.9358231\n",
      "Epoch:  2276 Loss:  0.59186864 accurracy:  0.9358366\n",
      "Epoch:  2277 Loss:  0.59186494 accurracy:  0.93585014\n",
      "Epoch:  2278 Loss:  0.59186095 accurracy:  0.9358637\n",
      "Epoch:  2279 Loss:  0.5918572 accurracy:  0.9358772\n",
      "Epoch:  2280 Loss:  0.59185344 accurracy:  0.9358907\n",
      "Epoch:  2281 Loss:  0.59185016 accurracy:  0.9359042\n",
      "Epoch:  2282 Loss:  0.5918466 accurracy:  0.9359177\n",
      "Epoch:  2283 Loss:  0.59184253 accurracy:  0.9359311\n",
      "Epoch:  2284 Loss:  0.5918389 accurracy:  0.93594456\n",
      "Epoch:  2285 Loss:  0.5918362 accurracy:  0.935958\n",
      "Epoch:  2286 Loss:  0.59183174 accurracy:  0.93597144\n",
      "Epoch:  2287 Loss:  0.59182686 accurracy:  0.93598485\n",
      "Epoch:  2288 Loss:  0.5918246 accurracy:  0.93599826\n",
      "Epoch:  2289 Loss:  0.59182155 accurracy:  0.9360117\n",
      "Epoch:  2290 Loss:  0.5918167 accurracy:  0.936025\n",
      "Epoch:  2291 Loss:  0.59181243 accurracy:  0.9360384\n",
      "Epoch:  2292 Loss:  0.59181035 accurracy:  0.9360517\n",
      "Epoch:  2293 Loss:  0.59180653 accurracy:  0.9360651\n",
      "Epoch:  2294 Loss:  0.59180176 accurracy:  0.9360784\n",
      "Epoch:  2295 Loss:  0.59179837 accurracy:  0.9360918\n",
      "Epoch:  2296 Loss:  0.591796 accurracy:  0.9361051\n",
      "Epoch:  2297 Loss:  0.59179187 accurracy:  0.93611836\n",
      "Epoch:  2298 Loss:  0.5917871 accurracy:  0.93613166\n",
      "Epoch:  2299 Loss:  0.5917844 accurracy:  0.93614495\n",
      "Epoch:  2300 Loss:  0.59178096 accurracy:  0.9361582\n",
      "Epoch:  2301 Loss:  0.5917768 accurracy:  0.9361715\n",
      "Epoch:  2302 Loss:  0.59177285 accurracy:  0.9361847\n",
      "Epoch:  2303 Loss:  0.5917701 accurracy:  0.93619794\n",
      "Epoch:  2304 Loss:  0.5917665 accurracy:  0.9362111\n",
      "Epoch:  2305 Loss:  0.59176195 accurracy:  0.93622434\n",
      "Epoch:  2306 Loss:  0.5917585 accurracy:  0.9362375\n",
      "Epoch:  2307 Loss:  0.5917557 accurracy:  0.93625075\n",
      "Epoch:  2308 Loss:  0.59175193 accurracy:  0.9362639\n",
      "Epoch:  2309 Loss:  0.5917475 accurracy:  0.93627703\n",
      "Epoch:  2310 Loss:  0.5917441 accurracy:  0.9362902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2311 Loss:  0.5917418 accurracy:  0.9363033\n",
      "Epoch:  2312 Loss:  0.5917371 accurracy:  0.9363165\n",
      "Epoch:  2313 Loss:  0.59173286 accurracy:  0.9363296\n",
      "Epoch:  2314 Loss:  0.59173 accurracy:  0.9363427\n",
      "Epoch:  2315 Loss:  0.59172726 accurracy:  0.93635577\n",
      "Epoch:  2316 Loss:  0.5917225 accurracy:  0.9363689\n",
      "Epoch:  2317 Loss:  0.59171844 accurracy:  0.93638194\n",
      "Epoch:  2318 Loss:  0.5917162 accurracy:  0.936395\n",
      "Epoch:  2319 Loss:  0.59171253 accurracy:  0.93640804\n",
      "Epoch:  2320 Loss:  0.59170794 accurracy:  0.9364211\n",
      "Epoch:  2321 Loss:  0.59170437 accurracy:  0.9364341\n",
      "Epoch:  2322 Loss:  0.59170187 accurracy:  0.93644714\n",
      "Epoch:  2323 Loss:  0.5916979 accurracy:  0.93646014\n",
      "Epoch:  2324 Loss:  0.5916932 accurracy:  0.93647313\n",
      "Epoch:  2325 Loss:  0.5916901 accurracy:  0.9364861\n",
      "Epoch:  2326 Loss:  0.5916878 accurracy:  0.93649906\n",
      "Epoch:  2327 Loss:  0.5916834 accurracy:  0.93651205\n",
      "Epoch:  2328 Loss:  0.5916793 accurracy:  0.936525\n",
      "Epoch:  2329 Loss:  0.591676 accurracy:  0.9365379\n",
      "Epoch:  2330 Loss:  0.59167355 accurracy:  0.93655086\n",
      "Epoch:  2331 Loss:  0.5916691 accurracy:  0.93656373\n",
      "Epoch:  2332 Loss:  0.5916649 accurracy:  0.93657666\n",
      "Epoch:  2333 Loss:  0.5916623 accurracy:  0.93658954\n",
      "Epoch:  2334 Loss:  0.5916592 accurracy:  0.9366024\n",
      "Epoch:  2335 Loss:  0.5916549 accurracy:  0.9366153\n",
      "Epoch:  2336 Loss:  0.5916508 accurracy:  0.93662816\n",
      "Epoch:  2337 Loss:  0.5916479 accurracy:  0.936641\n",
      "Epoch:  2338 Loss:  0.5916444 accurracy:  0.93665385\n",
      "Epoch:  2339 Loss:  0.5916405 accurracy:  0.93666667\n",
      "Epoch:  2340 Loss:  0.5916368 accurracy:  0.9366795\n",
      "Epoch:  2341 Loss:  0.5916335 accurracy:  0.9366923\n",
      "Epoch:  2342 Loss:  0.5916303 accurracy:  0.93670505\n",
      "Epoch:  2343 Loss:  0.5916264 accurracy:  0.93671787\n",
      "Epoch:  2344 Loss:  0.5916227 accurracy:  0.9367306\n",
      "Epoch:  2345 Loss:  0.5916195 accurracy:  0.9367434\n",
      "Epoch:  2346 Loss:  0.5916163 accurracy:  0.93675613\n",
      "Epoch:  2347 Loss:  0.5916123 accurracy:  0.9367689\n",
      "Epoch:  2348 Loss:  0.59160864 accurracy:  0.9367816\n",
      "Epoch:  2349 Loss:  0.5916057 accurracy:  0.93679434\n",
      "Epoch:  2350 Loss:  0.59160227 accurracy:  0.93680704\n",
      "Epoch:  2351 Loss:  0.59159786 accurracy:  0.93681973\n",
      "Epoch:  2352 Loss:  0.5915947 accurracy:  0.9368324\n",
      "Epoch:  2353 Loss:  0.5915919 accurracy:  0.93684506\n",
      "Epoch:  2354 Loss:  0.5915877 accurracy:  0.93685776\n",
      "Epoch:  2355 Loss:  0.59158385 accurracy:  0.9368704\n",
      "Epoch:  2356 Loss:  0.5915812 accurracy:  0.93688303\n",
      "Epoch:  2357 Loss:  0.5915781 accurracy:  0.93689567\n",
      "Epoch:  2358 Loss:  0.5915737 accurracy:  0.9369083\n",
      "Epoch:  2359 Loss:  0.59156984 accurracy:  0.9369209\n",
      "Epoch:  2360 Loss:  0.59156686 accurracy:  0.9369335\n",
      "Epoch:  2361 Loss:  0.591564 accurracy:  0.9369461\n",
      "Epoch:  2362 Loss:  0.59156 accurracy:  0.9369587\n",
      "Epoch:  2363 Loss:  0.59155554 accurracy:  0.93697125\n",
      "Epoch:  2364 Loss:  0.591553 accurracy:  0.93698376\n",
      "Epoch:  2365 Loss:  0.59155005 accurracy:  0.93699634\n",
      "Epoch:  2366 Loss:  0.5915455 accurracy:  0.93700886\n",
      "Epoch:  2367 Loss:  0.5915419 accurracy:  0.9370214\n",
      "Epoch:  2368 Loss:  0.59153944 accurracy:  0.9370339\n",
      "Epoch:  2369 Loss:  0.5915359 accurracy:  0.9370464\n",
      "Epoch:  2370 Loss:  0.5915316 accurracy:  0.9370589\n",
      "Epoch:  2371 Loss:  0.59152806 accurracy:  0.9370714\n",
      "Epoch:  2372 Loss:  0.59152544 accurracy:  0.93708384\n",
      "Epoch:  2373 Loss:  0.5915219 accurracy:  0.9370963\n",
      "Epoch:  2374 Loss:  0.5915177 accurracy:  0.93710876\n",
      "Epoch:  2375 Loss:  0.59151465 accurracy:  0.9371212\n",
      "Epoch:  2376 Loss:  0.59151155 accurracy:  0.93713367\n",
      "Epoch:  2377 Loss:  0.5915076 accurracy:  0.93714607\n",
      "Epoch:  2378 Loss:  0.5915039 accurracy:  0.93715847\n",
      "Epoch:  2379 Loss:  0.59150124 accurracy:  0.93717086\n",
      "Epoch:  2380 Loss:  0.5914975 accurracy:  0.93718326\n",
      "Epoch:  2381 Loss:  0.5914936 accurracy:  0.93719566\n",
      "Epoch:  2382 Loss:  0.59149057 accurracy:  0.937208\n",
      "Epoch:  2383 Loss:  0.59148735 accurracy:  0.93722034\n",
      "Epoch:  2384 Loss:  0.59148353 accurracy:  0.93723273\n",
      "Epoch:  2385 Loss:  0.59147954 accurracy:  0.937245\n",
      "Epoch:  2386 Loss:  0.5914768 accurracy:  0.93725735\n",
      "Epoch:  2387 Loss:  0.59147364 accurracy:  0.9372697\n",
      "Epoch:  2388 Loss:  0.5914698 accurracy:  0.93728197\n",
      "Epoch:  2389 Loss:  0.59146625 accurracy:  0.9372943\n",
      "Epoch:  2390 Loss:  0.5914631 accurracy:  0.9373066\n",
      "Epoch:  2391 Loss:  0.59145993 accurracy:  0.93731886\n",
      "Epoch:  2392 Loss:  0.5914558 accurracy:  0.9373311\n",
      "Epoch:  2393 Loss:  0.5914528 accurracy:  0.93734336\n",
      "Epoch:  2394 Loss:  0.5914495 accurracy:  0.9373556\n",
      "Epoch:  2395 Loss:  0.5914459 accurracy:  0.93736786\n",
      "Epoch:  2396 Loss:  0.59144235 accurracy:  0.9373801\n",
      "Epoch:  2397 Loss:  0.591439 accurracy:  0.9373923\n",
      "Epoch:  2398 Loss:  0.59143573 accurracy:  0.93740445\n",
      "Epoch:  2399 Loss:  0.59143263 accurracy:  0.9374167\n",
      "Epoch:  2400 Loss:  0.5914289 accurracy:  0.93742883\n",
      "Epoch:  2401 Loss:  0.5914251 accurracy:  0.93744105\n",
      "Epoch:  2402 Loss:  0.591422 accurracy:  0.9374532\n",
      "Epoch:  2403 Loss:  0.59141916 accurracy:  0.9374653\n",
      "Epoch:  2404 Loss:  0.5914153 accurracy:  0.93747747\n",
      "Epoch:  2405 Loss:  0.5914115 accurracy:  0.9374896\n",
      "Epoch:  2406 Loss:  0.59140855 accurracy:  0.9375017\n",
      "Epoch:  2407 Loss:  0.59140563 accurracy:  0.9375138\n",
      "Epoch:  2408 Loss:  0.5914017 accurracy:  0.9375259\n",
      "Epoch:  2409 Loss:  0.5913976 accurracy:  0.937538\n",
      "Epoch:  2410 Loss:  0.59139526 accurracy:  0.9375501\n",
      "Epoch:  2411 Loss:  0.5913922 accurracy:  0.93756217\n",
      "Epoch:  2412 Loss:  0.5913878 accurracy:  0.93757427\n",
      "Epoch:  2413 Loss:  0.5913843 accurracy:  0.9375863\n",
      "Epoch:  2414 Loss:  0.5913816 accurracy:  0.93759835\n",
      "Epoch:  2415 Loss:  0.59137833 accurracy:  0.9376104\n",
      "Epoch:  2416 Loss:  0.59137434 accurracy:  0.93762237\n",
      "Epoch:  2417 Loss:  0.59137094 accurracy:  0.9376344\n",
      "Epoch:  2418 Loss:  0.5913686 accurracy:  0.9376464\n",
      "Epoch:  2419 Loss:  0.59136474 accurracy:  0.9376584\n",
      "Epoch:  2420 Loss:  0.5913605 accurracy:  0.9376704\n",
      "Epoch:  2421 Loss:  0.59135765 accurracy:  0.93768233\n",
      "Epoch:  2422 Loss:  0.5913548 accurracy:  0.9376943\n",
      "Epoch:  2423 Loss:  0.5913508 accurracy:  0.9377063\n",
      "Epoch:  2424 Loss:  0.5913474 accurracy:  0.9377182\n",
      "Epoch:  2425 Loss:  0.5913447 accurracy:  0.93773013\n",
      "Epoch:  2426 Loss:  0.59134126 accurracy:  0.93774205\n",
      "Epoch:  2427 Loss:  0.59133726 accurracy:  0.937754\n",
      "Epoch:  2428 Loss:  0.59133404 accurracy:  0.9377659\n",
      "Epoch:  2429 Loss:  0.59133136 accurracy:  0.93777776\n",
      "Epoch:  2430 Loss:  0.5913278 accurracy:  0.9377897\n",
      "Epoch:  2431 Loss:  0.5913241 accurracy:  0.93780154\n",
      "Epoch:  2432 Loss:  0.5913207 accurracy:  0.9378134\n",
      "Epoch:  2433 Loss:  0.5913178 accurracy:  0.93782526\n",
      "Epoch:  2434 Loss:  0.59131455 accurracy:  0.9378371\n",
      "Epoch:  2435 Loss:  0.59131074 accurracy:  0.9378489\n",
      "Epoch:  2436 Loss:  0.5913078 accurracy:  0.9378608\n",
      "Epoch:  2437 Loss:  0.59130424 accurracy:  0.9378726\n",
      "Epoch:  2438 Loss:  0.59130055 accurracy:  0.9378844\n",
      "Epoch:  2439 Loss:  0.5912979 accurracy:  0.9378962\n",
      "Epoch:  2440 Loss:  0.5912946 accurracy:  0.93790793\n",
      "Epoch:  2441 Loss:  0.59129053 accurracy:  0.93791974\n",
      "Epoch:  2442 Loss:  0.59128755 accurracy:  0.9379315\n",
      "Epoch:  2443 Loss:  0.59128445 accurracy:  0.9379433\n",
      "Epoch:  2444 Loss:  0.5912812 accurracy:  0.937955\n",
      "Epoch:  2445 Loss:  0.5912777 accurracy:  0.93796676\n",
      "Epoch:  2446 Loss:  0.59127426 accurracy:  0.9379785\n",
      "Epoch:  2447 Loss:  0.59127146 accurracy:  0.9379902\n",
      "Epoch:  2448 Loss:  0.591268 accurracy:  0.93800193\n",
      "Epoch:  2449 Loss:  0.59126437 accurracy:  0.9380136\n",
      "Epoch:  2450 Loss:  0.59126127 accurracy:  0.9380253\n",
      "Epoch:  2451 Loss:  0.59125835 accurracy:  0.938037\n",
      "Epoch:  2452 Loss:  0.5912549 accurracy:  0.93804866\n",
      "Epoch:  2453 Loss:  0.59125113 accurracy:  0.9380603\n",
      "Epoch:  2454 Loss:  0.59124845 accurracy:  0.93807197\n",
      "Epoch:  2455 Loss:  0.5912451 accurracy:  0.9380836\n",
      "Epoch:  2456 Loss:  0.5912413 accurracy:  0.9380952\n",
      "Epoch:  2457 Loss:  0.5912379 accurracy:  0.93810683\n",
      "Epoch:  2458 Loss:  0.59123534 accurracy:  0.93811846\n",
      "Epoch:  2459 Loss:  0.59123206 accurracy:  0.9381301\n",
      "Epoch:  2460 Loss:  0.59122825 accurracy:  0.9381417\n",
      "Epoch:  2461 Loss:  0.59122485 accurracy:  0.93815327\n",
      "Epoch:  2462 Loss:  0.59122235 accurracy:  0.93816483\n",
      "Epoch:  2463 Loss:  0.59121895 accurracy:  0.9381764\n",
      "Epoch:  2464 Loss:  0.59121525 accurracy:  0.93818796\n",
      "Epoch:  2465 Loss:  0.59121186 accurracy:  0.9381995\n",
      "Epoch:  2466 Loss:  0.591209 accurracy:  0.938211\n",
      "Epoch:  2467 Loss:  0.59120595 accurracy:  0.9382226\n",
      "Epoch:  2468 Loss:  0.5912023 accurracy:  0.9382341\n",
      "Epoch:  2469 Loss:  0.5911986 accurracy:  0.9382456\n",
      "Epoch:  2470 Loss:  0.59119606 accurracy:  0.9382571\n",
      "Epoch:  2471 Loss:  0.59119296 accurracy:  0.9382686\n",
      "Epoch:  2472 Loss:  0.5911891 accurracy:  0.9382801\n",
      "Epoch:  2473 Loss:  0.5911858 accurracy:  0.93829155\n",
      "Epoch:  2474 Loss:  0.5911829 accurracy:  0.93830305\n",
      "Epoch:  2475 Loss:  0.59117997 accurracy:  0.9383145\n",
      "Epoch:  2476 Loss:  0.5911761 accurracy:  0.93832594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2477 Loss:  0.5911731 accurracy:  0.9383374\n",
      "Epoch:  2478 Loss:  0.59116995 accurracy:  0.93834877\n",
      "Epoch:  2479 Loss:  0.5911667 accurracy:  0.9383602\n",
      "Epoch:  2480 Loss:  0.59116364 accurracy:  0.9383716\n",
      "Epoch:  2481 Loss:  0.5911602 accurracy:  0.93838304\n",
      "Epoch:  2482 Loss:  0.59115666 accurracy:  0.9383944\n",
      "Epoch:  2483 Loss:  0.59115386 accurracy:  0.9384058\n",
      "Epoch:  2484 Loss:  0.5911509 accurracy:  0.9384172\n",
      "Epoch:  2485 Loss:  0.59114707 accurracy:  0.9384285\n",
      "Epoch:  2486 Loss:  0.59114367 accurracy:  0.9384399\n",
      "Epoch:  2487 Loss:  0.5911409 accurracy:  0.93845123\n",
      "Epoch:  2488 Loss:  0.59113824 accurracy:  0.93846256\n",
      "Epoch:  2489 Loss:  0.5911343 accurracy:  0.9384739\n",
      "Epoch:  2490 Loss:  0.5911307 accurracy:  0.9384852\n",
      "Epoch:  2491 Loss:  0.5911283 accurracy:  0.93849653\n",
      "Epoch:  2492 Loss:  0.5911255 accurracy:  0.9385078\n",
      "Epoch:  2493 Loss:  0.59112144 accurracy:  0.9385191\n",
      "Epoch:  2494 Loss:  0.59111804 accurracy:  0.9385304\n",
      "Epoch:  2495 Loss:  0.5911156 accurracy:  0.93854165\n",
      "Epoch:  2496 Loss:  0.5911124 accurracy:  0.9385529\n",
      "Epoch:  2497 Loss:  0.59110856 accurracy:  0.9385642\n",
      "Epoch:  2498 Loss:  0.5911056 accurracy:  0.93857545\n",
      "Epoch:  2499 Loss:  0.5911026 accurracy:  0.93858665\n",
      "Epoch:  2500 Loss:  0.59109944 accurracy:  0.9385979\n",
      "Epoch:  2501 Loss:  0.59109604 accurracy:  0.9386091\n",
      "Epoch:  2502 Loss:  0.5910928 accurracy:  0.9386203\n",
      "Epoch:  2503 Loss:  0.59108996 accurracy:  0.93863153\n",
      "Epoch:  2504 Loss:  0.59108704 accurracy:  0.93864274\n",
      "Epoch:  2505 Loss:  0.5910832 accurracy:  0.9386539\n",
      "Epoch:  2506 Loss:  0.5910797 accurracy:  0.9386651\n",
      "Epoch:  2507 Loss:  0.591077 accurracy:  0.93867624\n",
      "Epoch:  2508 Loss:  0.59107435 accurracy:  0.9386874\n",
      "Epoch:  2509 Loss:  0.5910704 accurracy:  0.93869853\n",
      "Epoch:  2510 Loss:  0.5910674 accurracy:  0.9387097\n",
      "Epoch:  2511 Loss:  0.59106433 accurracy:  0.9387208\n",
      "Epoch:  2512 Loss:  0.59106135 accurracy:  0.9387319\n",
      "Epoch:  2513 Loss:  0.59105796 accurracy:  0.93874305\n",
      "Epoch:  2514 Loss:  0.5910547 accurracy:  0.93875414\n",
      "Epoch:  2515 Loss:  0.59105235 accurracy:  0.9387652\n",
      "Epoch:  2516 Loss:  0.591049 accurracy:  0.9387763\n",
      "Epoch:  2517 Loss:  0.5910446 accurracy:  0.9387874\n",
      "Epoch:  2518 Loss:  0.5910423 accurracy:  0.9387985\n",
      "Epoch:  2519 Loss:  0.5910399 accurracy:  0.9388095\n",
      "Epoch:  2520 Loss:  0.59103584 accurracy:  0.9388206\n",
      "Epoch:  2521 Loss:  0.5910322 accurracy:  0.9388316\n",
      "Epoch:  2522 Loss:  0.59103 accurracy:  0.93884265\n",
      "Epoch:  2523 Loss:  0.59102696 accurracy:  0.9388537\n",
      "Epoch:  2524 Loss:  0.59102285 accurracy:  0.9388647\n",
      "Epoch:  2525 Loss:  0.5910198 accurracy:  0.9388757\n",
      "Epoch:  2526 Loss:  0.59101754 accurracy:  0.9388867\n",
      "Epoch:  2527 Loss:  0.59101444 accurracy:  0.93889767\n",
      "Epoch:  2528 Loss:  0.5910104 accurracy:  0.93890864\n",
      "Epoch:  2529 Loss:  0.5910073 accurracy:  0.9389196\n",
      "Epoch:  2530 Loss:  0.5910051 accurracy:  0.9389306\n",
      "Epoch:  2531 Loss:  0.59100217 accurracy:  0.93894154\n",
      "Epoch:  2532 Loss:  0.5909979 accurracy:  0.9389525\n",
      "Epoch:  2533 Loss:  0.59099495 accurracy:  0.9389634\n",
      "Epoch:  2534 Loss:  0.5909925 accurracy:  0.9389744\n",
      "Epoch:  2535 Loss:  0.59098965 accurracy:  0.9389853\n",
      "Epoch:  2536 Loss:  0.5909854 accurracy:  0.9389962\n",
      "Epoch:  2537 Loss:  0.59098256 accurracy:  0.9390071\n",
      "Epoch:  2538 Loss:  0.5909801 accurracy:  0.939018\n",
      "Epoch:  2539 Loss:  0.59097695 accurracy:  0.93902886\n",
      "Epoch:  2540 Loss:  0.5909732 accurracy:  0.93903977\n",
      "Epoch:  2541 Loss:  0.5909702 accurracy:  0.9390506\n",
      "Epoch:  2542 Loss:  0.59096754 accurracy:  0.93906146\n",
      "Epoch:  2543 Loss:  0.5909645 accurracy:  0.9390723\n",
      "Epoch:  2544 Loss:  0.59096116 accurracy:  0.93908316\n",
      "Epoch:  2545 Loss:  0.5909577 accurracy:  0.939094\n",
      "Epoch:  2546 Loss:  0.5909547 accurracy:  0.93910486\n",
      "Epoch:  2547 Loss:  0.5909526 accurracy:  0.93911564\n",
      "Epoch:  2548 Loss:  0.5909488 accurracy:  0.93912643\n",
      "Epoch:  2549 Loss:  0.59094524 accurracy:  0.9391373\n",
      "Epoch:  2550 Loss:  0.59094256 accurracy:  0.93914807\n",
      "Epoch:  2551 Loss:  0.5909401 accurracy:  0.93915886\n",
      "Epoch:  2552 Loss:  0.59093654 accurracy:  0.9391696\n",
      "Epoch:  2553 Loss:  0.5909327 accurracy:  0.9391804\n",
      "Epoch:  2554 Loss:  0.5909304 accurracy:  0.9391911\n",
      "Epoch:  2555 Loss:  0.590928 accurracy:  0.9392019\n",
      "Epoch:  2556 Loss:  0.5909241 accurracy:  0.9392126\n",
      "Epoch:  2557 Loss:  0.5909205 accurracy:  0.93922335\n",
      "Epoch:  2558 Loss:  0.5909181 accurracy:  0.9392341\n",
      "Epoch:  2559 Loss:  0.59091574 accurracy:  0.9392448\n",
      "Epoch:  2560 Loss:  0.59091187 accurracy:  0.9392555\n",
      "Epoch:  2561 Loss:  0.5909084 accurracy:  0.9392662\n",
      "Epoch:  2562 Loss:  0.59090596 accurracy:  0.9392769\n",
      "Epoch:  2563 Loss:  0.59090304 accurracy:  0.93928754\n",
      "Epoch:  2564 Loss:  0.5908995 accurracy:  0.9392983\n",
      "Epoch:  2565 Loss:  0.59089655 accurracy:  0.9393089\n",
      "Epoch:  2566 Loss:  0.59089357 accurracy:  0.93931955\n",
      "Epoch:  2567 Loss:  0.59089077 accurracy:  0.9393302\n",
      "Epoch:  2568 Loss:  0.5908874 accurracy:  0.93934083\n",
      "Epoch:  2569 Loss:  0.59088427 accurracy:  0.9393515\n",
      "Epoch:  2570 Loss:  0.59088147 accurracy:  0.9393621\n",
      "Epoch:  2571 Loss:  0.5908785 accurracy:  0.9393727\n",
      "Epoch:  2572 Loss:  0.59087545 accurracy:  0.9393833\n",
      "Epoch:  2573 Loss:  0.5908724 accurracy:  0.93939394\n",
      "Epoch:  2574 Loss:  0.59086955 accurracy:  0.93940455\n",
      "Epoch:  2575 Loss:  0.59086597 accurracy:  0.9394151\n",
      "Epoch:  2576 Loss:  0.5908632 accurracy:  0.9394257\n",
      "Epoch:  2577 Loss:  0.59086055 accurracy:  0.93943626\n",
      "Epoch:  2578 Loss:  0.5908574 accurracy:  0.9394468\n",
      "Epoch:  2579 Loss:  0.5908538 accurracy:  0.93945736\n",
      "Epoch:  2580 Loss:  0.59085095 accurracy:  0.9394679\n",
      "Epoch:  2581 Loss:  0.5908486 accurracy:  0.93947846\n",
      "Epoch:  2582 Loss:  0.5908452 accurracy:  0.93948895\n",
      "Epoch:  2583 Loss:  0.59084165 accurracy:  0.9394995\n",
      "Epoch:  2584 Loss:  0.5908392 accurracy:  0.93951\n",
      "Epoch:  2585 Loss:  0.5908364 accurracy:  0.9395205\n",
      "Epoch:  2586 Loss:  0.59083307 accurracy:  0.93953097\n",
      "Epoch:  2587 Loss:  0.5908299 accurracy:  0.93954146\n",
      "Epoch:  2588 Loss:  0.5908271 accurracy:  0.93955195\n",
      "Epoch:  2589 Loss:  0.59082437 accurracy:  0.93956244\n",
      "Epoch:  2590 Loss:  0.5908213 accurracy:  0.9395729\n",
      "Epoch:  2591 Loss:  0.5908181 accurracy:  0.93958336\n",
      "Epoch:  2592 Loss:  0.59081477 accurracy:  0.9395938\n",
      "Epoch:  2593 Loss:  0.59081185 accurracy:  0.9396042\n",
      "Epoch:  2594 Loss:  0.5908096 accurracy:  0.93961465\n",
      "Epoch:  2595 Loss:  0.59080625 accurracy:  0.9396251\n",
      "Epoch:  2596 Loss:  0.5908029 accurracy:  0.93963546\n",
      "Epoch:  2597 Loss:  0.59080017 accurracy:  0.9396459\n",
      "Epoch:  2598 Loss:  0.59079766 accurracy:  0.93965626\n",
      "Epoch:  2599 Loss:  0.5907944 accurracy:  0.9396667\n",
      "Epoch:  2600 Loss:  0.5907906 accurracy:  0.93967706\n",
      "Epoch:  2601 Loss:  0.5907883 accurracy:  0.93968743\n",
      "Epoch:  2602 Loss:  0.59078574 accurracy:  0.9396978\n",
      "Epoch:  2603 Loss:  0.5907824 accurracy:  0.9397081\n",
      "Epoch:  2604 Loss:  0.590779 accurracy:  0.9397185\n",
      "Epoch:  2605 Loss:  0.5907763 accurracy:  0.93972886\n",
      "Epoch:  2606 Loss:  0.5907737 accurracy:  0.93973917\n",
      "Epoch:  2607 Loss:  0.59077054 accurracy:  0.9397495\n",
      "Epoch:  2608 Loss:  0.5907673 accurracy:  0.9397598\n",
      "Epoch:  2609 Loss:  0.5907642 accurracy:  0.9397701\n",
      "Epoch:  2610 Loss:  0.5907618 accurracy:  0.9397804\n",
      "Epoch:  2611 Loss:  0.59075886 accurracy:  0.9397907\n",
      "Epoch:  2612 Loss:  0.5907556 accurracy:  0.939801\n",
      "Epoch:  2613 Loss:  0.59075266 accurracy:  0.9398113\n",
      "Epoch:  2614 Loss:  0.59075 accurracy:  0.93982154\n",
      "Epoch:  2615 Loss:  0.5907467 accurracy:  0.9398318\n",
      "Epoch:  2616 Loss:  0.5907438 accurracy:  0.93984205\n",
      "Epoch:  2617 Loss:  0.590741 accurracy:  0.9398523\n",
      "Epoch:  2618 Loss:  0.59073806 accurracy:  0.93986255\n",
      "Epoch:  2619 Loss:  0.59073484 accurracy:  0.9398728\n",
      "Epoch:  2620 Loss:  0.5907322 accurracy:  0.939883\n",
      "Epoch:  2621 Loss:  0.5907295 accurracy:  0.9398932\n",
      "Epoch:  2622 Loss:  0.59072626 accurracy:  0.93990344\n",
      "Epoch:  2623 Loss:  0.590723 accurracy:  0.93991363\n",
      "Epoch:  2624 Loss:  0.5907206 accurracy:  0.9399238\n",
      "Epoch:  2625 Loss:  0.5907176 accurracy:  0.939934\n",
      "Epoch:  2626 Loss:  0.5907144 accurracy:  0.93994415\n",
      "Epoch:  2627 Loss:  0.59071136 accurracy:  0.93995434\n",
      "Epoch:  2628 Loss:  0.5907086 accurracy:  0.9399645\n",
      "Epoch:  2629 Loss:  0.59070605 accurracy:  0.93997467\n",
      "Epoch:  2630 Loss:  0.5907029 accurracy:  0.9399848\n",
      "Epoch:  2631 Loss:  0.59069943 accurracy:  0.93999493\n",
      "Epoch:  2632 Loss:  0.5906971 accurracy:  0.94000506\n",
      "Epoch:  2633 Loss:  0.5906945 accurracy:  0.9400152\n",
      "Epoch:  2634 Loss:  0.5906912 accurracy:  0.9400253\n",
      "Epoch:  2635 Loss:  0.59068817 accurracy:  0.9400354\n",
      "Epoch:  2636 Loss:  0.59068555 accurracy:  0.94004554\n",
      "Epoch:  2637 Loss:  0.59068286 accurracy:  0.9400556\n",
      "Epoch:  2638 Loss:  0.5906794 accurracy:  0.9400657\n",
      "Epoch:  2639 Loss:  0.5906761 accurracy:  0.94007576\n",
      "Epoch:  2640 Loss:  0.5906744 accurracy:  0.9400858\n",
      "Epoch:  2641 Loss:  0.59067136 accurracy:  0.9400959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2642 Loss:  0.59066767 accurracy:  0.9401059\n",
      "Epoch:  2643 Loss:  0.5906648 accurracy:  0.940116\n",
      "Epoch:  2644 Loss:  0.59066254 accurracy:  0.940126\n",
      "Epoch:  2645 Loss:  0.5906595 accurracy:  0.9401361\n",
      "Epoch:  2646 Loss:  0.5906564 accurracy:  0.9401461\n",
      "Epoch:  2647 Loss:  0.5906531 accurracy:  0.9401561\n",
      "Epoch:  2648 Loss:  0.59065086 accurracy:  0.9401661\n",
      "Epoch:  2649 Loss:  0.59064794 accurracy:  0.9401761\n",
      "Epoch:  2650 Loss:  0.5906448 accurracy:  0.9401861\n",
      "Epoch:  2651 Loss:  0.59064186 accurracy:  0.9401961\n",
      "Epoch:  2652 Loss:  0.59063894 accurracy:  0.94020605\n",
      "Epoch:  2653 Loss:  0.59063655 accurracy:  0.940216\n",
      "Epoch:  2654 Loss:  0.59063363 accurracy:  0.940226\n",
      "Epoch:  2655 Loss:  0.59063053 accurracy:  0.940236\n",
      "Epoch:  2656 Loss:  0.5906277 accurracy:  0.94024587\n",
      "Epoch:  2657 Loss:  0.590625 accurracy:  0.9402558\n",
      "Epoch:  2658 Loss:  0.59062195 accurracy:  0.9402658\n",
      "Epoch:  2659 Loss:  0.59061915 accurracy:  0.94027567\n",
      "Epoch:  2660 Loss:  0.5906162 accurracy:  0.9402856\n",
      "Epoch:  2661 Loss:  0.59061337 accurracy:  0.9402955\n",
      "Epoch:  2662 Loss:  0.5906103 accurracy:  0.9403054\n",
      "Epoch:  2663 Loss:  0.5906076 accurracy:  0.9403153\n",
      "Epoch:  2664 Loss:  0.5906054 accurracy:  0.9403252\n",
      "Epoch:  2665 Loss:  0.59060186 accurracy:  0.9403351\n",
      "Epoch:  2666 Loss:  0.5905989 accurracy:  0.9403449\n",
      "Epoch:  2667 Loss:  0.59059656 accurracy:  0.9403548\n",
      "Epoch:  2668 Loss:  0.5905939 accurracy:  0.94036466\n",
      "Epoch:  2669 Loss:  0.5905905 accurracy:  0.94037455\n",
      "Epoch:  2670 Loss:  0.5905876 accurracy:  0.9403844\n",
      "Epoch:  2671 Loss:  0.590585 accurracy:  0.9403942\n",
      "Epoch:  2672 Loss:  0.59058213 accurracy:  0.94040406\n",
      "Epoch:  2673 Loss:  0.59057933 accurracy:  0.94041383\n",
      "Epoch:  2674 Loss:  0.59057635 accurracy:  0.94042367\n",
      "Epoch:  2675 Loss:  0.5905735 accurracy:  0.9404335\n",
      "Epoch:  2676 Loss:  0.5905707 accurracy:  0.9404433\n",
      "Epoch:  2677 Loss:  0.5905679 accurracy:  0.94045305\n",
      "Epoch:  2678 Loss:  0.59056515 accurracy:  0.9404629\n",
      "Epoch:  2679 Loss:  0.59056246 accurracy:  0.94047266\n",
      "Epoch:  2680 Loss:  0.59055924 accurracy:  0.9404824\n",
      "Epoch:  2681 Loss:  0.59055674 accurracy:  0.94049215\n",
      "Epoch:  2682 Loss:  0.5905539 accurracy:  0.9405019\n",
      "Epoch:  2683 Loss:  0.59055114 accurracy:  0.9405117\n",
      "Epoch:  2684 Loss:  0.59054834 accurracy:  0.9405214\n",
      "Epoch:  2685 Loss:  0.59054554 accurracy:  0.94053113\n",
      "Epoch:  2686 Loss:  0.59054255 accurracy:  0.94054085\n",
      "Epoch:  2687 Loss:  0.5905399 accurracy:  0.94055057\n",
      "Epoch:  2688 Loss:  0.59053725 accurracy:  0.9405603\n",
      "Epoch:  2689 Loss:  0.5905337 accurracy:  0.94057\n",
      "Epoch:  2690 Loss:  0.5905311 accurracy:  0.9405797\n",
      "Epoch:  2691 Loss:  0.5905289 accurracy:  0.9405894\n",
      "Epoch:  2692 Loss:  0.59052604 accurracy:  0.9405991\n",
      "Epoch:  2693 Loss:  0.59052277 accurracy:  0.94060874\n",
      "Epoch:  2694 Loss:  0.5905199 accurracy:  0.94061846\n",
      "Epoch:  2695 Loss:  0.5905178 accurracy:  0.9406281\n",
      "Epoch:  2696 Loss:  0.59051526 accurracy:  0.94063777\n",
      "Epoch:  2697 Loss:  0.59051156 accurracy:  0.94064736\n",
      "Epoch:  2698 Loss:  0.59050876 accurracy:  0.940657\n",
      "Epoch:  2699 Loss:  0.59050643 accurracy:  0.9406667\n",
      "Epoch:  2700 Loss:  0.59050375 accurracy:  0.9406763\n",
      "Epoch:  2701 Loss:  0.5905007 accurracy:  0.9406859\n",
      "Epoch:  2702 Loss:  0.59049773 accurracy:  0.9406955\n",
      "Epoch:  2703 Loss:  0.59049517 accurracy:  0.9407051\n",
      "Epoch:  2704 Loss:  0.5904926 accurracy:  0.9407147\n",
      "Epoch:  2705 Loss:  0.5904896 accurracy:  0.9407243\n",
      "Epoch:  2706 Loss:  0.59048665 accurracy:  0.9407339\n",
      "Epoch:  2707 Loss:  0.59048426 accurracy:  0.94074345\n",
      "Epoch:  2708 Loss:  0.5904816 accurracy:  0.94075304\n",
      "Epoch:  2709 Loss:  0.59047836 accurracy:  0.9407626\n",
      "Epoch:  2710 Loss:  0.5904759 accurracy:  0.9407722\n",
      "Epoch:  2711 Loss:  0.5904731 accurracy:  0.9407817\n",
      "Epoch:  2712 Loss:  0.59047014 accurracy:  0.94079125\n",
      "Epoch:  2713 Loss:  0.59046733 accurracy:  0.9408008\n",
      "Epoch:  2714 Loss:  0.590465 accurracy:  0.9408103\n",
      "Epoch:  2715 Loss:  0.5904623 accurracy:  0.94081986\n",
      "Epoch:  2716 Loss:  0.5904591 accurracy:  0.94082934\n",
      "Epoch:  2717 Loss:  0.59045637 accurracy:  0.9408389\n",
      "Epoch:  2718 Loss:  0.5904539 accurracy:  0.94084835\n",
      "Epoch:  2719 Loss:  0.5904515 accurracy:  0.9408578\n",
      "Epoch:  2720 Loss:  0.59044844 accurracy:  0.9408673\n",
      "Epoch:  2721 Loss:  0.5904451 accurracy:  0.9408768\n",
      "Epoch:  2722 Loss:  0.59044266 accurracy:  0.94088626\n",
      "Epoch:  2723 Loss:  0.5904404 accurracy:  0.94089574\n",
      "Epoch:  2724 Loss:  0.5904375 accurracy:  0.9409052\n",
      "Epoch:  2725 Loss:  0.59043443 accurracy:  0.94091463\n",
      "Epoch:  2726 Loss:  0.5904319 accurracy:  0.9409241\n",
      "Epoch:  2727 Loss:  0.5904293 accurracy:  0.9409335\n",
      "Epoch:  2728 Loss:  0.59042674 accurracy:  0.94094294\n",
      "Epoch:  2729 Loss:  0.59042364 accurracy:  0.94095236\n",
      "Epoch:  2730 Loss:  0.5904211 accurracy:  0.9409618\n",
      "Epoch:  2731 Loss:  0.59041846 accurracy:  0.9409712\n",
      "Epoch:  2732 Loss:  0.59041595 accurracy:  0.9409806\n",
      "Epoch:  2733 Loss:  0.590413 accurracy:  0.94099003\n",
      "Epoch:  2734 Loss:  0.59040993 accurracy:  0.9409994\n",
      "Epoch:  2735 Loss:  0.59040725 accurracy:  0.94100875\n",
      "Epoch:  2736 Loss:  0.5904053 accurracy:  0.94101816\n",
      "Epoch:  2737 Loss:  0.5904024 accurracy:  0.9410275\n",
      "Epoch:  2738 Loss:  0.590399 accurracy:  0.9410369\n",
      "Epoch:  2739 Loss:  0.59039605 accurracy:  0.94104624\n",
      "Epoch:  2740 Loss:  0.5903942 accurracy:  0.9410556\n",
      "Epoch:  2741 Loss:  0.5903919 accurracy:  0.9410649\n",
      "Epoch:  2742 Loss:  0.59038824 accurracy:  0.94107425\n",
      "Epoch:  2743 Loss:  0.5903853 accurracy:  0.94108355\n",
      "Epoch:  2744 Loss:  0.5903835 accurracy:  0.9410929\n",
      "Epoch:  2745 Loss:  0.59038097 accurracy:  0.9411022\n",
      "Epoch:  2746 Loss:  0.5903774 accurracy:  0.9411115\n",
      "Epoch:  2747 Loss:  0.59037465 accurracy:  0.9411208\n",
      "Epoch:  2748 Loss:  0.59037286 accurracy:  0.9411301\n",
      "Epoch:  2749 Loss:  0.5903701 accurracy:  0.9411394\n",
      "Epoch:  2750 Loss:  0.5903668 accurracy:  0.9411487\n",
      "Epoch:  2751 Loss:  0.5903638 accurracy:  0.94115794\n",
      "Epoch:  2752 Loss:  0.5903618 accurracy:  0.94116724\n",
      "Epoch:  2753 Loss:  0.5903595 accurracy:  0.9411765\n",
      "Epoch:  2754 Loss:  0.5903563 accurracy:  0.9411857\n",
      "Epoch:  2755 Loss:  0.5903532 accurracy:  0.94119495\n",
      "Epoch:  2756 Loss:  0.59035087 accurracy:  0.9412042\n",
      "Epoch:  2757 Loss:  0.5903484 accurracy:  0.9412134\n",
      "Epoch:  2758 Loss:  0.59034544 accurracy:  0.94122267\n",
      "Epoch:  2759 Loss:  0.5903427 accurracy:  0.9412319\n",
      "Epoch:  2760 Loss:  0.59034026 accurracy:  0.9412411\n",
      "Epoch:  2761 Loss:  0.590338 accurracy:  0.9412503\n",
      "Epoch:  2762 Loss:  0.5903352 accurracy:  0.9412595\n",
      "Epoch:  2763 Loss:  0.5903318 accurracy:  0.9412687\n",
      "Epoch:  2764 Loss:  0.5903291 accurracy:  0.94127786\n",
      "Epoch:  2765 Loss:  0.5903273 accurracy:  0.94128704\n",
      "Epoch:  2766 Loss:  0.5903245 accurracy:  0.9412962\n",
      "Epoch:  2767 Loss:  0.59032124 accurracy:  0.9413054\n",
      "Epoch:  2768 Loss:  0.59031886 accurracy:  0.9413146\n",
      "Epoch:  2769 Loss:  0.5903166 accurracy:  0.9413237\n",
      "Epoch:  2770 Loss:  0.59031385 accurracy:  0.9413329\n",
      "Epoch:  2771 Loss:  0.5903108 accurracy:  0.941342\n",
      "Epoch:  2772 Loss:  0.590308 accurracy:  0.9413511\n",
      "Epoch:  2773 Loss:  0.59030586 accurracy:  0.94136024\n",
      "Epoch:  2774 Loss:  0.59030354 accurracy:  0.94136935\n",
      "Epoch:  2775 Loss:  0.5903004 accurracy:  0.9413785\n",
      "Epoch:  2776 Loss:  0.59029746 accurracy:  0.9413876\n",
      "Epoch:  2777 Loss:  0.5902951 accurracy:  0.9413967\n",
      "Epoch:  2778 Loss:  0.590293 accurracy:  0.9414058\n",
      "Epoch:  2779 Loss:  0.59029025 accurracy:  0.9414149\n",
      "Epoch:  2780 Loss:  0.5902869 accurracy:  0.94142395\n",
      "Epoch:  2781 Loss:  0.5902841 accurracy:  0.941433\n",
      "Epoch:  2782 Loss:  0.5902822 accurracy:  0.9414421\n",
      "Epoch:  2783 Loss:  0.5902799 accurracy:  0.94145113\n",
      "Epoch:  2784 Loss:  0.5902769 accurracy:  0.9414602\n",
      "Epoch:  2785 Loss:  0.59027356 accurracy:  0.94146925\n",
      "Epoch:  2786 Loss:  0.5902713 accurracy:  0.9414783\n",
      "Epoch:  2787 Loss:  0.59026927 accurracy:  0.9414873\n",
      "Epoch:  2788 Loss:  0.5902665 accurracy:  0.9414964\n",
      "Epoch:  2789 Loss:  0.59026355 accurracy:  0.9415054\n",
      "Epoch:  2790 Loss:  0.5902607 accurracy:  0.9415144\n",
      "Epoch:  2791 Loss:  0.5902586 accurracy:  0.9415234\n",
      "Epoch:  2792 Loss:  0.5902563 accurracy:  0.9415324\n",
      "Epoch:  2793 Loss:  0.5902532 accurracy:  0.9415414\n",
      "Epoch:  2794 Loss:  0.59025013 accurracy:  0.9415504\n",
      "Epoch:  2795 Loss:  0.59024787 accurracy:  0.9415594\n",
      "Epoch:  2796 Loss:  0.59024584 accurracy:  0.9415684\n",
      "Epoch:  2797 Loss:  0.5902428 accurracy:  0.9415773\n",
      "Epoch:  2798 Loss:  0.59023976 accurracy:  0.94158626\n",
      "Epoch:  2799 Loss:  0.5902375 accurracy:  0.94159526\n",
      "Epoch:  2800 Loss:  0.5902353 accurracy:  0.9416042\n",
      "Epoch:  2801 Loss:  0.59023243 accurracy:  0.94161314\n",
      "Epoch:  2802 Loss:  0.5902296 accurracy:  0.9416221\n",
      "Epoch:  2803 Loss:  0.5902271 accurracy:  0.941631\n",
      "Epoch:  2804 Loss:  0.5902247 accurracy:  0.9416399\n",
      "Epoch:  2805 Loss:  0.5902222 accurracy:  0.94164884\n",
      "Epoch:  2806 Loss:  0.59021914 accurracy:  0.9416578\n",
      "Epoch:  2807 Loss:  0.5902165 accurracy:  0.94166666\n",
      "Epoch:  2808 Loss:  0.59021455 accurracy:  0.94167554\n",
      "Epoch:  2809 Loss:  0.590212 accurracy:  0.9416845\n",
      "Epoch:  2810 Loss:  0.5902088 accurracy:  0.94169337\n",
      "Epoch:  2811 Loss:  0.5902061 accurracy:  0.94170225\n",
      "Epoch:  2812 Loss:  0.59020424 accurracy:  0.9417111\n",
      "Epoch:  2813 Loss:  0.5902013 accurracy:  0.94171995\n",
      "Epoch:  2814 Loss:  0.5901984 accurracy:  0.94172883\n",
      "Epoch:  2815 Loss:  0.59019595 accurracy:  0.9417377\n",
      "Epoch:  2816 Loss:  0.5901937 accurracy:  0.94174653\n",
      "Epoch:  2817 Loss:  0.5901912 accurracy:  0.94175535\n",
      "Epoch:  2818 Loss:  0.59018826 accurracy:  0.94176424\n",
      "Epoch:  2819 Loss:  0.590186 accurracy:  0.94177306\n",
      "Epoch:  2820 Loss:  0.59018344 accurracy:  0.9417819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2821 Loss:  0.59018064 accurracy:  0.9417907\n",
      "Epoch:  2822 Loss:  0.59017795 accurracy:  0.9417995\n",
      "Epoch:  2823 Loss:  0.5901758 accurracy:  0.9418083\n",
      "Epoch:  2824 Loss:  0.59017307 accurracy:  0.9418171\n",
      "Epoch:  2825 Loss:  0.5901707 accurracy:  0.9418259\n",
      "Epoch:  2826 Loss:  0.5901681 accurracy:  0.9418347\n",
      "Epoch:  2827 Loss:  0.5901655 accurracy:  0.94184345\n",
      "Epoch:  2828 Loss:  0.5901629 accurracy:  0.9418523\n",
      "Epoch:  2829 Loss:  0.5901605 accurracy:  0.94186103\n",
      "Epoch:  2830 Loss:  0.5901581 accurracy:  0.9418698\n",
      "Epoch:  2831 Loss:  0.5901553 accurracy:  0.94187856\n",
      "Epoch:  2832 Loss:  0.59015274 accurracy:  0.94188726\n",
      "Epoch:  2833 Loss:  0.59015024 accurracy:  0.941896\n",
      "Epoch:  2834 Loss:  0.5901479 accurracy:  0.9419048\n",
      "Epoch:  2835 Loss:  0.59014523 accurracy:  0.9419135\n",
      "Epoch:  2836 Loss:  0.59014255 accurracy:  0.94192225\n",
      "Epoch:  2837 Loss:  0.5901402 accurracy:  0.94193095\n",
      "Epoch:  2838 Loss:  0.5901376 accurracy:  0.94193965\n",
      "Epoch:  2839 Loss:  0.5901352 accurracy:  0.94194835\n",
      "Epoch:  2840 Loss:  0.5901326 accurracy:  0.94195706\n",
      "Epoch:  2841 Loss:  0.59013015 accurracy:  0.94196576\n",
      "Epoch:  2842 Loss:  0.5901276 accurracy:  0.94197446\n",
      "Epoch:  2843 Loss:  0.5901249 accurracy:  0.9419831\n",
      "Epoch:  2844 Loss:  0.5901225 accurracy:  0.9419918\n",
      "Epoch:  2845 Loss:  0.59011996 accurracy:  0.94200045\n",
      "Epoch:  2846 Loss:  0.5901174 accurracy:  0.94200915\n",
      "Epoch:  2847 Loss:  0.5901153 accurracy:  0.9420178\n",
      "Epoch:  2848 Loss:  0.59011245 accurracy:  0.94202644\n",
      "Epoch:  2849 Loss:  0.5901097 accurracy:  0.9420351\n",
      "Epoch:  2850 Loss:  0.59010756 accurracy:  0.9420437\n",
      "Epoch:  2851 Loss:  0.5901052 accurracy:  0.94205236\n",
      "Epoch:  2852 Loss:  0.59010243 accurracy:  0.942061\n",
      "Epoch:  2853 Loss:  0.5900999 accurracy:  0.9420696\n",
      "Epoch:  2854 Loss:  0.5900973 accurracy:  0.94207823\n",
      "Epoch:  2855 Loss:  0.590095 accurracy:  0.9420868\n",
      "Epoch:  2856 Loss:  0.59009254 accurracy:  0.94209546\n",
      "Epoch:  2857 Loss:  0.59009004 accurracy:  0.94210404\n",
      "Epoch:  2858 Loss:  0.5900872 accurracy:  0.9421126\n",
      "Epoch:  2859 Loss:  0.59008485 accurracy:  0.9421212\n",
      "Epoch:  2860 Loss:  0.5900824 accurracy:  0.9421298\n",
      "Epoch:  2861 Loss:  0.59008 accurracy:  0.9421384\n",
      "Epoch:  2862 Loss:  0.59007746 accurracy:  0.94214696\n",
      "Epoch:  2863 Loss:  0.59007484 accurracy:  0.9421555\n",
      "Epoch:  2864 Loss:  0.5900724 accurracy:  0.94216406\n",
      "Epoch:  2865 Loss:  0.59007007 accurracy:  0.9421726\n",
      "Epoch:  2866 Loss:  0.5900677 accurracy:  0.94218117\n",
      "Epoch:  2867 Loss:  0.59006506 accurracy:  0.9421897\n",
      "Epoch:  2868 Loss:  0.5900622 accurracy:  0.9421982\n",
      "Epoch:  2869 Loss:  0.59006006 accurracy:  0.94220674\n",
      "Epoch:  2870 Loss:  0.59005773 accurracy:  0.94221526\n",
      "Epoch:  2871 Loss:  0.59005505 accurracy:  0.9422238\n",
      "Epoch:  2872 Loss:  0.59005255 accurracy:  0.94223225\n",
      "Epoch:  2873 Loss:  0.5900505 accurracy:  0.9422408\n",
      "Epoch:  2874 Loss:  0.5900479 accurracy:  0.9422493\n",
      "Epoch:  2875 Loss:  0.5900454 accurracy:  0.94225776\n",
      "Epoch:  2876 Loss:  0.5900424 accurracy:  0.9422662\n",
      "Epoch:  2877 Loss:  0.59004045 accurracy:  0.94227475\n",
      "Epoch:  2878 Loss:  0.59003824 accurracy:  0.9422832\n",
      "Epoch:  2879 Loss:  0.5900354 accurracy:  0.9422917\n",
      "Epoch:  2880 Loss:  0.5900327 accurracy:  0.94230014\n",
      "Epoch:  2881 Loss:  0.59003055 accurracy:  0.9423086\n",
      "Epoch:  2882 Loss:  0.59002817 accurracy:  0.942317\n",
      "Epoch:  2883 Loss:  0.5900256 accurracy:  0.9423255\n",
      "Epoch:  2884 Loss:  0.59002304 accurracy:  0.94233394\n",
      "Epoch:  2885 Loss:  0.59002084 accurracy:  0.94234234\n",
      "Epoch:  2886 Loss:  0.5900181 accurracy:  0.94235075\n",
      "Epoch:  2887 Loss:  0.59001553 accurracy:  0.9423592\n",
      "Epoch:  2888 Loss:  0.5900135 accurracy:  0.9423676\n",
      "Epoch:  2889 Loss:  0.5900113 accurracy:  0.942376\n",
      "Epoch:  2890 Loss:  0.59000856 accurracy:  0.9423844\n",
      "Epoch:  2891 Loss:  0.5900058 accurracy:  0.9423928\n",
      "Epoch:  2892 Loss:  0.5900037 accurracy:  0.9424012\n",
      "Epoch:  2893 Loss:  0.5900015 accurracy:  0.9424096\n",
      "Epoch:  2894 Loss:  0.58999854 accurracy:  0.942418\n",
      "Epoch:  2895 Loss:  0.589996 accurracy:  0.9424263\n",
      "Epoch:  2896 Loss:  0.5899939 accurracy:  0.9424347\n",
      "Epoch:  2897 Loss:  0.58999175 accurracy:  0.9424431\n",
      "Epoch:  2898 Loss:  0.58998895 accurracy:  0.9424514\n",
      "Epoch:  2899 Loss:  0.58998626 accurracy:  0.94245976\n",
      "Epoch:  2900 Loss:  0.5899843 accurracy:  0.9424681\n",
      "Epoch:  2901 Loss:  0.5899821 accurracy:  0.94247645\n",
      "Epoch:  2902 Loss:  0.58997923 accurracy:  0.9424848\n",
      "Epoch:  2903 Loss:  0.5899762 accurracy:  0.94249314\n",
      "Epoch:  2904 Loss:  0.5899746 accurracy:  0.9425014\n",
      "Epoch:  2905 Loss:  0.58997256 accurracy:  0.9425098\n",
      "Epoch:  2906 Loss:  0.58996993 accurracy:  0.94251806\n",
      "Epoch:  2907 Loss:  0.5899667 accurracy:  0.94252634\n",
      "Epoch:  2908 Loss:  0.58996445 accurracy:  0.9425347\n",
      "Epoch:  2909 Loss:  0.5899628 accurracy:  0.94254297\n",
      "Epoch:  2910 Loss:  0.58996034 accurracy:  0.94255126\n",
      "Epoch:  2911 Loss:  0.5899573 accurracy:  0.94255954\n",
      "Epoch:  2912 Loss:  0.58995473 accurracy:  0.9425678\n",
      "Epoch:  2913 Loss:  0.5899532 accurracy:  0.94257605\n",
      "Epoch:  2914 Loss:  0.5899506 accurracy:  0.94258434\n",
      "Epoch:  2915 Loss:  0.5899479 accurracy:  0.9425926\n",
      "Epoch:  2916 Loss:  0.58994526 accurracy:  0.94260085\n",
      "Epoch:  2917 Loss:  0.5899433 accurracy:  0.9426091\n",
      "Epoch:  2918 Loss:  0.58994114 accurracy:  0.94261736\n",
      "Epoch:  2919 Loss:  0.58993834 accurracy:  0.9426256\n",
      "Epoch:  2920 Loss:  0.5899359 accurracy:  0.9426338\n",
      "Epoch:  2921 Loss:  0.58993363 accurracy:  0.94264203\n",
      "Epoch:  2922 Loss:  0.58993137 accurracy:  0.94265026\n",
      "Epoch:  2923 Loss:  0.58992875 accurracy:  0.9426585\n",
      "Epoch:  2924 Loss:  0.5899263 accurracy:  0.94266665\n",
      "Epoch:  2925 Loss:  0.58992416 accurracy:  0.9426749\n",
      "Epoch:  2926 Loss:  0.5899222 accurracy:  0.94268304\n",
      "Epoch:  2927 Loss:  0.58991927 accurracy:  0.94269127\n",
      "Epoch:  2928 Loss:  0.58991665 accurracy:  0.94269943\n",
      "Epoch:  2929 Loss:  0.5899145 accurracy:  0.9427076\n",
      "Epoch:  2930 Loss:  0.5899125 accurracy:  0.9427158\n",
      "Epoch:  2931 Loss:  0.58991015 accurracy:  0.942724\n",
      "Epoch:  2932 Loss:  0.58990735 accurracy:  0.94273216\n",
      "Epoch:  2933 Loss:  0.5899047 accurracy:  0.94274026\n",
      "Epoch:  2934 Loss:  0.5899029 accurracy:  0.9427484\n",
      "Epoch:  2935 Loss:  0.5899006 accurracy:  0.9427566\n",
      "Epoch:  2936 Loss:  0.5898979 accurracy:  0.9427647\n",
      "Epoch:  2937 Loss:  0.58989537 accurracy:  0.94277287\n",
      "Epoch:  2938 Loss:  0.58989316 accurracy:  0.942781\n",
      "Epoch:  2939 Loss:  0.5898911 accurracy:  0.94278914\n",
      "Epoch:  2940 Loss:  0.5898885 accurracy:  0.94279724\n",
      "Epoch:  2941 Loss:  0.58988625 accurracy:  0.94280535\n",
      "Epoch:  2942 Loss:  0.5898837 accurracy:  0.94281346\n",
      "Epoch:  2943 Loss:  0.58988136 accurracy:  0.94282156\n",
      "Epoch:  2944 Loss:  0.5898788 accurracy:  0.94282967\n",
      "Epoch:  2945 Loss:  0.5898767 accurracy:  0.9428378\n",
      "Epoch:  2946 Loss:  0.58987457 accurracy:  0.9428458\n",
      "Epoch:  2947 Loss:  0.58987206 accurracy:  0.9428539\n",
      "Epoch:  2948 Loss:  0.58986944 accurracy:  0.942862\n",
      "Epoch:  2949 Loss:  0.5898674 accurracy:  0.9428701\n",
      "Epoch:  2950 Loss:  0.5898653 accurracy:  0.9428781\n",
      "Epoch:  2951 Loss:  0.5898628 accurracy:  0.9428862\n",
      "Epoch:  2952 Loss:  0.5898599 accurracy:  0.9428942\n",
      "Epoch:  2953 Loss:  0.5898579 accurracy:  0.94290227\n",
      "Epoch:  2954 Loss:  0.58985597 accurracy:  0.9429103\n",
      "Epoch:  2955 Loss:  0.5898535 accurracy:  0.94291836\n",
      "Epoch:  2956 Loss:  0.5898508 accurracy:  0.9429264\n",
      "Epoch:  2957 Loss:  0.5898485 accurracy:  0.9429344\n",
      "Epoch:  2958 Loss:  0.58984625 accurracy:  0.94294244\n",
      "Epoch:  2959 Loss:  0.5898441 accurracy:  0.9429504\n",
      "Epoch:  2960 Loss:  0.58984166 accurracy:  0.9429585\n",
      "Epoch:  2961 Loss:  0.58983904 accurracy:  0.94296646\n",
      "Epoch:  2962 Loss:  0.58983684 accurracy:  0.94297445\n",
      "Epoch:  2963 Loss:  0.58983475 accurracy:  0.94298244\n",
      "Epoch:  2964 Loss:  0.5898324 accurracy:  0.9429904\n",
      "Epoch:  2965 Loss:  0.58983 accurracy:  0.9429984\n",
      "Epoch:  2966 Loss:  0.5898276 accurracy:  0.9430064\n",
      "Epoch:  2967 Loss:  0.5898255 accurracy:  0.9430144\n",
      "Epoch:  2968 Loss:  0.5898231 accurracy:  0.9430224\n",
      "Epoch:  2969 Loss:  0.5898206 accurracy:  0.9430303\n",
      "Epoch:  2970 Loss:  0.5898184 accurracy:  0.9430383\n",
      "Epoch:  2971 Loss:  0.58981615 accurracy:  0.9430462\n",
      "Epoch:  2972 Loss:  0.5898139 accurracy:  0.94305414\n",
      "Epoch:  2973 Loss:  0.58981144 accurracy:  0.94306207\n",
      "Epoch:  2974 Loss:  0.5898092 accurracy:  0.94307005\n",
      "Epoch:  2975 Loss:  0.589807 accurracy:  0.943078\n",
      "Epoch:  2976 Loss:  0.5898046 accurracy:  0.9430859\n",
      "Epoch:  2977 Loss:  0.5898021 accurracy:  0.9430938\n",
      "Epoch:  2978 Loss:  0.5898001 accurracy:  0.9431017\n",
      "Epoch:  2979 Loss:  0.58979785 accurracy:  0.94310963\n",
      "Epoch:  2980 Loss:  0.5897953 accurracy:  0.9431175\n",
      "Epoch:  2981 Loss:  0.58979315 accurracy:  0.9431254\n",
      "Epoch:  2982 Loss:  0.589791 accurracy:  0.9431333\n",
      "Epoch:  2983 Loss:  0.58978873 accurracy:  0.9431412\n",
      "Epoch:  2984 Loss:  0.589786 accurracy:  0.9431491\n",
      "Epoch:  2985 Loss:  0.58978367 accurracy:  0.94315696\n",
      "Epoch:  2986 Loss:  0.5897819 accurracy:  0.9431648\n",
      "Epoch:  2987 Loss:  0.5897798 accurracy:  0.9431727\n",
      "Epoch:  2988 Loss:  0.58977675 accurracy:  0.94318056\n",
      "Epoch:  2989 Loss:  0.5897744 accurracy:  0.9431884\n",
      "Epoch:  2990 Loss:  0.58977276 accurracy:  0.94319624\n",
      "Epoch:  2991 Loss:  0.58977073 accurracy:  0.9432041\n",
      "Epoch:  2992 Loss:  0.5897677 accurracy:  0.9432119\n",
      "Epoch:  2993 Loss:  0.5897649 accurracy:  0.9432198\n",
      "Epoch:  2994 Loss:  0.5897633 accurracy:  0.9432276\n",
      "Epoch:  2995 Loss:  0.58976173 accurracy:  0.9432354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2996 Loss:  0.58975893 accurracy:  0.94324327\n",
      "Epoch:  2997 Loss:  0.58975613 accurracy:  0.9432511\n",
      "Epoch:  2998 Loss:  0.5897541 accurracy:  0.9432589\n",
      "Epoch:  2999 Loss:  0.5897523 accurracy:  0.9432667\n",
      "Epoch:  3000 Loss:  0.58974993 accurracy:  0.94327444\n",
      "Epoch:  3001 Loss:  0.5897472 accurracy:  0.94328225\n",
      "Epoch:  3002 Loss:  0.589745 accurracy:  0.94329005\n",
      "Epoch:  3003 Loss:  0.58974326 accurracy:  0.9432978\n",
      "Epoch:  3004 Loss:  0.589741 accurracy:  0.9433056\n",
      "Epoch:  3005 Loss:  0.5897382 accurracy:  0.94331336\n",
      "Epoch:  3006 Loss:  0.5897359 accurracy:  0.94332117\n",
      "Epoch:  3007 Loss:  0.5897339 accurracy:  0.9433289\n",
      "Epoch:  3008 Loss:  0.5897322 accurracy:  0.94333667\n",
      "Epoch:  3009 Loss:  0.58972955 accurracy:  0.9433444\n",
      "Epoch:  3010 Loss:  0.5897267 accurracy:  0.94335216\n",
      "Epoch:  3011 Loss:  0.5897247 accurracy:  0.9433599\n",
      "Epoch:  3012 Loss:  0.5897233 accurracy:  0.9433676\n",
      "Epoch:  3013 Loss:  0.5897205 accurracy:  0.94337535\n",
      "Epoch:  3014 Loss:  0.58971786 accurracy:  0.9433831\n",
      "Epoch:  3015 Loss:  0.58971584 accurracy:  0.9433908\n",
      "Epoch:  3016 Loss:  0.58971405 accurracy:  0.94339854\n",
      "Epoch:  3017 Loss:  0.5897117 accurracy:  0.9434062\n",
      "Epoch:  3018 Loss:  0.589709 accurracy:  0.9434139\n",
      "Epoch:  3019 Loss:  0.5897067 accurracy:  0.94342166\n",
      "Epoch:  3020 Loss:  0.58970505 accurracy:  0.94342935\n",
      "Epoch:  3021 Loss:  0.5897028 accurracy:  0.94343704\n",
      "Epoch:  3022 Loss:  0.58970016 accurracy:  0.9434447\n",
      "Epoch:  3023 Loss:  0.5896976 accurracy:  0.94345236\n",
      "Epoch:  3024 Loss:  0.58969575 accurracy:  0.94346005\n",
      "Epoch:  3025 Loss:  0.58969396 accurracy:  0.94346774\n",
      "Epoch:  3026 Loss:  0.58969134 accurracy:  0.94347537\n",
      "Epoch:  3027 Loss:  0.5896889 accurracy:  0.94348305\n",
      "Epoch:  3028 Loss:  0.589687 accurracy:  0.9434907\n",
      "Epoch:  3029 Loss:  0.5896849 accurracy:  0.9434984\n",
      "Epoch:  3030 Loss:  0.58968246 accurracy:  0.943506\n",
      "Epoch:  3031 Loss:  0.58967996 accurracy:  0.94351363\n",
      "Epoch:  3032 Loss:  0.58967817 accurracy:  0.94352126\n",
      "Epoch:  3033 Loss:  0.58967614 accurracy:  0.9435289\n",
      "Epoch:  3034 Loss:  0.58967376 accurracy:  0.9435365\n",
      "Epoch:  3035 Loss:  0.5896712 accurracy:  0.94354415\n",
      "Epoch:  3036 Loss:  0.58966905 accurracy:  0.9435518\n",
      "Epoch:  3037 Loss:  0.58966714 accurracy:  0.94355935\n",
      "Epoch:  3038 Loss:  0.58966476 accurracy:  0.943567\n",
      "Epoch:  3039 Loss:  0.5896625 accurracy:  0.94357455\n",
      "Epoch:  3040 Loss:  0.58966035 accurracy:  0.9435822\n",
      "Epoch:  3041 Loss:  0.5896583 accurracy:  0.94358975\n",
      "Epoch:  3042 Loss:  0.5896558 accurracy:  0.9435973\n",
      "Epoch:  3043 Loss:  0.5896537 accurracy:  0.9436049\n",
      "Epoch:  3044 Loss:  0.58965164 accurracy:  0.94361246\n",
      "Epoch:  3045 Loss:  0.5896495 accurracy:  0.94362\n",
      "Epoch:  3046 Loss:  0.5896471 accurracy:  0.9436276\n",
      "Epoch:  3047 Loss:  0.58964473 accurracy:  0.94363517\n",
      "Epoch:  3048 Loss:  0.58964294 accurracy:  0.94364274\n",
      "Epoch:  3049 Loss:  0.58964086 accurracy:  0.94365025\n",
      "Epoch:  3050 Loss:  0.5896383 accurracy:  0.9436578\n",
      "Epoch:  3051 Loss:  0.58963567 accurracy:  0.9436654\n",
      "Epoch:  3052 Loss:  0.5896342 accurracy:  0.9436729\n",
      "Epoch:  3053 Loss:  0.58963215 accurracy:  0.9436804\n",
      "Epoch:  3054 Loss:  0.58962923 accurracy:  0.9436879\n",
      "Epoch:  3055 Loss:  0.5896267 accurracy:  0.9436955\n",
      "Epoch:  3056 Loss:  0.5896253 accurracy:  0.943703\n",
      "Epoch:  3057 Loss:  0.58962363 accurracy:  0.9437105\n",
      "Epoch:  3058 Loss:  0.5896208 accurracy:  0.943718\n",
      "Epoch:  3059 Loss:  0.58961815 accurracy:  0.94372547\n",
      "Epoch:  3060 Loss:  0.5896165 accurracy:  0.943733\n",
      "Epoch:  3061 Loss:  0.5896147 accurracy:  0.9437405\n",
      "Epoch:  3062 Loss:  0.58961225 accurracy:  0.94374794\n",
      "Epoch:  3063 Loss:  0.5896098 accurracy:  0.94375545\n",
      "Epoch:  3064 Loss:  0.58960766 accurracy:  0.9437629\n",
      "Epoch:  3065 Loss:  0.58960587 accurracy:  0.9437704\n",
      "Epoch:  3066 Loss:  0.58960354 accurracy:  0.94377786\n",
      "Epoch:  3067 Loss:  0.5896013 accurracy:  0.9437853\n",
      "Epoch:  3068 Loss:  0.5895991 accurracy:  0.94379276\n",
      "Epoch:  3069 Loss:  0.58959717 accurracy:  0.9438002\n",
      "Epoch:  3070 Loss:  0.5895948 accurracy:  0.94380766\n",
      "Epoch:  3071 Loss:  0.58959264 accurracy:  0.9438151\n",
      "Epoch:  3072 Loss:  0.58959043 accurracy:  0.94382256\n",
      "Epoch:  3073 Loss:  0.58958846 accurracy:  0.94382995\n",
      "Epoch:  3074 Loss:  0.5895862 accurracy:  0.9438374\n",
      "Epoch:  3075 Loss:  0.589584 accurracy:  0.9438448\n",
      "Epoch:  3076 Loss:  0.589582 accurracy:  0.94385225\n",
      "Epoch:  3077 Loss:  0.5895798 accurracy:  0.94385964\n",
      "Epoch:  3078 Loss:  0.58957744 accurracy:  0.943867\n",
      "Epoch:  3079 Loss:  0.58957535 accurracy:  0.9438745\n",
      "Epoch:  3080 Loss:  0.5895735 accurracy:  0.94388187\n",
      "Epoch:  3081 Loss:  0.58957136 accurracy:  0.94388926\n",
      "Epoch:  3082 Loss:  0.5895689 accurracy:  0.94389665\n",
      "Epoch:  3083 Loss:  0.5895666 accurracy:  0.94390404\n",
      "Epoch:  3084 Loss:  0.58956486 accurracy:  0.9439114\n",
      "Epoch:  3085 Loss:  0.58956283 accurracy:  0.94391876\n",
      "Epoch:  3086 Loss:  0.58956045 accurracy:  0.94392616\n",
      "Epoch:  3087 Loss:  0.589558 accurracy:  0.9439335\n",
      "Epoch:  3088 Loss:  0.58955604 accurracy:  0.9439409\n",
      "Epoch:  3089 Loss:  0.58955425 accurracy:  0.9439482\n",
      "Epoch:  3090 Loss:  0.58955204 accurracy:  0.94395554\n",
      "Epoch:  3091 Loss:  0.5895495 accurracy:  0.94396293\n",
      "Epoch:  3092 Loss:  0.5895475 accurracy:  0.94397026\n",
      "Epoch:  3093 Loss:  0.58954597 accurracy:  0.9439776\n",
      "Epoch:  3094 Loss:  0.5895436 accurracy:  0.9439849\n",
      "Epoch:  3095 Loss:  0.5895408 accurracy:  0.94399226\n",
      "Epoch:  3096 Loss:  0.5895388 accurracy:  0.9439996\n",
      "Epoch:  3097 Loss:  0.58953744 accurracy:  0.94400686\n",
      "Epoch:  3098 Loss:  0.5895353 accurracy:  0.9440142\n",
      "Epoch:  3099 Loss:  0.58953214 accurracy:  0.9440215\n",
      "Epoch:  3100 Loss:  0.5895302 accurracy:  0.9440288\n",
      "Epoch:  3101 Loss:  0.58952886 accurracy:  0.9440361\n",
      "Epoch:  3102 Loss:  0.5895268 accurracy:  0.9440434\n",
      "Epoch:  3103 Loss:  0.58952403 accurracy:  0.94405067\n",
      "Epoch:  3104 Loss:  0.58952165 accurracy:  0.94405794\n",
      "Epoch:  3105 Loss:  0.58952016 accurracy:  0.9440653\n",
      "Epoch:  3106 Loss:  0.5895183 accurracy:  0.94407254\n",
      "Epoch:  3107 Loss:  0.5895157 accurracy:  0.9440798\n",
      "Epoch:  3108 Loss:  0.58951354 accurracy:  0.9440871\n",
      "Epoch:  3109 Loss:  0.58951163 accurracy:  0.9440943\n",
      "Epoch:  3110 Loss:  0.58950955 accurracy:  0.9441016\n",
      "Epoch:  3111 Loss:  0.58950716 accurracy:  0.94410884\n",
      "Epoch:  3112 Loss:  0.58950526 accurracy:  0.94411606\n",
      "Epoch:  3113 Loss:  0.5895031 accurracy:  0.9441233\n",
      "Epoch:  3114 Loss:  0.5895012 accurracy:  0.94413054\n",
      "Epoch:  3115 Loss:  0.58949906 accurracy:  0.9441378\n",
      "Epoch:  3116 Loss:  0.58949673 accurracy:  0.944145\n",
      "Epoch:  3117 Loss:  0.58949476 accurracy:  0.94415224\n",
      "Epoch:  3118 Loss:  0.5894926 accurracy:  0.94415945\n",
      "Epoch:  3119 Loss:  0.58949053 accurracy:  0.94416666\n",
      "Epoch:  3120 Loss:  0.58948874 accurracy:  0.9441739\n",
      "Epoch:  3121 Loss:  0.5894862 accurracy:  0.9441811\n",
      "Epoch:  3122 Loss:  0.58948404 accurracy:  0.9441883\n",
      "Epoch:  3123 Loss:  0.58948225 accurracy:  0.94419545\n",
      "Epoch:  3124 Loss:  0.5894803 accurracy:  0.94420266\n",
      "Epoch:  3125 Loss:  0.5894781 accurracy:  0.9442099\n",
      "Epoch:  3126 Loss:  0.58947575 accurracy:  0.944217\n",
      "Epoch:  3127 Loss:  0.5894737 accurracy:  0.94422424\n",
      "Epoch:  3128 Loss:  0.5894718 accurracy:  0.9442314\n",
      "Epoch:  3129 Loss:  0.5894698 accurracy:  0.94423854\n",
      "Epoch:  3130 Loss:  0.5894676 accurracy:  0.9442457\n",
      "Epoch:  3131 Loss:  0.5894653 accurracy:  0.94425285\n",
      "Epoch:  3132 Loss:  0.5894633 accurracy:  0.94426\n",
      "Epoch:  3133 Loss:  0.5894615 accurracy:  0.94426715\n",
      "Epoch:  3134 Loss:  0.5894595 accurracy:  0.9442743\n",
      "Epoch:  3135 Loss:  0.5894573 accurracy:  0.94428146\n",
      "Epoch:  3136 Loss:  0.58945477 accurracy:  0.9442886\n",
      "Epoch:  3137 Loss:  0.5894531 accurracy:  0.9442957\n",
      "Epoch:  3138 Loss:  0.58945125 accurracy:  0.94430286\n",
      "Epoch:  3139 Loss:  0.5894487 accurracy:  0.94430995\n",
      "Epoch:  3140 Loss:  0.58944666 accurracy:  0.9443171\n",
      "Epoch:  3141 Loss:  0.5894449 accurracy:  0.9443242\n",
      "Epoch:  3142 Loss:  0.58944297 accurracy:  0.94433135\n",
      "Epoch:  3143 Loss:  0.58944076 accurracy:  0.94433844\n",
      "Epoch:  3144 Loss:  0.5894388 accurracy:  0.94434553\n",
      "Epoch:  3145 Loss:  0.5894364 accurracy:  0.9443526\n",
      "Epoch:  3146 Loss:  0.58943444 accurracy:  0.9443597\n",
      "Epoch:  3147 Loss:  0.58943266 accurracy:  0.9443668\n",
      "Epoch:  3148 Loss:  0.58943063 accurracy:  0.94437385\n",
      "Epoch:  3149 Loss:  0.5894283 accurracy:  0.94438094\n",
      "Epoch:  3150 Loss:  0.5894263 accurracy:  0.94438803\n",
      "Epoch:  3151 Loss:  0.58942413 accurracy:  0.94439507\n",
      "Epoch:  3152 Loss:  0.5894223 accurracy:  0.94440216\n",
      "Epoch:  3153 Loss:  0.5894202 accurracy:  0.9444092\n",
      "Epoch:  3154 Loss:  0.5894183 accurracy:  0.9444163\n",
      "Epoch:  3155 Loss:  0.5894158 accurracy:  0.9444233\n",
      "Epoch:  3156 Loss:  0.58941424 accurracy:  0.94443035\n",
      "Epoch:  3157 Loss:  0.58941215 accurracy:  0.9444374\n",
      "Epoch:  3158 Loss:  0.58940977 accurracy:  0.9444444\n",
      "Epoch:  3159 Loss:  0.58940774 accurracy:  0.94445145\n",
      "Epoch:  3160 Loss:  0.58940583 accurracy:  0.9444585\n",
      "Epoch:  3161 Loss:  0.5894039 accurracy:  0.9444655\n",
      "Epoch:  3162 Loss:  0.5894018 accurracy:  0.94447255\n",
      "Epoch:  3163 Loss:  0.5893996 accurracy:  0.9444796\n",
      "Epoch:  3164 Loss:  0.5893977 accurracy:  0.94448656\n",
      "Epoch:  3165 Loss:  0.58939576 accurracy:  0.9444936\n",
      "Epoch:  3166 Loss:  0.5893936 accurracy:  0.94450057\n",
      "Epoch:  3167 Loss:  0.58939135 accurracy:  0.9445076\n",
      "Epoch:  3168 Loss:  0.58938956 accurracy:  0.9445146\n",
      "Epoch:  3169 Loss:  0.5893875 accurracy:  0.94452155\n",
      "Epoch:  3170 Loss:  0.58938575 accurracy:  0.9445285\n",
      "Epoch:  3171 Loss:  0.5893835 accurracy:  0.9445355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3172 Loss:  0.5893813 accurracy:  0.94454247\n",
      "Epoch:  3173 Loss:  0.5893794 accurracy:  0.94454944\n",
      "Epoch:  3174 Loss:  0.5893776 accurracy:  0.9445564\n",
      "Epoch:  3175 Loss:  0.58937544 accurracy:  0.9445634\n",
      "Epoch:  3176 Loss:  0.589373 accurracy:  0.94457036\n",
      "Epoch:  3177 Loss:  0.5893714 accurracy:  0.9445773\n",
      "Epoch:  3178 Loss:  0.5893696 accurracy:  0.94458425\n",
      "Epoch:  3179 Loss:  0.5893676 accurracy:  0.9445912\n",
      "Epoch:  3180 Loss:  0.58936536 accurracy:  0.94459814\n",
      "Epoch:  3181 Loss:  0.58936316 accurracy:  0.94460505\n",
      "Epoch:  3182 Loss:  0.5893613 accurracy:  0.944612\n",
      "Epoch:  3183 Loss:  0.58935964 accurracy:  0.94461894\n",
      "Epoch:  3184 Loss:  0.5893574 accurracy:  0.94462585\n",
      "Epoch:  3185 Loss:  0.5893551 accurracy:  0.94463277\n",
      "Epoch:  3186 Loss:  0.5893533 accurracy:  0.9446397\n",
      "Epoch:  3187 Loss:  0.5893515 accurracy:  0.9446466\n",
      "Epoch:  3188 Loss:  0.5893494 accurracy:  0.9446535\n",
      "Epoch:  3189 Loss:  0.5893472 accurracy:  0.9446604\n",
      "Epoch:  3190 Loss:  0.58934486 accurracy:  0.9446673\n",
      "Epoch:  3191 Loss:  0.5893433 accurracy:  0.9446742\n",
      "Epoch:  3192 Loss:  0.5893416 accurracy:  0.94468105\n",
      "Epoch:  3193 Loss:  0.5893393 accurracy:  0.94468796\n",
      "Epoch:  3194 Loss:  0.58933717 accurracy:  0.9446948\n",
      "Epoch:  3195 Loss:  0.5893353 accurracy:  0.94470173\n",
      "Epoch:  3196 Loss:  0.5893335 accurracy:  0.9447086\n",
      "Epoch:  3197 Loss:  0.58933145 accurracy:  0.94471544\n",
      "Epoch:  3198 Loss:  0.5893291 accurracy:  0.9447223\n",
      "Epoch:  3199 Loss:  0.5893272 accurracy:  0.94472915\n",
      "Epoch:  3200 Loss:  0.5893255 accurracy:  0.944736\n",
      "Epoch:  3201 Loss:  0.5893234 accurracy:  0.94474286\n",
      "Epoch:  3202 Loss:  0.5893214 accurracy:  0.9447497\n",
      "Epoch:  3203 Loss:  0.58931947 accurracy:  0.94475657\n",
      "Epoch:  3204 Loss:  0.58931744 accurracy:  0.94476336\n",
      "Epoch:  3205 Loss:  0.58931553 accurracy:  0.9447702\n",
      "Epoch:  3206 Loss:  0.5893135 accurracy:  0.9447771\n",
      "Epoch:  3207 Loss:  0.5893115 accurracy:  0.94478387\n",
      "Epoch:  3208 Loss:  0.58930945 accurracy:  0.9447907\n",
      "Epoch:  3209 Loss:  0.5893075 accurracy:  0.9447975\n",
      "Epoch:  3210 Loss:  0.5893055 accurracy:  0.9448043\n",
      "Epoch:  3211 Loss:  0.5893038 accurracy:  0.9448111\n",
      "Epoch:  3212 Loss:  0.5893018 accurracy:  0.9448179\n",
      "Epoch:  3213 Loss:  0.5892994 accurracy:  0.9448247\n",
      "Epoch:  3214 Loss:  0.5892975 accurracy:  0.9448315\n",
      "Epoch:  3215 Loss:  0.5892958 accurracy:  0.9448383\n",
      "Epoch:  3216 Loss:  0.589294 accurracy:  0.9448451\n",
      "Epoch:  3217 Loss:  0.58929163 accurracy:  0.9448519\n",
      "Epoch:  3218 Loss:  0.5892896 accurracy:  0.9448587\n",
      "Epoch:  3219 Loss:  0.5892879 accurracy:  0.9448654\n",
      "Epoch:  3220 Loss:  0.5892859 accurracy:  0.9448722\n",
      "Epoch:  3221 Loss:  0.58928394 accurracy:  0.94487894\n",
      "Epoch:  3222 Loss:  0.5892817 accurracy:  0.94488573\n",
      "Epoch:  3223 Loss:  0.5892802 accurracy:  0.94489247\n",
      "Epoch:  3224 Loss:  0.58927816 accurracy:  0.9448992\n",
      "Epoch:  3225 Loss:  0.58927596 accurracy:  0.944906\n",
      "Epoch:  3226 Loss:  0.58927417 accurracy:  0.94491273\n",
      "Epoch:  3227 Loss:  0.58927214 accurracy:  0.94491947\n",
      "Epoch:  3228 Loss:  0.5892705 accurracy:  0.9449262\n",
      "Epoch:  3229 Loss:  0.58926845 accurracy:  0.94493294\n",
      "Epoch:  3230 Loss:  0.58926636 accurracy:  0.9449397\n",
      "Epoch:  3231 Loss:  0.5892647 accurracy:  0.94494635\n",
      "Epoch:  3232 Loss:  0.5892624 accurracy:  0.9449531\n",
      "Epoch:  3233 Loss:  0.5892603 accurracy:  0.9449598\n",
      "Epoch:  3234 Loss:  0.58925843 accurracy:  0.9449665\n",
      "Epoch:  3235 Loss:  0.58925664 accurracy:  0.94497323\n",
      "Epoch:  3236 Loss:  0.58925503 accurracy:  0.9449799\n",
      "Epoch:  3237 Loss:  0.5892527 accurracy:  0.94498664\n",
      "Epoch:  3238 Loss:  0.58925045 accurracy:  0.9449933\n",
      "Epoch:  3239 Loss:  0.58924884 accurracy:  0.945\n",
      "Epoch:  3240 Loss:  0.58924747 accurracy:  0.94500667\n",
      "Epoch:  3241 Loss:  0.589245 accurracy:  0.94501334\n",
      "Epoch:  3242 Loss:  0.58924264 accurracy:  0.94502\n",
      "Epoch:  3243 Loss:  0.5892409 accurracy:  0.9450267\n",
      "Epoch:  3244 Loss:  0.5892395 accurracy:  0.9450334\n",
      "Epoch:  3245 Loss:  0.5892372 accurracy:  0.94504005\n",
      "Epoch:  3246 Loss:  0.58923495 accurracy:  0.9450467\n",
      "Epoch:  3247 Loss:  0.58923334 accurracy:  0.94505334\n",
      "Epoch:  3248 Loss:  0.5892317 accurracy:  0.94506\n",
      "Epoch:  3249 Loss:  0.58922964 accurracy:  0.9450667\n",
      "Epoch:  3250 Loss:  0.5892273 accurracy:  0.9450733\n",
      "Epoch:  3251 Loss:  0.58922553 accurracy:  0.9450799\n",
      "Epoch:  3252 Loss:  0.589224 accurracy:  0.9450866\n",
      "Epoch:  3253 Loss:  0.5892221 accurracy:  0.9450932\n",
      "Epoch:  3254 Loss:  0.5892198 accurracy:  0.94509983\n",
      "Epoch:  3255 Loss:  0.5892178 accurracy:  0.94510645\n",
      "Epoch:  3256 Loss:  0.58921605 accurracy:  0.94511306\n",
      "Epoch:  3257 Loss:  0.5892144 accurracy:  0.9451197\n",
      "Epoch:  3258 Loss:  0.5892124 accurracy:  0.9451263\n",
      "Epoch:  3259 Loss:  0.58921 accurracy:  0.9451329\n",
      "Epoch:  3260 Loss:  0.58920825 accurracy:  0.9451395\n",
      "Epoch:  3261 Loss:  0.5892066 accurracy:  0.94514614\n",
      "Epoch:  3262 Loss:  0.58920485 accurracy:  0.9451527\n",
      "Epoch:  3263 Loss:  0.58920264 accurracy:  0.9451593\n",
      "Epoch:  3264 Loss:  0.5892006 accurracy:  0.9451659\n",
      "Epoch:  3265 Loss:  0.5891987 accurracy:  0.9451725\n",
      "Epoch:  3266 Loss:  0.5891969 accurracy:  0.94517905\n",
      "Epoch:  3267 Loss:  0.58919513 accurracy:  0.94518566\n",
      "Epoch:  3268 Loss:  0.5891932 accurracy:  0.9451922\n",
      "Epoch:  3269 Loss:  0.58919084 accurracy:  0.9451988\n",
      "Epoch:  3270 Loss:  0.58918923 accurracy:  0.94520533\n",
      "Epoch:  3271 Loss:  0.5891876 accurracy:  0.9452119\n",
      "Epoch:  3272 Loss:  0.5891857 accurracy:  0.94521844\n",
      "Epoch:  3273 Loss:  0.5891834 accurracy:  0.945225\n",
      "Epoch:  3274 Loss:  0.5891816 accurracy:  0.94523156\n",
      "Epoch:  3275 Loss:  0.58918 accurracy:  0.9452381\n",
      "Epoch:  3276 Loss:  0.5891781 accurracy:  0.9452446\n",
      "Epoch:  3277 Loss:  0.58917594 accurracy:  0.94525117\n",
      "Epoch:  3278 Loss:  0.5891739 accurracy:  0.9452577\n",
      "Epoch:  3279 Loss:  0.5891723 accurracy:  0.9452642\n",
      "Epoch:  3280 Loss:  0.58917046 accurracy:  0.9452708\n",
      "Epoch:  3281 Loss:  0.5891685 accurracy:  0.9452773\n",
      "Epoch:  3282 Loss:  0.5891664 accurracy:  0.9452838\n",
      "Epoch:  3283 Loss:  0.5891646 accurracy:  0.94529027\n",
      "Epoch:  3284 Loss:  0.58916295 accurracy:  0.9452968\n",
      "Epoch:  3285 Loss:  0.589161 accurracy:  0.9453033\n",
      "Epoch:  3286 Loss:  0.589159 accurracy:  0.9453098\n",
      "Epoch:  3287 Loss:  0.58915734 accurracy:  0.9453163\n",
      "Epoch:  3288 Loss:  0.5891553 accurracy:  0.9453228\n",
      "Epoch:  3289 Loss:  0.58915335 accurracy:  0.9453293\n",
      "Epoch:  3290 Loss:  0.5891514 accurracy:  0.94533575\n",
      "Epoch:  3291 Loss:  0.5891496 accurracy:  0.94534224\n",
      "Epoch:  3292 Loss:  0.58914787 accurracy:  0.94534874\n",
      "Epoch:  3293 Loss:  0.5891461 accurracy:  0.9453552\n",
      "Epoch:  3294 Loss:  0.589144 accurracy:  0.9453617\n",
      "Epoch:  3295 Loss:  0.5891422 accurracy:  0.9453681\n",
      "Epoch:  3296 Loss:  0.58914024 accurracy:  0.9453746\n",
      "Epoch:  3297 Loss:  0.5891387 accurracy:  0.94538105\n",
      "Epoch:  3298 Loss:  0.5891365 accurracy:  0.9453875\n",
      "Epoch:  3299 Loss:  0.58913445 accurracy:  0.9453939\n",
      "Epoch:  3300 Loss:  0.5891327 accurracy:  0.94540036\n",
      "Epoch:  3301 Loss:  0.58913106 accurracy:  0.9454068\n",
      "Epoch:  3302 Loss:  0.5891291 accurracy:  0.94541323\n",
      "Epoch:  3303 Loss:  0.58912724 accurracy:  0.94541967\n",
      "Epoch:  3304 Loss:  0.58912534 accurracy:  0.9454261\n",
      "Epoch:  3305 Loss:  0.5891235 accurracy:  0.94543254\n",
      "Epoch:  3306 Loss:  0.5891217 accurracy:  0.945439\n",
      "Epoch:  3307 Loss:  0.58911985 accurracy:  0.94544536\n",
      "Epoch:  3308 Loss:  0.589118 accurracy:  0.9454518\n",
      "Epoch:  3309 Loss:  0.58911604 accurracy:  0.94545823\n",
      "Epoch:  3310 Loss:  0.58911425 accurracy:  0.9454646\n",
      "Epoch:  3311 Loss:  0.5891126 accurracy:  0.945471\n",
      "Epoch:  3312 Loss:  0.5891105 accurracy:  0.9454774\n",
      "Epoch:  3313 Loss:  0.58910847 accurracy:  0.9454838\n",
      "Epoch:  3314 Loss:  0.58910674 accurracy:  0.9454902\n",
      "Epoch:  3315 Loss:  0.58910537 accurracy:  0.94549656\n",
      "Epoch:  3316 Loss:  0.58910334 accurracy:  0.94550294\n",
      "Epoch:  3317 Loss:  0.5891011 accurracy:  0.9455093\n",
      "Epoch:  3318 Loss:  0.58909917 accurracy:  0.9455157\n",
      "Epoch:  3319 Loss:  0.5890978 accurracy:  0.94552207\n",
      "Epoch:  3320 Loss:  0.5890962 accurracy:  0.94552845\n",
      "Epoch:  3321 Loss:  0.589094 accurracy:  0.9455348\n",
      "Epoch:  3322 Loss:  0.5890917 accurracy:  0.9455412\n",
      "Epoch:  3323 Loss:  0.5890901 accurracy:  0.9455475\n",
      "Epoch:  3324 Loss:  0.58908886 accurracy:  0.9455539\n",
      "Epoch:  3325 Loss:  0.5890868 accurracy:  0.9455602\n",
      "Epoch:  3326 Loss:  0.58908457 accurracy:  0.9455666\n",
      "Epoch:  3327 Loss:  0.5890828 accurracy:  0.9455729\n",
      "Epoch:  3328 Loss:  0.58908135 accurracy:  0.94557923\n",
      "Epoch:  3329 Loss:  0.5890792 accurracy:  0.9455856\n",
      "Epoch:  3330 Loss:  0.58907735 accurracy:  0.9455919\n",
      "Epoch:  3331 Loss:  0.58907545 accurracy:  0.94559824\n",
      "Epoch:  3332 Loss:  0.58907384 accurracy:  0.94560456\n",
      "Epoch:  3333 Loss:  0.5890721 accurracy:  0.9456109\n",
      "Epoch:  3334 Loss:  0.58907 accurracy:  0.9456172\n",
      "Epoch:  3335 Loss:  0.5890682 accurracy:  0.9456235\n",
      "Epoch:  3336 Loss:  0.5890663 accurracy:  0.94562984\n",
      "Epoch:  3337 Loss:  0.5890647 accurracy:  0.9456361\n",
      "Epoch:  3338 Loss:  0.58906275 accurracy:  0.9456424\n",
      "Epoch:  3339 Loss:  0.58906084 accurracy:  0.9456487\n",
      "Epoch:  3340 Loss:  0.5890591 accurracy:  0.945655\n",
      "Epoch:  3341 Loss:  0.58905727 accurracy:  0.9456613\n",
      "Epoch:  3342 Loss:  0.5890557 accurracy:  0.94566756\n",
      "Epoch:  3343 Loss:  0.58905375 accurracy:  0.9456738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3344 Loss:  0.5890518 accurracy:  0.94568014\n",
      "Epoch:  3345 Loss:  0.58904994 accurracy:  0.9456864\n",
      "Epoch:  3346 Loss:  0.5890485 accurracy:  0.94569266\n",
      "Epoch:  3347 Loss:  0.5890467 accurracy:  0.9456989\n",
      "Epoch:  3348 Loss:  0.5890446 accurracy:  0.9457052\n",
      "Epoch:  3349 Loss:  0.5890428 accurracy:  0.94571143\n",
      "Epoch:  3350 Loss:  0.5890411 accurracy:  0.9457177\n",
      "Epoch:  3351 Loss:  0.5890394 accurracy:  0.94572395\n",
      "Epoch:  3352 Loss:  0.58903736 accurracy:  0.9457302\n",
      "Epoch:  3353 Loss:  0.5890353 accurracy:  0.9457364\n",
      "Epoch:  3354 Loss:  0.58903366 accurracy:  0.94574267\n",
      "Epoch:  3355 Loss:  0.58903223 accurracy:  0.9457489\n",
      "Epoch:  3356 Loss:  0.5890303 accurracy:  0.9457551\n",
      "Epoch:  3357 Loss:  0.58902824 accurracy:  0.9457614\n",
      "Epoch:  3358 Loss:  0.58902633 accurracy:  0.9457676\n",
      "Epoch:  3359 Loss:  0.58902484 accurracy:  0.9457738\n",
      "Epoch:  3360 Loss:  0.58902305 accurracy:  0.94578004\n",
      "Epoch:  3361 Loss:  0.5890211 accurracy:  0.94578624\n",
      "Epoch:  3362 Loss:  0.5890192 accurracy:  0.94579244\n",
      "Epoch:  3363 Loss:  0.5890176 accurracy:  0.94579864\n",
      "Epoch:  3364 Loss:  0.58901596 accurracy:  0.94580483\n",
      "Epoch:  3365 Loss:  0.5890142 accurracy:  0.94581103\n",
      "Epoch:  3366 Loss:  0.589012 accurracy:  0.94581723\n",
      "Epoch:  3367 Loss:  0.58901024 accurracy:  0.94582343\n",
      "Epoch:  3368 Loss:  0.58900887 accurracy:  0.94582963\n",
      "Epoch:  3369 Loss:  0.58900696 accurracy:  0.9458358\n",
      "Epoch:  3370 Loss:  0.5890052 accurracy:  0.94584197\n",
      "Epoch:  3371 Loss:  0.58900315 accurracy:  0.94584817\n",
      "Epoch:  3372 Loss:  0.58900154 accurracy:  0.9458543\n",
      "Epoch:  3373 Loss:  0.5889998 accurracy:  0.9458605\n",
      "Epoch:  3374 Loss:  0.5889978 accurracy:  0.94586664\n",
      "Epoch:  3375 Loss:  0.5889962 accurracy:  0.94587284\n",
      "Epoch:  3376 Loss:  0.5889943 accurracy:  0.945879\n",
      "Epoch:  3377 Loss:  0.58899283 accurracy:  0.9458851\n",
      "Epoch:  3378 Loss:  0.5889908 accurracy:  0.94589126\n",
      "Epoch:  3379 Loss:  0.588989 accurracy:  0.94589746\n",
      "Epoch:  3380 Loss:  0.58898735 accurracy:  0.9459036\n",
      "Epoch:  3381 Loss:  0.5889858 accurracy:  0.94590974\n",
      "Epoch:  3382 Loss:  0.58898365 accurracy:  0.9459159\n",
      "Epoch:  3383 Loss:  0.5889818 accurracy:  0.94592196\n",
      "Epoch:  3384 Loss:  0.5889803 accurracy:  0.9459281\n",
      "Epoch:  3385 Loss:  0.58897865 accurracy:  0.94593424\n",
      "Epoch:  3386 Loss:  0.5889768 accurracy:  0.9459404\n",
      "Epoch:  3387 Loss:  0.5889748 accurracy:  0.94594646\n",
      "Epoch:  3388 Loss:  0.588973 accurracy:  0.9459526\n",
      "Epoch:  3389 Loss:  0.5889712 accurracy:  0.9459587\n",
      "Epoch:  3390 Loss:  0.5889698 accurracy:  0.9459648\n",
      "Epoch:  3391 Loss:  0.5889679 accurracy:  0.9459709\n",
      "Epoch:  3392 Loss:  0.58896595 accurracy:  0.94597703\n",
      "Epoch:  3393 Loss:  0.58896405 accurracy:  0.9459831\n",
      "Epoch:  3394 Loss:  0.58896273 accurracy:  0.9459892\n",
      "Epoch:  3395 Loss:  0.588961 accurracy:  0.9459953\n",
      "Epoch:  3396 Loss:  0.58895886 accurracy:  0.94600135\n",
      "Epoch:  3397 Loss:  0.58895683 accurracy:  0.94600743\n",
      "Epoch:  3398 Loss:  0.5889555 accurracy:  0.9460135\n",
      "Epoch:  3399 Loss:  0.58895415 accurracy:  0.9460196\n",
      "Epoch:  3400 Loss:  0.58895224 accurracy:  0.94602567\n",
      "Epoch:  3401 Loss:  0.5889501 accurracy:  0.94603175\n",
      "Epoch:  3402 Loss:  0.5889484 accurracy:  0.9460378\n",
      "Epoch:  3403 Loss:  0.58894706 accurracy:  0.94604385\n",
      "Epoch:  3404 Loss:  0.5889454 accurracy:  0.9460499\n",
      "Epoch:  3405 Loss:  0.5889431 accurracy:  0.946056\n",
      "Epoch:  3406 Loss:  0.58894104 accurracy:  0.946062\n",
      "Epoch:  3407 Loss:  0.5889398 accurracy:  0.94606805\n",
      "Epoch:  3408 Loss:  0.5889383 accurracy:  0.9460741\n",
      "Epoch:  3409 Loss:  0.58893627 accurracy:  0.94608015\n",
      "Epoch:  3410 Loss:  0.5889343 accurracy:  0.94608617\n",
      "Epoch:  3411 Loss:  0.5889328 accurracy:  0.94609225\n",
      "Epoch:  3412 Loss:  0.5889311 accurracy:  0.94609827\n",
      "Epoch:  3413 Loss:  0.58892936 accurracy:  0.9461043\n",
      "Epoch:  3414 Loss:  0.58892757 accurracy:  0.9461103\n",
      "Epoch:  3415 Loss:  0.5889258 accurracy:  0.9461163\n",
      "Epoch:  3416 Loss:  0.5889241 accurracy:  0.94612235\n",
      "Epoch:  3417 Loss:  0.5889225 accurracy:  0.94612837\n",
      "Epoch:  3418 Loss:  0.5889208 accurracy:  0.9461343\n",
      "Epoch:  3419 Loss:  0.5889189 accurracy:  0.94614035\n",
      "Epoch:  3420 Loss:  0.588917 accurracy:  0.94614637\n",
      "Epoch:  3421 Loss:  0.5889156 accurracy:  0.9461523\n",
      "Epoch:  3422 Loss:  0.58891374 accurracy:  0.94615835\n",
      "Epoch:  3423 Loss:  0.58891195 accurracy:  0.9461643\n",
      "Epoch:  3424 Loss:  0.58891004 accurracy:  0.94617033\n",
      "Epoch:  3425 Loss:  0.5889086 accurracy:  0.9461763\n",
      "Epoch:  3426 Loss:  0.58890694 accurracy:  0.94618225\n",
      "Epoch:  3427 Loss:  0.5889051 accurracy:  0.9461883\n",
      "Epoch:  3428 Loss:  0.58890325 accurracy:  0.94619423\n",
      "Epoch:  3429 Loss:  0.58890164 accurracy:  0.9462002\n",
      "Epoch:  3430 Loss:  0.58889997 accurracy:  0.94620615\n",
      "Epoch:  3431 Loss:  0.58889824 accurracy:  0.9462121\n",
      "Epoch:  3432 Loss:  0.5888966 accurracy:  0.9462181\n",
      "Epoch:  3433 Loss:  0.58889467 accurracy:  0.94622403\n",
      "Epoch:  3434 Loss:  0.58889294 accurracy:  0.94623\n",
      "Epoch:  3435 Loss:  0.58889127 accurracy:  0.94623595\n",
      "Epoch:  3436 Loss:  0.5888897 accurracy:  0.94624186\n",
      "Epoch:  3437 Loss:  0.5888882 accurracy:  0.9462478\n",
      "Epoch:  3438 Loss:  0.5888861 accurracy:  0.9462538\n",
      "Epoch:  3439 Loss:  0.58888423 accurracy:  0.9462597\n",
      "Epoch:  3440 Loss:  0.58888274 accurracy:  0.94626564\n",
      "Epoch:  3441 Loss:  0.5888813 accurracy:  0.94627154\n",
      "Epoch:  3442 Loss:  0.5888794 accurracy:  0.9462775\n",
      "Epoch:  3443 Loss:  0.5888775 accurracy:  0.9462834\n",
      "Epoch:  3444 Loss:  0.58887595 accurracy:  0.9462893\n",
      "Epoch:  3445 Loss:  0.5888743 accurracy:  0.9462952\n",
      "Epoch:  3446 Loss:  0.58887255 accurracy:  0.9463011\n",
      "Epoch:  3447 Loss:  0.58887064 accurracy:  0.94630706\n",
      "Epoch:  3448 Loss:  0.5888692 accurracy:  0.94631296\n",
      "Epoch:  3449 Loss:  0.5888675 accurracy:  0.94631886\n",
      "Epoch:  3450 Loss:  0.5888655 accurracy:  0.94632477\n",
      "Epoch:  3451 Loss:  0.5888639 accurracy:  0.9463306\n",
      "Epoch:  3452 Loss:  0.5888623 accurracy:  0.9463365\n",
      "Epoch:  3453 Loss:  0.5888606 accurracy:  0.9463424\n",
      "Epoch:  3454 Loss:  0.5888588 accurracy:  0.9463483\n",
      "Epoch:  3455 Loss:  0.58885735 accurracy:  0.94635415\n",
      "Epoch:  3456 Loss:  0.5888557 accurracy:  0.94636005\n",
      "Epoch:  3457 Loss:  0.58885384 accurracy:  0.9463659\n",
      "Epoch:  3458 Loss:  0.58885205 accurracy:  0.9463718\n",
      "Epoch:  3459 Loss:  0.5888504 accurracy:  0.94637764\n",
      "Epoch:  3460 Loss:  0.5888487 accurracy:  0.94638354\n",
      "Epoch:  3461 Loss:  0.5888471 accurracy:  0.9463894\n",
      "Epoch:  3462 Loss:  0.5888452 accurracy:  0.9463952\n",
      "Epoch:  3463 Loss:  0.58884364 accurracy:  0.94640106\n",
      "Epoch:  3464 Loss:  0.5888418 accurracy:  0.9464069\n",
      "Epoch:  3465 Loss:  0.58884025 accurracy:  0.94641274\n",
      "Epoch:  3466 Loss:  0.5888386 accurracy:  0.94641864\n",
      "Epoch:  3467 Loss:  0.588837 accurracy:  0.9464244\n",
      "Epoch:  3468 Loss:  0.5888353 accurracy:  0.94643027\n",
      "Epoch:  3469 Loss:  0.58883345 accurracy:  0.9464361\n",
      "Epoch:  3470 Loss:  0.58883184 accurracy:  0.94644195\n",
      "Epoch:  3471 Loss:  0.5888303 accurracy:  0.9464478\n",
      "Epoch:  3472 Loss:  0.5888284 accurracy:  0.9464536\n",
      "Epoch:  3473 Loss:  0.58882684 accurracy:  0.9464594\n",
      "Epoch:  3474 Loss:  0.5888252 accurracy:  0.94646525\n",
      "Epoch:  3475 Loss:  0.5888235 accurracy:  0.94647104\n",
      "Epoch:  3476 Loss:  0.58882177 accurracy:  0.9464769\n",
      "Epoch:  3477 Loss:  0.5888203 accurracy:  0.94648266\n",
      "Epoch:  3478 Loss:  0.58881855 accurracy:  0.94648844\n",
      "Epoch:  3479 Loss:  0.5888167 accurracy:  0.9464943\n",
      "Epoch:  3480 Loss:  0.58881474 accurracy:  0.94650006\n",
      "Epoch:  3481 Loss:  0.58881354 accurracy:  0.94650584\n",
      "Epoch:  3482 Loss:  0.5888121 accurracy:  0.9465116\n",
      "Epoch:  3483 Loss:  0.5888103 accurracy:  0.9465174\n",
      "Epoch:  3484 Loss:  0.5888083 accurracy:  0.9465232\n",
      "Epoch:  3485 Loss:  0.58880657 accurracy:  0.946529\n",
      "Epoch:  3486 Loss:  0.5888054 accurracy:  0.94653475\n",
      "Epoch:  3487 Loss:  0.5888037 accurracy:  0.94654053\n",
      "Epoch:  3488 Loss:  0.5888017 accurracy:  0.9465463\n",
      "Epoch:  3489 Loss:  0.5887998 accurracy:  0.94655204\n",
      "Epoch:  3490 Loss:  0.5887985 accurracy:  0.9465578\n",
      "Epoch:  3491 Loss:  0.58879733 accurracy:  0.9465636\n",
      "Epoch:  3492 Loss:  0.5887951 accurracy:  0.9465693\n",
      "Epoch:  3493 Loss:  0.58879304 accurracy:  0.9465751\n",
      "Epoch:  3494 Loss:  0.58879155 accurracy:  0.9465808\n",
      "Epoch:  3495 Loss:  0.58879054 accurracy:  0.94658655\n",
      "Epoch:  3496 Loss:  0.58878905 accurracy:  0.94659233\n",
      "Epoch:  3497 Loss:  0.5887867 accurracy:  0.94659805\n",
      "Epoch:  3498 Loss:  0.5887849 accurracy:  0.9466038\n",
      "Epoch:  3499 Loss:  0.5887836 accurracy:  0.9466095\n",
      "Epoch:  3500 Loss:  0.5887825 accurracy:  0.9466153\n",
      "Epoch:  3501 Loss:  0.5887804 accurracy:  0.946621\n",
      "Epoch:  3502 Loss:  0.58877814 accurracy:  0.9466267\n",
      "Epoch:  3503 Loss:  0.58877677 accurracy:  0.94663244\n",
      "Epoch:  3504 Loss:  0.5887757 accurracy:  0.9466381\n",
      "Epoch:  3505 Loss:  0.5887741 accurracy:  0.9466438\n",
      "Epoch:  3506 Loss:  0.58877206 accurracy:  0.94664955\n",
      "Epoch:  3507 Loss:  0.58876985 accurracy:  0.9466553\n",
      "Epoch:  3508 Loss:  0.58876866 accurracy:  0.946661\n",
      "Epoch:  3509 Loss:  0.58876735 accurracy:  0.94666666\n",
      "Epoch:  3510 Loss:  0.58876586 accurracy:  0.9466724\n",
      "Epoch:  3511 Loss:  0.58876354 accurracy:  0.94667804\n",
      "Epoch:  3512 Loss:  0.5887619 accurracy:  0.94668376\n",
      "Epoch:  3513 Loss:  0.58876073 accurracy:  0.9466894\n",
      "Epoch:  3514 Loss:  0.58875924 accurracy:  0.9466951\n",
      "Epoch:  3515 Loss:  0.5887574 accurracy:  0.9467008\n",
      "Epoch:  3516 Loss:  0.58875555 accurracy:  0.9467065\n",
      "Epoch:  3517 Loss:  0.5887539 accurracy:  0.94671214\n",
      "Epoch:  3518 Loss:  0.5887527 accurracy:  0.9467178\n",
      "Epoch:  3519 Loss:  0.5887509 accurracy:  0.94672346\n",
      "Epoch:  3520 Loss:  0.58874905 accurracy:  0.9467291\n",
      "Epoch:  3521 Loss:  0.58874756 accurracy:  0.9467348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3522 Loss:  0.58874583 accurracy:  0.94674045\n",
      "Epoch:  3523 Loss:  0.5887442 accurracy:  0.9467461\n",
      "Epoch:  3524 Loss:  0.58874285 accurracy:  0.9467518\n",
      "Epoch:  3525 Loss:  0.588741 accurracy:  0.94675744\n",
      "Epoch:  3526 Loss:  0.5887394 accurracy:  0.94676304\n",
      "Epoch:  3527 Loss:  0.58873755 accurracy:  0.9467687\n",
      "Epoch:  3528 Loss:  0.5887361 accurracy:  0.94677436\n",
      "Epoch:  3529 Loss:  0.58873457 accurracy:  0.94677997\n",
      "Epoch:  3530 Loss:  0.5887329 accurracy:  0.9467856\n",
      "Epoch:  3531 Loss:  0.588731 accurracy:  0.94679123\n",
      "Epoch:  3532 Loss:  0.58872986 accurracy:  0.9467969\n",
      "Epoch:  3533 Loss:  0.588728 accurracy:  0.9468025\n",
      "Epoch:  3534 Loss:  0.5887263 accurracy:  0.9468081\n",
      "Epoch:  3535 Loss:  0.5887248 accurracy:  0.9468137\n",
      "Epoch:  3536 Loss:  0.58872324 accurracy:  0.94681937\n",
      "Epoch:  3537 Loss:  0.5887217 accurracy:  0.94682497\n",
      "Epoch:  3538 Loss:  0.5887202 accurracy:  0.9468306\n",
      "Epoch:  3539 Loss:  0.58871824 accurracy:  0.9468362\n",
      "Epoch:  3540 Loss:  0.5887165 accurracy:  0.9468418\n",
      "Epoch:  3541 Loss:  0.58871514 accurracy:  0.9468474\n",
      "Epoch:  3542 Loss:  0.58871365 accurracy:  0.9468529\n",
      "Epoch:  3543 Loss:  0.58871186 accurracy:  0.9468585\n",
      "Epoch:  3544 Loss:  0.5887101 accurracy:  0.9468641\n",
      "Epoch:  3545 Loss:  0.58870876 accurracy:  0.94686973\n",
      "Epoch:  3546 Loss:  0.58870715 accurracy:  0.9468753\n",
      "Epoch:  3547 Loss:  0.5887056 accurracy:  0.9468809\n",
      "Epoch:  3548 Loss:  0.58870375 accurracy:  0.9468864\n",
      "Epoch:  3549 Loss:  0.588702 accurracy:  0.946892\n",
      "Epoch:  3550 Loss:  0.58870065 accurracy:  0.94689757\n",
      "Epoch:  3551 Loss:  0.58869934 accurracy:  0.94690317\n",
      "Epoch:  3552 Loss:  0.58869773 accurracy:  0.9469087\n",
      "Epoch:  3553 Loss:  0.58869576 accurracy:  0.94691426\n",
      "Epoch:  3554 Loss:  0.58869386 accurracy:  0.94691986\n",
      "Epoch:  3555 Loss:  0.5886926 accurracy:  0.9469254\n",
      "Epoch:  3556 Loss:  0.5886915 accurracy:  0.94693094\n",
      "Epoch:  3557 Loss:  0.58868957 accurracy:  0.9469365\n",
      "Epoch:  3558 Loss:  0.58868766 accurracy:  0.94694203\n",
      "Epoch:  3559 Loss:  0.58868617 accurracy:  0.9469476\n",
      "Epoch:  3560 Loss:  0.588685 accurracy:  0.9469531\n",
      "Epoch:  3561 Loss:  0.5886834 accurracy:  0.94695866\n",
      "Epoch:  3562 Loss:  0.5886814 accurracy:  0.94696414\n",
      "Epoch:  3563 Loss:  0.5886797 accurracy:  0.9469697\n",
      "Epoch:  3564 Loss:  0.5886785 accurracy:  0.94697523\n",
      "Epoch:  3565 Loss:  0.5886768 accurracy:  0.9469807\n",
      "Epoch:  3566 Loss:  0.5886752 accurracy:  0.94698626\n",
      "Epoch:  3567 Loss:  0.5886735 accurracy:  0.9469918\n",
      "Epoch:  3568 Loss:  0.588672 accurracy:  0.9469973\n",
      "Epoch:  3569 Loss:  0.5886705 accurracy:  0.9470028\n",
      "Epoch:  3570 Loss:  0.5886688 accurracy:  0.9470083\n",
      "Epoch:  3571 Loss:  0.58866715 accurracy:  0.9470138\n",
      "Epoch:  3572 Loss:  0.58866566 accurracy:  0.94701934\n",
      "Epoch:  3573 Loss:  0.58866435 accurracy:  0.9470248\n",
      "Epoch:  3574 Loss:  0.5886628 accurracy:  0.9470303\n",
      "Epoch:  3575 Loss:  0.5886608 accurracy:  0.9470358\n",
      "Epoch:  3576 Loss:  0.5886591 accurracy:  0.9470413\n",
      "Epoch:  3577 Loss:  0.58865774 accurracy:  0.94704676\n",
      "Epoch:  3578 Loss:  0.5886566 accurracy:  0.94705224\n",
      "Epoch:  3579 Loss:  0.5886548 accurracy:  0.9470577\n",
      "Epoch:  3580 Loss:  0.5886525 accurracy:  0.9470632\n",
      "Epoch:  3581 Loss:  0.58865124 accurracy:  0.9470687\n",
      "Epoch:  3582 Loss:  0.5886504 accurracy:  0.9470742\n",
      "Epoch:  3583 Loss:  0.58864874 accurracy:  0.9470796\n",
      "Epoch:  3584 Loss:  0.58864677 accurracy:  0.9470851\n",
      "Epoch:  3585 Loss:  0.58864486 accurracy:  0.94709057\n",
      "Epoch:  3586 Loss:  0.5886436 accurracy:  0.947096\n",
      "Epoch:  3587 Loss:  0.5886423 accurracy:  0.9471015\n",
      "Epoch:  3588 Loss:  0.58864075 accurracy:  0.9471069\n",
      "Epoch:  3589 Loss:  0.58863884 accurracy:  0.9471123\n",
      "Epoch:  3590 Loss:  0.5886375 accurracy:  0.9471178\n",
      "Epoch:  3591 Loss:  0.588636 accurracy:  0.9471232\n",
      "Epoch:  3592 Loss:  0.5886344 accurracy:  0.94712865\n",
      "Epoch:  3593 Loss:  0.5886326 accurracy:  0.94713414\n",
      "Epoch:  3594 Loss:  0.588631 accurracy:  0.94713956\n",
      "Epoch:  3595 Loss:  0.58862966 accurracy:  0.947145\n",
      "Epoch:  3596 Loss:  0.5886281 accurracy:  0.9471504\n",
      "Epoch:  3597 Loss:  0.5886263 accurracy:  0.94715583\n",
      "Epoch:  3598 Loss:  0.58862495 accurracy:  0.94716126\n",
      "Epoch:  3599 Loss:  0.5886234 accurracy:  0.9471667\n",
      "Epoch:  3600 Loss:  0.58862203 accurracy:  0.9471721\n",
      "Epoch:  3601 Loss:  0.5886201 accurracy:  0.94717747\n",
      "Epoch:  3602 Loss:  0.5886185 accurracy:  0.9471829\n",
      "Epoch:  3603 Loss:  0.5886173 accurracy:  0.9471883\n",
      "Epoch:  3604 Loss:  0.58861595 accurracy:  0.94719374\n",
      "Epoch:  3605 Loss:  0.58861417 accurracy:  0.9471991\n",
      "Epoch:  3606 Loss:  0.5886124 accurracy:  0.94720453\n",
      "Epoch:  3607 Loss:  0.5886107 accurracy:  0.9472099\n",
      "Epoch:  3608 Loss:  0.58860964 accurracy:  0.9472153\n",
      "Epoch:  3609 Loss:  0.5886082 accurracy:  0.9472207\n",
      "Epoch:  3610 Loss:  0.58860624 accurracy:  0.94722605\n",
      "Epoch:  3611 Loss:  0.5886044 accurracy:  0.9472315\n",
      "Epoch:  3612 Loss:  0.58860326 accurracy:  0.94723684\n",
      "Epoch:  3613 Loss:  0.5886022 accurracy:  0.9472422\n",
      "Epoch:  3614 Loss:  0.58860034 accurracy:  0.94724756\n",
      "Epoch:  3615 Loss:  0.58859825 accurracy:  0.9472529\n",
      "Epoch:  3616 Loss:  0.58859694 accurracy:  0.9472583\n",
      "Epoch:  3617 Loss:  0.5885958 accurracy:  0.94726366\n",
      "Epoch:  3618 Loss:  0.5885943 accurracy:  0.947269\n",
      "Epoch:  3619 Loss:  0.5885924 accurracy:  0.9472744\n",
      "Epoch:  3620 Loss:  0.5885905 accurracy:  0.94727975\n",
      "Epoch:  3621 Loss:  0.58858925 accurracy:  0.9472851\n",
      "Epoch:  3622 Loss:  0.5885883 accurracy:  0.9472905\n",
      "Epoch:  3623 Loss:  0.5885867 accurracy:  0.9472958\n",
      "Epoch:  3624 Loss:  0.5885845 accurracy:  0.94730115\n",
      "Epoch:  3625 Loss:  0.58858293 accurracy:  0.9473065\n",
      "Epoch:  3626 Loss:  0.588582 accurracy:  0.9473118\n",
      "Epoch:  3627 Loss:  0.58858055 accurracy:  0.9473172\n",
      "Epoch:  3628 Loss:  0.58857894 accurracy:  0.9473225\n",
      "Epoch:  3629 Loss:  0.58857685 accurracy:  0.94732785\n",
      "Epoch:  3630 Loss:  0.5885756 accurracy:  0.94733316\n",
      "Epoch:  3631 Loss:  0.5885744 accurracy:  0.94733846\n",
      "Epoch:  3632 Loss:  0.58857274 accurracy:  0.94734377\n",
      "Epoch:  3633 Loss:  0.5885708 accurracy:  0.94734913\n",
      "Epoch:  3634 Loss:  0.5885693 accurracy:  0.94735444\n",
      "Epoch:  3635 Loss:  0.588568 accurracy:  0.94735974\n",
      "Epoch:  3636 Loss:  0.5885668 accurracy:  0.94736505\n",
      "Epoch:  3637 Loss:  0.58856505 accurracy:  0.94737035\n",
      "Epoch:  3638 Loss:  0.5885632 accurracy:  0.94737566\n",
      "Epoch:  3639 Loss:  0.5885619 accurracy:  0.94738096\n",
      "Epoch:  3640 Loss:  0.58856046 accurracy:  0.94738626\n",
      "Epoch:  3641 Loss:  0.5885591 accurracy:  0.94739157\n",
      "Epoch:  3642 Loss:  0.5885574 accurracy:  0.9473968\n",
      "Epoch:  3643 Loss:  0.5885556 accurracy:  0.9474021\n",
      "Epoch:  3644 Loss:  0.58855414 accurracy:  0.9474074\n",
      "Epoch:  3645 Loss:  0.5885531 accurracy:  0.94741267\n",
      "Epoch:  3646 Loss:  0.5885515 accurracy:  0.947418\n",
      "Epoch:  3647 Loss:  0.5885498 accurracy:  0.9474232\n",
      "Epoch:  3648 Loss:  0.5885481 accurracy:  0.9474285\n",
      "Epoch:  3649 Loss:  0.58854675 accurracy:  0.94743377\n",
      "Epoch:  3650 Loss:  0.58854544 accurracy:  0.9474391\n",
      "Epoch:  3651 Loss:  0.58854395 accurracy:  0.9474443\n",
      "Epoch:  3652 Loss:  0.58854216 accurracy:  0.94744956\n",
      "Epoch:  3653 Loss:  0.5885405 accurracy:  0.94745487\n",
      "Epoch:  3654 Loss:  0.58853924 accurracy:  0.9474601\n",
      "Epoch:  3655 Loss:  0.5885379 accurracy:  0.94746536\n",
      "Epoch:  3656 Loss:  0.5885362 accurracy:  0.9474706\n",
      "Epoch:  3657 Loss:  0.58853453 accurracy:  0.94747585\n",
      "Epoch:  3658 Loss:  0.5885333 accurracy:  0.9474811\n",
      "Epoch:  3659 Loss:  0.58853173 accurracy:  0.94748634\n",
      "Epoch:  3660 Loss:  0.58853024 accurracy:  0.9474916\n",
      "Epoch:  3661 Loss:  0.5885288 accurracy:  0.94749683\n",
      "Epoch:  3662 Loss:  0.5885273 accurracy:  0.9475021\n",
      "Epoch:  3663 Loss:  0.58852565 accurracy:  0.94750726\n",
      "Epoch:  3664 Loss:  0.5885241 accurracy:  0.9475125\n",
      "Epoch:  3665 Loss:  0.5885228 accurracy:  0.94751775\n",
      "Epoch:  3666 Loss:  0.5885211 accurracy:  0.94752294\n",
      "Epoch:  3667 Loss:  0.5885197 accurracy:  0.9475282\n",
      "Epoch:  3668 Loss:  0.58851826 accurracy:  0.94753337\n",
      "Epoch:  3669 Loss:  0.588517 accurracy:  0.9475386\n",
      "Epoch:  3670 Loss:  0.5885153 accurracy:  0.9475438\n",
      "Epoch:  3671 Loss:  0.58851355 accurracy:  0.94754905\n",
      "Epoch:  3672 Loss:  0.588512 accurracy:  0.94755423\n",
      "Epoch:  3673 Loss:  0.58851093 accurracy:  0.9475594\n",
      "Epoch:  3674 Loss:  0.5885097 accurracy:  0.9475646\n",
      "Epoch:  3675 Loss:  0.5885077 accurracy:  0.94756985\n",
      "Epoch:  3676 Loss:  0.588506 accurracy:  0.94757503\n",
      "Epoch:  3677 Loss:  0.5885047 accurracy:  0.9475802\n",
      "Epoch:  3678 Loss:  0.5885034 accurracy:  0.9475854\n",
      "Epoch:  3679 Loss:  0.5885018 accurracy:  0.9475906\n",
      "Epoch:  3680 Loss:  0.5885001 accurracy:  0.9475958\n",
      "Epoch:  3681 Loss:  0.5884987 accurracy:  0.94760096\n",
      "Epoch:  3682 Loss:  0.5884975 accurracy:  0.94760615\n",
      "Epoch:  3683 Loss:  0.58849615 accurracy:  0.9476113\n",
      "Epoch:  3684 Loss:  0.58849436 accurracy:  0.94761646\n",
      "Epoch:  3685 Loss:  0.58849275 accurracy:  0.94762164\n",
      "Epoch:  3686 Loss:  0.58849144 accurracy:  0.94762677\n",
      "Epoch:  3687 Loss:  0.58849007 accurracy:  0.94763196\n",
      "Epoch:  3688 Loss:  0.5884885 accurracy:  0.94763714\n",
      "Epoch:  3689 Loss:  0.5884869 accurracy:  0.94764227\n",
      "Epoch:  3690 Loss:  0.5884855 accurracy:  0.94764745\n",
      "Epoch:  3691 Loss:  0.5884841 accurracy:  0.9476526\n",
      "Epoch:  3692 Loss:  0.5884828 accurracy:  0.9476577\n",
      "Epoch:  3693 Loss:  0.58848107 accurracy:  0.9476629\n",
      "Epoch:  3694 Loss:  0.58847934 accurracy:  0.947668\n",
      "Epoch:  3695 Loss:  0.58847797 accurracy:  0.94767314\n",
      "Epoch:  3696 Loss:  0.58847684 accurracy:  0.94767827\n",
      "Epoch:  3697 Loss:  0.5884754 accurracy:  0.94768345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3698 Loss:  0.58847374 accurracy:  0.9476886\n",
      "Epoch:  3699 Loss:  0.5884723 accurracy:  0.9476937\n",
      "Epoch:  3700 Loss:  0.5884707 accurracy:  0.94769883\n",
      "Epoch:  3701 Loss:  0.58846945 accurracy:  0.94770396\n",
      "Epoch:  3702 Loss:  0.58846784 accurracy:  0.9477091\n",
      "Epoch:  3703 Loss:  0.58846647 accurracy:  0.9477142\n",
      "Epoch:  3704 Loss:  0.5884648 accurracy:  0.9477193\n",
      "Epoch:  3705 Loss:  0.5884635 accurracy:  0.9477244\n",
      "Epoch:  3706 Loss:  0.58846194 accurracy:  0.9477295\n",
      "Epoch:  3707 Loss:  0.5884605 accurracy:  0.94773465\n",
      "Epoch:  3708 Loss:  0.5884591 accurracy:  0.9477397\n",
      "Epoch:  3709 Loss:  0.58845764 accurracy:  0.94774485\n",
      "Epoch:  3710 Loss:  0.58845633 accurracy:  0.9477499\n",
      "Epoch:  3711 Loss:  0.5884549 accurracy:  0.94775504\n",
      "Epoch:  3712 Loss:  0.58845305 accurracy:  0.9477601\n",
      "Epoch:  3713 Loss:  0.5884517 accurracy:  0.94776523\n",
      "Epoch:  3714 Loss:  0.5884505 accurracy:  0.9477703\n",
      "Epoch:  3715 Loss:  0.5884492 accurracy:  0.94777536\n",
      "Epoch:  3716 Loss:  0.58844733 accurracy:  0.9477805\n",
      "Epoch:  3717 Loss:  0.5884457 accurracy:  0.94778556\n",
      "Epoch:  3718 Loss:  0.58844453 accurracy:  0.9477906\n",
      "Epoch:  3719 Loss:  0.58844334 accurracy:  0.9477957\n",
      "Epoch:  3720 Loss:  0.5884416 accurracy:  0.94780076\n",
      "Epoch:  3721 Loss:  0.58844 accurracy:  0.9478058\n",
      "Epoch:  3722 Loss:  0.5884384 accurracy:  0.9478109\n",
      "Epoch:  3723 Loss:  0.5884374 accurracy:  0.94781595\n",
      "Epoch:  3724 Loss:  0.58843625 accurracy:  0.947821\n",
      "Epoch:  3725 Loss:  0.5884345 accurracy:  0.9478261\n",
      "Epoch:  3726 Loss:  0.58843267 accurracy:  0.94783115\n",
      "Epoch:  3727 Loss:  0.5884313 accurracy:  0.9478362\n",
      "Epoch:  3728 Loss:  0.58843017 accurracy:  0.9478412\n",
      "Epoch:  3729 Loss:  0.5884289 accurracy:  0.9478463\n",
      "Epoch:  3730 Loss:  0.5884271 accurracy:  0.94785136\n",
      "Epoch:  3731 Loss:  0.5884256 accurracy:  0.94785637\n",
      "Epoch:  3732 Loss:  0.588424 accurracy:  0.94786143\n",
      "Epoch:  3733 Loss:  0.5884229 accurracy:  0.94786644\n",
      "Epoch:  3734 Loss:  0.58842146 accurracy:  0.9478715\n",
      "Epoch:  3735 Loss:  0.58842 accurracy:  0.9478765\n",
      "Epoch:  3736 Loss:  0.58841836 accurracy:  0.9478815\n",
      "Epoch:  3737 Loss:  0.58841693 accurracy:  0.9478866\n",
      "Epoch:  3738 Loss:  0.58841574 accurracy:  0.9478916\n",
      "Epoch:  3739 Loss:  0.5884143 accurracy:  0.9478966\n",
      "Epoch:  3740 Loss:  0.5884128 accurracy:  0.9479016\n",
      "Epoch:  3741 Loss:  0.5884111 accurracy:  0.9479067\n",
      "Epoch:  3742 Loss:  0.5884098 accurracy:  0.9479117\n",
      "Epoch:  3743 Loss:  0.58840865 accurracy:  0.9479167\n",
      "Epoch:  3744 Loss:  0.5884073 accurracy:  0.9479217\n",
      "Epoch:  3745 Loss:  0.5884055 accurracy:  0.9479267\n",
      "Epoch:  3746 Loss:  0.588404 accurracy:  0.9479317\n",
      "Epoch:  3747 Loss:  0.5884028 accurracy:  0.94793665\n",
      "Epoch:  3748 Loss:  0.58840156 accurracy:  0.94794166\n",
      "Epoch:  3749 Loss:  0.5883999 accurracy:  0.94794667\n",
      "Epoch:  3750 Loss:  0.58839834 accurracy:  0.9479517\n",
      "Epoch:  3751 Loss:  0.58839697 accurracy:  0.9479566\n",
      "Epoch:  3752 Loss:  0.5883957 accurracy:  0.9479616\n",
      "Epoch:  3753 Loss:  0.58839405 accurracy:  0.94796664\n",
      "Epoch:  3754 Loss:  0.5883928 accurracy:  0.9479716\n",
      "Epoch:  3755 Loss:  0.58839136 accurracy:  0.9479766\n",
      "Epoch:  3756 Loss:  0.5883901 accurracy:  0.94798154\n",
      "Epoch:  3757 Loss:  0.58838856 accurracy:  0.94798654\n",
      "Epoch:  3758 Loss:  0.58838683 accurracy:  0.9479915\n",
      "Epoch:  3759 Loss:  0.5883857 accurracy:  0.94799644\n",
      "Epoch:  3760 Loss:  0.5883845 accurracy:  0.94800144\n",
      "Epoch:  3761 Loss:  0.5883831 accurracy:  0.9480064\n",
      "Epoch:  3762 Loss:  0.58838135 accurracy:  0.94801134\n",
      "Epoch:  3763 Loss:  0.58837986 accurracy:  0.9480163\n",
      "Epoch:  3764 Loss:  0.58837837 accurracy:  0.94802123\n",
      "Epoch:  3765 Loss:  0.58837736 accurracy:  0.9480262\n",
      "Epoch:  3766 Loss:  0.58837587 accurracy:  0.9480311\n",
      "Epoch:  3767 Loss:  0.5883744 accurracy:  0.9480361\n",
      "Epoch:  3768 Loss:  0.5883729 accurracy:  0.948041\n",
      "Epoch:  3769 Loss:  0.58837163 accurracy:  0.94804597\n",
      "Epoch:  3770 Loss:  0.58837 accurracy:  0.9480509\n",
      "Epoch:  3771 Loss:  0.58836865 accurracy:  0.94805586\n",
      "Epoch:  3772 Loss:  0.5883673 accurracy:  0.9480608\n",
      "Epoch:  3773 Loss:  0.5883659 accurracy:  0.9480657\n",
      "Epoch:  3774 Loss:  0.5883644 accurracy:  0.94807065\n",
      "Epoch:  3775 Loss:  0.58836305 accurracy:  0.9480756\n",
      "Epoch:  3776 Loss:  0.5883619 accurracy:  0.9480805\n",
      "Epoch:  3777 Loss:  0.58836025 accurracy:  0.9480854\n",
      "Epoch:  3778 Loss:  0.58835876 accurracy:  0.9480903\n",
      "Epoch:  3779 Loss:  0.5883574 accurracy:  0.94809526\n",
      "Epoch:  3780 Loss:  0.5883562 accurracy:  0.94810015\n",
      "Epoch:  3781 Loss:  0.58835447 accurracy:  0.94810504\n",
      "Epoch:  3782 Loss:  0.5883532 accurracy:  0.94811\n",
      "Epoch:  3783 Loss:  0.5883519 accurracy:  0.9481149\n",
      "Epoch:  3784 Loss:  0.58835053 accurracy:  0.94811976\n",
      "Epoch:  3785 Loss:  0.58834904 accurracy:  0.94812465\n",
      "Epoch:  3786 Loss:  0.58834755 accurracy:  0.9481296\n",
      "Epoch:  3787 Loss:  0.5883461 accurracy:  0.9481345\n",
      "Epoch:  3788 Loss:  0.5883449 accurracy:  0.94813937\n",
      "Epoch:  3789 Loss:  0.58834344 accurracy:  0.94814426\n",
      "Epoch:  3790 Loss:  0.58834213 accurracy:  0.94814914\n",
      "Epoch:  3791 Loss:  0.58834064 accurracy:  0.94815403\n",
      "Epoch:  3792 Loss:  0.58833927 accurracy:  0.94815886\n",
      "Epoch:  3793 Loss:  0.58833784 accurracy:  0.94816375\n",
      "Epoch:  3794 Loss:  0.5883365 accurracy:  0.94816864\n",
      "Epoch:  3795 Loss:  0.5883352 accurracy:  0.9481735\n",
      "Epoch:  3796 Loss:  0.5883339 accurracy:  0.9481784\n",
      "Epoch:  3797 Loss:  0.5883325 accurracy:  0.94818324\n",
      "Epoch:  3798 Loss:  0.58833104 accurracy:  0.9481881\n",
      "Epoch:  3799 Loss:  0.58832943 accurracy:  0.94819295\n",
      "Epoch:  3800 Loss:  0.58832806 accurracy:  0.94819784\n",
      "Epoch:  3801 Loss:  0.5883269 accurracy:  0.9482027\n",
      "Epoch:  3802 Loss:  0.5883255 accurracy:  0.94820756\n",
      "Epoch:  3803 Loss:  0.5883241 accurracy:  0.9482124\n",
      "Epoch:  3804 Loss:  0.58832246 accurracy:  0.9482173\n",
      "Epoch:  3805 Loss:  0.58832115 accurracy:  0.9482221\n",
      "Epoch:  3806 Loss:  0.5883199 accurracy:  0.9482269\n",
      "Epoch:  3807 Loss:  0.5883185 accurracy:  0.9482318\n",
      "Epoch:  3808 Loss:  0.58831704 accurracy:  0.94823664\n",
      "Epoch:  3809 Loss:  0.5883156 accurracy:  0.9482415\n",
      "Epoch:  3810 Loss:  0.5883142 accurracy:  0.9482463\n",
      "Epoch:  3811 Loss:  0.58831304 accurracy:  0.9482511\n",
      "Epoch:  3812 Loss:  0.5883118 accurracy:  0.94825596\n",
      "Epoch:  3813 Loss:  0.5883102 accurracy:  0.9482608\n",
      "Epoch:  3814 Loss:  0.58830863 accurracy:  0.9482656\n",
      "Epoch:  3815 Loss:  0.58830744 accurracy:  0.94827044\n",
      "Epoch:  3816 Loss:  0.5883063 accurracy:  0.94827527\n",
      "Epoch:  3817 Loss:  0.58830476 accurracy:  0.9482801\n",
      "Epoch:  3818 Loss:  0.58830327 accurracy:  0.94828486\n",
      "Epoch:  3819 Loss:  0.58830184 accurracy:  0.9482897\n",
      "Epoch:  3820 Loss:  0.5883009 accurracy:  0.9482945\n",
      "Epoch:  3821 Loss:  0.58829945 accurracy:  0.94829935\n",
      "Epoch:  3822 Loss:  0.5882977 accurracy:  0.9483041\n",
      "Epoch:  3823 Loss:  0.5882963 accurracy:  0.94830894\n",
      "Epoch:  3824 Loss:  0.58829486 accurracy:  0.9483137\n",
      "Epoch:  3825 Loss:  0.5882938 accurracy:  0.94831854\n",
      "Epoch:  3826 Loss:  0.5882924 accurracy:  0.9483233\n",
      "Epoch:  3827 Loss:  0.5882908 accurracy:  0.94832814\n",
      "Epoch:  3828 Loss:  0.58828944 accurracy:  0.9483329\n",
      "Epoch:  3829 Loss:  0.58828825 accurracy:  0.9483377\n",
      "Epoch:  3830 Loss:  0.588287 accurracy:  0.94834244\n",
      "Epoch:  3831 Loss:  0.58828545 accurracy:  0.9483473\n",
      "Epoch:  3832 Loss:  0.5882841 accurracy:  0.94835204\n",
      "Epoch:  3833 Loss:  0.5882829 accurracy:  0.9483568\n",
      "Epoch:  3834 Loss:  0.58828145 accurracy:  0.9483616\n",
      "Epoch:  3835 Loss:  0.58827996 accurracy:  0.94836634\n",
      "Epoch:  3836 Loss:  0.5882787 accurracy:  0.9483711\n",
      "Epoch:  3837 Loss:  0.5882775 accurracy:  0.9483759\n",
      "Epoch:  3838 Loss:  0.5882761 accurracy:  0.94838065\n",
      "Epoch:  3839 Loss:  0.58827466 accurracy:  0.9483854\n",
      "Epoch:  3840 Loss:  0.58827335 accurracy:  0.9483902\n",
      "Epoch:  3841 Loss:  0.588272 accurracy:  0.94839495\n",
      "Epoch:  3842 Loss:  0.58827055 accurracy:  0.94839966\n",
      "Epoch:  3843 Loss:  0.58826923 accurracy:  0.94840443\n",
      "Epoch:  3844 Loss:  0.58826804 accurracy:  0.9484092\n",
      "Epoch:  3845 Loss:  0.5882665 accurracy:  0.9484139\n",
      "Epoch:  3846 Loss:  0.5882652 accurracy:  0.9484187\n",
      "Epoch:  3847 Loss:  0.58826405 accurracy:  0.94842345\n",
      "Epoch:  3848 Loss:  0.5882625 accurracy:  0.94842815\n",
      "Epoch:  3849 Loss:  0.58826107 accurracy:  0.9484329\n",
      "Epoch:  3850 Loss:  0.58825964 accurracy:  0.94843763\n",
      "Epoch:  3851 Loss:  0.5882584 accurracy:  0.94844234\n",
      "Epoch:  3852 Loss:  0.5882574 accurracy:  0.9484471\n",
      "Epoch:  3853 Loss:  0.5882558 accurracy:  0.9484518\n",
      "Epoch:  3854 Loss:  0.5882545 accurracy:  0.9484565\n",
      "Epoch:  3855 Loss:  0.588253 accurracy:  0.9484613\n",
      "Epoch:  3856 Loss:  0.5882515 accurracy:  0.948466\n",
      "Epoch:  3857 Loss:  0.58825046 accurracy:  0.9484707\n",
      "Epoch:  3858 Loss:  0.5882491 accurracy:  0.9484754\n",
      "Epoch:  3859 Loss:  0.58824754 accurracy:  0.9484801\n",
      "Epoch:  3860 Loss:  0.5882463 accurracy:  0.94848484\n",
      "Epoch:  3861 Loss:  0.5882451 accurracy:  0.94848955\n",
      "Epoch:  3862 Loss:  0.58824384 accurracy:  0.94849426\n",
      "Epoch:  3863 Loss:  0.58824223 accurracy:  0.94849896\n",
      "Epoch:  3864 Loss:  0.58824074 accurracy:  0.9485037\n",
      "Epoch:  3865 Loss:  0.58823955 accurracy:  0.9485084\n",
      "Epoch:  3866 Loss:  0.58823854 accurracy:  0.94851303\n",
      "Epoch:  3867 Loss:  0.58823705 accurracy:  0.94851774\n",
      "Epoch:  3868 Loss:  0.5882353 accurracy:  0.94852245\n",
      "Epoch:  3869 Loss:  0.5882337 accurracy:  0.94852716\n",
      "Epoch:  3870 Loss:  0.58823276 accurracy:  0.9485318\n",
      "Epoch:  3871 Loss:  0.5882318 accurracy:  0.9485365\n",
      "Epoch:  3872 Loss:  0.58823043 accurracy:  0.94854116\n",
      "Epoch:  3873 Loss:  0.58822876 accurracy:  0.9485459\n",
      "Epoch:  3874 Loss:  0.58822733 accurracy:  0.9485505\n",
      "Epoch:  3875 Loss:  0.5882261 accurracy:  0.94855523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3876 Loss:  0.58822507 accurracy:  0.9485599\n",
      "Epoch:  3877 Loss:  0.58822376 accurracy:  0.9485645\n",
      "Epoch:  3878 Loss:  0.58822215 accurracy:  0.94856924\n",
      "Epoch:  3879 Loss:  0.58822083 accurracy:  0.9485739\n",
      "Epoch:  3880 Loss:  0.58821934 accurracy:  0.94857854\n",
      "Epoch:  3881 Loss:  0.5882183 accurracy:  0.9485832\n",
      "Epoch:  3882 Loss:  0.588217 accurracy:  0.94858783\n",
      "Epoch:  3883 Loss:  0.58821565 accurracy:  0.94859254\n",
      "Epoch:  3884 Loss:  0.588214 accurracy:  0.9485972\n",
      "Epoch:  3885 Loss:  0.58821285 accurracy:  0.94860184\n",
      "Epoch:  3886 Loss:  0.58821183 accurracy:  0.9486065\n",
      "Epoch:  3887 Loss:  0.58821034 accurracy:  0.94861114\n",
      "Epoch:  3888 Loss:  0.5882088 accurracy:  0.94861573\n",
      "Epoch:  3889 Loss:  0.58820736 accurracy:  0.9486204\n",
      "Epoch:  3890 Loss:  0.58820635 accurracy:  0.948625\n",
      "Epoch:  3891 Loss:  0.58820516 accurracy:  0.9486297\n",
      "Epoch:  3892 Loss:  0.58820397 accurracy:  0.9486343\n",
      "Epoch:  3893 Loss:  0.58820224 accurracy:  0.9486389\n",
      "Epoch:  3894 Loss:  0.5882009 accurracy:  0.94864357\n",
      "Epoch:  3895 Loss:  0.58819973 accurracy:  0.9486482\n",
      "Epoch:  3896 Loss:  0.5881985 accurracy:  0.9486528\n",
      "Epoch:  3897 Loss:  0.5881972 accurracy:  0.94865745\n",
      "Epoch:  3898 Loss:  0.5881957 accurracy:  0.94866204\n",
      "Epoch:  3899 Loss:  0.58819425 accurracy:  0.9486667\n",
      "Epoch:  3900 Loss:  0.58819306 accurracy:  0.9486713\n",
      "Epoch:  3901 Loss:  0.588192 accurracy:  0.9486759\n",
      "Epoch:  3902 Loss:  0.58819073 accurracy:  0.9486805\n",
      "Epoch:  3903 Loss:  0.58818907 accurracy:  0.9486851\n",
      "Epoch:  3904 Loss:  0.58818793 accurracy:  0.9486897\n",
      "Epoch:  3905 Loss:  0.5881867 accurracy:  0.9486943\n",
      "Epoch:  3906 Loss:  0.5881854 accurracy:  0.94869894\n",
      "Epoch:  3907 Loss:  0.5881838 accurracy:  0.9487035\n",
      "Epoch:  3908 Loss:  0.58818257 accurracy:  0.9487081\n",
      "Epoch:  3909 Loss:  0.5881814 accurracy:  0.9487127\n",
      "Epoch:  3910 Loss:  0.5881802 accurracy:  0.9487173\n",
      "Epoch:  3911 Loss:  0.58817875 accurracy:  0.9487219\n",
      "Epoch:  3912 Loss:  0.5881774 accurracy:  0.9487265\n",
      "Epoch:  3913 Loss:  0.5881761 accurracy:  0.94873106\n",
      "Epoch:  3914 Loss:  0.58817494 accurracy:  0.94873565\n",
      "Epoch:  3915 Loss:  0.5881737 accurracy:  0.9487402\n",
      "Epoch:  3916 Loss:  0.588172 accurracy:  0.9487448\n",
      "Epoch:  3917 Loss:  0.5881709 accurracy:  0.94874936\n",
      "Epoch:  3918 Loss:  0.58816975 accurracy:  0.94875395\n",
      "Epoch:  3919 Loss:  0.58816844 accurracy:  0.9487585\n",
      "Epoch:  3920 Loss:  0.588167 accurracy:  0.9487631\n",
      "Epoch:  3921 Loss:  0.58816564 accurracy:  0.94876766\n",
      "Epoch:  3922 Loss:  0.58816427 accurracy:  0.9487722\n",
      "Epoch:  3923 Loss:  0.58816326 accurracy:  0.9487768\n",
      "Epoch:  3924 Loss:  0.5881618 accurracy:  0.9487813\n",
      "Epoch:  3925 Loss:  0.58816034 accurracy:  0.9487859\n",
      "Epoch:  3926 Loss:  0.588159 accurracy:  0.94879043\n",
      "Epoch:  3927 Loss:  0.5881581 accurracy:  0.94879496\n",
      "Epoch:  3928 Loss:  0.5881569 accurracy:  0.94879955\n",
      "Epoch:  3929 Loss:  0.5881554 accurracy:  0.9488041\n",
      "Epoch:  3930 Loss:  0.5881538 accurracy:  0.9488086\n",
      "Epoch:  3931 Loss:  0.58815277 accurracy:  0.94881314\n",
      "Epoch:  3932 Loss:  0.58815175 accurracy:  0.9488177\n",
      "Epoch:  3933 Loss:  0.5881502 accurracy:  0.94882226\n",
      "Epoch:  3934 Loss:  0.5881489 accurracy:  0.9488268\n",
      "Epoch:  3935 Loss:  0.5881474 accurracy:  0.9488313\n",
      "Epoch:  3936 Loss:  0.588146 accurracy:  0.94883585\n",
      "Epoch:  3937 Loss:  0.5881452 accurracy:  0.9488404\n",
      "Epoch:  3938 Loss:  0.588144 accurracy:  0.9488449\n",
      "Epoch:  3939 Loss:  0.5881424 accurracy:  0.9488494\n",
      "Epoch:  3940 Loss:  0.5881409 accurracy:  0.9488539\n",
      "Epoch:  3941 Loss:  0.5881397 accurracy:  0.94885844\n",
      "Epoch:  3942 Loss:  0.58813894 accurracy:  0.94886297\n",
      "Epoch:  3943 Loss:  0.58813757 accurracy:  0.9488675\n",
      "Epoch:  3944 Loss:  0.588136 accurracy:  0.94887197\n",
      "Epoch:  3945 Loss:  0.5881345 accurracy:  0.9488765\n",
      "Epoch:  3946 Loss:  0.58813345 accurracy:  0.94888103\n",
      "Epoch:  3947 Loss:  0.5881322 accurracy:  0.9488855\n",
      "Epoch:  3948 Loss:  0.58813083 accurracy:  0.94889003\n",
      "Epoch:  3949 Loss:  0.5881296 accurracy:  0.9488945\n",
      "Epoch:  3950 Loss:  0.5881285 accurracy:  0.94889903\n",
      "Epoch:  3951 Loss:  0.58812726 accurracy:  0.9489035\n",
      "Epoch:  3952 Loss:  0.5881258 accurracy:  0.94890803\n",
      "Epoch:  3953 Loss:  0.5881244 accurracy:  0.9489125\n",
      "Epoch:  3954 Loss:  0.58812326 accurracy:  0.948917\n",
      "Epoch:  3955 Loss:  0.58812195 accurracy:  0.94892144\n",
      "Epoch:  3956 Loss:  0.58812076 accurracy:  0.948926\n",
      "Epoch:  3957 Loss:  0.5881193 accurracy:  0.94893044\n",
      "Epoch:  3958 Loss:  0.58811796 accurracy:  0.9489349\n",
      "Epoch:  3959 Loss:  0.588117 accurracy:  0.9489394\n",
      "Epoch:  3960 Loss:  0.5881157 accurracy:  0.94894385\n",
      "Epoch:  3961 Loss:  0.58811414 accurracy:  0.9489483\n",
      "Epoch:  3962 Loss:  0.5881131 accurracy:  0.9489528\n",
      "Epoch:  3963 Loss:  0.588112 accurracy:  0.94895726\n",
      "Epoch:  3964 Loss:  0.58811086 accurracy:  0.94896173\n",
      "Epoch:  3965 Loss:  0.5881093 accurracy:  0.9489662\n",
      "Epoch:  3966 Loss:  0.5881078 accurracy:  0.9489707\n",
      "Epoch:  3967 Loss:  0.5881068 accurracy:  0.94897515\n",
      "Epoch:  3968 Loss:  0.5881056 accurracy:  0.9489796\n",
      "Epoch:  3969 Loss:  0.58810425 accurracy:  0.948984\n",
      "Epoch:  3970 Loss:  0.5881029 accurracy:  0.9489885\n",
      "Epoch:  3971 Loss:  0.5881016 accurracy:  0.94899297\n",
      "Epoch:  3972 Loss:  0.58810043 accurracy:  0.9489974\n",
      "Epoch:  3973 Loss:  0.58809924 accurracy:  0.94900185\n",
      "Epoch:  3974 Loss:  0.5880979 accurracy:  0.9490063\n",
      "Epoch:  3975 Loss:  0.5880967 accurracy:  0.9490107\n",
      "Epoch:  3976 Loss:  0.58809537 accurracy:  0.9490152\n",
      "Epoch:  3977 Loss:  0.5880941 accurracy:  0.9490196\n",
      "Epoch:  3978 Loss:  0.5880928 accurracy:  0.949024\n",
      "Epoch:  3979 Loss:  0.5880917 accurracy:  0.9490285\n",
      "Epoch:  3980 Loss:  0.5880902 accurracy:  0.9490329\n",
      "Epoch:  3981 Loss:  0.588089 accurracy:  0.9490373\n",
      "Epoch:  3982 Loss:  0.5880879 accurracy:  0.9490418\n",
      "Epoch:  3983 Loss:  0.5880867 accurracy:  0.9490462\n",
      "Epoch:  3984 Loss:  0.5880853 accurracy:  0.9490506\n",
      "Epoch:  3985 Loss:  0.5880839 accurracy:  0.949055\n",
      "Epoch:  3986 Loss:  0.5880826 accurracy:  0.9490594\n",
      "Epoch:  3987 Loss:  0.5880816 accurracy:  0.94906384\n",
      "Epoch:  3988 Loss:  0.58808047 accurracy:  0.94906825\n",
      "Epoch:  3989 Loss:  0.5880791 accurracy:  0.94907266\n",
      "Epoch:  3990 Loss:  0.58807755 accurracy:  0.94907707\n",
      "Epoch:  3991 Loss:  0.58807635 accurracy:  0.9490815\n",
      "Epoch:  3992 Loss:  0.5880753 accurracy:  0.9490859\n",
      "Epoch:  3993 Loss:  0.58807415 accurracy:  0.9490903\n",
      "Epoch:  3994 Loss:  0.58807284 accurracy:  0.9490947\n",
      "Epoch:  3995 Loss:  0.5880712 accurracy:  0.9490991\n",
      "Epoch:  3996 Loss:  0.5880699 accurracy:  0.9491035\n",
      "Epoch:  3997 Loss:  0.5880689 accurracy:  0.9491079\n",
      "Epoch:  3998 Loss:  0.588068 accurracy:  0.9491123\n",
      "Epoch:  3999 Loss:  0.58806676 accurracy:  0.94911665\n",
      "Epoch:  4000 Loss:  0.58806527 accurracy:  0.94912106\n",
      "Epoch:  4001 Loss:  0.5880636 accurracy:  0.9491254\n",
      "Epoch:  4002 Loss:  0.5880625 accurracy:  0.9491298\n",
      "Epoch:  4003 Loss:  0.58806175 accurracy:  0.9491342\n",
      "Epoch:  4004 Loss:  0.5880607 accurracy:  0.9491386\n",
      "Epoch:  4005 Loss:  0.5880589 accurracy:  0.94914293\n",
      "Epoch:  4006 Loss:  0.58805746 accurracy:  0.94914734\n",
      "Epoch:  4007 Loss:  0.5880566 accurracy:  0.9491517\n",
      "Epoch:  4008 Loss:  0.58805555 accurracy:  0.94915605\n",
      "Epoch:  4009 Loss:  0.588054 accurracy:  0.94916046\n",
      "Epoch:  4010 Loss:  0.58805263 accurracy:  0.9491648\n",
      "Epoch:  4011 Loss:  0.5880515 accurracy:  0.94916916\n",
      "Epoch:  4012 Loss:  0.58805054 accurracy:  0.9491735\n",
      "Epoch:  4013 Loss:  0.5880493 accurracy:  0.94917786\n",
      "Epoch:  4014 Loss:  0.5880481 accurracy:  0.9491822\n",
      "Epoch:  4015 Loss:  0.58804643 accurracy:  0.94918656\n",
      "Epoch:  4016 Loss:  0.5880452 accurracy:  0.9491909\n",
      "Epoch:  4017 Loss:  0.5880442 accurracy:  0.94919527\n",
      "Epoch:  4018 Loss:  0.5880431 accurracy:  0.9491996\n",
      "Epoch:  4019 Loss:  0.58804154 accurracy:  0.94920397\n",
      "Epoch:  4020 Loss:  0.5880403 accurracy:  0.9492083\n",
      "Epoch:  4021 Loss:  0.58803934 accurracy:  0.9492127\n",
      "Epoch:  4022 Loss:  0.5880381 accurracy:  0.949217\n",
      "Epoch:  4023 Loss:  0.58803695 accurracy:  0.9492213\n",
      "Epoch:  4024 Loss:  0.58803546 accurracy:  0.94922566\n",
      "Epoch:  4025 Loss:  0.5880342 accurracy:  0.94923\n",
      "Epoch:  4026 Loss:  0.58803314 accurracy:  0.9492343\n",
      "Epoch:  4027 Loss:  0.588032 accurracy:  0.94923866\n",
      "Epoch:  4028 Loss:  0.5880308 accurracy:  0.949243\n",
      "Epoch:  4029 Loss:  0.58802927 accurracy:  0.9492473\n",
      "Epoch:  4030 Loss:  0.5880281 accurracy:  0.94925165\n",
      "Epoch:  4031 Loss:  0.58802694 accurracy:  0.94925594\n",
      "Epoch:  4032 Loss:  0.588026 accurracy:  0.9492603\n",
      "Epoch:  4033 Loss:  0.58802474 accurracy:  0.9492646\n",
      "Epoch:  4034 Loss:  0.58802325 accurracy:  0.9492689\n",
      "Epoch:  4035 Loss:  0.5880219 accurracy:  0.9492732\n",
      "Epoch:  4036 Loss:  0.5880209 accurracy:  0.9492775\n",
      "Epoch:  4037 Loss:  0.58801997 accurracy:  0.9492818\n",
      "Epoch:  4038 Loss:  0.58801854 accurracy:  0.9492861\n",
      "Epoch:  4039 Loss:  0.5880171 accurracy:  0.94929045\n",
      "Epoch:  4040 Loss:  0.58801585 accurracy:  0.94929475\n",
      "Epoch:  4041 Loss:  0.58801484 accurracy:  0.94929904\n",
      "Epoch:  4042 Loss:  0.5880138 accurracy:  0.9493033\n",
      "Epoch:  4043 Loss:  0.58801234 accurracy:  0.9493076\n",
      "Epoch:  4044 Loss:  0.58801097 accurracy:  0.9493119\n",
      "Epoch:  4045 Loss:  0.58801 accurracy:  0.9493162\n",
      "Epoch:  4046 Loss:  0.58800876 accurracy:  0.9493205\n",
      "Epoch:  4047 Loss:  0.58800733 accurracy:  0.9493248\n",
      "Epoch:  4048 Loss:  0.5880062 accurracy:  0.9493291\n",
      "Epoch:  4049 Loss:  0.5880051 accurracy:  0.9493333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4050 Loss:  0.58800393 accurracy:  0.9493376\n",
      "Epoch:  4051 Loss:  0.5880026 accurracy:  0.9493419\n",
      "Epoch:  4052 Loss:  0.58800155 accurracy:  0.9493462\n",
      "Epoch:  4053 Loss:  0.5880001 accurracy:  0.9493504\n",
      "Epoch:  4054 Loss:  0.58799905 accurracy:  0.9493547\n",
      "Epoch:  4055 Loss:  0.5879977 accurracy:  0.949359\n",
      "Epoch:  4056 Loss:  0.58799666 accurracy:  0.94936323\n",
      "Epoch:  4057 Loss:  0.5879955 accurracy:  0.9493675\n",
      "Epoch:  4058 Loss:  0.5879939 accurracy:  0.94937176\n",
      "Epoch:  4059 Loss:  0.5879927 accurracy:  0.94937605\n",
      "Epoch:  4060 Loss:  0.58799183 accurracy:  0.9493803\n",
      "Epoch:  4061 Loss:  0.58799076 accurracy:  0.9493845\n",
      "Epoch:  4062 Loss:  0.58798945 accurracy:  0.9493888\n",
      "Epoch:  4063 Loss:  0.5879879 accurracy:  0.94939303\n",
      "Epoch:  4064 Loss:  0.5879868 accurracy:  0.94939727\n",
      "Epoch:  4065 Loss:  0.5879859 accurracy:  0.94940156\n",
      "Epoch:  4066 Loss:  0.58798474 accurracy:  0.9494058\n",
      "Epoch:  4067 Loss:  0.5879833 accurracy:  0.94941\n",
      "Epoch:  4068 Loss:  0.5879818 accurracy:  0.94941425\n",
      "Epoch:  4069 Loss:  0.587981 accurracy:  0.9494185\n",
      "Epoch:  4070 Loss:  0.58798003 accurracy:  0.9494227\n",
      "Epoch:  4071 Loss:  0.5879786 accurracy:  0.949427\n",
      "Epoch:  4072 Loss:  0.5879771 accurracy:  0.94943124\n",
      "Epoch:  4073 Loss:  0.5879761 accurracy:  0.9494355\n",
      "Epoch:  4074 Loss:  0.58797514 accurracy:  0.94943964\n",
      "Epoch:  4075 Loss:  0.58797413 accurracy:  0.9494439\n",
      "Epoch:  4076 Loss:  0.5879725 accurracy:  0.9494481\n",
      "Epoch:  4077 Loss:  0.5879711 accurracy:  0.94945234\n",
      "Epoch:  4078 Loss:  0.5879701 accurracy:  0.9494566\n",
      "Epoch:  4079 Loss:  0.58796906 accurracy:  0.9494608\n",
      "Epoch:  4080 Loss:  0.58796793 accurracy:  0.949465\n",
      "Epoch:  4081 Loss:  0.58796674 accurracy:  0.9494692\n",
      "Epoch:  4082 Loss:  0.58796525 accurracy:  0.94947344\n",
      "Epoch:  4083 Loss:  0.5879642 accurracy:  0.9494776\n",
      "Epoch:  4084 Loss:  0.58796316 accurracy:  0.94948184\n",
      "Epoch:  4085 Loss:  0.587962 accurracy:  0.9494861\n",
      "Epoch:  4086 Loss:  0.58796054 accurracy:  0.94949025\n",
      "Epoch:  4087 Loss:  0.5879593 accurracy:  0.9494945\n",
      "Epoch:  4088 Loss:  0.5879583 accurracy:  0.94949865\n",
      "Epoch:  4089 Loss:  0.5879572 accurracy:  0.9495028\n",
      "Epoch:  4090 Loss:  0.587956 accurracy:  0.94950706\n",
      "Epoch:  4091 Loss:  0.5879546 accurracy:  0.94951123\n",
      "Epoch:  4092 Loss:  0.58795345 accurracy:  0.94951546\n",
      "Epoch:  4093 Loss:  0.5879523 accurracy:  0.94951963\n",
      "Epoch:  4094 Loss:  0.5879511 accurracy:  0.9495238\n",
      "Epoch:  4095 Loss:  0.5879499 accurracy:  0.949528\n",
      "Epoch:  4096 Loss:  0.5879486 accurracy:  0.94953215\n",
      "Epoch:  4097 Loss:  0.5879474 accurracy:  0.9495364\n",
      "Epoch:  4098 Loss:  0.5879465 accurracy:  0.94954056\n",
      "Epoch:  4099 Loss:  0.5879454 accurracy:  0.9495447\n",
      "Epoch:  4100 Loss:  0.58794427 accurracy:  0.9495489\n",
      "Epoch:  4101 Loss:  0.58794284 accurracy:  0.9495531\n",
      "Epoch:  4102 Loss:  0.58794135 accurracy:  0.94955724\n",
      "Epoch:  4103 Loss:  0.58794034 accurracy:  0.9495614\n",
      "Epoch:  4104 Loss:  0.5879397 accurracy:  0.9495656\n",
      "Epoch:  4105 Loss:  0.58793855 accurracy:  0.94956976\n",
      "Epoch:  4106 Loss:  0.58793694 accurracy:  0.9495739\n",
      "Epoch:  4107 Loss:  0.5879355 accurracy:  0.94957805\n",
      "Epoch:  4108 Loss:  0.5879345 accurracy:  0.9495822\n",
      "Epoch:  4109 Loss:  0.5879338 accurracy:  0.9495864\n",
      "Epoch:  4110 Loss:  0.5879325 accurracy:  0.9495905\n",
      "Epoch:  4111 Loss:  0.5879308 accurracy:  0.9495947\n",
      "Epoch:  4112 Loss:  0.5879295 accurracy:  0.94959885\n",
      "Epoch:  4113 Loss:  0.58792865 accurracy:  0.94960296\n",
      "Epoch:  4114 Loss:  0.5879279 accurracy:  0.94960713\n",
      "Epoch:  4115 Loss:  0.58792657 accurracy:  0.94961125\n",
      "Epoch:  4116 Loss:  0.5879249 accurracy:  0.9496154\n",
      "Epoch:  4117 Loss:  0.5879237 accurracy:  0.94961953\n",
      "Epoch:  4118 Loss:  0.5879231 accurracy:  0.9496237\n",
      "Epoch:  4119 Loss:  0.587922 accurracy:  0.9496278\n",
      "Epoch:  4120 Loss:  0.5879205 accurracy:  0.949632\n",
      "Epoch:  4121 Loss:  0.58791894 accurracy:  0.9496361\n",
      "Epoch:  4122 Loss:  0.5879181 accurracy:  0.9496402\n",
      "Epoch:  4123 Loss:  0.5879173 accurracy:  0.9496444\n",
      "Epoch:  4124 Loss:  0.587916 accurracy:  0.9496485\n",
      "Epoch:  4125 Loss:  0.5879144 accurracy:  0.9496526\n",
      "Epoch:  4126 Loss:  0.58791345 accurracy:  0.9496567\n",
      "Epoch:  4127 Loss:  0.58791256 accurracy:  0.94966084\n",
      "Epoch:  4128 Loss:  0.5879115 accurracy:  0.94966495\n",
      "Epoch:  4129 Loss:  0.58791006 accurracy:  0.94966906\n",
      "Epoch:  4130 Loss:  0.58790874 accurracy:  0.9496732\n",
      "Epoch:  4131 Loss:  0.5879077 accurracy:  0.9496773\n",
      "Epoch:  4132 Loss:  0.5879068 accurracy:  0.9496814\n",
      "Epoch:  4133 Loss:  0.58790535 accurracy:  0.9496855\n",
      "Epoch:  4134 Loss:  0.587904 accurracy:  0.9496896\n",
      "Epoch:  4135 Loss:  0.587903 accurracy:  0.94969374\n",
      "Epoch:  4136 Loss:  0.5879019 accurracy:  0.94969785\n",
      "Epoch:  4137 Loss:  0.5879008 accurracy:  0.94970196\n",
      "Epoch:  4138 Loss:  0.58789957 accurracy:  0.9497061\n",
      "Epoch:  4139 Loss:  0.5878985 accurracy:  0.94971013\n",
      "Epoch:  4140 Loss:  0.58789736 accurracy:  0.94971424\n",
      "Epoch:  4141 Loss:  0.5878962 accurracy:  0.94971836\n",
      "Epoch:  4142 Loss:  0.58789515 accurracy:  0.9497224\n",
      "Epoch:  4143 Loss:  0.5878939 accurracy:  0.9497265\n",
      "Epoch:  4144 Loss:  0.58789265 accurracy:  0.9497306\n",
      "Epoch:  4145 Loss:  0.5878915 accurracy:  0.9497347\n",
      "Epoch:  4146 Loss:  0.58789045 accurracy:  0.94973874\n",
      "Epoch:  4147 Loss:  0.5878894 accurracy:  0.94974285\n",
      "Epoch:  4148 Loss:  0.58788806 accurracy:  0.9497469\n",
      "Epoch:  4149 Loss:  0.58788687 accurracy:  0.949751\n",
      "Epoch:  4150 Loss:  0.5878857 accurracy:  0.9497551\n",
      "Epoch:  4151 Loss:  0.5878847 accurracy:  0.9497591\n",
      "Epoch:  4152 Loss:  0.5878836 accurracy:  0.94976324\n",
      "Epoch:  4153 Loss:  0.5878823 accurracy:  0.9497673\n",
      "Epoch:  4154 Loss:  0.5878812 accurracy:  0.94977134\n",
      "Epoch:  4155 Loss:  0.58787996 accurracy:  0.9497754\n",
      "Epoch:  4156 Loss:  0.5878788 accurracy:  0.9497795\n",
      "Epoch:  4157 Loss:  0.58787787 accurracy:  0.94978356\n",
      "Epoch:  4158 Loss:  0.5878767 accurracy:  0.9497876\n",
      "Epoch:  4159 Loss:  0.5878755 accurracy:  0.94979167\n",
      "Epoch:  4160 Loss:  0.5878741 accurracy:  0.9497957\n",
      "Epoch:  4161 Loss:  0.58787304 accurracy:  0.9497998\n",
      "Epoch:  4162 Loss:  0.58787215 accurracy:  0.9498038\n",
      "Epoch:  4163 Loss:  0.587871 accurracy:  0.9498079\n",
      "Epoch:  4164 Loss:  0.5878695 accurracy:  0.94981194\n",
      "Epoch:  4165 Loss:  0.5878684 accurracy:  0.949816\n",
      "Epoch:  4166 Loss:  0.5878677 accurracy:  0.94982004\n",
      "Epoch:  4167 Loss:  0.58786654 accurracy:  0.94982404\n",
      "Epoch:  4168 Loss:  0.58786523 accurracy:  0.9498281\n",
      "Epoch:  4169 Loss:  0.58786374 accurracy:  0.94983214\n",
      "Epoch:  4170 Loss:  0.58786285 accurracy:  0.9498362\n",
      "Epoch:  4171 Loss:  0.587862 accurracy:  0.9498402\n",
      "Epoch:  4172 Loss:  0.5878608 accurracy:  0.94984424\n",
      "Epoch:  4173 Loss:  0.5878593 accurracy:  0.9498483\n",
      "Epoch:  4174 Loss:  0.5878581 accurracy:  0.9498523\n",
      "Epoch:  4175 Loss:  0.58785725 accurracy:  0.94985634\n",
      "Epoch:  4176 Loss:  0.5878563 accurracy:  0.94986033\n",
      "Epoch:  4177 Loss:  0.58785504 accurracy:  0.9498644\n",
      "Epoch:  4178 Loss:  0.5878536 accurracy:  0.9498684\n",
      "Epoch:  4179 Loss:  0.5878526 accurracy:  0.94987243\n",
      "Epoch:  4180 Loss:  0.58785164 accurracy:  0.9498764\n",
      "Epoch:  4181 Loss:  0.58785063 accurracy:  0.9498804\n",
      "Epoch:  4182 Loss:  0.5878493 accurracy:  0.9498845\n",
      "Epoch:  4183 Loss:  0.587848 accurracy:  0.94988847\n",
      "Epoch:  4184 Loss:  0.5878469 accurracy:  0.94989246\n",
      "Epoch:  4185 Loss:  0.587846 accurracy:  0.94989645\n",
      "Epoch:  4186 Loss:  0.5878448 accurracy:  0.9499005\n",
      "Epoch:  4187 Loss:  0.58784354 accurracy:  0.9499045\n",
      "Epoch:  4188 Loss:  0.5878424 accurracy:  0.9499085\n",
      "Epoch:  4189 Loss:  0.5878413 accurracy:  0.9499125\n",
      "Epoch:  4190 Loss:  0.5878403 accurracy:  0.9499165\n",
      "Epoch:  4191 Loss:  0.58783925 accurracy:  0.9499205\n",
      "Epoch:  4192 Loss:  0.58783793 accurracy:  0.94992447\n",
      "Epoch:  4193 Loss:  0.5878367 accurracy:  0.94992846\n",
      "Epoch:  4194 Loss:  0.58783555 accurracy:  0.94993246\n",
      "Epoch:  4195 Loss:  0.5878347 accurracy:  0.94993645\n",
      "Epoch:  4196 Loss:  0.58783346 accurracy:  0.94994044\n",
      "Epoch:  4197 Loss:  0.5878323 accurracy:  0.94994444\n",
      "Epoch:  4198 Loss:  0.58783114 accurracy:  0.94994843\n",
      "Epoch:  4199 Loss:  0.5878301 accurracy:  0.94995236\n",
      "Epoch:  4200 Loss:  0.58782876 accurracy:  0.94995636\n",
      "Epoch:  4201 Loss:  0.58782774 accurracy:  0.94996035\n",
      "Epoch:  4202 Loss:  0.5878268 accurracy:  0.9499643\n",
      "Epoch:  4203 Loss:  0.58782566 accurracy:  0.9499683\n",
      "Epoch:  4204 Loss:  0.5878243 accurracy:  0.9499723\n",
      "Epoch:  4205 Loss:  0.5878231 accurracy:  0.9499762\n",
      "Epoch:  4206 Loss:  0.5878223 accurracy:  0.9499802\n",
      "Epoch:  4207 Loss:  0.5878212 accurracy:  0.94998413\n",
      "Epoch:  4208 Loss:  0.5878199 accurracy:  0.9499881\n",
      "Epoch:  4209 Loss:  0.5878187 accurracy:  0.94999206\n",
      "Epoch:  4210 Loss:  0.5878178 accurracy:  0.94999605\n",
      "Epoch:  4211 Loss:  0.5878171 accurracy:  0.95\n",
      "Epoch:  4212 Loss:  0.5878156 accurracy:  0.950004\n",
      "Epoch:  4213 Loss:  0.587814 accurracy:  0.9500079\n",
      "Epoch:  4214 Loss:  0.58781296 accurracy:  0.95001185\n",
      "Epoch:  4215 Loss:  0.5878122 accurracy:  0.9500158\n",
      "Epoch:  4216 Loss:  0.5878113 accurracy:  0.9500198\n",
      "Epoch:  4217 Loss:  0.5878101 accurracy:  0.9500237\n",
      "Epoch:  4218 Loss:  0.5878086 accurracy:  0.95002764\n",
      "Epoch:  4219 Loss:  0.5878076 accurracy:  0.9500316\n",
      "Epoch:  4220 Loss:  0.5878067 accurracy:  0.9500355\n",
      "Epoch:  4221 Loss:  0.5878057 accurracy:  0.95003945\n",
      "Epoch:  4222 Loss:  0.58780444 accurracy:  0.95004344\n",
      "Epoch:  4223 Loss:  0.58780295 accurracy:  0.9500474\n",
      "Epoch:  4224 Loss:  0.5878018 accurracy:  0.9500513\n",
      "Epoch:  4225 Loss:  0.5878011 accurracy:  0.95005524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4226 Loss:  0.5878002 accurracy:  0.9500591\n",
      "Epoch:  4227 Loss:  0.58779883 accurracy:  0.95006305\n",
      "Epoch:  4228 Loss:  0.5877974 accurracy:  0.950067\n",
      "Epoch:  4229 Loss:  0.5877964 accurracy:  0.9500709\n",
      "Epoch:  4230 Loss:  0.5877956 accurracy:  0.95007485\n",
      "Epoch:  4231 Loss:  0.58779466 accurracy:  0.9500788\n",
      "Epoch:  4232 Loss:  0.58779323 accurracy:  0.95008266\n",
      "Epoch:  4233 Loss:  0.587792 accurracy:  0.9500866\n",
      "Epoch:  4234 Loss:  0.5877909 accurracy:  0.9500905\n",
      "Epoch:  4235 Loss:  0.5877901 accurracy:  0.9500944\n",
      "Epoch:  4236 Loss:  0.5877892 accurracy:  0.95009834\n",
      "Epoch:  4237 Loss:  0.58778775 accurracy:  0.95010227\n",
      "Epoch:  4238 Loss:  0.58778644 accurracy:  0.95010614\n",
      "Epoch:  4239 Loss:  0.5877854 accurracy:  0.9501101\n",
      "Epoch:  4240 Loss:  0.5877846 accurracy:  0.95011395\n",
      "Epoch:  4241 Loss:  0.5877836 accurracy:  0.9501179\n",
      "Epoch:  4242 Loss:  0.5877821 accurracy:  0.95012176\n",
      "Epoch:  4243 Loss:  0.5877808 accurracy:  0.9501257\n",
      "Epoch:  4244 Loss:  0.58778 accurracy:  0.95012957\n",
      "Epoch:  4245 Loss:  0.5877791 accurracy:  0.95013344\n",
      "Epoch:  4246 Loss:  0.5877782 accurracy:  0.9501374\n",
      "Epoch:  4247 Loss:  0.5877767 accurracy:  0.95014125\n",
      "Epoch:  4248 Loss:  0.58777535 accurracy:  0.9501451\n",
      "Epoch:  4249 Loss:  0.5877744 accurracy:  0.950149\n",
      "Epoch:  4250 Loss:  0.58777374 accurracy:  0.95015293\n",
      "Epoch:  4251 Loss:  0.5877725 accurracy:  0.9501568\n",
      "Epoch:  4252 Loss:  0.58777106 accurracy:  0.9501607\n",
      "Epoch:  4253 Loss:  0.5877698 accurracy:  0.95016456\n",
      "Epoch:  4254 Loss:  0.5877691 accurracy:  0.95016843\n",
      "Epoch:  4255 Loss:  0.5877683 accurracy:  0.9501723\n",
      "Epoch:  4256 Loss:  0.587767 accurracy:  0.9501762\n",
      "Epoch:  4257 Loss:  0.5877655 accurracy:  0.95018005\n",
      "Epoch:  4258 Loss:  0.5877646 accurracy:  0.9501839\n",
      "Epoch:  4259 Loss:  0.5877638 accurracy:  0.9501878\n",
      "Epoch:  4260 Loss:  0.5877627 accurracy:  0.9501917\n",
      "Epoch:  4261 Loss:  0.58776134 accurracy:  0.95019555\n",
      "Epoch:  4262 Loss:  0.58776003 accurracy:  0.95019937\n",
      "Epoch:  4263 Loss:  0.5877594 accurracy:  0.95020324\n",
      "Epoch:  4264 Loss:  0.58775836 accurracy:  0.9502071\n",
      "Epoch:  4265 Loss:  0.5877571 accurracy:  0.950211\n",
      "Epoch:  4266 Loss:  0.58775586 accurracy:  0.9502148\n",
      "Epoch:  4267 Loss:  0.58775485 accurracy:  0.9502187\n",
      "Epoch:  4268 Loss:  0.58775383 accurracy:  0.95022255\n",
      "Epoch:  4269 Loss:  0.58775294 accurracy:  0.95022637\n",
      "Epoch:  4270 Loss:  0.58775175 accurracy:  0.95023024\n",
      "Epoch:  4271 Loss:  0.5877506 accurracy:  0.95023406\n",
      "Epoch:  4272 Loss:  0.5877495 accurracy:  0.95023793\n",
      "Epoch:  4273 Loss:  0.58774847 accurracy:  0.95024174\n",
      "Epoch:  4274 Loss:  0.5877473 accurracy:  0.9502456\n",
      "Epoch:  4275 Loss:  0.5877463 accurracy:  0.95024943\n",
      "Epoch:  4276 Loss:  0.58774513 accurracy:  0.9502533\n",
      "Epoch:  4277 Loss:  0.5877443 accurracy:  0.9502571\n",
      "Epoch:  4278 Loss:  0.5877431 accurracy:  0.95026094\n",
      "Epoch:  4279 Loss:  0.58774185 accurracy:  0.9502648\n",
      "Epoch:  4280 Loss:  0.58774084 accurracy:  0.9502686\n",
      "Epoch:  4281 Loss:  0.58773994 accurracy:  0.95027244\n",
      "Epoch:  4282 Loss:  0.5877389 accurracy:  0.9502763\n",
      "Epoch:  4283 Loss:  0.5877375 accurracy:  0.95028013\n",
      "Epoch:  4284 Loss:  0.5877363 accurracy:  0.95028394\n",
      "Epoch:  4285 Loss:  0.58773535 accurracy:  0.95028776\n",
      "Epoch:  4286 Loss:  0.5877346 accurracy:  0.9502916\n",
      "Epoch:  4287 Loss:  0.58773345 accurracy:  0.9502954\n",
      "Epoch:  4288 Loss:  0.5877323 accurracy:  0.9502992\n",
      "Epoch:  4289 Loss:  0.5877312 accurracy:  0.950303\n",
      "Epoch:  4290 Loss:  0.58773017 accurracy:  0.95030683\n",
      "Epoch:  4291 Loss:  0.58772916 accurracy:  0.95031065\n",
      "Epoch:  4292 Loss:  0.58772796 accurracy:  0.95031446\n",
      "Epoch:  4293 Loss:  0.58772695 accurracy:  0.9503183\n",
      "Epoch:  4294 Loss:  0.5877258 accurracy:  0.9503221\n",
      "Epoch:  4295 Loss:  0.58772475 accurracy:  0.9503259\n",
      "Epoch:  4296 Loss:  0.5877238 accurracy:  0.95032966\n",
      "Epoch:  4297 Loss:  0.58772266 accurracy:  0.9503335\n",
      "Epoch:  4298 Loss:  0.5877214 accurracy:  0.9503373\n",
      "Epoch:  4299 Loss:  0.5877205 accurracy:  0.9503411\n",
      "Epoch:  4300 Loss:  0.58771956 accurracy:  0.95034486\n",
      "Epoch:  4301 Loss:  0.5877186 accurracy:  0.9503487\n",
      "Epoch:  4302 Loss:  0.5877173 accurracy:  0.9503525\n",
      "Epoch:  4303 Loss:  0.5877159 accurracy:  0.95035625\n",
      "Epoch:  4304 Loss:  0.587715 accurracy:  0.95036006\n",
      "Epoch:  4305 Loss:  0.58771425 accurracy:  0.9503638\n",
      "Epoch:  4306 Loss:  0.5877132 accurracy:  0.9503676\n",
      "Epoch:  4307 Loss:  0.5877119 accurracy:  0.9503714\n",
      "Epoch:  4308 Loss:  0.5877108 accurracy:  0.9503752\n",
      "Epoch:  4309 Loss:  0.58770967 accurracy:  0.95037895\n",
      "Epoch:  4310 Loss:  0.5877087 accurracy:  0.95038277\n",
      "Epoch:  4311 Loss:  0.58770776 accurracy:  0.9503865\n",
      "Epoch:  4312 Loss:  0.5877066 accurracy:  0.9503903\n",
      "Epoch:  4313 Loss:  0.5877053 accurracy:  0.9503941\n",
      "Epoch:  4314 Loss:  0.58770436 accurracy:  0.95039785\n",
      "Epoch:  4315 Loss:  0.58770347 accurracy:  0.9504016\n",
      "Epoch:  4316 Loss:  0.58770245 accurracy:  0.95040536\n",
      "Epoch:  4317 Loss:  0.58770144 accurracy:  0.9504091\n",
      "Epoch:  4318 Loss:  0.5877004 accurracy:  0.9504129\n",
      "Epoch:  4319 Loss:  0.5876991 accurracy:  0.9504167\n",
      "Epoch:  4320 Loss:  0.58769804 accurracy:  0.95042044\n",
      "Epoch:  4321 Loss:  0.58769715 accurracy:  0.9504242\n",
      "Epoch:  4322 Loss:  0.5876962 accurracy:  0.95042795\n",
      "Epoch:  4323 Loss:  0.58769494 accurracy:  0.9504317\n",
      "Epoch:  4324 Loss:  0.58769363 accurracy:  0.95043546\n",
      "Epoch:  4325 Loss:  0.5876928 accurracy:  0.9504392\n",
      "Epoch:  4326 Loss:  0.587692 accurracy:  0.95044297\n",
      "Epoch:  4327 Loss:  0.5876909 accurracy:  0.9504467\n",
      "Epoch:  4328 Loss:  0.5876895 accurracy:  0.9504505\n",
      "Epoch:  4329 Loss:  0.58768845 accurracy:  0.9504542\n",
      "Epoch:  4330 Loss:  0.5876877 accurracy:  0.95045793\n",
      "Epoch:  4331 Loss:  0.5876867 accurracy:  0.9504617\n",
      "Epoch:  4332 Loss:  0.5876855 accurracy:  0.95046544\n",
      "Epoch:  4333 Loss:  0.5876843 accurracy:  0.95046914\n",
      "Epoch:  4334 Loss:  0.5876835 accurracy:  0.9504729\n",
      "Epoch:  4335 Loss:  0.5876825 accurracy:  0.95047665\n",
      "Epoch:  4336 Loss:  0.58768135 accurracy:  0.95048034\n",
      "Epoch:  4337 Loss:  0.58768004 accurracy:  0.9504841\n",
      "Epoch:  4338 Loss:  0.58767915 accurracy:  0.95048785\n",
      "Epoch:  4339 Loss:  0.58767825 accurracy:  0.95049155\n",
      "Epoch:  4340 Loss:  0.58767706 accurracy:  0.9504953\n",
      "Epoch:  4341 Loss:  0.587676 accurracy:  0.950499\n",
      "Epoch:  4342 Loss:  0.58767486 accurracy:  0.95050275\n",
      "Epoch:  4343 Loss:  0.58767384 accurracy:  0.95050645\n",
      "Epoch:  4344 Loss:  0.58767307 accurracy:  0.95051014\n",
      "Epoch:  4345 Loss:  0.58767205 accurracy:  0.9505139\n",
      "Epoch:  4346 Loss:  0.58767074 accurracy:  0.9505176\n",
      "Epoch:  4347 Loss:  0.58766955 accurracy:  0.9505213\n",
      "Epoch:  4348 Loss:  0.5876686 accurracy:  0.95052505\n",
      "Epoch:  4349 Loss:  0.5876678 accurracy:  0.95052874\n",
      "Epoch:  4350 Loss:  0.5876669 accurracy:  0.95053244\n",
      "Epoch:  4351 Loss:  0.5876657 accurracy:  0.95053613\n",
      "Epoch:  4352 Loss:  0.5876645 accurracy:  0.9505399\n",
      "Epoch:  4353 Loss:  0.5876635 accurracy:  0.9505436\n",
      "Epoch:  4354 Loss:  0.5876626 accurracy:  0.9505473\n",
      "Epoch:  4355 Loss:  0.5876615 accurracy:  0.950551\n",
      "Epoch:  4356 Loss:  0.5876605 accurracy:  0.95055467\n",
      "Epoch:  4357 Loss:  0.5876595 accurracy:  0.95055836\n",
      "Epoch:  4358 Loss:  0.5876581 accurracy:  0.95056206\n",
      "Epoch:  4359 Loss:  0.58765703 accurracy:  0.95056576\n",
      "Epoch:  4360 Loss:  0.58765626 accurracy:  0.95056945\n",
      "Epoch:  4361 Loss:  0.5876555 accurracy:  0.95057315\n",
      "Epoch:  4362 Loss:  0.5876544 accurracy:  0.95057684\n",
      "Epoch:  4363 Loss:  0.58765304 accurracy:  0.9505805\n",
      "Epoch:  4364 Loss:  0.58765185 accurracy:  0.9505842\n",
      "Epoch:  4365 Loss:  0.5876511 accurracy:  0.95058787\n",
      "Epoch:  4366 Loss:  0.58765006 accurracy:  0.95059156\n",
      "Epoch:  4367 Loss:  0.5876492 accurracy:  0.95059526\n",
      "Epoch:  4368 Loss:  0.58764803 accurracy:  0.9505989\n",
      "Epoch:  4369 Loss:  0.5876468 accurracy:  0.9506026\n",
      "Epoch:  4370 Loss:  0.5876458 accurracy:  0.9506063\n",
      "Epoch:  4371 Loss:  0.587645 accurracy:  0.9506099\n",
      "Epoch:  4372 Loss:  0.58764386 accurracy:  0.9506136\n",
      "Epoch:  4373 Loss:  0.5876427 accurracy:  0.9506173\n",
      "Epoch:  4374 Loss:  0.5876416 accurracy:  0.95062095\n",
      "Epoch:  4375 Loss:  0.5876407 accurracy:  0.95062464\n",
      "Epoch:  4376 Loss:  0.5876398 accurracy:  0.9506283\n",
      "Epoch:  4377 Loss:  0.58763885 accurracy:  0.950632\n",
      "Epoch:  4378 Loss:  0.5876377 accurracy:  0.9506356\n",
      "Epoch:  4379 Loss:  0.5876364 accurracy:  0.95063925\n",
      "Epoch:  4380 Loss:  0.58763564 accurracy:  0.95064294\n",
      "Epoch:  4381 Loss:  0.5876347 accurracy:  0.9506466\n",
      "Epoch:  4382 Loss:  0.5876337 accurracy:  0.9506502\n",
      "Epoch:  4383 Loss:  0.5876324 accurracy:  0.9506539\n",
      "Epoch:  4384 Loss:  0.58763134 accurracy:  0.95065755\n",
      "Epoch:  4385 Loss:  0.58763045 accurracy:  0.9506612\n",
      "Epoch:  4386 Loss:  0.58762944 accurracy:  0.9506648\n",
      "Epoch:  4387 Loss:  0.5876284 accurracy:  0.9506685\n",
      "Epoch:  4388 Loss:  0.5876273 accurracy:  0.95067215\n",
      "Epoch:  4389 Loss:  0.5876263 accurracy:  0.9506758\n",
      "Epoch:  4390 Loss:  0.58762527 accurracy:  0.9506794\n",
      "Epoch:  4391 Loss:  0.5876245 accurracy:  0.95068306\n",
      "Epoch:  4392 Loss:  0.5876234 accurracy:  0.9506867\n",
      "Epoch:  4393 Loss:  0.5876224 accurracy:  0.9506903\n",
      "Epoch:  4394 Loss:  0.5876213 accurracy:  0.95069396\n",
      "Epoch:  4395 Loss:  0.58762014 accurracy:  0.9506976\n",
      "Epoch:  4396 Loss:  0.58761925 accurracy:  0.95070124\n",
      "Epoch:  4397 Loss:  0.5876184 accurracy:  0.9507049\n",
      "Epoch:  4398 Loss:  0.58761734 accurracy:  0.9507085\n",
      "Epoch:  4399 Loss:  0.5876161 accurracy:  0.95071214\n",
      "Epoch:  4400 Loss:  0.58761495 accurracy:  0.9507157\n",
      "Epoch:  4401 Loss:  0.58761394 accurracy:  0.95071936\n",
      "Epoch:  4402 Loss:  0.5876133 accurracy:  0.950723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4403 Loss:  0.5876123 accurracy:  0.9507266\n",
      "Epoch:  4404 Loss:  0.587611 accurracy:  0.9507302\n",
      "Epoch:  4405 Loss:  0.58761 accurracy:  0.95073384\n",
      "Epoch:  4406 Loss:  0.5876091 accurracy:  0.9507375\n",
      "Epoch:  4407 Loss:  0.58760804 accurracy:  0.95074105\n",
      "Epoch:  4408 Loss:  0.58760685 accurracy:  0.9507447\n",
      "Epoch:  4409 Loss:  0.5876062 accurracy:  0.9507483\n",
      "Epoch:  4410 Loss:  0.5876052 accurracy:  0.9507519\n",
      "Epoch:  4411 Loss:  0.587604 accurracy:  0.95075554\n",
      "Epoch:  4412 Loss:  0.58760303 accurracy:  0.9507591\n",
      "Epoch:  4413 Loss:  0.58760196 accurracy:  0.95076275\n",
      "Epoch:  4414 Loss:  0.5876009 accurracy:  0.9507663\n",
      "Epoch:  4415 Loss:  0.58759993 accurracy:  0.9507699\n",
      "Epoch:  4416 Loss:  0.5875989 accurracy:  0.95077354\n",
      "Epoch:  4417 Loss:  0.5875981 accurracy:  0.9507771\n",
      "Epoch:  4418 Loss:  0.5875968 accurracy:  0.95078075\n",
      "Epoch:  4419 Loss:  0.58759576 accurracy:  0.9507843\n",
      "Epoch:  4420 Loss:  0.587595 accurracy:  0.9507879\n",
      "Epoch:  4421 Loss:  0.58759403 accurracy:  0.9507915\n",
      "Epoch:  4422 Loss:  0.5875929 accurracy:  0.9507951\n",
      "Epoch:  4423 Loss:  0.58759207 accurracy:  0.9507987\n",
      "Epoch:  4424 Loss:  0.58759093 accurracy:  0.95080227\n",
      "Epoch:  4425 Loss:  0.5875896 accurracy:  0.95080584\n",
      "Epoch:  4426 Loss:  0.5875887 accurracy:  0.9508094\n",
      "Epoch:  4427 Loss:  0.587588 accurracy:  0.950813\n",
      "Epoch:  4428 Loss:  0.5875871 accurracy:  0.9508166\n",
      "Epoch:  4429 Loss:  0.5875858 accurracy:  0.95082015\n",
      "Epoch:  4430 Loss:  0.5875847 accurracy:  0.9508237\n",
      "Epoch:  4431 Loss:  0.58758366 accurracy:  0.9508273\n",
      "Epoch:  4432 Loss:  0.5875828 accurracy:  0.9508309\n",
      "Epoch:  4433 Loss:  0.5875819 accurracy:  0.95083445\n",
      "Epoch:  4434 Loss:  0.587581 accurracy:  0.950838\n",
      "Epoch:  4435 Loss:  0.5875798 accurracy:  0.9508416\n",
      "Epoch:  4436 Loss:  0.5875787 accurracy:  0.9508452\n",
      "Epoch:  4437 Loss:  0.5875778 accurracy:  0.95084876\n",
      "Epoch:  4438 Loss:  0.5875771 accurracy:  0.9508523\n",
      "Epoch:  4439 Loss:  0.5875759 accurracy:  0.95085585\n",
      "Epoch:  4440 Loss:  0.5875746 accurracy:  0.9508594\n",
      "Epoch:  4441 Loss:  0.58757365 accurracy:  0.950863\n",
      "Epoch:  4442 Loss:  0.5875731 accurracy:  0.9508665\n",
      "Epoch:  4443 Loss:  0.587572 accurracy:  0.9508701\n",
      "Epoch:  4444 Loss:  0.58757085 accurracy:  0.9508736\n",
      "Epoch:  4445 Loss:  0.5875696 accurracy:  0.9508772\n",
      "Epoch:  4446 Loss:  0.5875688 accurracy:  0.95088077\n",
      "Epoch:  4447 Loss:  0.58756816 accurracy:  0.9508843\n",
      "Epoch:  4448 Loss:  0.58756703 accurracy:  0.95088786\n",
      "Epoch:  4449 Loss:  0.58756554 accurracy:  0.9508914\n",
      "Epoch:  4450 Loss:  0.58756465 accurracy:  0.95089495\n",
      "Epoch:  4451 Loss:  0.58756375 accurracy:  0.95089847\n",
      "Epoch:  4452 Loss:  0.5875631 accurracy:  0.950902\n",
      "Epoch:  4453 Loss:  0.58756196 accurracy:  0.95090556\n",
      "Epoch:  4454 Loss:  0.5875608 accurracy:  0.9509091\n",
      "Epoch:  4455 Loss:  0.58755976 accurracy:  0.95091265\n",
      "Epoch:  4456 Loss:  0.587559 accurracy:  0.9509162\n",
      "Epoch:  4457 Loss:  0.58755803 accurracy:  0.9509197\n",
      "Epoch:  4458 Loss:  0.5875569 accurracy:  0.9509232\n",
      "Epoch:  4459 Loss:  0.5875559 accurracy:  0.9509268\n",
      "Epoch:  4460 Loss:  0.587555 accurracy:  0.9509303\n",
      "Epoch:  4461 Loss:  0.58755404 accurracy:  0.9509338\n",
      "Epoch:  4462 Loss:  0.587553 accurracy:  0.95093733\n",
      "Epoch:  4463 Loss:  0.5875519 accurracy:  0.95094085\n",
      "Epoch:  4464 Loss:  0.587551 accurracy:  0.95094436\n",
      "Epoch:  4465 Loss:  0.58755 accurracy:  0.9509479\n",
      "Epoch:  4466 Loss:  0.58754903 accurracy:  0.9509514\n",
      "Epoch:  4467 Loss:  0.5875481 accurracy:  0.9509549\n",
      "Epoch:  4468 Loss:  0.58754706 accurracy:  0.95095843\n",
      "Epoch:  4469 Loss:  0.58754593 accurracy:  0.95096195\n",
      "Epoch:  4470 Loss:  0.58754516 accurracy:  0.95096546\n",
      "Epoch:  4471 Loss:  0.58754426 accurracy:  0.950969\n",
      "Epoch:  4472 Loss:  0.58754337 accurracy:  0.9509725\n",
      "Epoch:  4473 Loss:  0.58754176 accurracy:  0.950976\n",
      "Epoch:  4474 Loss:  0.587541 accurracy:  0.95097953\n",
      "Epoch:  4475 Loss:  0.5875403 accurracy:  0.95098305\n",
      "Epoch:  4476 Loss:  0.5875394 accurracy:  0.9509865\n",
      "Epoch:  4477 Loss:  0.5875381 accurracy:  0.95099\n",
      "Epoch:  4478 Loss:  0.5875369 accurracy:  0.95099354\n",
      "Epoch:  4479 Loss:  0.5875359 accurracy:  0.950997\n",
      "Epoch:  4480 Loss:  0.5875353 accurracy:  0.9510005\n",
      "Epoch:  4481 Loss:  0.58753467 accurracy:  0.951004\n",
      "Epoch:  4482 Loss:  0.5875334 accurracy:  0.9510075\n",
      "Epoch:  4483 Loss:  0.58753204 accurracy:  0.951011\n",
      "Epoch:  4484 Loss:  0.58753103 accurracy:  0.9510145\n",
      "Epoch:  4485 Loss:  0.5875303 accurracy:  0.951018\n",
      "Epoch:  4486 Loss:  0.5875296 accurracy:  0.9510215\n",
      "Epoch:  4487 Loss:  0.58752847 accurracy:  0.95102495\n",
      "Epoch:  4488 Loss:  0.5875272 accurracy:  0.95102847\n",
      "Epoch:  4489 Loss:  0.5875261 accurracy:  0.9510319\n",
      "Epoch:  4490 Loss:  0.58752567 accurracy:  0.9510354\n",
      "Epoch:  4491 Loss:  0.58752495 accurracy:  0.9510389\n",
      "Epoch:  4492 Loss:  0.5875235 accurracy:  0.95104235\n",
      "Epoch:  4493 Loss:  0.5875223 accurracy:  0.9510458\n",
      "Epoch:  4494 Loss:  0.5875215 accurracy:  0.9510493\n",
      "Epoch:  4495 Loss:  0.5875207 accurracy:  0.9510528\n",
      "Epoch:  4496 Loss:  0.58751994 accurracy:  0.95105624\n",
      "Epoch:  4497 Loss:  0.5875187 accurracy:  0.95105976\n",
      "Epoch:  4498 Loss:  0.5875177 accurracy:  0.9510632\n",
      "Epoch:  4499 Loss:  0.58751667 accurracy:  0.9510667\n",
      "Epoch:  4500 Loss:  0.5875158 accurracy:  0.95107013\n",
      "Epoch:  4501 Loss:  0.5875149 accurracy:  0.9510736\n",
      "Epoch:  4502 Loss:  0.58751374 accurracy:  0.95107704\n",
      "Epoch:  4503 Loss:  0.58751285 accurracy:  0.9510805\n",
      "Epoch:  4504 Loss:  0.5875119 accurracy:  0.95108396\n",
      "Epoch:  4505 Loss:  0.58751094 accurracy:  0.9510874\n",
      "Epoch:  4506 Loss:  0.58750993 accurracy:  0.9510909\n",
      "Epoch:  4507 Loss:  0.5875089 accurracy:  0.9510943\n",
      "Epoch:  4508 Loss:  0.5875081 accurracy:  0.9510978\n",
      "Epoch:  4509 Loss:  0.5875071 accurracy:  0.95110124\n",
      "Epoch:  4510 Loss:  0.5875061 accurracy:  0.9511047\n",
      "Epoch:  4511 Loss:  0.5875053 accurracy:  0.95110816\n",
      "Epoch:  4512 Loss:  0.5875042 accurracy:  0.9511116\n",
      "Epoch:  4513 Loss:  0.587503 accurracy:  0.9511151\n",
      "Epoch:  4514 Loss:  0.5875021 accurracy:  0.95111847\n",
      "Epoch:  4515 Loss:  0.58750147 accurracy:  0.9511219\n",
      "Epoch:  4516 Loss:  0.5875005 accurracy:  0.9511254\n",
      "Epoch:  4517 Loss:  0.5874994 accurracy:  0.95112884\n",
      "Epoch:  4518 Loss:  0.5874981 accurracy:  0.95113224\n",
      "Epoch:  4519 Loss:  0.5874974 accurracy:  0.9511357\n",
      "Epoch:  4520 Loss:  0.5874967 accurracy:  0.95113915\n",
      "Epoch:  4521 Loss:  0.58749574 accurracy:  0.95114255\n",
      "Epoch:  4522 Loss:  0.5874946 accurracy:  0.951146\n",
      "Epoch:  4523 Loss:  0.5874933 accurracy:  0.9511494\n",
      "Epoch:  4524 Loss:  0.5874926 accurracy:  0.95115286\n",
      "Epoch:  4525 Loss:  0.587492 accurracy:  0.95115626\n",
      "Epoch:  4526 Loss:  0.5874909 accurracy:  0.9511597\n",
      "Epoch:  4527 Loss:  0.58748966 accurracy:  0.9511631\n",
      "Epoch:  4528 Loss:  0.58748853 accurracy:  0.95116657\n",
      "Epoch:  4529 Loss:  0.5874878 accurracy:  0.95116997\n",
      "Epoch:  4530 Loss:  0.58748704 accurracy:  0.9511734\n",
      "Epoch:  4531 Loss:  0.5874862 accurracy:  0.9511768\n",
      "Epoch:  4532 Loss:  0.587485 accurracy:  0.9511802\n",
      "Epoch:  4533 Loss:  0.587484 accurracy:  0.9511837\n",
      "Epoch:  4534 Loss:  0.5874831 accurracy:  0.9511871\n",
      "Epoch:  4535 Loss:  0.58748233 accurracy:  0.9511905\n",
      "Epoch:  4536 Loss:  0.58748114 accurracy:  0.95119387\n",
      "Epoch:  4537 Loss:  0.58748 accurracy:  0.9511973\n",
      "Epoch:  4538 Loss:  0.5874792 accurracy:  0.9512007\n",
      "Epoch:  4539 Loss:  0.5874786 accurracy:  0.9512041\n",
      "Epoch:  4540 Loss:  0.5874775 accurracy:  0.9512075\n",
      "Epoch:  4541 Loss:  0.5874762 accurracy:  0.9512109\n",
      "Epoch:  4542 Loss:  0.58747524 accurracy:  0.9512143\n",
      "Epoch:  4543 Loss:  0.5874746 accurracy:  0.9512177\n",
      "Epoch:  4544 Loss:  0.5874737 accurracy:  0.9512211\n",
      "Epoch:  4545 Loss:  0.5874726 accurracy:  0.9512245\n",
      "Epoch:  4546 Loss:  0.58747166 accurracy:  0.9512279\n",
      "Epoch:  4547 Loss:  0.5874709 accurracy:  0.9512313\n",
      "Epoch:  4548 Loss:  0.5874699 accurracy:  0.9512347\n",
      "Epoch:  4549 Loss:  0.58746904 accurracy:  0.9512381\n",
      "Epoch:  4550 Loss:  0.5874679 accurracy:  0.9512415\n",
      "Epoch:  4551 Loss:  0.58746684 accurracy:  0.9512449\n",
      "Epoch:  4552 Loss:  0.5874659 accurracy:  0.9512483\n",
      "Epoch:  4553 Loss:  0.58746517 accurracy:  0.9512516\n",
      "Epoch:  4554 Loss:  0.5874644 accurracy:  0.951255\n",
      "Epoch:  4555 Loss:  0.58746326 accurracy:  0.9512584\n",
      "Epoch:  4556 Loss:  0.587462 accurracy:  0.9512618\n",
      "Epoch:  4557 Loss:  0.58746123 accurracy:  0.95126516\n",
      "Epoch:  4558 Loss:  0.58746034 accurracy:  0.95126855\n",
      "Epoch:  4559 Loss:  0.58745956 accurracy:  0.95127195\n",
      "Epoch:  4560 Loss:  0.5874585 accurracy:  0.9512753\n",
      "Epoch:  4561 Loss:  0.5874575 accurracy:  0.9512787\n",
      "Epoch:  4562 Loss:  0.5874564 accurracy:  0.951282\n",
      "Epoch:  4563 Loss:  0.58745575 accurracy:  0.9512854\n",
      "Epoch:  4564 Loss:  0.58745503 accurracy:  0.9512888\n",
      "Epoch:  4565 Loss:  0.5874538 accurracy:  0.95129216\n",
      "Epoch:  4566 Loss:  0.58745265 accurracy:  0.95129555\n",
      "Epoch:  4567 Loss:  0.58745164 accurracy:  0.9512989\n",
      "Epoch:  4568 Loss:  0.58745104 accurracy:  0.95130223\n",
      "Epoch:  4569 Loss:  0.58745027 accurracy:  0.9513056\n",
      "Epoch:  4570 Loss:  0.58744913 accurracy:  0.95130897\n",
      "Epoch:  4571 Loss:  0.58744794 accurracy:  0.95131236\n",
      "Epoch:  4572 Loss:  0.587447 accurracy:  0.9513157\n",
      "Epoch:  4573 Loss:  0.58744633 accurracy:  0.95131904\n",
      "Epoch:  4574 Loss:  0.58744556 accurracy:  0.9513224\n",
      "Epoch:  4575 Loss:  0.5874444 accurracy:  0.9513258\n",
      "Epoch:  4576 Loss:  0.5874432 accurracy:  0.9513291\n",
      "Epoch:  4577 Loss:  0.5874423 accurracy:  0.95133245\n",
      "Epoch:  4578 Loss:  0.5874416 accurracy:  0.9513358\n",
      "Epoch:  4579 Loss:  0.58744067 accurracy:  0.9513392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4580 Loss:  0.58743954 accurracy:  0.9513425\n",
      "Epoch:  4581 Loss:  0.5874386 accurracy:  0.95134586\n",
      "Epoch:  4582 Loss:  0.5874378 accurracy:  0.9513492\n",
      "Epoch:  4583 Loss:  0.58743703 accurracy:  0.95135254\n",
      "Epoch:  4584 Loss:  0.587436 accurracy:  0.9513559\n",
      "Epoch:  4585 Loss:  0.5874348 accurracy:  0.9513592\n",
      "Epoch:  4586 Loss:  0.5874339 accurracy:  0.95136255\n",
      "Epoch:  4587 Loss:  0.58743316 accurracy:  0.9513659\n",
      "Epoch:  4588 Loss:  0.58743244 accurracy:  0.9513692\n",
      "Epoch:  4589 Loss:  0.5874313 accurracy:  0.95137256\n",
      "Epoch:  4590 Loss:  0.58743006 accurracy:  0.9513759\n",
      "Epoch:  4591 Loss:  0.58742905 accurracy:  0.95137924\n",
      "Epoch:  4592 Loss:  0.5874285 accurracy:  0.9513825\n",
      "Epoch:  4593 Loss:  0.5874277 accurracy:  0.95138586\n",
      "Epoch:  4594 Loss:  0.5874266 accurracy:  0.9513892\n",
      "Epoch:  4595 Loss:  0.5874256 accurracy:  0.95139253\n",
      "Epoch:  4596 Loss:  0.58742464 accurracy:  0.9513958\n",
      "Epoch:  4597 Loss:  0.587424 accurracy:  0.95139915\n",
      "Epoch:  4598 Loss:  0.5874231 accurracy:  0.9514025\n",
      "Epoch:  4599 Loss:  0.5874221 accurracy:  0.9514058\n",
      "Epoch:  4600 Loss:  0.5874209 accurracy:  0.9514091\n",
      "Epoch:  4601 Loss:  0.58741987 accurracy:  0.95141244\n",
      "Epoch:  4602 Loss:  0.5874194 accurracy:  0.9514157\n",
      "Epoch:  4603 Loss:  0.5874185 accurracy:  0.95141906\n",
      "Epoch:  4604 Loss:  0.5874174 accurracy:  0.9514224\n",
      "Epoch:  4605 Loss:  0.58741635 accurracy:  0.9514257\n",
      "Epoch:  4606 Loss:  0.5874156 accurracy:  0.951429\n",
      "Epoch:  4607 Loss:  0.5874148 accurracy:  0.9514323\n",
      "Epoch:  4608 Loss:  0.58741367 accurracy:  0.9514356\n",
      "Epoch:  4609 Loss:  0.58741283 accurracy:  0.9514389\n",
      "Epoch:  4610 Loss:  0.5874118 accurracy:  0.9514422\n",
      "Epoch:  4611 Loss:  0.587411 accurracy:  0.9514455\n",
      "Epoch:  4612 Loss:  0.5874101 accurracy:  0.9514488\n",
      "Epoch:  4613 Loss:  0.58740914 accurracy:  0.9514521\n",
      "Epoch:  4614 Loss:  0.58740807 accurracy:  0.9514554\n",
      "Epoch:  4615 Loss:  0.5874073 accurracy:  0.9514587\n",
      "Epoch:  4616 Loss:  0.5874063 accurracy:  0.951462\n",
      "Epoch:  4617 Loss:  0.58740515 accurracy:  0.9514653\n",
      "Epoch:  4618 Loss:  0.5874046 accurracy:  0.9514686\n",
      "Epoch:  4619 Loss:  0.5874039 accurracy:  0.95147187\n",
      "Epoch:  4620 Loss:  0.5874027 accurracy:  0.95147514\n",
      "Epoch:  4621 Loss:  0.5874017 accurracy:  0.9514784\n",
      "Epoch:  4622 Loss:  0.5874005 accurracy:  0.9514817\n",
      "Epoch:  4623 Loss:  0.5873998 accurracy:  0.951485\n",
      "Epoch:  4624 Loss:  0.5873992 accurracy:  0.9514883\n",
      "Epoch:  4625 Loss:  0.5873983 accurracy:  0.9514916\n",
      "Epoch:  4626 Loss:  0.587397 accurracy:  0.9514949\n",
      "Epoch:  4627 Loss:  0.5873961 accurracy:  0.95149815\n",
      "Epoch:  4628 Loss:  0.58739525 accurracy:  0.9515014\n",
      "Epoch:  4629 Loss:  0.5873947 accurracy:  0.9515047\n",
      "Epoch:  4630 Loss:  0.5873937 accurracy:  0.9515079\n",
      "Epoch:  4631 Loss:  0.5873923 accurracy:  0.9515112\n",
      "Epoch:  4632 Loss:  0.5873915 accurracy:  0.9515145\n",
      "Epoch:  4633 Loss:  0.5873907 accurracy:  0.95151776\n",
      "Epoch:  4634 Loss:  0.58739007 accurracy:  0.95152104\n",
      "Epoch:  4635 Loss:  0.58738905 accurracy:  0.9515243\n",
      "Epoch:  4636 Loss:  0.5873879 accurracy:  0.9515276\n",
      "Epoch:  4637 Loss:  0.5873869 accurracy:  0.9515308\n",
      "Epoch:  4638 Loss:  0.5873862 accurracy:  0.9515341\n",
      "Epoch:  4639 Loss:  0.5873854 accurracy:  0.9515374\n",
      "Epoch:  4640 Loss:  0.5873845 accurracy:  0.9515406\n",
      "Epoch:  4641 Loss:  0.58738345 accurracy:  0.95154387\n",
      "Epoch:  4642 Loss:  0.5873825 accurracy:  0.95154715\n",
      "Epoch:  4643 Loss:  0.58738136 accurracy:  0.95155036\n",
      "Epoch:  4644 Loss:  0.58738065 accurracy:  0.95155364\n",
      "Epoch:  4645 Loss:  0.5873801 accurracy:  0.9515569\n",
      "Epoch:  4646 Loss:  0.5873789 accurracy:  0.95156014\n",
      "Epoch:  4647 Loss:  0.5873779 accurracy:  0.9515634\n",
      "Epoch:  4648 Loss:  0.5873769 accurracy:  0.95156664\n",
      "Epoch:  4649 Loss:  0.5873763 accurracy:  0.9515699\n",
      "Epoch:  4650 Loss:  0.5873753 accurracy:  0.95157313\n",
      "Epoch:  4651 Loss:  0.5873745 accurracy:  0.9515764\n",
      "Epoch:  4652 Loss:  0.5873735 accurracy:  0.95157963\n",
      "Epoch:  4653 Loss:  0.5873727 accurracy:  0.95158285\n",
      "Epoch:  4654 Loss:  0.58737177 accurracy:  0.9515861\n",
      "Epoch:  4655 Loss:  0.58737075 accurracy:  0.95158935\n",
      "Epoch:  4656 Loss:  0.5873697 accurracy:  0.95159256\n",
      "Epoch:  4657 Loss:  0.587369 accurracy:  0.95159584\n",
      "Epoch:  4658 Loss:  0.58736825 accurracy:  0.95159906\n",
      "Epoch:  4659 Loss:  0.5873672 accurracy:  0.9516023\n",
      "Epoch:  4660 Loss:  0.5873663 accurracy:  0.9516055\n",
      "Epoch:  4661 Loss:  0.58736515 accurracy:  0.9516088\n",
      "Epoch:  4662 Loss:  0.58736444 accurracy:  0.951612\n",
      "Epoch:  4663 Loss:  0.58736366 accurracy:  0.9516152\n",
      "Epoch:  4664 Loss:  0.58736295 accurracy:  0.95161843\n",
      "Epoch:  4665 Loss:  0.5873617 accurracy:  0.95162165\n",
      "Epoch:  4666 Loss:  0.5873607 accurracy:  0.9516249\n",
      "Epoch:  4667 Loss:  0.58735996 accurracy:  0.9516281\n",
      "Epoch:  4668 Loss:  0.58735913 accurracy:  0.9516313\n",
      "Epoch:  4669 Loss:  0.58735836 accurracy:  0.9516345\n",
      "Epoch:  4670 Loss:  0.58735734 accurracy:  0.95163774\n",
      "Epoch:  4671 Loss:  0.5873562 accurracy:  0.95164096\n",
      "Epoch:  4672 Loss:  0.58735555 accurracy:  0.9516442\n",
      "Epoch:  4673 Loss:  0.58735484 accurracy:  0.9516474\n",
      "Epoch:  4674 Loss:  0.58735365 accurracy:  0.9516506\n",
      "Epoch:  4675 Loss:  0.5873526 accurracy:  0.95165384\n",
      "Epoch:  4676 Loss:  0.58735186 accurracy:  0.95165706\n",
      "Epoch:  4677 Loss:  0.5873511 accurracy:  0.9516603\n",
      "Epoch:  4678 Loss:  0.5873502 accurracy:  0.95166343\n",
      "Epoch:  4679 Loss:  0.5873492 accurracy:  0.95166665\n",
      "Epoch:  4680 Loss:  0.5873483 accurracy:  0.9516699\n",
      "Epoch:  4681 Loss:  0.5873474 accurracy:  0.9516731\n",
      "Epoch:  4682 Loss:  0.5873465 accurracy:  0.95167625\n",
      "Epoch:  4683 Loss:  0.58734566 accurracy:  0.95167947\n",
      "Epoch:  4684 Loss:  0.5873449 accurracy:  0.9516827\n",
      "Epoch:  4685 Loss:  0.5873441 accurracy:  0.95168585\n",
      "Epoch:  4686 Loss:  0.58734286 accurracy:  0.95168906\n",
      "Epoch:  4687 Loss:  0.587342 accurracy:  0.9516923\n",
      "Epoch:  4688 Loss:  0.5873414 accurracy:  0.95169544\n",
      "Epoch:  4689 Loss:  0.5873404 accurracy:  0.95169866\n",
      "Epoch:  4690 Loss:  0.58733946 accurracy:  0.9517018\n",
      "Epoch:  4691 Loss:  0.5873385 accurracy:  0.95170504\n",
      "Epoch:  4692 Loss:  0.58733773 accurracy:  0.9517082\n",
      "Epoch:  4693 Loss:  0.58733696 accurracy:  0.9517114\n",
      "Epoch:  4694 Loss:  0.5873358 accurracy:  0.9517146\n",
      "Epoch:  4695 Loss:  0.58733493 accurracy:  0.9517178\n",
      "Epoch:  4696 Loss:  0.58733404 accurracy:  0.95172095\n",
      "Epoch:  4697 Loss:  0.58733326 accurracy:  0.9517241\n",
      "Epoch:  4698 Loss:  0.5873323 accurracy:  0.95172733\n",
      "Epoch:  4699 Loss:  0.5873315 accurracy:  0.9517305\n",
      "Epoch:  4700 Loss:  0.5873305 accurracy:  0.95173365\n",
      "Epoch:  4701 Loss:  0.5873297 accurracy:  0.95173687\n",
      "Epoch:  4702 Loss:  0.58732873 accurracy:  0.95174\n",
      "Epoch:  4703 Loss:  0.58732796 accurracy:  0.9517432\n",
      "Epoch:  4704 Loss:  0.5873272 accurracy:  0.95174634\n",
      "Epoch:  4705 Loss:  0.58732617 accurracy:  0.95174956\n",
      "Epoch:  4706 Loss:  0.5873251 accurracy:  0.9517527\n",
      "Epoch:  4707 Loss:  0.5873244 accurracy:  0.9517559\n",
      "Epoch:  4708 Loss:  0.5873236 accurracy:  0.95175904\n",
      "Epoch:  4709 Loss:  0.58732265 accurracy:  0.9517622\n",
      "Epoch:  4710 Loss:  0.5873216 accurracy:  0.95176536\n",
      "Epoch:  4711 Loss:  0.58732074 accurracy:  0.9517685\n",
      "Epoch:  4712 Loss:  0.58732015 accurracy:  0.9517717\n",
      "Epoch:  4713 Loss:  0.5873192 accurracy:  0.95177484\n",
      "Epoch:  4714 Loss:  0.5873181 accurracy:  0.951778\n",
      "Epoch:  4715 Loss:  0.5873174 accurracy:  0.95178115\n",
      "Epoch:  4716 Loss:  0.5873166 accurracy:  0.9517843\n",
      "Epoch:  4717 Loss:  0.58731574 accurracy:  0.9517875\n",
      "Epoch:  4718 Loss:  0.5873147 accurracy:  0.95179063\n",
      "Epoch:  4719 Loss:  0.5873136 accurracy:  0.9517938\n",
      "Epoch:  4720 Loss:  0.58731276 accurracy:  0.95179695\n",
      "Epoch:  4721 Loss:  0.587312 accurracy:  0.9518001\n",
      "Epoch:  4722 Loss:  0.5873112 accurracy:  0.9518032\n",
      "Epoch:  4723 Loss:  0.58731043 accurracy:  0.95180637\n",
      "Epoch:  4724 Loss:  0.58730924 accurracy:  0.9518095\n",
      "Epoch:  4725 Loss:  0.58730835 accurracy:  0.9518127\n",
      "Epoch:  4726 Loss:  0.58730775 accurracy:  0.9518158\n",
      "Epoch:  4727 Loss:  0.5873072 accurracy:  0.95181894\n",
      "Epoch:  4728 Loss:  0.58730614 accurracy:  0.9518221\n",
      "Epoch:  4729 Loss:  0.58730495 accurracy:  0.9518252\n",
      "Epoch:  4730 Loss:  0.58730394 accurracy:  0.95182836\n",
      "Epoch:  4731 Loss:  0.5873032 accurracy:  0.9518315\n",
      "Epoch:  4732 Loss:  0.58730257 accurracy:  0.9518346\n",
      "Epoch:  4733 Loss:  0.5873016 accurracy:  0.9518378\n",
      "Epoch:  4734 Loss:  0.58730054 accurracy:  0.9518409\n",
      "Epoch:  4735 Loss:  0.58729976 accurracy:  0.95184404\n",
      "Epoch:  4736 Loss:  0.58729917 accurracy:  0.95184714\n",
      "Epoch:  4737 Loss:  0.58729815 accurracy:  0.9518503\n",
      "Epoch:  4738 Loss:  0.58729714 accurracy:  0.9518534\n",
      "Epoch:  4739 Loss:  0.58729637 accurracy:  0.95185655\n",
      "Epoch:  4740 Loss:  0.58729553 accurracy:  0.95185965\n",
      "Epoch:  4741 Loss:  0.58729464 accurracy:  0.9518628\n",
      "Epoch:  4742 Loss:  0.58729374 accurracy:  0.9518659\n",
      "Epoch:  4743 Loss:  0.58729285 accurracy:  0.951869\n",
      "Epoch:  4744 Loss:  0.58729213 accurracy:  0.95187217\n",
      "Epoch:  4745 Loss:  0.5872912 accurracy:  0.95187527\n",
      "Epoch:  4746 Loss:  0.5872902 accurracy:  0.95187837\n",
      "Epoch:  4747 Loss:  0.5872893 accurracy:  0.95188147\n",
      "Epoch:  4748 Loss:  0.5872885 accurracy:  0.9518846\n",
      "Epoch:  4749 Loss:  0.58728766 accurracy:  0.9518877\n",
      "Epoch:  4750 Loss:  0.5872869 accurracy:  0.9518908\n",
      "Epoch:  4751 Loss:  0.587286 accurracy:  0.9518939\n",
      "Epoch:  4752 Loss:  0.58728516 accurracy:  0.951897\n",
      "Epoch:  4753 Loss:  0.5872842 accurracy:  0.9519001\n",
      "Epoch:  4754 Loss:  0.58728343 accurracy:  0.9519033\n",
      "Epoch:  4755 Loss:  0.5872825 accurracy:  0.9519064\n",
      "Epoch:  4756 Loss:  0.58728164 accurracy:  0.9519095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4757 Loss:  0.58728063 accurracy:  0.9519126\n",
      "Epoch:  4758 Loss:  0.5872799 accurracy:  0.9519157\n",
      "Epoch:  4759 Loss:  0.58727926 accurracy:  0.9519188\n",
      "Epoch:  4760 Loss:  0.5872785 accurracy:  0.9519219\n",
      "Epoch:  4761 Loss:  0.5872773 accurracy:  0.951925\n",
      "Epoch:  4762 Loss:  0.5872762 accurracy:  0.9519281\n",
      "Epoch:  4763 Loss:  0.5872756 accurracy:  0.9519312\n",
      "Epoch:  4764 Loss:  0.58727497 accurracy:  0.9519342\n",
      "Epoch:  4765 Loss:  0.5872742 accurracy:  0.9519373\n",
      "Epoch:  4766 Loss:  0.58727294 accurracy:  0.9519404\n",
      "Epoch:  4767 Loss:  0.58727175 accurracy:  0.9519435\n",
      "Epoch:  4768 Loss:  0.5872713 accurracy:  0.9519466\n",
      "Epoch:  4769 Loss:  0.58727074 accurracy:  0.95194966\n",
      "Epoch:  4770 Loss:  0.5872699 accurracy:  0.95195276\n",
      "Epoch:  4771 Loss:  0.5872687 accurracy:  0.95195585\n",
      "Epoch:  4772 Loss:  0.5872678 accurracy:  0.95195895\n",
      "Epoch:  4773 Loss:  0.58726686 accurracy:  0.951962\n",
      "Epoch:  4774 Loss:  0.5872661 accurracy:  0.9519651\n",
      "Epoch:  4775 Loss:  0.5872654 accurracy:  0.9519682\n",
      "Epoch:  4776 Loss:  0.5872648 accurracy:  0.95197123\n",
      "Epoch:  4777 Loss:  0.5872637 accurracy:  0.95197433\n",
      "Epoch:  4778 Loss:  0.58726275 accurracy:  0.9519774\n",
      "Epoch:  4779 Loss:  0.5872618 accurracy:  0.9519805\n",
      "Epoch:  4780 Loss:  0.5872611 accurracy:  0.9519836\n",
      "Epoch:  4781 Loss:  0.5872604 accurracy:  0.9519866\n",
      "Epoch:  4782 Loss:  0.58725953 accurracy:  0.9519897\n",
      "Epoch:  4783 Loss:  0.5872583 accurracy:  0.95199275\n",
      "Epoch:  4784 Loss:  0.5872574 accurracy:  0.95199585\n",
      "Epoch:  4785 Loss:  0.58725685 accurracy:  0.9519989\n",
      "Epoch:  4786 Loss:  0.58725625 accurracy:  0.9520019\n",
      "Epoch:  4787 Loss:  0.5872552 accurracy:  0.952005\n",
      "Epoch:  4788 Loss:  0.58725417 accurracy:  0.95200807\n",
      "Epoch:  4789 Loss:  0.5872532 accurracy:  0.9520111\n",
      "Epoch:  4790 Loss:  0.5872527 accurracy:  0.9520142\n",
      "Epoch:  4791 Loss:  0.587252 accurracy:  0.95201725\n",
      "Epoch:  4792 Loss:  0.58725095 accurracy:  0.9520203\n",
      "Epoch:  4793 Loss:  0.58724976 accurracy:  0.9520234\n",
      "Epoch:  4794 Loss:  0.587249 accurracy:  0.9520264\n",
      "Epoch:  4795 Loss:  0.5872485 accurracy:  0.95202947\n",
      "Epoch:  4796 Loss:  0.5872477 accurracy:  0.9520325\n",
      "Epoch:  4797 Loss:  0.5872467 accurracy:  0.95203555\n",
      "Epoch:  4798 Loss:  0.5872457 accurracy:  0.95203865\n",
      "Epoch:  4799 Loss:  0.5872447 accurracy:  0.9520417\n",
      "Epoch:  4800 Loss:  0.58724415 accurracy:  0.9520447\n",
      "Epoch:  4801 Loss:  0.58724344 accurracy:  0.95204777\n",
      "Epoch:  4802 Loss:  0.5872425 accurracy:  0.9520508\n",
      "Epoch:  4803 Loss:  0.5872413 accurracy:  0.95205384\n",
      "Epoch:  4804 Loss:  0.58724046 accurracy:  0.9520569\n",
      "Epoch:  4805 Loss:  0.5872399 accurracy:  0.9520599\n",
      "Epoch:  4806 Loss:  0.5872393 accurracy:  0.95206296\n",
      "Epoch:  4807 Loss:  0.58723825 accurracy:  0.952066\n",
      "Epoch:  4808 Loss:  0.58723724 accurracy:  0.95206904\n",
      "Epoch:  4809 Loss:  0.5872363 accurracy:  0.9520721\n",
      "Epoch:  4810 Loss:  0.58723587 accurracy:  0.9520751\n",
      "Epoch:  4811 Loss:  0.5872351 accurracy:  0.95207816\n",
      "Epoch:  4812 Loss:  0.58723396 accurracy:  0.95208114\n",
      "Epoch:  4813 Loss:  0.5872327 accurracy:  0.9520842\n",
      "Epoch:  4814 Loss:  0.58723193 accurracy:  0.9520872\n",
      "Epoch:  4815 Loss:  0.5872317 accurracy:  0.95209026\n",
      "Epoch:  4816 Loss:  0.5872309 accurracy:  0.9520933\n",
      "Epoch:  4817 Loss:  0.58722985 accurracy:  0.9520963\n",
      "Epoch:  4818 Loss:  0.5872287 accurracy:  0.9520993\n",
      "Epoch:  4819 Loss:  0.5872279 accurracy:  0.95210236\n",
      "Epoch:  4820 Loss:  0.5872273 accurracy:  0.95210534\n",
      "Epoch:  4821 Loss:  0.5872266 accurracy:  0.9521084\n",
      "Epoch:  4822 Loss:  0.5872257 accurracy:  0.9521114\n",
      "Epoch:  4823 Loss:  0.58722454 accurracy:  0.9521144\n",
      "Epoch:  4824 Loss:  0.58722377 accurracy:  0.95211744\n",
      "Epoch:  4825 Loss:  0.58722293 accurracy:  0.9521205\n",
      "Epoch:  4826 Loss:  0.5872224 accurracy:  0.95212346\n",
      "Epoch:  4827 Loss:  0.58722156 accurracy:  0.9521265\n",
      "Epoch:  4828 Loss:  0.5872206 accurracy:  0.9521295\n",
      "Epoch:  4829 Loss:  0.5872196 accurracy:  0.9521325\n",
      "Epoch:  4830 Loss:  0.58721864 accurracy:  0.9521355\n",
      "Epoch:  4831 Loss:  0.5872181 accurracy:  0.95213854\n",
      "Epoch:  4832 Loss:  0.58721733 accurracy:  0.9521415\n",
      "Epoch:  4833 Loss:  0.58721644 accurracy:  0.9521445\n",
      "Epoch:  4834 Loss:  0.5872155 accurracy:  0.95214754\n",
      "Epoch:  4835 Loss:  0.5872146 accurracy:  0.9521505\n",
      "Epoch:  4836 Loss:  0.5872138 accurracy:  0.95215356\n",
      "Epoch:  4837 Loss:  0.5872132 accurracy:  0.95215654\n",
      "Epoch:  4838 Loss:  0.5872124 accurracy:  0.9521595\n",
      "Epoch:  4839 Loss:  0.5872115 accurracy:  0.95216256\n",
      "Epoch:  4840 Loss:  0.5872106 accurracy:  0.95216554\n",
      "Epoch:  4841 Loss:  0.5872097 accurracy:  0.9521685\n",
      "Epoch:  4842 Loss:  0.5872089 accurracy:  0.9521715\n",
      "Epoch:  4843 Loss:  0.58720815 accurracy:  0.9521745\n",
      "Epoch:  4844 Loss:  0.58720714 accurracy:  0.9521775\n",
      "Epoch:  4845 Loss:  0.58720624 accurracy:  0.9521805\n",
      "Epoch:  4846 Loss:  0.58720565 accurracy:  0.9521835\n",
      "Epoch:  4847 Loss:  0.5872048 accurracy:  0.95218647\n",
      "Epoch:  4848 Loss:  0.58720404 accurracy:  0.95218945\n",
      "Epoch:  4849 Loss:  0.587203 accurracy:  0.9521924\n",
      "Epoch:  4850 Loss:  0.5872021 accurracy:  0.9521954\n",
      "Epoch:  4851 Loss:  0.58720154 accurracy:  0.9521984\n",
      "Epoch:  4852 Loss:  0.58720094 accurracy:  0.95220137\n",
      "Epoch:  4853 Loss:  0.5871998 accurracy:  0.95220435\n",
      "Epoch:  4854 Loss:  0.5871988 accurracy:  0.9522073\n",
      "Epoch:  4855 Loss:  0.587198 accurracy:  0.9522103\n",
      "Epoch:  4856 Loss:  0.58719736 accurracy:  0.9522133\n",
      "Epoch:  4857 Loss:  0.5871966 accurracy:  0.95221627\n",
      "Epoch:  4858 Loss:  0.5871955 accurracy:  0.95221925\n",
      "Epoch:  4859 Loss:  0.58719456 accurracy:  0.9522222\n",
      "Epoch:  4860 Loss:  0.5871938 accurracy:  0.9522252\n",
      "Epoch:  4861 Loss:  0.58719325 accurracy:  0.9522282\n",
      "Epoch:  4862 Loss:  0.5871925 accurracy:  0.9522311\n",
      "Epoch:  4863 Loss:  0.5871916 accurracy:  0.9522341\n",
      "Epoch:  4864 Loss:  0.5871905 accurracy:  0.95223707\n",
      "Epoch:  4865 Loss:  0.58718956 accurracy:  0.95224005\n",
      "Epoch:  4866 Loss:  0.58718896 accurracy:  0.952243\n",
      "Epoch:  4867 Loss:  0.5871886 accurracy:  0.95224595\n",
      "Epoch:  4868 Loss:  0.5871877 accurracy:  0.95224893\n",
      "Epoch:  4869 Loss:  0.5871864 accurracy:  0.9522519\n",
      "Epoch:  4870 Loss:  0.58718526 accurracy:  0.95225483\n",
      "Epoch:  4871 Loss:  0.5871849 accurracy:  0.9522578\n",
      "Epoch:  4872 Loss:  0.58718437 accurracy:  0.95226073\n",
      "Epoch:  4873 Loss:  0.5871834 accurracy:  0.9522637\n",
      "Epoch:  4874 Loss:  0.5871822 accurracy:  0.9522667\n",
      "Epoch:  4875 Loss:  0.5871812 accurracy:  0.9522696\n",
      "Epoch:  4876 Loss:  0.5871807 accurracy:  0.9522726\n",
      "Epoch:  4877 Loss:  0.58718044 accurracy:  0.9522755\n",
      "Epoch:  4878 Loss:  0.58717954 accurracy:  0.9522785\n",
      "Epoch:  4879 Loss:  0.5871783 accurracy:  0.9522814\n",
      "Epoch:  4880 Loss:  0.5871773 accurracy:  0.9522844\n",
      "Epoch:  4881 Loss:  0.58717674 accurracy:  0.9522873\n",
      "Epoch:  4882 Loss:  0.5871763 accurracy:  0.95229024\n",
      "Epoch:  4883 Loss:  0.5871755 accurracy:  0.9522932\n",
      "Epoch:  4884 Loss:  0.5871742 accurracy:  0.95229614\n",
      "Epoch:  4885 Loss:  0.5871733 accurracy:  0.95229906\n",
      "Epoch:  4886 Loss:  0.5871726 accurracy:  0.95230204\n",
      "Epoch:  4887 Loss:  0.58717215 accurracy:  0.95230496\n",
      "Epoch:  4888 Loss:  0.5871713 accurracy:  0.9523079\n",
      "Epoch:  4889 Loss:  0.58717 accurracy:  0.95231086\n",
      "Epoch:  4890 Loss:  0.5871691 accurracy:  0.9523138\n",
      "Epoch:  4891 Loss:  0.58716863 accurracy:  0.9523167\n",
      "Epoch:  4892 Loss:  0.58716804 accurracy:  0.9523196\n",
      "Epoch:  4893 Loss:  0.5871671 accurracy:  0.95232254\n",
      "Epoch:  4894 Loss:  0.58716595 accurracy:  0.9523255\n",
      "Epoch:  4895 Loss:  0.58716506 accurracy:  0.95232844\n",
      "Epoch:  4896 Loss:  0.5871646 accurracy:  0.95233136\n",
      "Epoch:  4897 Loss:  0.58716387 accurracy:  0.9523343\n",
      "Epoch:  4898 Loss:  0.58716285 accurracy:  0.9523372\n",
      "Epoch:  4899 Loss:  0.587162 accurracy:  0.9523401\n",
      "Epoch:  4900 Loss:  0.58716124 accurracy:  0.95234305\n",
      "Epoch:  4901 Loss:  0.58716065 accurracy:  0.95234597\n",
      "Epoch:  4902 Loss:  0.5871596 accurracy:  0.9523489\n",
      "Epoch:  4903 Loss:  0.58715886 accurracy:  0.9523518\n",
      "Epoch:  4904 Loss:  0.5871581 accurracy:  0.9523547\n",
      "Epoch:  4905 Loss:  0.5871573 accurracy:  0.95235765\n",
      "Epoch:  4906 Loss:  0.5871563 accurracy:  0.9523606\n",
      "Epoch:  4907 Loss:  0.5871555 accurracy:  0.9523635\n",
      "Epoch:  4908 Loss:  0.5871548 accurracy:  0.9523664\n",
      "Epoch:  4909 Loss:  0.58715403 accurracy:  0.95236933\n",
      "Epoch:  4910 Loss:  0.58715326 accurracy:  0.95237225\n",
      "Epoch:  4911 Loss:  0.5871524 accurracy:  0.9523751\n",
      "Epoch:  4912 Loss:  0.58715147 accurracy:  0.95237803\n",
      "Epoch:  4913 Loss:  0.5871507 accurracy:  0.95238096\n",
      "Epoch:  4914 Loss:  0.5871499 accurracy:  0.9523839\n",
      "Epoch:  4915 Loss:  0.5871491 accurracy:  0.95238674\n",
      "Epoch:  4916 Loss:  0.5871484 accurracy:  0.95238966\n",
      "Epoch:  4917 Loss:  0.5871476 accurracy:  0.9523926\n",
      "Epoch:  4918 Loss:  0.58714664 accurracy:  0.9523955\n",
      "Epoch:  4919 Loss:  0.5871458 accurracy:  0.95239836\n",
      "Epoch:  4920 Loss:  0.58714503 accurracy:  0.9524013\n",
      "Epoch:  4921 Loss:  0.58714426 accurracy:  0.9524042\n",
      "Epoch:  4922 Loss:  0.58714354 accurracy:  0.95240706\n",
      "Epoch:  4923 Loss:  0.5871427 accurracy:  0.95241\n",
      "Epoch:  4924 Loss:  0.5871418 accurracy:  0.95241284\n",
      "Epoch:  4925 Loss:  0.5871411 accurracy:  0.95241576\n",
      "Epoch:  4926 Loss:  0.5871404 accurracy:  0.9524186\n",
      "Epoch:  4927 Loss:  0.5871397 accurracy:  0.95242155\n",
      "Epoch:  4928 Loss:  0.58713883 accurracy:  0.9524244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4929 Loss:  0.58713776 accurracy:  0.9524273\n",
      "Epoch:  4930 Loss:  0.5871367 accurracy:  0.9524302\n",
      "Epoch:  4931 Loss:  0.5871362 accurracy:  0.9524331\n",
      "Epoch:  4932 Loss:  0.58713555 accurracy:  0.952436\n",
      "Epoch:  4933 Loss:  0.58713496 accurracy:  0.95243883\n",
      "Epoch:  4934 Loss:  0.5871338 accurracy:  0.95244175\n",
      "Epoch:  4935 Loss:  0.58713275 accurracy:  0.9524446\n",
      "Epoch:  4936 Loss:  0.5871321 accurracy:  0.95244753\n",
      "Epoch:  4937 Loss:  0.5871317 accurracy:  0.9524504\n",
      "Epoch:  4938 Loss:  0.5871311 accurracy:  0.95245326\n",
      "Epoch:  4939 Loss:  0.58712983 accurracy:  0.9524561\n",
      "Epoch:  4940 Loss:  0.5871287 accurracy:  0.95245904\n",
      "Epoch:  4941 Loss:  0.5871279 accurracy:  0.9524619\n",
      "Epoch:  4942 Loss:  0.5871276 accurracy:  0.95246476\n",
      "Epoch:  4943 Loss:  0.58712715 accurracy:  0.9524676\n",
      "Epoch:  4944 Loss:  0.5871262 accurracy:  0.9524705\n",
      "Epoch:  4945 Loss:  0.5871248 accurracy:  0.9524734\n",
      "Epoch:  4946 Loss:  0.587124 accurracy:  0.95247626\n",
      "Epoch:  4947 Loss:  0.5871237 accurracy:  0.9524791\n",
      "Epoch:  4948 Loss:  0.5871231 accurracy:  0.952482\n",
      "Epoch:  4949 Loss:  0.587122 accurracy:  0.95248485\n",
      "Epoch:  4950 Loss:  0.58712107 accurracy:  0.9524877\n",
      "Epoch:  4951 Loss:  0.5871203 accurracy:  0.95249057\n",
      "Epoch:  4952 Loss:  0.5871197 accurracy:  0.9524934\n",
      "Epoch:  4953 Loss:  0.5871188 accurracy:  0.9524963\n",
      "Epoch:  4954 Loss:  0.58711785 accurracy:  0.95249915\n",
      "Epoch:  4955 Loss:  0.58711725 accurracy:  0.952502\n",
      "Epoch:  4956 Loss:  0.58711654 accurracy:  0.9525049\n",
      "Epoch:  4957 Loss:  0.5871156 accurracy:  0.95250773\n",
      "Epoch:  4958 Loss:  0.5871147 accurracy:  0.9525106\n",
      "Epoch:  4959 Loss:  0.587114 accurracy:  0.95251346\n",
      "Epoch:  4960 Loss:  0.5871134 accurracy:  0.9525163\n",
      "Epoch:  4961 Loss:  0.58711255 accurracy:  0.9525191\n",
      "Epoch:  4962 Loss:  0.5871116 accurracy:  0.952522\n",
      "Epoch:  4963 Loss:  0.5871107 accurracy:  0.95252484\n",
      "Epoch:  4964 Loss:  0.58711 accurracy:  0.9525277\n",
      "Epoch:  4965 Loss:  0.5871095 accurracy:  0.95253056\n",
      "Epoch:  4966 Loss:  0.5871086 accurracy:  0.95253336\n",
      "Epoch:  4967 Loss:  0.5871077 accurracy:  0.9525362\n",
      "Epoch:  4968 Loss:  0.5871067 accurracy:  0.9525391\n",
      "Epoch:  4969 Loss:  0.58710605 accurracy:  0.95254195\n",
      "Epoch:  4970 Loss:  0.5871057 accurracy:  0.95254475\n",
      "Epoch:  4971 Loss:  0.5871049 accurracy:  0.9525476\n",
      "Epoch:  4972 Loss:  0.58710355 accurracy:  0.9525504\n",
      "Epoch:  4973 Loss:  0.58710253 accurracy:  0.9525533\n",
      "Epoch:  4974 Loss:  0.5871021 accurracy:  0.95255613\n",
      "Epoch:  4975 Loss:  0.5871018 accurracy:  0.95255893\n",
      "Epoch:  4976 Loss:  0.58710104 accurracy:  0.9525618\n",
      "Epoch:  4977 Loss:  0.5870996 accurracy:  0.9525646\n",
      "Epoch:  4978 Loss:  0.5870984 accurracy:  0.95256746\n",
      "Epoch:  4979 Loss:  0.5870982 accurracy:  0.95257026\n",
      "Epoch:  4980 Loss:  0.587098 accurracy:  0.9525731\n",
      "Epoch:  4981 Loss:  0.58709717 accurracy:  0.9525759\n",
      "Epoch:  4982 Loss:  0.5870957 accurracy:  0.9525788\n",
      "Epoch:  4983 Loss:  0.58709455 accurracy:  0.9525816\n",
      "Epoch:  4984 Loss:  0.5870941 accurracy:  0.95258445\n",
      "Epoch:  4985 Loss:  0.587094 accurracy:  0.95258725\n",
      "Epoch:  4986 Loss:  0.58709335 accurracy:  0.95259005\n",
      "Epoch:  4987 Loss:  0.58709204 accurracy:  0.9525929\n",
      "Epoch:  4988 Loss:  0.58709073 accurracy:  0.9525957\n",
      "Epoch:  4989 Loss:  0.5870901 accurracy:  0.9525985\n",
      "Epoch:  4990 Loss:  0.58708996 accurracy:  0.9526014\n",
      "Epoch:  4991 Loss:  0.5870894 accurracy:  0.9526042\n",
      "Epoch:  4992 Loss:  0.58708805 accurracy:  0.952607\n",
      "Epoch:  4993 Loss:  0.5870869 accurracy:  0.9526098\n",
      "Epoch:  4994 Loss:  0.5870864 accurracy:  0.95261264\n",
      "Epoch:  4995 Loss:  0.58708614 accurracy:  0.95261544\n",
      "Epoch:  4996 Loss:  0.58708566 accurracy:  0.95261824\n",
      "Epoch:  4997 Loss:  0.58708423 accurracy:  0.95262104\n",
      "Epoch:  4998 Loss:  0.587083 accurracy:  0.95262384\n",
      "Epoch:  4999 Loss:  0.58708245 accurracy:  0.95262665\n",
      "Epoch:  5000 Loss:  0.58708227 accurracy:  0.95262945\n",
      "Epoch:  5001 Loss:  0.58708155 accurracy:  0.9526323\n",
      "Epoch:  5002 Loss:  0.58708024 accurracy:  0.9526351\n",
      "Epoch:  5003 Loss:  0.5870792 accurracy:  0.9526379\n",
      "Epoch:  5004 Loss:  0.58707875 accurracy:  0.9526407\n",
      "Epoch:  5005 Loss:  0.58707833 accurracy:  0.9526435\n",
      "Epoch:  5006 Loss:  0.58707756 accurracy:  0.9526463\n",
      "Epoch:  5007 Loss:  0.5870768 accurracy:  0.9526491\n",
      "Epoch:  5008 Loss:  0.58707553 accurracy:  0.9526519\n",
      "Epoch:  5009 Loss:  0.58707494 accurracy:  0.9526547\n",
      "Epoch:  5010 Loss:  0.5870743 accurracy:  0.95265746\n",
      "Epoch:  5011 Loss:  0.58707356 accurracy:  0.95266026\n",
      "Epoch:  5012 Loss:  0.5870726 accurracy:  0.95266306\n",
      "Epoch:  5013 Loss:  0.58707166 accurracy:  0.95266587\n",
      "Epoch:  5014 Loss:  0.5870709 accurracy:  0.95266867\n",
      "Epoch:  5015 Loss:  0.58707047 accurracy:  0.95267147\n",
      "Epoch:  5016 Loss:  0.5870697 accurracy:  0.95267427\n",
      "Epoch:  5017 Loss:  0.5870687 accurracy:  0.952677\n",
      "Epoch:  5018 Loss:  0.58706784 accurracy:  0.9526798\n",
      "Epoch:  5019 Loss:  0.5870672 accurracy:  0.9526826\n",
      "Epoch:  5020 Loss:  0.58706665 accurracy:  0.9526854\n",
      "Epoch:  5021 Loss:  0.5870659 accurracy:  0.95268816\n",
      "Epoch:  5022 Loss:  0.58706486 accurracy:  0.95269096\n",
      "Epoch:  5023 Loss:  0.5870641 accurracy:  0.95269376\n",
      "Epoch:  5024 Loss:  0.5870635 accurracy:  0.9526965\n",
      "Epoch:  5025 Loss:  0.58706284 accurracy:  0.9526993\n",
      "Epoch:  5026 Loss:  0.5870619 accurracy:  0.9527021\n",
      "Epoch:  5027 Loss:  0.5870608 accurracy:  0.95270485\n",
      "Epoch:  5028 Loss:  0.58706 accurracy:  0.95270765\n",
      "Epoch:  5029 Loss:  0.58705944 accurracy:  0.9527104\n",
      "Epoch:  5030 Loss:  0.58705914 accurracy:  0.9527132\n",
      "Epoch:  5031 Loss:  0.5870583 accurracy:  0.95271593\n",
      "Epoch:  5032 Loss:  0.58705723 accurracy:  0.95271873\n",
      "Epoch:  5033 Loss:  0.58705634 accurracy:  0.9527215\n",
      "Epoch:  5034 Loss:  0.5870556 accurracy:  0.9527243\n",
      "Epoch:  5035 Loss:  0.587055 accurracy:  0.952727\n",
      "Epoch:  5036 Loss:  0.5870545 accurracy:  0.9527298\n",
      "Epoch:  5037 Loss:  0.5870537 accurracy:  0.95273256\n",
      "Epoch:  5038 Loss:  0.5870527 accurracy:  0.9527353\n",
      "Epoch:  5039 Loss:  0.58705175 accurracy:  0.9527381\n",
      "Epoch:  5040 Loss:  0.58705103 accurracy:  0.95274085\n",
      "Epoch:  5041 Loss:  0.5870506 accurracy:  0.95274365\n",
      "Epoch:  5042 Loss:  0.5870498 accurracy:  0.9527464\n",
      "Epoch:  5043 Loss:  0.5870486 accurracy:  0.95274913\n",
      "Epoch:  5044 Loss:  0.5870479 accurracy:  0.9527519\n",
      "Epoch:  5045 Loss:  0.58704746 accurracy:  0.9527547\n",
      "Epoch:  5046 Loss:  0.58704686 accurracy:  0.9527574\n",
      "Epoch:  5047 Loss:  0.5870459 accurracy:  0.95276016\n",
      "Epoch:  5048 Loss:  0.5870448 accurracy:  0.9527629\n",
      "Epoch:  5049 Loss:  0.5870441 accurracy:  0.9527657\n",
      "Epoch:  5050 Loss:  0.58704364 accurracy:  0.95276845\n",
      "Epoch:  5051 Loss:  0.5870431 accurracy:  0.9527712\n",
      "Epoch:  5052 Loss:  0.5870423 accurracy:  0.9527739\n",
      "Epoch:  5053 Loss:  0.58704096 accurracy:  0.9527767\n",
      "Epoch:  5054 Loss:  0.5870402 accurracy:  0.9527794\n",
      "Epoch:  5055 Loss:  0.5870396 accurracy:  0.95278215\n",
      "Epoch:  5056 Loss:  0.5870393 accurracy:  0.9527849\n",
      "Epoch:  5057 Loss:  0.5870384 accurracy:  0.95278764\n",
      "Epoch:  5058 Loss:  0.5870374 accurracy:  0.9527904\n",
      "Epoch:  5059 Loss:  0.5870364 accurracy:  0.9527931\n",
      "Epoch:  5060 Loss:  0.58703583 accurracy:  0.95279586\n",
      "Epoch:  5061 Loss:  0.5870355 accurracy:  0.9527986\n",
      "Epoch:  5062 Loss:  0.5870346 accurracy:  0.95280135\n",
      "Epoch:  5063 Loss:  0.5870337 accurracy:  0.9528041\n",
      "Epoch:  5064 Loss:  0.58703285 accurracy:  0.95280683\n",
      "Epoch:  5065 Loss:  0.5870321 accurracy:  0.9528096\n",
      "Epoch:  5066 Loss:  0.58703154 accurracy:  0.9528123\n",
      "Epoch:  5067 Loss:  0.5870307 accurracy:  0.95281506\n",
      "Epoch:  5068 Loss:  0.58702976 accurracy:  0.9528178\n",
      "Epoch:  5069 Loss:  0.5870289 accurracy:  0.95282054\n",
      "Epoch:  5070 Loss:  0.5870284 accurracy:  0.9528232\n",
      "Epoch:  5071 Loss:  0.5870279 accurracy:  0.95282596\n",
      "Epoch:  5072 Loss:  0.5870272 accurracy:  0.9528287\n",
      "Epoch:  5073 Loss:  0.587026 accurracy:  0.95283145\n",
      "Epoch:  5074 Loss:  0.5870252 accurracy:  0.9528341\n",
      "Epoch:  5075 Loss:  0.58702475 accurracy:  0.9528369\n",
      "Epoch:  5076 Loss:  0.58702445 accurracy:  0.9528396\n",
      "Epoch:  5077 Loss:  0.5870233 accurracy:  0.95284235\n",
      "Epoch:  5078 Loss:  0.5870221 accurracy:  0.95284504\n",
      "Epoch:  5079 Loss:  0.5870214 accurracy:  0.9528478\n",
      "Epoch:  5080 Loss:  0.587021 accurracy:  0.95285046\n",
      "Epoch:  5081 Loss:  0.58702034 accurracy:  0.9528532\n",
      "Epoch:  5082 Loss:  0.5870196 accurracy:  0.95285594\n",
      "Epoch:  5083 Loss:  0.5870186 accurracy:  0.9528586\n",
      "Epoch:  5084 Loss:  0.58701783 accurracy:  0.95286137\n",
      "Epoch:  5085 Loss:  0.58701706 accurracy:  0.95286405\n",
      "Epoch:  5086 Loss:  0.5870165 accurracy:  0.9528668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5087 Loss:  0.5870159 accurracy:  0.9528695\n",
      "Epoch:  5088 Loss:  0.58701515 accurracy:  0.9528722\n",
      "Epoch:  5089 Loss:  0.587014 accurracy:  0.9528749\n",
      "Epoch:  5090 Loss:  0.58701336 accurracy:  0.95287764\n",
      "Epoch:  5091 Loss:  0.5870129 accurracy:  0.9528803\n",
      "Epoch:  5092 Loss:  0.58701223 accurracy:  0.95288306\n",
      "Epoch:  5093 Loss:  0.5870114 accurracy:  0.95288575\n",
      "Epoch:  5094 Loss:  0.5870102 accurracy:  0.9528884\n",
      "Epoch:  5095 Loss:  0.58700943 accurracy:  0.9528912\n",
      "Epoch:  5096 Loss:  0.5870091 accurracy:  0.95289385\n",
      "Epoch:  5097 Loss:  0.5870084 accurracy:  0.95289654\n",
      "Epoch:  5098 Loss:  0.5870076 accurracy:  0.9528993\n",
      "Epoch:  5099 Loss:  0.5870066 accurracy:  0.95290196\n",
      "Epoch:  5100 Loss:  0.58700573 accurracy:  0.95290464\n",
      "Epoch:  5101 Loss:  0.5870053 accurracy:  0.9529074\n",
      "Epoch:  5102 Loss:  0.58700466 accurracy:  0.95291007\n",
      "Epoch:  5103 Loss:  0.58700395 accurracy:  0.95291275\n",
      "Epoch:  5104 Loss:  0.58700293 accurracy:  0.95291543\n",
      "Epoch:  5105 Loss:  0.58700204 accurracy:  0.9529181\n",
      "Epoch:  5106 Loss:  0.58700144 accurracy:  0.95292085\n",
      "Epoch:  5107 Loss:  0.5870009 accurracy:  0.95292354\n",
      "Epoch:  5108 Loss:  0.5870004 accurracy:  0.9529262\n",
      "Epoch:  5109 Loss:  0.58699924 accurracy:  0.9529289\n",
      "Epoch:  5110 Loss:  0.5869983 accurracy:  0.9529316\n",
      "Epoch:  5111 Loss:  0.58699775 accurracy:  0.95293427\n",
      "Epoch:  5112 Loss:  0.58699715 accurracy:  0.95293695\n",
      "Epoch:  5113 Loss:  0.5869966 accurracy:  0.9529396\n",
      "Epoch:  5114 Loss:  0.58699566 accurracy:  0.9529423\n",
      "Epoch:  5115 Loss:  0.5869947 accurracy:  0.952945\n",
      "Epoch:  5116 Loss:  0.586994 accurracy:  0.9529477\n",
      "Epoch:  5117 Loss:  0.5869935 accurracy:  0.95295036\n",
      "Epoch:  5118 Loss:  0.5869929 accurracy:  0.95295304\n",
      "Epoch:  5119 Loss:  0.5869921 accurracy:  0.9529557\n",
      "Epoch:  5120 Loss:  0.5869911 accurracy:  0.9529584\n",
      "Epoch:  5121 Loss:  0.5869904 accurracy:  0.9529611\n",
      "Epoch:  5122 Loss:  0.58698976 accurracy:  0.95296377\n",
      "Epoch:  5123 Loss:  0.58698916 accurracy:  0.95296645\n",
      "Epoch:  5124 Loss:  0.58698845 accurracy:  0.95296913\n",
      "Epoch:  5125 Loss:  0.58698744 accurracy:  0.95297176\n",
      "Epoch:  5126 Loss:  0.58698654 accurracy:  0.95297444\n",
      "Epoch:  5127 Loss:  0.5869859 accurracy:  0.9529771\n",
      "Epoch:  5128 Loss:  0.5869855 accurracy:  0.9529798\n",
      "Epoch:  5129 Loss:  0.586985 accurracy:  0.9529825\n",
      "Epoch:  5130 Loss:  0.58698386 accurracy:  0.9529851\n",
      "Epoch:  5131 Loss:  0.58698285 accurracy:  0.9529878\n",
      "Epoch:  5132 Loss:  0.586982 accurracy:  0.9529905\n",
      "Epoch:  5133 Loss:  0.5869816 accurracy:  0.9529931\n",
      "Epoch:  5134 Loss:  0.58698136 accurracy:  0.9529958\n",
      "Epoch:  5135 Loss:  0.5869805 accurracy:  0.95299846\n",
      "Epoch:  5136 Loss:  0.58697927 accurracy:  0.9530011\n",
      "Epoch:  5137 Loss:  0.58697826 accurracy:  0.95300376\n",
      "Epoch:  5138 Loss:  0.5869778 accurracy:  0.95300645\n",
      "Epoch:  5139 Loss:  0.58697736 accurracy:  0.95300907\n",
      "Epoch:  5140 Loss:  0.5869767 accurracy:  0.95301175\n",
      "Epoch:  5141 Loss:  0.58697563 accurracy:  0.9530144\n",
      "Epoch:  5142 Loss:  0.5869748 accurracy:  0.95301706\n",
      "Epoch:  5143 Loss:  0.5869742 accurracy:  0.9530197\n",
      "Epoch:  5144 Loss:  0.5869738 accurracy:  0.95302236\n",
      "Epoch:  5145 Loss:  0.586973 accurracy:  0.953025\n",
      "Epoch:  5146 Loss:  0.5869721 accurracy:  0.95302767\n",
      "Epoch:  5147 Loss:  0.5869713 accurracy:  0.9530303\n",
      "Epoch:  5148 Loss:  0.5869706 accurracy:  0.953033\n",
      "Epoch:  5149 Loss:  0.5869699 accurracy:  0.9530356\n",
      "Epoch:  5150 Loss:  0.58696926 accurracy:  0.9530382\n",
      "Epoch:  5151 Loss:  0.58696854 accurracy:  0.9530409\n",
      "Epoch:  5152 Loss:  0.58696777 accurracy:  0.9530435\n",
      "Epoch:  5153 Loss:  0.58696705 accurracy:  0.9530462\n",
      "Epoch:  5154 Loss:  0.5869662 accurracy:  0.9530488\n",
      "Epoch:  5155 Loss:  0.58696544 accurracy:  0.95305145\n",
      "Epoch:  5156 Loss:  0.5869649 accurracy:  0.95305413\n",
      "Epoch:  5157 Loss:  0.5869642 accurracy:  0.95305675\n",
      "Epoch:  5158 Loss:  0.5869634 accurracy:  0.9530594\n",
      "Epoch:  5159 Loss:  0.58696276 accurracy:  0.953062\n",
      "Epoch:  5160 Loss:  0.58696187 accurracy:  0.9530647\n",
      "Epoch:  5161 Loss:  0.5869612 accurracy:  0.9530673\n",
      "Epoch:  5162 Loss:  0.5869606 accurracy:  0.9530699\n",
      "Epoch:  5163 Loss:  0.5869598 accurracy:  0.95307255\n",
      "Epoch:  5164 Loss:  0.5869589 accurracy:  0.9530752\n",
      "Epoch:  5165 Loss:  0.58695817 accurracy:  0.9530778\n",
      "Epoch:  5166 Loss:  0.5869577 accurracy:  0.9530805\n",
      "Epoch:  5167 Loss:  0.58695704 accurracy:  0.9530831\n",
      "Epoch:  5168 Loss:  0.58695614 accurracy:  0.9530857\n",
      "Epoch:  5169 Loss:  0.5869553 accurracy:  0.95308834\n",
      "Epoch:  5170 Loss:  0.5869544 accurracy:  0.95309097\n",
      "Epoch:  5171 Loss:  0.5869539 accurracy:  0.9530936\n",
      "Epoch:  5172 Loss:  0.58695316 accurracy:  0.9530962\n",
      "Epoch:  5173 Loss:  0.58695257 accurracy:  0.95309883\n",
      "Epoch:  5174 Loss:  0.58695185 accurracy:  0.95310146\n",
      "Epoch:  5175 Loss:  0.58695096 accurracy:  0.9531041\n",
      "Epoch:  5176 Loss:  0.5869503 accurracy:  0.9531067\n",
      "Epoch:  5177 Loss:  0.58694965 accurracy:  0.9531093\n",
      "Epoch:  5178 Loss:  0.58694905 accurracy:  0.95311195\n",
      "Epoch:  5179 Loss:  0.58694834 accurracy:  0.95311457\n",
      "Epoch:  5180 Loss:  0.5869473 accurracy:  0.95311713\n",
      "Epoch:  5181 Loss:  0.5869467 accurracy:  0.95311975\n",
      "Epoch:  5182 Loss:  0.58694595 accurracy:  0.9531224\n",
      "Epoch:  5183 Loss:  0.5869454 accurracy:  0.953125\n",
      "Epoch:  5184 Loss:  0.5869448 accurracy:  0.9531276\n",
      "Epoch:  5185 Loss:  0.5869439 accurracy:  0.95313025\n",
      "Epoch:  5186 Loss:  0.58694303 accurracy:  0.9531328\n",
      "Epoch:  5187 Loss:  0.5869423 accurracy:  0.95313543\n",
      "Epoch:  5188 Loss:  0.58694166 accurracy:  0.95313805\n",
      "Epoch:  5189 Loss:  0.5869411 accurracy:  0.9531407\n",
      "Epoch:  5190 Loss:  0.5869404 accurracy:  0.95314324\n",
      "Epoch:  5191 Loss:  0.58693975 accurracy:  0.95314586\n",
      "Epoch:  5192 Loss:  0.58693886 accurracy:  0.9531485\n",
      "Epoch:  5193 Loss:  0.58693784 accurracy:  0.95315105\n",
      "Epoch:  5194 Loss:  0.58693725 accurracy:  0.95315367\n",
      "Epoch:  5195 Loss:  0.5869368 accurracy:  0.9531563\n",
      "Epoch:  5196 Loss:  0.58693624 accurracy:  0.95315886\n",
      "Epoch:  5197 Loss:  0.5869354 accurracy:  0.9531615\n",
      "Epoch:  5198 Loss:  0.58693445 accurracy:  0.95316404\n",
      "Epoch:  5199 Loss:  0.5869337 accurracy:  0.95316666\n",
      "Epoch:  5200 Loss:  0.58693314 accurracy:  0.9531693\n",
      "Epoch:  5201 Loss:  0.5869325 accurracy:  0.95317185\n",
      "Epoch:  5202 Loss:  0.5869316 accurracy:  0.9531745\n",
      "Epoch:  5203 Loss:  0.5869309 accurracy:  0.95317703\n",
      "Epoch:  5204 Loss:  0.5869302 accurracy:  0.95317966\n",
      "Epoch:  5205 Loss:  0.5869297 accurracy:  0.9531822\n",
      "Epoch:  5206 Loss:  0.58692896 accurracy:  0.95318484\n",
      "Epoch:  5207 Loss:  0.5869281 accurracy:  0.9531874\n",
      "Epoch:  5208 Loss:  0.58692735 accurracy:  0.95318997\n",
      "Epoch:  5209 Loss:  0.5869269 accurracy:  0.9531926\n",
      "Epoch:  5210 Loss:  0.58692616 accurracy:  0.95319515\n",
      "Epoch:  5211 Loss:  0.58692527 accurracy:  0.9531978\n",
      "Epoch:  5212 Loss:  0.58692455 accurracy:  0.95320034\n",
      "Epoch:  5213 Loss:  0.5869238 accurracy:  0.9532029\n",
      "Epoch:  5214 Loss:  0.5869233 accurracy:  0.9532055\n",
      "Epoch:  5215 Loss:  0.5869226 accurracy:  0.9532081\n",
      "Epoch:  5216 Loss:  0.58692163 accurracy:  0.95321065\n",
      "Epoch:  5217 Loss:  0.5869209 accurracy:  0.9532132\n",
      "Epoch:  5218 Loss:  0.5869202 accurracy:  0.95321584\n",
      "Epoch:  5219 Loss:  0.5869197 accurracy:  0.9532184\n",
      "Epoch:  5220 Loss:  0.5869192 accurracy:  0.95322096\n",
      "Epoch:  5221 Loss:  0.586918 accurracy:  0.9532235\n",
      "Epoch:  5222 Loss:  0.58691716 accurracy:  0.9532261\n",
      "Epoch:  5223 Loss:  0.5869167 accurracy:  0.9532287\n",
      "Epoch:  5224 Loss:  0.5869163 accurracy:  0.9532313\n",
      "Epoch:  5225 Loss:  0.5869157 accurracy:  0.95323384\n",
      "Epoch:  5226 Loss:  0.5869147 accurracy:  0.9532364\n",
      "Epoch:  5227 Loss:  0.58691365 accurracy:  0.95323896\n",
      "Epoch:  5228 Loss:  0.58691305 accurracy:  0.9532415\n",
      "Epoch:  5229 Loss:  0.5869127 accurracy:  0.9532441\n",
      "Epoch:  5230 Loss:  0.5869122 accurracy:  0.95324665\n",
      "Epoch:  5231 Loss:  0.58691126 accurracy:  0.9532492\n",
      "Epoch:  5232 Loss:  0.58691037 accurracy:  0.9532518\n",
      "Epoch:  5233 Loss:  0.5869097 accurracy:  0.95325434\n",
      "Epoch:  5234 Loss:  0.58690923 accurracy:  0.9532569\n",
      "Epoch:  5235 Loss:  0.58690846 accurracy:  0.95325947\n",
      "Epoch:  5236 Loss:  0.5869076 accurracy:  0.95326203\n",
      "Epoch:  5237 Loss:  0.586907 accurracy:  0.9532646\n",
      "Epoch:  5238 Loss:  0.5869064 accurracy:  0.95326716\n",
      "Epoch:  5239 Loss:  0.5869054 accurracy:  0.9532697\n",
      "Epoch:  5240 Loss:  0.58690476 accurracy:  0.9532723\n",
      "Epoch:  5241 Loss:  0.5869042 accurracy:  0.95327485\n",
      "Epoch:  5242 Loss:  0.5869036 accurracy:  0.9532774\n",
      "Epoch:  5243 Loss:  0.5869028 accurracy:  0.9532799\n",
      "Epoch:  5244 Loss:  0.5869021 accurracy:  0.9532825\n",
      "Epoch:  5245 Loss:  0.58690125 accurracy:  0.95328504\n",
      "Epoch:  5246 Loss:  0.5869005 accurracy:  0.9532876\n",
      "Epoch:  5247 Loss:  0.58689994 accurracy:  0.95329016\n",
      "Epoch:  5248 Loss:  0.5868995 accurracy:  0.95329267\n",
      "Epoch:  5249 Loss:  0.58689904 accurracy:  0.95329523\n",
      "Epoch:  5250 Loss:  0.5868979 accurracy:  0.9532978\n",
      "Epoch:  5251 Loss:  0.5868968 accurracy:  0.95330036\n",
      "Epoch:  5252 Loss:  0.586896 accurracy:  0.95330286\n",
      "Epoch:  5253 Loss:  0.5868958 accurracy:  0.9533054\n",
      "Epoch:  5254 Loss:  0.5868954 accurracy:  0.953308\n",
      "Epoch:  5255 Loss:  0.58689445 accurracy:  0.9533105\n",
      "Epoch:  5256 Loss:  0.5868933 accurracy:  0.95331305\n",
      "Epoch:  5257 Loss:  0.58689266 accurracy:  0.95331556\n",
      "Epoch:  5258 Loss:  0.5868923 accurracy:  0.9533181\n",
      "Epoch:  5259 Loss:  0.586892 accurracy:  0.9533207\n",
      "Epoch:  5260 Loss:  0.5868911 accurracy:  0.9533232\n",
      "Epoch:  5261 Loss:  0.5868899 accurracy:  0.95332575\n",
      "Epoch:  5262 Loss:  0.58688927 accurracy:  0.95332825\n",
      "Epoch:  5263 Loss:  0.58688885 accurracy:  0.9533308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5264 Loss:  0.58688843 accurracy:  0.9533333\n",
      "Epoch:  5265 Loss:  0.5868876 accurracy:  0.9533359\n",
      "Epoch:  5266 Loss:  0.5868867 accurracy:  0.9533384\n",
      "Epoch:  5267 Loss:  0.586886 accurracy:  0.95334095\n",
      "Epoch:  5268 Loss:  0.5868854 accurracy:  0.95334345\n",
      "Epoch:  5269 Loss:  0.5868847 accurracy:  0.95334595\n",
      "Epoch:  5270 Loss:  0.58688384 accurracy:  0.9533485\n",
      "Epoch:  5271 Loss:  0.5868833 accurracy:  0.953351\n",
      "Epoch:  5272 Loss:  0.5868826 accurracy:  0.9533536\n",
      "Epoch:  5273 Loss:  0.58688194 accurracy:  0.9533561\n",
      "Epoch:  5274 Loss:  0.5868811 accurracy:  0.9533586\n",
      "Epoch:  5275 Loss:  0.5868805 accurracy:  0.95336115\n",
      "Epoch:  5276 Loss:  0.5868798 accurracy:  0.95336366\n",
      "Epoch:  5277 Loss:  0.5868791 accurracy:  0.95336616\n",
      "Epoch:  5278 Loss:  0.5868784 accurracy:  0.95336866\n",
      "Epoch:  5279 Loss:  0.5868777 accurracy:  0.9533712\n",
      "Epoch:  5280 Loss:  0.5868771 accurracy:  0.95337373\n",
      "Epoch:  5281 Loss:  0.5868766 accurracy:  0.95337623\n",
      "Epoch:  5282 Loss:  0.5868757 accurracy:  0.95337874\n",
      "Epoch:  5283 Loss:  0.58687484 accurracy:  0.9533813\n",
      "Epoch:  5284 Loss:  0.58687437 accurracy:  0.9533838\n",
      "Epoch:  5285 Loss:  0.58687377 accurracy:  0.9533863\n",
      "Epoch:  5286 Loss:  0.586873 accurracy:  0.9533888\n",
      "Epoch:  5287 Loss:  0.58687204 accurracy:  0.9533913\n",
      "Epoch:  5288 Loss:  0.5868712 accurracy:  0.9533938\n",
      "Epoch:  5289 Loss:  0.5868708 accurracy:  0.9533963\n",
      "Epoch:  5290 Loss:  0.5868704 accurracy:  0.9533988\n",
      "Epoch:  5291 Loss:  0.58686966 accurracy:  0.9534014\n",
      "Epoch:  5292 Loss:  0.58686864 accurracy:  0.9534039\n",
      "Epoch:  5293 Loss:  0.58686775 accurracy:  0.9534064\n",
      "Epoch:  5294 Loss:  0.5868672 accurracy:  0.9534089\n",
      "Epoch:  5295 Loss:  0.5868669 accurracy:  0.9534114\n",
      "Epoch:  5296 Loss:  0.58686626 accurracy:  0.9534139\n",
      "Epoch:  5297 Loss:  0.5868653 accurracy:  0.9534164\n",
      "Epoch:  5298 Loss:  0.5868645 accurracy:  0.9534189\n",
      "Epoch:  5299 Loss:  0.5868639 accurracy:  0.95342135\n",
      "Epoch:  5300 Loss:  0.5868634 accurracy:  0.95342386\n",
      "Epoch:  5301 Loss:  0.5868627 accurracy:  0.95342636\n",
      "Epoch:  5302 Loss:  0.586862 accurracy:  0.95342886\n",
      "Epoch:  5303 Loss:  0.58686125 accurracy:  0.95343137\n",
      "Epoch:  5304 Loss:  0.58686054 accurracy:  0.9534339\n",
      "Epoch:  5305 Loss:  0.5868599 accurracy:  0.9534364\n",
      "Epoch:  5306 Loss:  0.586859 accurracy:  0.9534389\n",
      "Epoch:  5307 Loss:  0.58685833 accurracy:  0.9534413\n",
      "Epoch:  5308 Loss:  0.58685786 accurracy:  0.9534438\n",
      "Epoch:  5309 Loss:  0.58685744 accurracy:  0.9534463\n",
      "Epoch:  5310 Loss:  0.5868566 accurracy:  0.95344883\n",
      "Epoch:  5311 Loss:  0.58685565 accurracy:  0.9534513\n",
      "Epoch:  5312 Loss:  0.5868547 accurracy:  0.9534538\n",
      "Epoch:  5313 Loss:  0.58685416 accurracy:  0.9534563\n",
      "Epoch:  5314 Loss:  0.5868539 accurracy:  0.9534588\n",
      "Epoch:  5315 Loss:  0.5868534 accurracy:  0.9534612\n",
      "Epoch:  5316 Loss:  0.5868527 accurracy:  0.95346373\n",
      "Epoch:  5317 Loss:  0.5868515 accurracy:  0.95346624\n",
      "Epoch:  5318 Loss:  0.5868505 accurracy:  0.9534687\n",
      "Epoch:  5319 Loss:  0.58685 accurracy:  0.9534712\n",
      "Epoch:  5320 Loss:  0.5868498 accurracy:  0.9534737\n",
      "Epoch:  5321 Loss:  0.58684945 accurracy:  0.95347613\n",
      "Epoch:  5322 Loss:  0.58684844 accurracy:  0.95347863\n",
      "Epoch:  5323 Loss:  0.5868473 accurracy:  0.9534811\n",
      "Epoch:  5324 Loss:  0.58684653 accurracy:  0.9534836\n",
      "Epoch:  5325 Loss:  0.5868462 accurracy:  0.953486\n",
      "Epoch:  5326 Loss:  0.58684576 accurracy:  0.9534885\n",
      "Epoch:  5327 Loss:  0.58684504 accurracy:  0.953491\n",
      "Epoch:  5328 Loss:  0.58684427 accurracy:  0.9534935\n",
      "Epoch:  5329 Loss:  0.5868434 accurracy:  0.9534959\n",
      "Epoch:  5330 Loss:  0.5868427 accurracy:  0.9534984\n",
      "Epoch:  5331 Loss:  0.5868421 accurracy:  0.95350087\n",
      "Epoch:  5332 Loss:  0.5868415 accurracy:  0.9535034\n",
      "Epoch:  5333 Loss:  0.5868408 accurracy:  0.9535058\n",
      "Epoch:  5334 Loss:  0.58684033 accurracy:  0.95350826\n",
      "Epoch:  5335 Loss:  0.58683956 accurracy:  0.95351076\n",
      "Epoch:  5336 Loss:  0.5868388 accurracy:  0.9535132\n",
      "Epoch:  5337 Loss:  0.58683807 accurracy:  0.95351565\n",
      "Epoch:  5338 Loss:  0.58683753 accurracy:  0.95351815\n",
      "Epoch:  5339 Loss:  0.5868368 accurracy:  0.9535206\n",
      "Epoch:  5340 Loss:  0.5868361 accurracy:  0.95352304\n",
      "Epoch:  5341 Loss:  0.58683544 accurracy:  0.95352554\n",
      "Epoch:  5342 Loss:  0.58683485 accurracy:  0.953528\n",
      "Epoch:  5343 Loss:  0.5868341 accurracy:  0.95353043\n",
      "Epoch:  5344 Loss:  0.5868332 accurracy:  0.9535329\n",
      "Epoch:  5345 Loss:  0.5868326 accurracy:  0.9535354\n",
      "Epoch:  5346 Loss:  0.58683205 accurracy:  0.9535378\n",
      "Epoch:  5347 Loss:  0.5868316 accurracy:  0.95354027\n",
      "Epoch:  5348 Loss:  0.58683085 accurracy:  0.9535427\n",
      "Epoch:  5349 Loss:  0.5868299 accurracy:  0.95354515\n",
      "Epoch:  5350 Loss:  0.5868291 accurracy:  0.9535476\n",
      "Epoch:  5351 Loss:  0.5868288 accurracy:  0.9535501\n",
      "Epoch:  5352 Loss:  0.58682835 accurracy:  0.95355254\n",
      "Epoch:  5353 Loss:  0.58682746 accurracy:  0.953555\n",
      "Epoch:  5354 Loss:  0.5868265 accurracy:  0.95355743\n",
      "Epoch:  5355 Loss:  0.5868257 accurracy:  0.9535599\n",
      "Epoch:  5356 Loss:  0.5868253 accurracy:  0.9535623\n",
      "Epoch:  5357 Loss:  0.5868248 accurracy:  0.95356476\n",
      "Epoch:  5358 Loss:  0.58682424 accurracy:  0.9535672\n",
      "Epoch:  5359 Loss:  0.5868235 accurracy:  0.95356965\n",
      "Epoch:  5360 Loss:  0.5868225 accurracy:  0.9535721\n",
      "Epoch:  5361 Loss:  0.586822 accurracy:  0.95357454\n",
      "Epoch:  5362 Loss:  0.58682126 accurracy:  0.953577\n",
      "Epoch:  5363 Loss:  0.5868206 accurracy:  0.9535794\n",
      "Epoch:  5364 Loss:  0.5868202 accurracy:  0.95358187\n",
      "Epoch:  5365 Loss:  0.5868194 accurracy:  0.9535843\n",
      "Epoch:  5366 Loss:  0.5868188 accurracy:  0.95358676\n",
      "Epoch:  5367 Loss:  0.5868179 accurracy:  0.95358914\n",
      "Epoch:  5368 Loss:  0.58681715 accurracy:  0.9535916\n",
      "Epoch:  5369 Loss:  0.58681655 accurracy:  0.953594\n",
      "Epoch:  5370 Loss:  0.586816 accurracy:  0.9535965\n",
      "Epoch:  5371 Loss:  0.5868155 accurracy:  0.9535989\n",
      "Epoch:  5372 Loss:  0.5868149 accurracy:  0.95360136\n",
      "Epoch:  5373 Loss:  0.58681417 accurracy:  0.95360374\n",
      "Epoch:  5374 Loss:  0.5868135 accurracy:  0.9536062\n",
      "Epoch:  5375 Loss:  0.5868126 accurracy:  0.95360863\n",
      "Epoch:  5376 Loss:  0.5868118 accurracy:  0.9536111\n",
      "Epoch:  5377 Loss:  0.5868114 accurracy:  0.95361346\n",
      "Epoch:  5378 Loss:  0.58681095 accurracy:  0.9536159\n",
      "Epoch:  5379 Loss:  0.5868103 accurracy:  0.95361835\n",
      "Epoch:  5380 Loss:  0.5868093 accurracy:  0.9536208\n",
      "Epoch:  5381 Loss:  0.5868085 accurracy:  0.9536232\n",
      "Epoch:  5382 Loss:  0.5868079 accurracy:  0.9536256\n",
      "Epoch:  5383 Loss:  0.5868075 accurracy:  0.95362806\n",
      "Epoch:  5384 Loss:  0.5868069 accurracy:  0.95363045\n",
      "Epoch:  5385 Loss:  0.58680606 accurracy:  0.9536329\n",
      "Epoch:  5386 Loss:  0.5868053 accurracy:  0.9536353\n",
      "Epoch:  5387 Loss:  0.5868047 accurracy:  0.9536377\n",
      "Epoch:  5388 Loss:  0.58680403 accurracy:  0.9536401\n",
      "Epoch:  5389 Loss:  0.58680344 accurracy:  0.95364255\n",
      "Epoch:  5390 Loss:  0.5868028 accurracy:  0.953645\n",
      "Epoch:  5391 Loss:  0.58680207 accurracy:  0.9536474\n",
      "Epoch:  5392 Loss:  0.5868014 accurracy:  0.9536498\n",
      "Epoch:  5393 Loss:  0.5868009 accurracy:  0.9536522\n",
      "Epoch:  5394 Loss:  0.58680034 accurracy:  0.95365465\n",
      "Epoch:  5395 Loss:  0.58679926 accurracy:  0.95365703\n",
      "Epoch:  5396 Loss:  0.5867986 accurracy:  0.9536594\n",
      "Epoch:  5397 Loss:  0.58679813 accurracy:  0.95366186\n",
      "Epoch:  5398 Loss:  0.5867977 accurracy:  0.95366424\n",
      "Epoch:  5399 Loss:  0.586797 accurracy:  0.9536667\n",
      "Epoch:  5400 Loss:  0.5867961 accurracy:  0.9536691\n",
      "Epoch:  5401 Loss:  0.58679545 accurracy:  0.95367146\n",
      "Epoch:  5402 Loss:  0.5867947 accurracy:  0.9536739\n",
      "Epoch:  5403 Loss:  0.58679426 accurracy:  0.9536763\n",
      "Epoch:  5404 Loss:  0.5867939 accurracy:  0.95367867\n",
      "Epoch:  5405 Loss:  0.58679307 accurracy:  0.9536811\n",
      "Epoch:  5406 Loss:  0.58679223 accurracy:  0.9536835\n",
      "Epoch:  5407 Loss:  0.58679134 accurracy:  0.9536859\n",
      "Epoch:  5408 Loss:  0.5867906 accurracy:  0.9536883\n",
      "Epoch:  5409 Loss:  0.5867902 accurracy:  0.9536907\n",
      "Epoch:  5410 Loss:  0.58678985 accurracy:  0.9536931\n",
      "Epoch:  5411 Loss:  0.5867891 accurracy:  0.9536955\n",
      "Epoch:  5412 Loss:  0.5867882 accurracy:  0.95369786\n",
      "Epoch:  5413 Loss:  0.5867874 accurracy:  0.9537003\n",
      "Epoch:  5414 Loss:  0.58678687 accurracy:  0.9537027\n",
      "Epoch:  5415 Loss:  0.5867864 accurracy:  0.9537051\n",
      "Epoch:  5416 Loss:  0.58678573 accurracy:  0.95370746\n",
      "Epoch:  5417 Loss:  0.586785 accurracy:  0.95370984\n",
      "Epoch:  5418 Loss:  0.5867842 accurracy:  0.9537122\n",
      "Epoch:  5419 Loss:  0.58678365 accurracy:  0.9537146\n",
      "Epoch:  5420 Loss:  0.58678323 accurracy:  0.95371705\n",
      "Epoch:  5421 Loss:  0.58678246 accurracy:  0.95371944\n",
      "Epoch:  5422 Loss:  0.5867816 accurracy:  0.9537218\n",
      "Epoch:  5423 Loss:  0.5867809 accurracy:  0.9537242\n",
      "Epoch:  5424 Loss:  0.58678055 accurracy:  0.9537266\n",
      "Epoch:  5425 Loss:  0.5867799 accurracy:  0.953729\n",
      "Epoch:  5426 Loss:  0.586779 accurracy:  0.95373136\n",
      "Epoch:  5427 Loss:  0.5867782 accurracy:  0.95373374\n",
      "Epoch:  5428 Loss:  0.5867777 accurracy:  0.9537361\n",
      "Epoch:  5429 Loss:  0.58677727 accurracy:  0.9537385\n",
      "Epoch:  5430 Loss:  0.58677673 accurracy:  0.9537409\n",
      "Epoch:  5431 Loss:  0.58677596 accurracy:  0.9537433\n",
      "Epoch:  5432 Loss:  0.58677506 accurracy:  0.9537456\n",
      "Epoch:  5433 Loss:  0.5867744 accurracy:  0.953748\n",
      "Epoch:  5434 Loss:  0.58677393 accurracy:  0.9537504\n",
      "Epoch:  5435 Loss:  0.58677334 accurracy:  0.95375276\n",
      "Epoch:  5436 Loss:  0.5867725 accurracy:  0.95375514\n",
      "Epoch:  5437 Loss:  0.5867719 accurracy:  0.9537575\n",
      "Epoch:  5438 Loss:  0.58677137 accurracy:  0.9537599\n",
      "Epoch:  5439 Loss:  0.5867709 accurracy:  0.95376223\n",
      "Epoch:  5440 Loss:  0.5867701 accurracy:  0.9537646\n",
      "Epoch:  5441 Loss:  0.5867693 accurracy:  0.953767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5442 Loss:  0.5867685 accurracy:  0.9537694\n",
      "Epoch:  5443 Loss:  0.586768 accurracy:  0.9537717\n",
      "Epoch:  5444 Loss:  0.5867676 accurracy:  0.9537741\n",
      "Epoch:  5445 Loss:  0.5867671 accurracy:  0.9537765\n",
      "Epoch:  5446 Loss:  0.5867663 accurracy:  0.95377886\n",
      "Epoch:  5447 Loss:  0.5867653 accurracy:  0.9537812\n",
      "Epoch:  5448 Loss:  0.5867645 accurracy:  0.9537836\n",
      "Epoch:  5449 Loss:  0.5867641 accurracy:  0.95378596\n",
      "Epoch:  5450 Loss:  0.5867636 accurracy:  0.9537883\n",
      "Epoch:  5451 Loss:  0.586763 accurracy:  0.95379066\n",
      "Epoch:  5452 Loss:  0.58676237 accurracy:  0.95379305\n",
      "Epoch:  5453 Loss:  0.58676153 accurracy:  0.9537954\n",
      "Epoch:  5454 Loss:  0.58676094 accurracy:  0.95379776\n",
      "Epoch:  5455 Loss:  0.58676034 accurracy:  0.9538001\n",
      "Epoch:  5456 Loss:  0.5867596 accurracy:  0.95380247\n",
      "Epoch:  5457 Loss:  0.5867589 accurracy:  0.9538048\n",
      "Epoch:  5458 Loss:  0.5867581 accurracy:  0.9538072\n",
      "Epoch:  5459 Loss:  0.58675766 accurracy:  0.9538095\n",
      "Epoch:  5460 Loss:  0.58675724 accurracy:  0.9538119\n",
      "Epoch:  5461 Loss:  0.5867566 accurracy:  0.9538142\n",
      "Epoch:  5462 Loss:  0.58675575 accurracy:  0.9538166\n",
      "Epoch:  5463 Loss:  0.586755 accurracy:  0.9538189\n",
      "Epoch:  5464 Loss:  0.58675444 accurracy:  0.9538213\n",
      "Epoch:  5465 Loss:  0.58675396 accurracy:  0.9538236\n",
      "Epoch:  5466 Loss:  0.5867534 accurracy:  0.953826\n",
      "Epoch:  5467 Loss:  0.58675283 accurracy:  0.95382833\n",
      "Epoch:  5468 Loss:  0.58675194 accurracy:  0.95383066\n",
      "Epoch:  5469 Loss:  0.5867513 accurracy:  0.95383304\n",
      "Epoch:  5470 Loss:  0.58675075 accurracy:  0.95383537\n",
      "Epoch:  5471 Loss:  0.58675003 accurracy:  0.9538377\n",
      "Epoch:  5472 Loss:  0.58674926 accurracy:  0.9538401\n",
      "Epoch:  5473 Loss:  0.58674866 accurracy:  0.9538424\n",
      "Epoch:  5474 Loss:  0.5867481 accurracy:  0.9538447\n",
      "Epoch:  5475 Loss:  0.5867476 accurracy:  0.9538471\n",
      "Epoch:  5476 Loss:  0.5867468 accurracy:  0.95384943\n",
      "Epoch:  5477 Loss:  0.58674616 accurracy:  0.95385176\n",
      "Epoch:  5478 Loss:  0.58674556 accurracy:  0.9538541\n",
      "Epoch:  5479 Loss:  0.58674484 accurracy:  0.95385647\n",
      "Epoch:  5480 Loss:  0.5867442 accurracy:  0.9538588\n",
      "Epoch:  5481 Loss:  0.5867438 accurracy:  0.9538611\n",
      "Epoch:  5482 Loss:  0.5867431 accurracy:  0.95386344\n",
      "Epoch:  5483 Loss:  0.5867423 accurracy:  0.95386577\n",
      "Epoch:  5484 Loss:  0.5867416 accurracy:  0.95386815\n",
      "Epoch:  5485 Loss:  0.5867412 accurracy:  0.9538705\n",
      "Epoch:  5486 Loss:  0.5867406 accurracy:  0.9538728\n",
      "Epoch:  5487 Loss:  0.58673984 accurracy:  0.9538751\n",
      "Epoch:  5488 Loss:  0.5867391 accurracy:  0.95387745\n",
      "Epoch:  5489 Loss:  0.5867385 accurracy:  0.9538798\n",
      "Epoch:  5490 Loss:  0.58673793 accurracy:  0.9538821\n",
      "Epoch:  5491 Loss:  0.58673733 accurracy:  0.9538844\n",
      "Epoch:  5492 Loss:  0.58673656 accurracy:  0.95388675\n",
      "Epoch:  5493 Loss:  0.5867359 accurracy:  0.9538891\n",
      "Epoch:  5494 Loss:  0.5867353 accurracy:  0.9538914\n",
      "Epoch:  5495 Loss:  0.5867348 accurracy:  0.9538937\n",
      "Epoch:  5496 Loss:  0.58673424 accurracy:  0.95389605\n",
      "Epoch:  5497 Loss:  0.58673346 accurracy:  0.9538984\n",
      "Epoch:  5498 Loss:  0.5867326 accurracy:  0.9539007\n",
      "Epoch:  5499 Loss:  0.5867321 accurracy:  0.953903\n",
      "Epoch:  5500 Loss:  0.5867316 accurracy:  0.95390534\n",
      "Epoch:  5501 Loss:  0.5867311 accurracy:  0.95390767\n",
      "Epoch:  5502 Loss:  0.5867302 accurracy:  0.95391\n",
      "Epoch:  5503 Loss:  0.5867296 accurracy:  0.9539123\n",
      "Epoch:  5504 Loss:  0.58672893 accurracy:  0.95391464\n",
      "Epoch:  5505 Loss:  0.5867284 accurracy:  0.95391697\n",
      "Epoch:  5506 Loss:  0.58672786 accurracy:  0.95391923\n",
      "Epoch:  5507 Loss:  0.58672714 accurracy:  0.95392156\n",
      "Epoch:  5508 Loss:  0.5867265 accurracy:  0.9539239\n",
      "Epoch:  5509 Loss:  0.5867258 accurracy:  0.9539262\n",
      "Epoch:  5510 Loss:  0.5867251 accurracy:  0.95392853\n",
      "Epoch:  5511 Loss:  0.58672446 accurracy:  0.9539308\n",
      "Epoch:  5512 Loss:  0.58672386 accurracy:  0.9539331\n",
      "Epoch:  5513 Loss:  0.58672327 accurracy:  0.95393544\n",
      "Epoch:  5514 Loss:  0.5867228 accurracy:  0.95393777\n",
      "Epoch:  5515 Loss:  0.5867222 accurracy:  0.95394003\n",
      "Epoch:  5516 Loss:  0.58672154 accurracy:  0.95394236\n",
      "Epoch:  5517 Loss:  0.5867209 accurracy:  0.9539447\n",
      "Epoch:  5518 Loss:  0.58671993 accurracy:  0.95394695\n",
      "Epoch:  5519 Loss:  0.58671916 accurracy:  0.9539493\n",
      "Epoch:  5520 Loss:  0.5867187 accurracy:  0.9539516\n",
      "Epoch:  5521 Loss:  0.5867185 accurracy:  0.95395386\n",
      "Epoch:  5522 Loss:  0.58671796 accurracy:  0.9539562\n",
      "Epoch:  5523 Loss:  0.58671725 accurracy:  0.9539585\n",
      "Epoch:  5524 Loss:  0.5867161 accurracy:  0.9539608\n",
      "Epoch:  5525 Loss:  0.5867155 accurracy:  0.9539631\n",
      "Epoch:  5526 Loss:  0.5867151 accurracy:  0.95396537\n",
      "Epoch:  5527 Loss:  0.5867146 accurracy:  0.9539677\n",
      "Epoch:  5528 Loss:  0.5867139 accurracy:  0.95396996\n",
      "Epoch:  5529 Loss:  0.5867132 accurracy:  0.9539723\n",
      "Epoch:  5530 Loss:  0.58671266 accurracy:  0.95397455\n",
      "Epoch:  5531 Loss:  0.5867122 accurracy:  0.95397687\n",
      "Epoch:  5532 Loss:  0.5867115 accurracy:  0.95397913\n",
      "Epoch:  5533 Loss:  0.5867106 accurracy:  0.95398146\n",
      "Epoch:  5534 Loss:  0.58671 accurracy:  0.9539837\n",
      "Epoch:  5535 Loss:  0.58670956 accurracy:  0.95398605\n",
      "Epoch:  5536 Loss:  0.586709 accurracy:  0.9539883\n",
      "Epoch:  5537 Loss:  0.58670837 accurracy:  0.95399064\n",
      "Epoch:  5538 Loss:  0.5867077 accurracy:  0.9539929\n",
      "Epoch:  5539 Loss:  0.58670694 accurracy:  0.95399517\n",
      "Epoch:  5540 Loss:  0.5867062 accurracy:  0.9539975\n",
      "Epoch:  5541 Loss:  0.5867058 accurracy:  0.95399976\n",
      "Epoch:  5542 Loss:  0.5867052 accurracy:  0.954002\n",
      "Epoch:  5543 Loss:  0.5867045 accurracy:  0.95400435\n",
      "Epoch:  5544 Loss:  0.58670396 accurracy:  0.9540066\n",
      "Epoch:  5545 Loss:  0.58670324 accurracy:  0.9540089\n",
      "Epoch:  5546 Loss:  0.5867026 accurracy:  0.9540112\n",
      "Epoch:  5547 Loss:  0.58670205 accurracy:  0.95401347\n",
      "Epoch:  5548 Loss:  0.58670145 accurracy:  0.95401573\n",
      "Epoch:  5549 Loss:  0.58670086 accurracy:  0.954018\n",
      "Epoch:  5550 Loss:  0.5867002 accurracy:  0.9540203\n",
      "Epoch:  5551 Loss:  0.5866994 accurracy:  0.9540226\n",
      "Epoch:  5552 Loss:  0.5866989 accurracy:  0.95402485\n",
      "Epoch:  5553 Loss:  0.5866985 accurracy:  0.9540271\n",
      "Epoch:  5554 Loss:  0.5866979 accurracy:  0.9540294\n",
      "Epoch:  5555 Loss:  0.58669704 accurracy:  0.9540317\n",
      "Epoch:  5556 Loss:  0.58669627 accurracy:  0.954034\n",
      "Epoch:  5557 Loss:  0.5866958 accurracy:  0.95403624\n",
      "Epoch:  5558 Loss:  0.5866954 accurracy:  0.9540385\n",
      "Epoch:  5559 Loss:  0.58669484 accurracy:  0.95404077\n",
      "Epoch:  5560 Loss:  0.58669406 accurracy:  0.95404303\n",
      "Epoch:  5561 Loss:  0.58669335 accurracy:  0.9540453\n",
      "Epoch:  5562 Loss:  0.58669245 accurracy:  0.95404756\n",
      "Epoch:  5563 Loss:  0.586692 accurracy:  0.9540498\n",
      "Epoch:  5564 Loss:  0.58669156 accurracy:  0.9540521\n",
      "Epoch:  5565 Loss:  0.586691 accurracy:  0.95405436\n",
      "Epoch:  5566 Loss:  0.5866902 accurracy:  0.9540566\n",
      "Epoch:  5567 Loss:  0.58668935 accurracy:  0.9540589\n",
      "Epoch:  5568 Loss:  0.5866889 accurracy:  0.95406115\n",
      "Epoch:  5569 Loss:  0.5866884 accurracy:  0.9540634\n",
      "Epoch:  5570 Loss:  0.58668786 accurracy:  0.9540657\n",
      "Epoch:  5571 Loss:  0.58668697 accurracy:  0.95406795\n",
      "Epoch:  5572 Loss:  0.5866864 accurracy:  0.9540702\n",
      "Epoch:  5573 Loss:  0.58668596 accurracy:  0.9540725\n",
      "Epoch:  5574 Loss:  0.58668536 accurracy:  0.95407474\n",
      "Epoch:  5575 Loss:  0.58668476 accurracy:  0.954077\n",
      "Epoch:  5576 Loss:  0.58668417 accurracy:  0.9540793\n",
      "Epoch:  5577 Loss:  0.58668333 accurracy:  0.95408154\n",
      "Epoch:  5578 Loss:  0.58668274 accurracy:  0.95408374\n",
      "Epoch:  5579 Loss:  0.5866824 accurracy:  0.954086\n",
      "Epoch:  5580 Loss:  0.5866817 accurracy:  0.9540883\n",
      "Epoch:  5581 Loss:  0.5866808 accurracy:  0.95409054\n",
      "Epoch:  5582 Loss:  0.5866803 accurracy:  0.9540928\n",
      "Epoch:  5583 Loss:  0.5866799 accurracy:  0.954095\n",
      "Epoch:  5584 Loss:  0.5866794 accurracy:  0.9540973\n",
      "Epoch:  5585 Loss:  0.58667856 accurracy:  0.95409954\n",
      "Epoch:  5586 Loss:  0.5866778 accurracy:  0.9541018\n",
      "Epoch:  5587 Loss:  0.5866773 accurracy:  0.954104\n",
      "Epoch:  5588 Loss:  0.5866768 accurracy:  0.9541063\n",
      "Epoch:  5589 Loss:  0.5866763 accurracy:  0.95410854\n",
      "Epoch:  5590 Loss:  0.5866757 accurracy:  0.9541108\n",
      "Epoch:  5591 Loss:  0.5866749 accurracy:  0.954113\n",
      "Epoch:  5592 Loss:  0.586674 accurracy:  0.9541153\n",
      "Epoch:  5593 Loss:  0.5866735 accurracy:  0.95411754\n",
      "Epoch:  5594 Loss:  0.586673 accurracy:  0.95411974\n",
      "Epoch:  5595 Loss:  0.5866726 accurracy:  0.954122\n",
      "Epoch:  5596 Loss:  0.5866718 accurracy:  0.9541242\n",
      "Epoch:  5597 Loss:  0.5866712 accurracy:  0.9541265\n",
      "Epoch:  5598 Loss:  0.5866705 accurracy:  0.95412874\n",
      "Epoch:  5599 Loss:  0.5866699 accurracy:  0.95413095\n",
      "Epoch:  5600 Loss:  0.58666927 accurracy:  0.9541332\n",
      "Epoch:  5601 Loss:  0.58666867 accurracy:  0.9541354\n",
      "Epoch:  5602 Loss:  0.586668 accurracy:  0.9541377\n",
      "Epoch:  5603 Loss:  0.58666766 accurracy:  0.9541399\n",
      "Epoch:  5604 Loss:  0.586667 accurracy:  0.95414215\n",
      "Epoch:  5605 Loss:  0.5866662 accurracy:  0.95414436\n",
      "Epoch:  5606 Loss:  0.5866656 accurracy:  0.9541466\n",
      "Epoch:  5607 Loss:  0.586665 accurracy:  0.9541488\n",
      "Epoch:  5608 Loss:  0.58666444 accurracy:  0.9541511\n",
      "Epoch:  5609 Loss:  0.58666396 accurracy:  0.9541533\n",
      "Epoch:  5610 Loss:  0.5866632 accurracy:  0.9541555\n",
      "Epoch:  5611 Loss:  0.58666253 accurracy:  0.95415777\n",
      "Epoch:  5612 Loss:  0.586662 accurracy:  0.95416\n",
      "Epoch:  5613 Loss:  0.5866616 accurracy:  0.95416224\n",
      "Epoch:  5614 Loss:  0.58666104 accurracy:  0.95416445\n",
      "Epoch:  5615 Loss:  0.58666015 accurracy:  0.95416665\n",
      "Epoch:  5616 Loss:  0.5866595 accurracy:  0.9541689\n",
      "Epoch:  5617 Loss:  0.58665884 accurracy:  0.9541711\n",
      "Epoch:  5618 Loss:  0.5866585 accurracy:  0.9541733\n",
      "Epoch:  5619 Loss:  0.58665806 accurracy:  0.9541756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5620 Loss:  0.5866572 accurracy:  0.9541778\n",
      "Epoch:  5621 Loss:  0.5866566 accurracy:  0.95418\n",
      "Epoch:  5622 Loss:  0.5866558 accurracy:  0.9541822\n",
      "Epoch:  5623 Loss:  0.58665526 accurracy:  0.9541845\n",
      "Epoch:  5624 Loss:  0.5866547 accurracy:  0.9541867\n",
      "Epoch:  5625 Loss:  0.5866541 accurracy:  0.9541889\n",
      "Epoch:  5626 Loss:  0.58665365 accurracy:  0.9541911\n",
      "Epoch:  5627 Loss:  0.586653 accurracy:  0.9541933\n",
      "Epoch:  5628 Loss:  0.5866522 accurracy:  0.95419556\n",
      "Epoch:  5629 Loss:  0.5866517 accurracy:  0.95419776\n",
      "Epoch:  5630 Loss:  0.5866512 accurracy:  0.95419997\n",
      "Epoch:  5631 Loss:  0.5866507 accurracy:  0.9542022\n",
      "Epoch:  5632 Loss:  0.58665 accurracy:  0.9542044\n",
      "Epoch:  5633 Loss:  0.58664924 accurracy:  0.9542066\n",
      "Epoch:  5634 Loss:  0.5866486 accurracy:  0.9542088\n",
      "Epoch:  5635 Loss:  0.5866483 accurracy:  0.954211\n",
      "Epoch:  5636 Loss:  0.5866477 accurracy:  0.95421326\n",
      "Epoch:  5637 Loss:  0.586647 accurracy:  0.95421547\n",
      "Epoch:  5638 Loss:  0.5866463 accurracy:  0.9542177\n",
      "Epoch:  5639 Loss:  0.5866458 accurracy:  0.9542199\n",
      "Epoch:  5640 Loss:  0.5866452 accurracy:  0.9542221\n",
      "Epoch:  5641 Loss:  0.5866446 accurracy:  0.9542243\n",
      "Epoch:  5642 Loss:  0.58664423 accurracy:  0.9542265\n",
      "Epoch:  5643 Loss:  0.58664346 accurracy:  0.9542287\n",
      "Epoch:  5644 Loss:  0.5866427 accurracy:  0.9542309\n",
      "Epoch:  5645 Loss:  0.58664215 accurracy:  0.9542331\n",
      "Epoch:  5646 Loss:  0.58664155 accurracy:  0.9542353\n",
      "Epoch:  5647 Loss:  0.5866411 accurracy:  0.95423746\n",
      "Epoch:  5648 Loss:  0.5866405 accurracy:  0.95423967\n",
      "Epoch:  5649 Loss:  0.58663976 accurracy:  0.9542419\n",
      "Epoch:  5650 Loss:  0.5866392 accurracy:  0.9542441\n",
      "Epoch:  5651 Loss:  0.5866386 accurracy:  0.9542463\n",
      "Epoch:  5652 Loss:  0.58663803 accurracy:  0.9542485\n",
      "Epoch:  5653 Loss:  0.58663726 accurracy:  0.9542507\n",
      "Epoch:  5654 Loss:  0.58663666 accurracy:  0.9542529\n",
      "Epoch:  5655 Loss:  0.58663625 accurracy:  0.95425504\n",
      "Epoch:  5656 Loss:  0.5866356 accurracy:  0.95425725\n",
      "Epoch:  5657 Loss:  0.58663505 accurracy:  0.95425946\n",
      "Epoch:  5658 Loss:  0.5866345 accurracy:  0.95426166\n",
      "Epoch:  5659 Loss:  0.5866339 accurracy:  0.95426387\n",
      "Epoch:  5660 Loss:  0.58663315 accurracy:  0.954266\n",
      "Epoch:  5661 Loss:  0.58663255 accurracy:  0.9542682\n",
      "Epoch:  5662 Loss:  0.586632 accurracy:  0.9542704\n",
      "Epoch:  5663 Loss:  0.58663166 accurracy:  0.9542726\n",
      "Epoch:  5664 Loss:  0.58663106 accurracy:  0.9542748\n",
      "Epoch:  5665 Loss:  0.5866302 accurracy:  0.954277\n",
      "Epoch:  5666 Loss:  0.5866296 accurracy:  0.9542792\n",
      "Epoch:  5667 Loss:  0.58662915 accurracy:  0.95428133\n",
      "Epoch:  5668 Loss:  0.5866288 accurracy:  0.95428354\n",
      "Epoch:  5669 Loss:  0.5866281 accurracy:  0.95428574\n",
      "Epoch:  5670 Loss:  0.5866273 accurracy:  0.9542879\n",
      "Epoch:  5671 Loss:  0.58662665 accurracy:  0.9542901\n",
      "Epoch:  5672 Loss:  0.5866262 accurracy:  0.95429224\n",
      "Epoch:  5673 Loss:  0.5866258 accurracy:  0.95429444\n",
      "Epoch:  5674 Loss:  0.5866253 accurracy:  0.95429665\n",
      "Epoch:  5675 Loss:  0.5866245 accurracy:  0.9542988\n",
      "Epoch:  5676 Loss:  0.5866239 accurracy:  0.954301\n",
      "Epoch:  5677 Loss:  0.5866233 accurracy:  0.95430315\n",
      "Epoch:  5678 Loss:  0.5866226 accurracy:  0.95430535\n",
      "Epoch:  5679 Loss:  0.5866219 accurracy:  0.9543075\n",
      "Epoch:  5680 Loss:  0.5866213 accurracy:  0.9543097\n",
      "Epoch:  5681 Loss:  0.5866209 accurracy:  0.95431185\n",
      "Epoch:  5682 Loss:  0.58662057 accurracy:  0.95431405\n",
      "Epoch:  5683 Loss:  0.5866199 accurracy:  0.9543162\n",
      "Epoch:  5684 Loss:  0.58661914 accurracy:  0.9543184\n",
      "Epoch:  5685 Loss:  0.5866184 accurracy:  0.95432055\n",
      "Epoch:  5686 Loss:  0.5866178 accurracy:  0.9543227\n",
      "Epoch:  5687 Loss:  0.5866172 accurracy:  0.9543249\n",
      "Epoch:  5688 Loss:  0.5866166 accurracy:  0.95432705\n",
      "Epoch:  5689 Loss:  0.5866162 accurracy:  0.95432925\n",
      "Epoch:  5690 Loss:  0.5866157 accurracy:  0.9543314\n",
      "Epoch:  5691 Loss:  0.58661515 accurracy:  0.95433354\n",
      "Epoch:  5692 Loss:  0.58661425 accurracy:  0.95433575\n",
      "Epoch:  5693 Loss:  0.58661383 accurracy:  0.9543379\n",
      "Epoch:  5694 Loss:  0.5866135 accurracy:  0.95434004\n",
      "Epoch:  5695 Loss:  0.5866129 accurracy:  0.95434225\n",
      "Epoch:  5696 Loss:  0.5866119 accurracy:  0.9543444\n",
      "Epoch:  5697 Loss:  0.5866112 accurracy:  0.95434654\n",
      "Epoch:  5698 Loss:  0.58661085 accurracy:  0.95434874\n",
      "Epoch:  5699 Loss:  0.58661044 accurracy:  0.9543509\n",
      "Epoch:  5700 Loss:  0.5866099 accurracy:  0.95435303\n",
      "Epoch:  5701 Loss:  0.58660924 accurracy:  0.9543552\n",
      "Epoch:  5702 Loss:  0.58660865 accurracy:  0.9543573\n",
      "Epoch:  5703 Loss:  0.586608 accurracy:  0.95435953\n",
      "Epoch:  5704 Loss:  0.5866075 accurracy:  0.9543617\n",
      "Epoch:  5705 Loss:  0.5866068 accurracy:  0.9543638\n",
      "Epoch:  5706 Loss:  0.58660626 accurracy:  0.95436597\n",
      "Epoch:  5707 Loss:  0.58660585 accurracy:  0.9543681\n",
      "Epoch:  5708 Loss:  0.58660525 accurracy:  0.9543703\n",
      "Epoch:  5709 Loss:  0.58660465 accurracy:  0.95437247\n",
      "Epoch:  5710 Loss:  0.5866038 accurracy:  0.9543746\n",
      "Epoch:  5711 Loss:  0.5866033 accurracy:  0.95437676\n",
      "Epoch:  5712 Loss:  0.58660275 accurracy:  0.9543789\n",
      "Epoch:  5713 Loss:  0.58660233 accurracy:  0.95438105\n",
      "Epoch:  5714 Loss:  0.5866017 accurracy:  0.9543832\n",
      "Epoch:  5715 Loss:  0.586601 accurracy:  0.95438534\n",
      "Epoch:  5716 Loss:  0.58660024 accurracy:  0.9543875\n",
      "Epoch:  5717 Loss:  0.5865997 accurracy:  0.95438963\n",
      "Epoch:  5718 Loss:  0.58659947 accurracy:  0.9543918\n",
      "Epoch:  5719 Loss:  0.58659893 accurracy:  0.9543939\n",
      "Epoch:  5720 Loss:  0.586598 accurracy:  0.95439607\n",
      "Epoch:  5721 Loss:  0.5865971 accurracy:  0.9543982\n",
      "Epoch:  5722 Loss:  0.5865969 accurracy:  0.95440036\n",
      "Epoch:  5723 Loss:  0.58659655 accurracy:  0.9544025\n",
      "Epoch:  5724 Loss:  0.5865961 accurracy:  0.95440465\n",
      "Epoch:  5725 Loss:  0.5865952 accurracy:  0.9544068\n",
      "Epoch:  5726 Loss:  0.5865945 accurracy:  0.95440894\n",
      "Epoch:  5727 Loss:  0.5865939 accurracy:  0.9544111\n",
      "Epoch:  5728 Loss:  0.58659357 accurracy:  0.95441324\n",
      "Epoch:  5729 Loss:  0.5865931 accurracy:  0.9544154\n",
      "Epoch:  5730 Loss:  0.5865924 accurracy:  0.95441747\n",
      "Epoch:  5731 Loss:  0.5865916 accurracy:  0.9544196\n",
      "Epoch:  5732 Loss:  0.58659106 accurracy:  0.95442176\n",
      "Epoch:  5733 Loss:  0.5865907 accurracy:  0.9544239\n",
      "Epoch:  5734 Loss:  0.58659035 accurracy:  0.95442605\n",
      "Epoch:  5735 Loss:  0.5865895 accurracy:  0.9544282\n",
      "Epoch:  5736 Loss:  0.58658856 accurracy:  0.9544303\n",
      "Epoch:  5737 Loss:  0.58658814 accurracy:  0.9544324\n",
      "Epoch:  5738 Loss:  0.5865878 accurracy:  0.9544346\n",
      "Epoch:  5739 Loss:  0.5865875 accurracy:  0.9544367\n",
      "Epoch:  5740 Loss:  0.5865868 accurracy:  0.9544388\n",
      "Epoch:  5741 Loss:  0.58658576 accurracy:  0.95444095\n",
      "Epoch:  5742 Loss:  0.586585 accurracy:  0.9544431\n",
      "Epoch:  5743 Loss:  0.58658475 accurracy:  0.95444524\n",
      "Epoch:  5744 Loss:  0.58658445 accurracy:  0.9544473\n",
      "Epoch:  5745 Loss:  0.586584 accurracy:  0.9544495\n",
      "Epoch:  5746 Loss:  0.58658314 accurracy:  0.9544516\n",
      "Epoch:  5747 Loss:  0.5865823 accurracy:  0.9544537\n",
      "Epoch:  5748 Loss:  0.58658177 accurracy:  0.95445585\n",
      "Epoch:  5749 Loss:  0.58658165 accurracy:  0.954458\n",
      "Epoch:  5750 Loss:  0.58658123 accurracy:  0.9544601\n",
      "Epoch:  5751 Loss:  0.5865803 accurracy:  0.95446223\n",
      "Epoch:  5752 Loss:  0.58657956 accurracy:  0.9544643\n",
      "Epoch:  5753 Loss:  0.5865789 accurracy:  0.95446646\n",
      "Epoch:  5754 Loss:  0.5865784 accurracy:  0.95446855\n",
      "Epoch:  5755 Loss:  0.586578 accurracy:  0.9544707\n",
      "Epoch:  5756 Loss:  0.5865774 accurracy:  0.95447284\n",
      "Epoch:  5757 Loss:  0.5865768 accurracy:  0.9544749\n",
      "Epoch:  5758 Loss:  0.5865763 accurracy:  0.9544771\n",
      "Epoch:  5759 Loss:  0.5865758 accurracy:  0.95447916\n",
      "Epoch:  5760 Loss:  0.5865752 accurracy:  0.9544813\n",
      "Epoch:  5761 Loss:  0.5865745 accurracy:  0.9544834\n",
      "Epoch:  5762 Loss:  0.58657384 accurracy:  0.95448554\n",
      "Epoch:  5763 Loss:  0.5865734 accurracy:  0.9544876\n",
      "Epoch:  5764 Loss:  0.5865729 accurracy:  0.9544897\n",
      "Epoch:  5765 Loss:  0.58657247 accurracy:  0.95449185\n",
      "Epoch:  5766 Loss:  0.5865717 accurracy:  0.95449394\n",
      "Epoch:  5767 Loss:  0.586571 accurracy:  0.9544961\n",
      "Epoch:  5768 Loss:  0.5865706 accurracy:  0.9544982\n",
      "Epoch:  5769 Loss:  0.5865702 accurracy:  0.9545003\n",
      "Epoch:  5770 Loss:  0.5865695 accurracy:  0.9545024\n",
      "Epoch:  5771 Loss:  0.5865686 accurracy:  0.9545045\n",
      "Epoch:  5772 Loss:  0.58656806 accurracy:  0.95450664\n",
      "Epoch:  5773 Loss:  0.5865677 accurracy:  0.9545087\n",
      "Epoch:  5774 Loss:  0.5865673 accurracy:  0.9545108\n",
      "Epoch:  5775 Loss:  0.5865667 accurracy:  0.95451295\n",
      "Epoch:  5776 Loss:  0.5865659 accurracy:  0.95451504\n",
      "Epoch:  5777 Loss:  0.58656526 accurracy:  0.9545171\n",
      "Epoch:  5778 Loss:  0.5865647 accurracy:  0.9545192\n",
      "Epoch:  5779 Loss:  0.5865642 accurracy:  0.95452136\n",
      "Epoch:  5780 Loss:  0.58656377 accurracy:  0.95452344\n",
      "Epoch:  5781 Loss:  0.58656317 accurracy:  0.95452553\n",
      "Epoch:  5782 Loss:  0.58656234 accurracy:  0.9545276\n",
      "Epoch:  5783 Loss:  0.586562 accurracy:  0.95452976\n",
      "Epoch:  5784 Loss:  0.58656156 accurracy:  0.95453185\n",
      "Epoch:  5785 Loss:  0.5865611 accurracy:  0.95453393\n",
      "Epoch:  5786 Loss:  0.58656055 accurracy:  0.954536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5787 Loss:  0.5865596 accurracy:  0.9545381\n",
      "Epoch:  5788 Loss:  0.58655894 accurracy:  0.9545402\n",
      "Epoch:  5789 Loss:  0.5865584 accurracy:  0.95454234\n",
      "Epoch:  5790 Loss:  0.5865581 accurracy:  0.9545444\n",
      "Epoch:  5791 Loss:  0.5865576 accurracy:  0.9545465\n",
      "Epoch:  5792 Loss:  0.58655703 accurracy:  0.9545486\n",
      "Epoch:  5793 Loss:  0.58655626 accurracy:  0.9545507\n",
      "Epoch:  5794 Loss:  0.5865556 accurracy:  0.95455277\n",
      "Epoch:  5795 Loss:  0.58655536 accurracy:  0.95455486\n",
      "Epoch:  5796 Loss:  0.5865548 accurracy:  0.95455694\n",
      "Epoch:  5797 Loss:  0.5865541 accurracy:  0.954559\n",
      "Epoch:  5798 Loss:  0.58655334 accurracy:  0.9545611\n",
      "Epoch:  5799 Loss:  0.5865527 accurracy:  0.9545632\n",
      "Epoch:  5800 Loss:  0.58655244 accurracy:  0.9545653\n",
      "Epoch:  5801 Loss:  0.58655226 accurracy:  0.9545674\n",
      "Epoch:  5802 Loss:  0.58655155 accurracy:  0.95456946\n",
      "Epoch:  5803 Loss:  0.5865506 accurracy:  0.95457155\n",
      "Epoch:  5804 Loss:  0.5865498 accurracy:  0.95457363\n",
      "Epoch:  5805 Loss:  0.5865494 accurracy:  0.9545757\n",
      "Epoch:  5806 Loss:  0.5865492 accurracy:  0.9545778\n",
      "Epoch:  5807 Loss:  0.58654875 accurracy:  0.9545799\n",
      "Epoch:  5808 Loss:  0.58654785 accurracy:  0.954582\n",
      "Epoch:  5809 Loss:  0.58654696 accurracy:  0.95458406\n",
      "Epoch:  5810 Loss:  0.5865466 accurracy:  0.95458615\n",
      "Epoch:  5811 Loss:  0.58654624 accurracy:  0.95458823\n",
      "Epoch:  5812 Loss:  0.5865459 accurracy:  0.95459026\n",
      "Epoch:  5813 Loss:  0.58654517 accurracy:  0.95459235\n",
      "Epoch:  5814 Loss:  0.58654433 accurracy:  0.95459443\n",
      "Epoch:  5815 Loss:  0.5865437 accurracy:  0.9545965\n",
      "Epoch:  5816 Loss:  0.58654326 accurracy:  0.9545986\n",
      "Epoch:  5817 Loss:  0.586543 accurracy:  0.9546007\n",
      "Epoch:  5818 Loss:  0.5865425 accurracy:  0.9546027\n",
      "Epoch:  5819 Loss:  0.5865419 accurracy:  0.9546048\n",
      "Epoch:  5820 Loss:  0.58654106 accurracy:  0.9546069\n",
      "Epoch:  5821 Loss:  0.58654034 accurracy:  0.954609\n",
      "Epoch:  5822 Loss:  0.58653986 accurracy:  0.954611\n",
      "Epoch:  5823 Loss:  0.58653957 accurracy:  0.9546131\n",
      "Epoch:  5824 Loss:  0.5865392 accurracy:  0.9546152\n",
      "Epoch:  5825 Loss:  0.58653843 accurracy:  0.95461726\n",
      "Epoch:  5826 Loss:  0.5865378 accurracy:  0.9546193\n",
      "Epoch:  5827 Loss:  0.5865372 accurracy:  0.9546214\n",
      "Epoch:  5828 Loss:  0.5865367 accurracy:  0.95462346\n",
      "Epoch:  5829 Loss:  0.58653617 accurracy:  0.9546255\n",
      "Epoch:  5830 Loss:  0.5865356 accurracy:  0.9546276\n",
      "Epoch:  5831 Loss:  0.58653486 accurracy:  0.9546296\n",
      "Epoch:  5832 Loss:  0.58653426 accurracy:  0.9546317\n",
      "Epoch:  5833 Loss:  0.58653384 accurracy:  0.9546338\n",
      "Epoch:  5834 Loss:  0.58653355 accurracy:  0.9546358\n",
      "Epoch:  5835 Loss:  0.58653295 accurracy:  0.9546379\n",
      "Epoch:  5836 Loss:  0.5865323 accurracy:  0.9546399\n",
      "Epoch:  5837 Loss:  0.58653146 accurracy:  0.954642\n",
      "Epoch:  5838 Loss:  0.586531 accurracy:  0.9546441\n",
      "Epoch:  5839 Loss:  0.5865307 accurracy:  0.9546461\n",
      "Epoch:  5840 Loss:  0.58653027 accurracy:  0.9546482\n",
      "Epoch:  5841 Loss:  0.5865295 accurracy:  0.9546502\n",
      "Epoch:  5842 Loss:  0.5865288 accurracy:  0.9546523\n",
      "Epoch:  5843 Loss:  0.58652806 accurracy:  0.95465434\n",
      "Epoch:  5844 Loss:  0.58652776 accurracy:  0.9546564\n",
      "Epoch:  5845 Loss:  0.5865274 accurracy:  0.95465845\n",
      "Epoch:  5846 Loss:  0.5865269 accurracy:  0.95466053\n",
      "Epoch:  5847 Loss:  0.58652616 accurracy:  0.95466256\n",
      "Epoch:  5848 Loss:  0.5865255 accurracy:  0.9546646\n",
      "Epoch:  5849 Loss:  0.5865248 accurracy:  0.9546667\n",
      "Epoch:  5850 Loss:  0.5865243 accurracy:  0.9546687\n",
      "Epoch:  5851 Loss:  0.58652395 accurracy:  0.9546708\n",
      "Epoch:  5852 Loss:  0.5865234 accurracy:  0.9546728\n",
      "Epoch:  5853 Loss:  0.58652276 accurracy:  0.95467484\n",
      "Epoch:  5854 Loss:  0.58652216 accurracy:  0.9546769\n",
      "Epoch:  5855 Loss:  0.5865217 accurracy:  0.95467895\n",
      "Epoch:  5856 Loss:  0.5865213 accurracy:  0.954681\n",
      "Epoch:  5857 Loss:  0.58652085 accurracy:  0.95468307\n",
      "Epoch:  5858 Loss:  0.5865199 accurracy:  0.9546851\n",
      "Epoch:  5859 Loss:  0.5865191 accurracy:  0.9546871\n",
      "Epoch:  5860 Loss:  0.5865187 accurracy:  0.9546892\n",
      "Epoch:  5861 Loss:  0.5865185 accurracy:  0.95469123\n",
      "Epoch:  5862 Loss:  0.58651805 accurracy:  0.95469326\n",
      "Epoch:  5863 Loss:  0.58651733 accurracy:  0.95469534\n",
      "Epoch:  5864 Loss:  0.5865167 accurracy:  0.9546974\n",
      "Epoch:  5865 Loss:  0.5865162 accurracy:  0.9546994\n",
      "Epoch:  5866 Loss:  0.58651584 accurracy:  0.9547014\n",
      "Epoch:  5867 Loss:  0.58651525 accurracy:  0.95470345\n",
      "Epoch:  5868 Loss:  0.5865144 accurracy:  0.95470554\n",
      "Epoch:  5869 Loss:  0.58651364 accurracy:  0.95470756\n",
      "Epoch:  5870 Loss:  0.5865133 accurracy:  0.9547096\n",
      "Epoch:  5871 Loss:  0.58651316 accurracy:  0.9547116\n",
      "Epoch:  5872 Loss:  0.5865125 accurracy:  0.95471364\n",
      "Epoch:  5873 Loss:  0.58651173 accurracy:  0.95471567\n",
      "Epoch:  5874 Loss:  0.5865112 accurracy:  0.95471776\n",
      "Epoch:  5875 Loss:  0.58651066 accurracy:  0.9547198\n",
      "Epoch:  5876 Loss:  0.5865104 accurracy:  0.9547218\n",
      "Epoch:  5877 Loss:  0.58650976 accurracy:  0.95472383\n",
      "Epoch:  5878 Loss:  0.5865089 accurracy:  0.95472586\n",
      "Epoch:  5879 Loss:  0.58650804 accurracy:  0.9547279\n",
      "Epoch:  5880 Loss:  0.58650756 accurracy:  0.9547299\n",
      "Epoch:  5881 Loss:  0.58650744 accurracy:  0.95473194\n",
      "Epoch:  5882 Loss:  0.586507 accurracy:  0.95473397\n",
      "Epoch:  5883 Loss:  0.58650655 accurracy:  0.954736\n",
      "Epoch:  5884 Loss:  0.5865058 accurracy:  0.954738\n",
      "Epoch:  5885 Loss:  0.586505 accurracy:  0.95474005\n",
      "Epoch:  5886 Loss:  0.5865045 accurracy:  0.9547421\n",
      "Epoch:  5887 Loss:  0.58650434 accurracy:  0.9547441\n",
      "Epoch:  5888 Loss:  0.58650386 accurracy:  0.9547461\n",
      "Epoch:  5889 Loss:  0.5865032 accurracy:  0.95474815\n",
      "Epoch:  5890 Loss:  0.58650243 accurracy:  0.9547502\n",
      "Epoch:  5891 Loss:  0.58650184 accurracy:  0.9547522\n",
      "Epoch:  5892 Loss:  0.5865013 accurracy:  0.95475423\n",
      "Epoch:  5893 Loss:  0.58650106 accurracy:  0.95475626\n",
      "Epoch:  5894 Loss:  0.5865007 accurracy:  0.9547583\n",
      "Epoch:  5895 Loss:  0.5865 accurracy:  0.9547603\n",
      "Epoch:  5896 Loss:  0.5864991 accurracy:  0.9547623\n",
      "Epoch:  5897 Loss:  0.58649844 accurracy:  0.9547643\n",
      "Epoch:  5898 Loss:  0.58649826 accurracy:  0.95476633\n",
      "Epoch:  5899 Loss:  0.586498 accurracy:  0.95476836\n",
      "Epoch:  5900 Loss:  0.58649725 accurracy:  0.9547704\n",
      "Epoch:  5901 Loss:  0.5864966 accurracy:  0.9547724\n",
      "Epoch:  5902 Loss:  0.58649606 accurracy:  0.9547744\n",
      "Epoch:  5903 Loss:  0.5864956 accurracy:  0.9547764\n",
      "Epoch:  5904 Loss:  0.5864951 accurracy:  0.95477843\n",
      "Epoch:  5905 Loss:  0.58649445 accurracy:  0.95478046\n",
      "Epoch:  5906 Loss:  0.5864938 accurracy:  0.9547825\n",
      "Epoch:  5907 Loss:  0.5864932 accurracy:  0.95478445\n",
      "Epoch:  5908 Loss:  0.5864929 accurracy:  0.9547865\n",
      "Epoch:  5909 Loss:  0.5864925 accurracy:  0.9547885\n",
      "Epoch:  5910 Loss:  0.5864919 accurracy:  0.95479053\n",
      "Epoch:  5911 Loss:  0.5864913 accurracy:  0.9547925\n",
      "Epoch:  5912 Loss:  0.5864906 accurracy:  0.9547945\n",
      "Epoch:  5913 Loss:  0.5864901 accurracy:  0.95479655\n",
      "Epoch:  5914 Loss:  0.58648956 accurracy:  0.9547985\n",
      "Epoch:  5915 Loss:  0.586489 accurracy:  0.95480055\n",
      "Epoch:  5916 Loss:  0.5864886 accurracy:  0.9548026\n",
      "Epoch:  5917 Loss:  0.58648795 accurracy:  0.95480454\n",
      "Epoch:  5918 Loss:  0.58648735 accurracy:  0.95480657\n",
      "Epoch:  5919 Loss:  0.5864869 accurracy:  0.95480853\n",
      "Epoch:  5920 Loss:  0.5864863 accurracy:  0.95481056\n",
      "Epoch:  5921 Loss:  0.5864858 accurracy:  0.9548126\n",
      "Epoch:  5922 Loss:  0.58648515 accurracy:  0.95481455\n",
      "Epoch:  5923 Loss:  0.5864847 accurracy:  0.9548166\n",
      "Epoch:  5924 Loss:  0.58648413 accurracy:  0.95481855\n",
      "Epoch:  5925 Loss:  0.5864836 accurracy:  0.9548206\n",
      "Epoch:  5926 Loss:  0.58648306 accurracy:  0.95482254\n",
      "Epoch:  5927 Loss:  0.58648247 accurracy:  0.95482457\n",
      "Epoch:  5928 Loss:  0.58648187 accurracy:  0.95482653\n",
      "Epoch:  5929 Loss:  0.58648163 accurracy:  0.95482856\n",
      "Epoch:  5930 Loss:  0.586481 accurracy:  0.9548305\n",
      "Epoch:  5931 Loss:  0.5864803 accurracy:  0.95483255\n",
      "Epoch:  5932 Loss:  0.5864799 accurracy:  0.9548345\n",
      "Epoch:  5933 Loss:  0.58647937 accurracy:  0.95483655\n",
      "Epoch:  5934 Loss:  0.5864788 accurracy:  0.9548385\n",
      "Epoch:  5935 Loss:  0.58647835 accurracy:  0.95484054\n",
      "Epoch:  5936 Loss:  0.58647764 accurracy:  0.9548425\n",
      "Epoch:  5937 Loss:  0.5864772 accurracy:  0.9548445\n",
      "Epoch:  5938 Loss:  0.58647674 accurracy:  0.9548465\n",
      "Epoch:  5939 Loss:  0.58647627 accurracy:  0.95484847\n",
      "Epoch:  5940 Loss:  0.58647573 accurracy:  0.9548505\n",
      "Epoch:  5941 Loss:  0.586475 accurracy:  0.95485246\n",
      "Epoch:  5942 Loss:  0.58647454 accurracy:  0.9548544\n",
      "Epoch:  5943 Loss:  0.5864741 accurracy:  0.95485646\n",
      "Epoch:  5944 Loss:  0.5864736 accurracy:  0.9548584\n",
      "Epoch:  5945 Loss:  0.5864729 accurracy:  0.9548604\n",
      "Epoch:  5946 Loss:  0.58647233 accurracy:  0.9548624\n",
      "Epoch:  5947 Loss:  0.58647186 accurracy:  0.9548644\n",
      "Epoch:  5948 Loss:  0.5864714 accurracy:  0.95486635\n",
      "Epoch:  5949 Loss:  0.58647096 accurracy:  0.9548684\n",
      "Epoch:  5950 Loss:  0.5864704 accurracy:  0.95487034\n",
      "Epoch:  5951 Loss:  0.5864698 accurracy:  0.9548723\n",
      "Epoch:  5952 Loss:  0.5864691 accurracy:  0.9548743\n",
      "Epoch:  5953 Loss:  0.5864685 accurracy:  0.95487624\n",
      "Epoch:  5954 Loss:  0.586468 accurracy:  0.9548783\n",
      "Epoch:  5955 Loss:  0.58646774 accurracy:  0.95488024\n",
      "Epoch:  5956 Loss:  0.58646715 accurracy:  0.9548822\n",
      "Epoch:  5957 Loss:  0.58646667 accurracy:  0.9548842\n",
      "Epoch:  5958 Loss:  0.586466 accurracy:  0.95488614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5959 Loss:  0.58646524 accurracy:  0.95488816\n",
      "Epoch:  5960 Loss:  0.58646476 accurracy:  0.95489013\n",
      "Epoch:  5961 Loss:  0.58646446 accurracy:  0.9548921\n",
      "Epoch:  5962 Loss:  0.5864639 accurracy:  0.95489407\n",
      "Epoch:  5963 Loss:  0.58646315 accurracy:  0.95489603\n",
      "Epoch:  5964 Loss:  0.58646256 accurracy:  0.954898\n",
      "Epoch:  5965 Loss:  0.586462 accurracy:  0.95489997\n",
      "Epoch:  5966 Loss:  0.58646184 accurracy:  0.95490193\n",
      "Epoch:  5967 Loss:  0.5864613 accurracy:  0.95490396\n",
      "Epoch:  5968 Loss:  0.58646077 accurracy:  0.9549059\n",
      "Epoch:  5969 Loss:  0.58646 accurracy:  0.9549079\n",
      "Epoch:  5970 Loss:  0.58645946 accurracy:  0.95490986\n",
      "Epoch:  5971 Loss:  0.58645934 accurracy:  0.9549118\n",
      "Epoch:  5972 Loss:  0.58645874 accurracy:  0.9549138\n",
      "Epoch:  5973 Loss:  0.58645797 accurracy:  0.95491576\n",
      "Epoch:  5974 Loss:  0.5864571 accurracy:  0.9549177\n",
      "Epoch:  5975 Loss:  0.58645684 accurracy:  0.9549197\n",
      "Epoch:  5976 Loss:  0.58645666 accurracy:  0.95492166\n",
      "Epoch:  5977 Loss:  0.58645624 accurracy:  0.9549236\n",
      "Epoch:  5978 Loss:  0.5864554 accurracy:  0.9549256\n",
      "Epoch:  5979 Loss:  0.5864545 accurracy:  0.95492756\n",
      "Epoch:  5980 Loss:  0.58645403 accurracy:  0.9549295\n",
      "Epoch:  5981 Loss:  0.58645403 accurracy:  0.95493144\n",
      "Epoch:  5982 Loss:  0.5864537 accurracy:  0.9549334\n",
      "Epoch:  5983 Loss:  0.5864528 accurracy:  0.9549354\n",
      "Epoch:  5984 Loss:  0.5864518 accurracy:  0.95493734\n",
      "Epoch:  5985 Loss:  0.58645135 accurracy:  0.9549393\n",
      "Epoch:  5986 Loss:  0.5864513 accurracy:  0.9549413\n",
      "Epoch:  5987 Loss:  0.5864511 accurracy:  0.95494324\n",
      "Epoch:  5988 Loss:  0.5864504 accurracy:  0.9549452\n",
      "Epoch:  5989 Loss:  0.58644956 accurracy:  0.9549471\n",
      "Epoch:  5990 Loss:  0.5864488 accurracy:  0.9549491\n",
      "Epoch:  5991 Loss:  0.5864487 accurracy:  0.95495105\n",
      "Epoch:  5992 Loss:  0.5864484 accurracy:  0.954953\n",
      "Epoch:  5993 Loss:  0.58644766 accurracy:  0.954955\n",
      "Epoch:  5994 Loss:  0.58644694 accurracy:  0.9549569\n",
      "Epoch:  5995 Loss:  0.58644634 accurracy:  0.95495886\n",
      "Epoch:  5996 Loss:  0.58644587 accurracy:  0.9549608\n",
      "Epoch:  5997 Loss:  0.58644557 accurracy:  0.9549628\n",
      "Epoch:  5998 Loss:  0.5864451 accurracy:  0.9549647\n",
      "Epoch:  5999 Loss:  0.5864445 accurracy:  0.95496666\n",
      "Epoch:  6000 Loss:  0.5864438 accurracy:  0.95496863\n",
      "Epoch:  6001 Loss:  0.58644325 accurracy:  0.95497054\n",
      "Epoch:  6002 Loss:  0.5864428 accurracy:  0.9549725\n",
      "Epoch:  6003 Loss:  0.5864422 accurracy:  0.9549745\n",
      "Epoch:  6004 Loss:  0.5864417 accurracy:  0.9549764\n",
      "Epoch:  6005 Loss:  0.5864411 accurracy:  0.95497835\n",
      "Epoch:  6006 Loss:  0.5864407 accurracy:  0.9549803\n",
      "Epoch:  6007 Loss:  0.5864403 accurracy:  0.9549822\n",
      "Epoch:  6008 Loss:  0.5864398 accurracy:  0.9549842\n",
      "Epoch:  6009 Loss:  0.586439 accurracy:  0.95498616\n",
      "Epoch:  6010 Loss:  0.5864386 accurracy:  0.95498806\n",
      "Epoch:  6011 Loss:  0.5864383 accurracy:  0.95499\n",
      "Epoch:  6012 Loss:  0.5864375 accurracy:  0.95499194\n",
      "Epoch:  6013 Loss:  0.58643687 accurracy:  0.9549939\n",
      "Epoch:  6014 Loss:  0.58643633 accurracy:  0.9549959\n",
      "Epoch:  6015 Loss:  0.58643603 accurracy:  0.9549978\n",
      "Epoch:  6016 Loss:  0.58643556 accurracy:  0.95499974\n",
      "Epoch:  6017 Loss:  0.58643514 accurracy:  0.95500165\n",
      "Epoch:  6018 Loss:  0.5864344 accurracy:  0.9550036\n",
      "Epoch:  6019 Loss:  0.58643377 accurracy:  0.9550055\n",
      "Epoch:  6020 Loss:  0.58643335 accurracy:  0.9550075\n",
      "Epoch:  6021 Loss:  0.5864329 accurracy:  0.9550094\n",
      "Epoch:  6022 Loss:  0.5864324 accurracy:  0.95501137\n",
      "Epoch:  6023 Loss:  0.5864318 accurracy:  0.9550133\n",
      "Epoch:  6024 Loss:  0.58643126 accurracy:  0.95501524\n",
      "Epoch:  6025 Loss:  0.5864307 accurracy:  0.95501715\n",
      "Epoch:  6026 Loss:  0.5864303 accurracy:  0.95501906\n",
      "Epoch:  6027 Loss:  0.58642983 accurracy:  0.955021\n",
      "Epoch:  6028 Loss:  0.58642936 accurracy:  0.95502293\n",
      "Epoch:  6029 Loss:  0.5864287 accurracy:  0.9550249\n",
      "Epoch:  6030 Loss:  0.58642805 accurracy:  0.9550268\n",
      "Epoch:  6031 Loss:  0.58642757 accurracy:  0.9550287\n",
      "Epoch:  6032 Loss:  0.58642715 accurracy:  0.9550307\n",
      "Epoch:  6033 Loss:  0.5864268 accurracy:  0.9550326\n",
      "Epoch:  6034 Loss:  0.58642614 accurracy:  0.9550345\n",
      "Epoch:  6035 Loss:  0.5864255 accurracy:  0.95503646\n",
      "Epoch:  6036 Loss:  0.586425 accurracy:  0.95503837\n",
      "Epoch:  6037 Loss:  0.5864245 accurracy:  0.9550403\n",
      "Epoch:  6038 Loss:  0.5864241 accurracy:  0.95504224\n",
      "Epoch:  6039 Loss:  0.58642364 accurracy:  0.95504415\n",
      "Epoch:  6040 Loss:  0.5864231 accurracy:  0.95504606\n",
      "Epoch:  6041 Loss:  0.5864225 accurracy:  0.955048\n",
      "Epoch:  6042 Loss:  0.5864219 accurracy:  0.95504993\n",
      "Epoch:  6043 Loss:  0.58642143 accurracy:  0.95505184\n",
      "Epoch:  6044 Loss:  0.5864211 accurracy:  0.95505375\n",
      "Epoch:  6045 Loss:  0.5864206 accurracy:  0.9550557\n",
      "Epoch:  6046 Loss:  0.5864198 accurracy:  0.9550576\n",
      "Epoch:  6047 Loss:  0.5864193 accurracy:  0.9550595\n",
      "Epoch:  6048 Loss:  0.58641875 accurracy:  0.95506144\n",
      "Epoch:  6049 Loss:  0.5864184 accurracy:  0.95506334\n",
      "Epoch:  6050 Loss:  0.5864181 accurracy:  0.95506525\n",
      "Epoch:  6051 Loss:  0.5864175 accurracy:  0.9550672\n",
      "Epoch:  6052 Loss:  0.5864168 accurracy:  0.9550691\n",
      "Epoch:  6053 Loss:  0.5864161 accurracy:  0.95507103\n",
      "Epoch:  6054 Loss:  0.5864155 accurracy:  0.95507294\n",
      "Epoch:  6055 Loss:  0.5864153 accurracy:  0.95507485\n",
      "Epoch:  6056 Loss:  0.586415 accurracy:  0.95507675\n",
      "Epoch:  6057 Loss:  0.58641434 accurracy:  0.95507866\n",
      "Epoch:  6058 Loss:  0.5864136 accurracy:  0.95508057\n",
      "Epoch:  6059 Loss:  0.5864131 accurracy:  0.95508254\n",
      "Epoch:  6060 Loss:  0.5864127 accurracy:  0.95508444\n",
      "Epoch:  6061 Loss:  0.5864125 accurracy:  0.95508635\n",
      "Epoch:  6062 Loss:  0.5864119 accurracy:  0.95508826\n",
      "Epoch:  6063 Loss:  0.5864112 accurracy:  0.95509017\n",
      "Epoch:  6064 Loss:  0.5864104 accurracy:  0.9550921\n",
      "Epoch:  6065 Loss:  0.58640975 accurracy:  0.955094\n",
      "Epoch:  6066 Loss:  0.5864096 accurracy:  0.9550959\n",
      "Epoch:  6067 Loss:  0.5864094 accurracy:  0.9550978\n",
      "Epoch:  6068 Loss:  0.58640873 accurracy:  0.9550997\n",
      "Epoch:  6069 Loss:  0.58640796 accurracy:  0.9551016\n",
      "Epoch:  6070 Loss:  0.58640736 accurracy:  0.9551035\n",
      "Epoch:  6071 Loss:  0.58640707 accurracy:  0.9551054\n",
      "Epoch:  6072 Loss:  0.5864068 accurracy:  0.95510733\n",
      "Epoch:  6073 Loss:  0.58640635 accurracy:  0.9551092\n",
      "Epoch:  6074 Loss:  0.5864056 accurracy:  0.9551111\n",
      "Epoch:  6075 Loss:  0.5864049 accurracy:  0.955113\n",
      "Epoch:  6076 Loss:  0.58640444 accurracy:  0.9551149\n",
      "Epoch:  6077 Loss:  0.5864042 accurracy:  0.9551168\n",
      "Epoch:  6078 Loss:  0.58640385 accurracy:  0.9551187\n",
      "Epoch:  6079 Loss:  0.58640313 accurracy:  0.9551206\n",
      "Epoch:  6080 Loss:  0.58640236 accurracy:  0.95512253\n",
      "Epoch:  6081 Loss:  0.586402 accurracy:  0.95512444\n",
      "Epoch:  6082 Loss:  0.5864017 accurracy:  0.9551263\n",
      "Epoch:  6083 Loss:  0.5864014 accurracy:  0.9551282\n",
      "Epoch:  6084 Loss:  0.58640075 accurracy:  0.9551301\n",
      "Epoch:  6085 Loss:  0.58639973 accurracy:  0.955132\n",
      "Epoch:  6086 Loss:  0.5863992 accurracy:  0.9551339\n",
      "Epoch:  6087 Loss:  0.58639896 accurracy:  0.95513576\n",
      "Epoch:  6088 Loss:  0.5863989 accurracy:  0.95513767\n",
      "Epoch:  6089 Loss:  0.5863982 accurracy:  0.9551396\n",
      "Epoch:  6090 Loss:  0.58639723 accurracy:  0.9551415\n",
      "Epoch:  6091 Loss:  0.5863968 accurracy:  0.95514333\n",
      "Epoch:  6092 Loss:  0.58639663 accurracy:  0.95514524\n",
      "Epoch:  6093 Loss:  0.58639616 accurracy:  0.95514715\n",
      "Epoch:  6094 Loss:  0.5863956 accurracy:  0.95514905\n",
      "Epoch:  6095 Loss:  0.5863949 accurracy:  0.9551509\n",
      "Epoch:  6096 Loss:  0.58639425 accurracy:  0.9551528\n",
      "Epoch:  6097 Loss:  0.5863939 accurracy:  0.9551547\n",
      "Epoch:  6098 Loss:  0.5863936 accurracy:  0.95515656\n",
      "Epoch:  6099 Loss:  0.5863931 accurracy:  0.9551585\n",
      "Epoch:  6100 Loss:  0.58639246 accurracy:  0.9551604\n",
      "Epoch:  6101 Loss:  0.58639175 accurracy:  0.9551622\n",
      "Epoch:  6102 Loss:  0.58639127 accurracy:  0.95516413\n",
      "Epoch:  6103 Loss:  0.5863911 accurracy:  0.955166\n",
      "Epoch:  6104 Loss:  0.5863908 accurracy:  0.9551679\n",
      "Epoch:  6105 Loss:  0.58639014 accurracy:  0.9551698\n",
      "Epoch:  6106 Loss:  0.5863893 accurracy:  0.95517164\n",
      "Epoch:  6107 Loss:  0.58638865 accurracy:  0.95517355\n",
      "Epoch:  6108 Loss:  0.58638835 accurracy:  0.9551754\n",
      "Epoch:  6109 Loss:  0.58638805 accurracy:  0.9551773\n",
      "Epoch:  6110 Loss:  0.58638775 accurracy:  0.9551792\n",
      "Epoch:  6111 Loss:  0.58638686 accurracy:  0.95518106\n",
      "Epoch:  6112 Loss:  0.5863861 accurracy:  0.95518297\n",
      "Epoch:  6113 Loss:  0.5863856 accurracy:  0.9551848\n",
      "Epoch:  6114 Loss:  0.5863856 accurracy:  0.9551867\n",
      "Epoch:  6115 Loss:  0.58638537 accurracy:  0.9551886\n",
      "Epoch:  6116 Loss:  0.58638465 accurracy:  0.9551905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  6117 Loss:  0.5863839 accurracy:  0.9551923\n",
      "Epoch:  6118 Loss:  0.58638316 accurracy:  0.9551942\n",
      "Epoch:  6119 Loss:  0.5863828 accurracy:  0.9551961\n",
      "Epoch:  6120 Loss:  0.5863825 accurracy:  0.95519793\n",
      "Epoch:  6121 Loss:  0.5863821 accurracy:  0.95519984\n",
      "Epoch:  6122 Loss:  0.58638155 accurracy:  0.9552017\n",
      "Epoch:  6123 Loss:  0.5863809 accurracy:  0.9552036\n",
      "Epoch:  6124 Loss:  0.5863803 accurracy:  0.95520544\n",
      "Epoch:  6125 Loss:  0.58638 accurracy:  0.9552073\n",
      "Epoch:  6126 Loss:  0.5863796 accurracy:  0.9552092\n",
      "Epoch:  6127 Loss:  0.58637905 accurracy:  0.95521104\n",
      "Epoch:  6128 Loss:  0.58637863 accurracy:  0.95521295\n",
      "Epoch:  6129 Loss:  0.58637786 accurracy:  0.9552148\n",
      "Epoch:  6130 Loss:  0.5863773 accurracy:  0.95521665\n",
      "Epoch:  6131 Loss:  0.58637685 accurracy:  0.95521855\n",
      "Epoch:  6132 Loss:  0.5863765 accurracy:  0.9552204\n",
      "Epoch:  6133 Loss:  0.5863761 accurracy:  0.95522225\n",
      "Epoch:  6134 Loss:  0.5863756 accurracy:  0.9552241\n",
      "Epoch:  6135 Loss:  0.58637494 accurracy:  0.955226\n",
      "Epoch:  6136 Loss:  0.5863744 accurracy:  0.95522785\n",
      "Epoch:  6137 Loss:  0.58637404 accurracy:  0.9552297\n",
      "Epoch:  6138 Loss:  0.5863736 accurracy:  0.9552316\n",
      "Epoch:  6139 Loss:  0.58637315 accurracy:  0.95523345\n",
      "Epoch:  6140 Loss:  0.5863724 accurracy:  0.9552353\n",
      "Epoch:  6141 Loss:  0.5863717 accurracy:  0.95523715\n",
      "Epoch:  6142 Loss:  0.58637154 accurracy:  0.955239\n",
      "Epoch:  6143 Loss:  0.58637124 accurracy:  0.9552409\n",
      "Epoch:  6144 Loss:  0.58637047 accurracy:  0.95524275\n",
      "Epoch:  6145 Loss:  0.5863697 accurracy:  0.9552446\n",
      "Epoch:  6146 Loss:  0.5863693 accurracy:  0.95524645\n",
      "Epoch:  6147 Loss:  0.5863689 accurracy:  0.9552483\n",
      "Epoch:  6148 Loss:  0.5863686 accurracy:  0.9552502\n",
      "Epoch:  6149 Loss:  0.5863679 accurracy:  0.95525205\n",
      "Epoch:  6150 Loss:  0.58636737 accurracy:  0.9552539\n",
      "Epoch:  6151 Loss:  0.5863668 accurracy:  0.95525575\n",
      "Epoch:  6152 Loss:  0.58636636 accurracy:  0.9552576\n",
      "Epoch:  6153 Loss:  0.586366 accurracy:  0.95525944\n",
      "Epoch:  6154 Loss:  0.5863656 accurracy:  0.9552613\n",
      "Epoch:  6155 Loss:  0.5863651 accurracy:  0.95526314\n",
      "Epoch:  6156 Loss:  0.5863645 accurracy:  0.955265\n",
      "Epoch:  6157 Loss:  0.586364 accurracy:  0.95526683\n",
      "Epoch:  6158 Loss:  0.58636373 accurracy:  0.95526874\n",
      "Epoch:  6159 Loss:  0.5863634 accurracy:  0.9552706\n",
      "Epoch:  6160 Loss:  0.58636284 accurracy:  0.95527244\n",
      "Epoch:  6161 Loss:  0.58636194 accurracy:  0.9552743\n",
      "Epoch:  6162 Loss:  0.5863613 accurracy:  0.95527613\n",
      "Epoch:  6163 Loss:  0.58636093 accurracy:  0.955278\n",
      "Epoch:  6164 Loss:  0.5863606 accurracy:  0.9552798\n",
      "Epoch:  6165 Loss:  0.58636004 accurracy:  0.9552817\n",
      "Epoch:  6166 Loss:  0.58635956 accurracy:  0.9552835\n",
      "Epoch:  6167 Loss:  0.58635914 accurracy:  0.9552854\n",
      "Epoch:  6168 Loss:  0.58635867 accurracy:  0.9552872\n",
      "Epoch:  6169 Loss:  0.58635825 accurracy:  0.955289\n",
      "Epoch:  6170 Loss:  0.5863578 accurracy:  0.95529085\n",
      "Epoch:  6171 Loss:  0.58635724 accurracy:  0.9552927\n",
      "Epoch:  6172 Loss:  0.58635676 accurracy:  0.95529455\n",
      "Epoch:  6173 Loss:  0.58635616 accurracy:  0.9552964\n",
      "Epoch:  6174 Loss:  0.5863554 accurracy:  0.95529824\n",
      "Epoch:  6175 Loss:  0.586355 accurracy:  0.9553001\n",
      "Epoch:  6176 Loss:  0.5863548 accurracy:  0.95530194\n",
      "Epoch:  6177 Loss:  0.5863544 accurracy:  0.9553038\n",
      "Epoch:  6178 Loss:  0.58635366 accurracy:  0.9553056\n",
      "Epoch:  6179 Loss:  0.58635306 accurracy:  0.9553074\n",
      "Epoch:  6180 Loss:  0.58635265 accurracy:  0.9553093\n",
      "Epoch:  6181 Loss:  0.5863524 accurracy:  0.9553111\n",
      "Epoch:  6182 Loss:  0.58635205 accurracy:  0.95531297\n",
      "Epoch:  6183 Loss:  0.5863514 accurracy:  0.9553148\n",
      "Epoch:  6184 Loss:  0.58635074 accurracy:  0.9553166\n",
      "Epoch:  6185 Loss:  0.5863502 accurracy:  0.95531845\n",
      "Epoch:  6186 Loss:  0.5863497 accurracy:  0.9553203\n",
      "Epoch:  6187 Loss:  0.58634937 accurracy:  0.95532215\n",
      "Epoch:  6188 Loss:  0.5863489 accurracy:  0.95532393\n",
      "Epoch:  6189 Loss:  0.58634853 accurracy:  0.9553258\n",
      "Epoch:  6190 Loss:  0.5863478 accurracy:  0.95532763\n",
      "Epoch:  6191 Loss:  0.58634734 accurracy:  0.9553295\n",
      "Epoch:  6192 Loss:  0.5863469 accurracy:  0.95533127\n",
      "Epoch:  6193 Loss:  0.58634657 accurracy:  0.9553331\n",
      "Epoch:  6194 Loss:  0.58634603 accurracy:  0.95533496\n",
      "Epoch:  6195 Loss:  0.58634555 accurracy:  0.95533675\n",
      "Epoch:  6196 Loss:  0.5863449 accurracy:  0.9553386\n",
      "Epoch:  6197 Loss:  0.5863443 accurracy:  0.95534045\n",
      "Epoch:  6198 Loss:  0.58634365 accurracy:  0.95534223\n",
      "Epoch:  6199 Loss:  0.5863434 accurracy:  0.9553441\n",
      "Epoch:  6200 Loss:  0.5863432 accurracy:  0.9553459\n",
      "Epoch:  6201 Loss:  0.58634263 accurracy:  0.9553477\n",
      "Epoch:  6202 Loss:  0.58634174 accurracy:  0.95534956\n",
      "Epoch:  6203 Loss:  0.5863411 accurracy:  0.9553514\n",
      "Epoch:  6204 Loss:  0.58634096 accurracy:  0.9553532\n",
      "Epoch:  6205 Loss:  0.58634084 accurracy:  0.95535505\n",
      "Epoch:  6206 Loss:  0.5863403 accurracy:  0.95535684\n",
      "Epoch:  6207 Loss:  0.5863394 accurracy:  0.9553587\n",
      "Epoch:  6208 Loss:  0.5863387 accurracy:  0.9553605\n",
      "Epoch:  6209 Loss:  0.5863383 accurracy:  0.9553623\n",
      "Epoch:  6210 Loss:  0.5863383 accurracy:  0.95536417\n",
      "Epoch:  6211 Loss:  0.5863379 accurracy:  0.95536596\n",
      "Epoch:  6212 Loss:  0.58633703 accurracy:  0.9553678\n",
      "Epoch:  6213 Loss:  0.58633626 accurracy:  0.9553696\n",
      "Epoch:  6214 Loss:  0.58633596 accurracy:  0.95537144\n",
      "Epoch:  6215 Loss:  0.5863359 accurracy:  0.9553732\n",
      "Epoch:  6216 Loss:  0.5863356 accurracy:  0.9553751\n",
      "Epoch:  6217 Loss:  0.58633476 accurracy:  0.95537686\n",
      "Epoch:  6218 Loss:  0.586334 accurracy:  0.95537865\n",
      "Epoch:  6219 Loss:  0.58633363 accurracy:  0.9553805\n",
      "Epoch:  6220 Loss:  0.58633333 accurracy:  0.9553823\n",
      "Epoch:  6221 Loss:  0.5863329 accurracy:  0.95538414\n",
      "Epoch:  6222 Loss:  0.5863323 accurracy:  0.9553859\n",
      "Epoch:  6223 Loss:  0.5863317 accurracy:  0.9553878\n",
      "Epoch:  6224 Loss:  0.5863312 accurracy:  0.95538956\n",
      "Epoch:  6225 Loss:  0.5863308 accurracy:  0.95539135\n",
      "Epoch:  6226 Loss:  0.5863304 accurracy:  0.9553932\n",
      "Epoch:  6227 Loss:  0.58633006 accurracy:  0.955395\n",
      "Epoch:  6228 Loss:  0.5863295 accurracy:  0.9553968\n",
      "Epoch:  6229 Loss:  0.58632886 accurracy:  0.9553986\n",
      "Epoch:  6230 Loss:  0.58632845 accurracy:  0.9554004\n",
      "Epoch:  6231 Loss:  0.58632797 accurracy:  0.9554022\n",
      "Epoch:  6232 Loss:  0.58632743 accurracy:  0.95540404\n",
      "Epoch:  6233 Loss:  0.5863269 accurracy:  0.95540583\n",
      "Epoch:  6234 Loss:  0.5863266 accurracy:  0.9554076\n",
      "Epoch:  6235 Loss:  0.58632606 accurracy:  0.95540947\n",
      "Epoch:  6236 Loss:  0.5863256 accurracy:  0.95541126\n",
      "Epoch:  6237 Loss:  0.58632493 accurracy:  0.95541304\n",
      "Epoch:  6238 Loss:  0.58632445 accurracy:  0.9554149\n",
      "Epoch:  6239 Loss:  0.58632404 accurracy:  0.9554167\n",
      "Epoch:  6240 Loss:  0.5863238 accurracy:  0.95541847\n",
      "Epoch:  6241 Loss:  0.5863233 accurracy:  0.95542026\n",
      "Epoch:  6242 Loss:  0.5863228 accurracy:  0.95542204\n",
      "Epoch:  6243 Loss:  0.586322 accurracy:  0.9554239\n",
      "Epoch:  6244 Loss:  0.58632153 accurracy:  0.9554257\n",
      "Epoch:  6245 Loss:  0.5863211 accurracy:  0.95542747\n",
      "Epoch:  6246 Loss:  0.58632094 accurracy:  0.95542926\n",
      "Epoch:  6247 Loss:  0.58632064 accurracy:  0.95543104\n",
      "Epoch:  6248 Loss:  0.5863199 accurracy:  0.9554329\n",
      "Epoch:  6249 Loss:  0.5863192 accurracy:  0.9554347\n",
      "Epoch:  6250 Loss:  0.58631873 accurracy:  0.95543647\n",
      "Epoch:  6251 Loss:  0.5863184 accurracy:  0.95543826\n",
      "Epoch:  6252 Loss:  0.586318 accurracy:  0.95544004\n",
      "Epoch:  6253 Loss:  0.5863175 accurracy:  0.95544183\n",
      "Epoch:  6254 Loss:  0.58631694 accurracy:  0.9554436\n",
      "Epoch:  6255 Loss:  0.58631635 accurracy:  0.95544547\n",
      "Epoch:  6256 Loss:  0.5863158 accurracy:  0.95544726\n",
      "Epoch:  6257 Loss:  0.5863154 accurracy:  0.95544904\n",
      "Epoch:  6258 Loss:  0.5863149 accurracy:  0.95545083\n",
      "Epoch:  6259 Loss:  0.5863145 accurracy:  0.9554526\n",
      "Epoch:  6260 Loss:  0.58631414 accurracy:  0.9554544\n",
      "Epoch:  6261 Loss:  0.58631366 accurracy:  0.9554562\n",
      "Epoch:  6262 Loss:  0.58631325 accurracy:  0.955458\n",
      "Epoch:  6263 Loss:  0.5863126 accurracy:  0.9554598\n",
      "Epoch:  6264 Loss:  0.586312 accurracy:  0.95546156\n",
      "Epoch:  6265 Loss:  0.5863116 accurracy:  0.95546335\n",
      "Epoch:  6266 Loss:  0.5863112 accurracy:  0.95546514\n",
      "Epoch:  6267 Loss:  0.5863107 accurracy:  0.9554669\n",
      "Epoch:  6268 Loss:  0.58631 accurracy:  0.9554687\n",
      "Epoch:  6269 Loss:  0.5863096 accurracy:  0.9554705\n",
      "Epoch:  6270 Loss:  0.58630943 accurracy:  0.9554723\n",
      "Epoch:  6271 Loss:  0.5863089 accurracy:  0.9554741\n",
      "Epoch:  6272 Loss:  0.5863083 accurracy:  0.95547587\n",
      "Epoch:  6273 Loss:  0.58630776 accurracy:  0.95547765\n",
      "Epoch:  6274 Loss:  0.5863074 accurracy:  0.95547944\n",
      "Epoch:  6275 Loss:  0.58630717 accurracy:  0.9554812\n",
      "Epoch:  6276 Loss:  0.5863067 accurracy:  0.95548296\n",
      "Epoch:  6277 Loss:  0.586306 accurracy:  0.95548475\n",
      "Epoch:  6278 Loss:  0.5863053 accurracy:  0.95548654\n",
      "Epoch:  6279 Loss:  0.58630484 accurracy:  0.9554883\n",
      "Epoch:  6280 Loss:  0.5863046 accurracy:  0.9554901\n",
      "Epoch:  6281 Loss:  0.5863041 accurracy:  0.9554919\n",
      "Epoch:  6282 Loss:  0.58630365 accurracy:  0.9554937\n",
      "Epoch:  6283 Loss:  0.586303 accurracy:  0.9554954\n",
      "Epoch:  6284 Loss:  0.5863025 accurracy:  0.9554972\n",
      "Epoch:  6285 Loss:  0.5863022 accurracy:  0.955499\n",
      "Epoch:  6286 Loss:  0.586302 accurracy:  0.9555008\n",
      "Epoch:  6287 Loss:  0.5863016 accurracy:  0.95550257\n",
      "Epoch:  6288 Loss:  0.58630085 accurracy:  0.9555043\n",
      "Epoch:  6289 Loss:  0.5863001 accurracy:  0.9555061\n",
      "Epoch:  6290 Loss:  0.58629966 accurracy:  0.9555079\n",
      "Epoch:  6291 Loss:  0.58629936 accurracy:  0.95550966\n",
      "Epoch:  6292 Loss:  0.58629894 accurracy:  0.9555114\n",
      "Epoch:  6293 Loss:  0.58629835 accurracy:  0.9555132\n",
      "Epoch:  6294 Loss:  0.58629787 accurracy:  0.95551497\n",
      "Epoch:  6295 Loss:  0.58629745 accurracy:  0.95551676\n",
      "Epoch:  6296 Loss:  0.5862971 accurracy:  0.9555185\n",
      "Epoch:  6297 Loss:  0.5862967 accurracy:  0.9555203\n",
      "Epoch:  6298 Loss:  0.58629626 accurracy:  0.95552206\n",
      "Epoch:  6299 Loss:  0.5862958 accurracy:  0.9555238\n",
      "Epoch:  6300 Loss:  0.5862951 accurracy:  0.9555256\n",
      "Epoch:  6301 Loss:  0.5862947 accurracy:  0.95552737\n",
      "Epoch:  6302 Loss:  0.5862943 accurracy:  0.9555291\n",
      "Epoch:  6303 Loss:  0.58629394 accurracy:  0.9555309\n",
      "Epoch:  6304 Loss:  0.5862932 accurracy:  0.95553267\n",
      "Epoch:  6305 Loss:  0.5862925 accurracy:  0.9555344\n",
      "Epoch:  6306 Loss:  0.58629215 accurracy:  0.9555362\n",
      "Epoch:  6307 Loss:  0.5862919 accurracy:  0.9555379\n",
      "Epoch:  6308 Loss:  0.5862916 accurracy:  0.9555397\n",
      "Epoch:  6309 Loss:  0.58629113 accurracy:  0.9555415\n",
      "Epoch:  6310 Loss:  0.5862904 accurracy:  0.9555432\n",
      "Epoch:  6311 Loss:  0.5862898 accurracy:  0.955545\n",
      "Epoch:  6312 Loss:  0.5862894 accurracy:  0.95554674\n",
      "Epoch:  6313 Loss:  0.5862892 accurracy:  0.9555485\n",
      "Epoch:  6314 Loss:  0.5862887 accurracy:  0.95555025\n",
      "Epoch:  6315 Loss:  0.5862881 accurracy:  0.95555204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  6316 Loss:  0.5862875 accurracy:  0.95555377\n",
      "Epoch:  6317 Loss:  0.5862869 accurracy:  0.95555556\n",
      "Epoch:  6318 Loss:  0.58628654 accurracy:  0.9555573\n",
      "Epoch:  6319 Loss:  0.5862862 accurracy:  0.9555591\n",
      "Epoch:  6320 Loss:  0.5862858 accurracy:  0.9555608\n",
      "Epoch:  6321 Loss:  0.58628535 accurracy:  0.9555626\n",
      "Epoch:  6322 Loss:  0.58628476 accurracy:  0.9555643\n",
      "Epoch:  6323 Loss:  0.5862842 accurracy:  0.9555661\n",
      "Epoch:  6324 Loss:  0.5862838 accurracy:  0.95556784\n",
      "Epoch:  6325 Loss:  0.5862836 accurracy:  0.9555696\n",
      "Epoch:  6326 Loss:  0.5862833 accurracy:  0.95557135\n",
      "Epoch:  6327 Loss:  0.5862826 accurracy:  0.95557314\n",
      "Epoch:  6328 Loss:  0.5862819 accurracy:  0.95557487\n",
      "Epoch:  6329 Loss:  0.5862815 accurracy:  0.9555766\n",
      "Epoch:  6330 Loss:  0.5862812 accurracy:  0.9555784\n",
      "Epoch:  6331 Loss:  0.5862807 accurracy:  0.9555801\n",
      "Epoch:  6332 Loss:  0.58628017 accurracy:  0.95558184\n",
      "Epoch:  6333 Loss:  0.5862795 accurracy:  0.95558363\n",
      "Epoch:  6334 Loss:  0.5862792 accurracy:  0.95558536\n",
      "Epoch:  6335 Loss:  0.5862791 accurracy:  0.95558715\n",
      "Epoch:  6336 Loss:  0.58627856 accurracy:  0.9555889\n",
      "Epoch:  6337 Loss:  0.5862777 accurracy:  0.9555906\n",
      "Epoch:  6338 Loss:  0.5862771 accurracy:  0.9555924\n",
      "Epoch:  6339 Loss:  0.58627695 accurracy:  0.9555941\n",
      "Epoch:  6340 Loss:  0.58627677 accurracy:  0.95559585\n",
      "Epoch:  6341 Loss:  0.5862763 accurracy:  0.9555976\n",
      "Epoch:  6342 Loss:  0.5862755 accurracy:  0.95559937\n",
      "Epoch:  6343 Loss:  0.5862748 accurracy:  0.9556011\n",
      "Epoch:  6344 Loss:  0.58627445 accurracy:  0.9556028\n",
      "Epoch:  6345 Loss:  0.5862743 accurracy:  0.95560455\n",
      "Epoch:  6346 Loss:  0.5862741 accurracy:  0.95560634\n",
      "Epoch:  6347 Loss:  0.5862734 accurracy:  0.95560807\n",
      "Epoch:  6348 Loss:  0.58627254 accurracy:  0.9556098\n",
      "Epoch:  6349 Loss:  0.5862721 accurracy:  0.9556115\n",
      "Epoch:  6350 Loss:  0.58627194 accurracy:  0.9556133\n",
      "Epoch:  6351 Loss:  0.58627194 accurracy:  0.95561504\n",
      "Epoch:  6352 Loss:  0.5862713 accurracy:  0.9556168\n",
      "Epoch:  6353 Loss:  0.58627045 accurracy:  0.9556185\n",
      "Epoch:  6354 Loss:  0.58627 accurracy:  0.9556202\n",
      "Epoch:  6355 Loss:  0.58626956 accurracy:  0.95562196\n",
      "Epoch:  6356 Loss:  0.5862692 accurracy:  0.95562375\n",
      "Epoch:  6357 Loss:  0.5862686 accurracy:  0.9556255\n",
      "Epoch:  6358 Loss:  0.586268 accurracy:  0.9556272\n",
      "Epoch:  6359 Loss:  0.5862676 accurracy:  0.95562893\n",
      "Epoch:  6360 Loss:  0.5862673 accurracy:  0.95563066\n",
      "Epoch:  6361 Loss:  0.58626693 accurracy:  0.9556324\n",
      "Epoch:  6362 Loss:  0.5862664 accurracy:  0.9556341\n",
      "Epoch:  6363 Loss:  0.5862657 accurracy:  0.95563585\n",
      "Epoch:  6364 Loss:  0.58626544 accurracy:  0.9556376\n",
      "Epoch:  6365 Loss:  0.58626497 accurracy:  0.95563936\n",
      "Epoch:  6366 Loss:  0.58626467 accurracy:  0.9556411\n",
      "Epoch:  6367 Loss:  0.5862642 accurracy:  0.9556428\n",
      "Epoch:  6368 Loss:  0.58626354 accurracy:  0.95564455\n",
      "Epoch:  6369 Loss:  0.586263 accurracy:  0.9556463\n",
      "Epoch:  6370 Loss:  0.58626264 accurracy:  0.955648\n",
      "Epoch:  6371 Loss:  0.58626235 accurracy:  0.95564973\n",
      "Epoch:  6372 Loss:  0.586262 accurracy:  0.95565146\n",
      "Epoch:  6373 Loss:  0.58626145 accurracy:  0.9556532\n",
      "Epoch:  6374 Loss:  0.5862608 accurracy:  0.9556549\n",
      "Epoch:  6375 Loss:  0.5862604 accurracy:  0.95565665\n",
      "Epoch:  6376 Loss:  0.5862601 accurracy:  0.9556584\n",
      "Epoch:  6377 Loss:  0.5862597 accurracy:  0.9556601\n",
      "Epoch:  6378 Loss:  0.5862591 accurracy:  0.95566183\n",
      "Epoch:  6379 Loss:  0.5862587 accurracy:  0.9556635\n",
      "Epoch:  6380 Loss:  0.5862582 accurracy:  0.95566523\n",
      "Epoch:  6381 Loss:  0.5862575 accurracy:  0.95566696\n",
      "Epoch:  6382 Loss:  0.58625686 accurracy:  0.9556687\n",
      "Epoch:  6383 Loss:  0.5862566 accurracy:  0.9556704\n",
      "Epoch:  6384 Loss:  0.5862564 accurracy:  0.95567214\n",
      "Epoch:  6385 Loss:  0.5862561 accurracy:  0.9556739\n",
      "Epoch:  6386 Loss:  0.5862555 accurracy:  0.9556756\n",
      "Epoch:  6387 Loss:  0.5862549 accurracy:  0.95567733\n",
      "Epoch:  6388 Loss:  0.58625424 accurracy:  0.95567906\n",
      "Epoch:  6389 Loss:  0.586254 accurracy:  0.9556807\n",
      "Epoch:  6390 Loss:  0.5862536 accurracy:  0.95568246\n",
      "Epoch:  6391 Loss:  0.58625335 accurracy:  0.9556842\n",
      "Epoch:  6392 Loss:  0.58625275 accurracy:  0.9556859\n",
      "Epoch:  6393 Loss:  0.5862521 accurracy:  0.95568764\n",
      "Epoch:  6394 Loss:  0.58625156 accurracy:  0.9556893\n",
      "Epoch:  6395 Loss:  0.5862512 accurracy:  0.95569104\n",
      "Epoch:  6396 Loss:  0.58625096 accurracy:  0.95569277\n",
      "Epoch:  6397 Loss:  0.5862504 accurracy:  0.9556945\n",
      "Epoch:  6398 Loss:  0.58624995 accurracy:  0.9556962\n",
      "Epoch:  6399 Loss:  0.5862493 accurracy:  0.9556979\n",
      "Epoch:  6400 Loss:  0.586249 accurracy:  0.9556996\n",
      "Epoch:  6401 Loss:  0.58624864 accurracy:  0.95570135\n",
      "Epoch:  6402 Loss:  0.58624816 accurracy:  0.9557031\n",
      "Epoch:  6403 Loss:  0.5862477 accurracy:  0.95570475\n",
      "Epoch:  6404 Loss:  0.5862474 accurracy:  0.9557065\n",
      "Epoch:  6405 Loss:  0.5862469 accurracy:  0.9557082\n",
      "Epoch:  6406 Loss:  0.58624625 accurracy:  0.9557099\n",
      "Epoch:  6407 Loss:  0.5862457 accurracy:  0.9557116\n",
      "Epoch:  6408 Loss:  0.58624524 accurracy:  0.95571333\n",
      "Epoch:  6409 Loss:  0.58624494 accurracy:  0.955715\n",
      "Epoch:  6410 Loss:  0.5862446 accurracy:  0.9557167\n",
      "Epoch:  6411 Loss:  0.58624405 accurracy:  0.95571846\n",
      "Epoch:  6412 Loss:  0.5862436 accurracy:  0.9557201\n",
      "Epoch:  6413 Loss:  0.5862433 accurracy:  0.95572186\n",
      "Epoch:  6414 Loss:  0.5862428 accurracy:  0.9557236\n",
      "Epoch:  6415 Loss:  0.5862424 accurracy:  0.95572525\n",
      "Epoch:  6416 Loss:  0.5862418 accurracy:  0.955727\n",
      "Epoch:  6417 Loss:  0.58624136 accurracy:  0.95572865\n",
      "Epoch:  6418 Loss:  0.58624095 accurracy:  0.9557304\n",
      "Epoch:  6419 Loss:  0.58624065 accurracy:  0.9557321\n",
      "Epoch:  6420 Loss:  0.5862401 accurracy:  0.9557338\n",
      "Epoch:  6421 Loss:  0.58623946 accurracy:  0.9557355\n",
      "Epoch:  6422 Loss:  0.58623886 accurracy:  0.9557372\n",
      "Epoch:  6423 Loss:  0.58623874 accurracy:  0.9557389\n",
      "Epoch:  6424 Loss:  0.5862385 accurracy:  0.9557406\n",
      "Epoch:  6425 Loss:  0.586238 accurracy:  0.9557423\n",
      "Epoch:  6426 Loss:  0.5862373 accurracy:  0.95574397\n",
      "Epoch:  6427 Loss:  0.58623683 accurracy:  0.9557457\n",
      "Epoch:  6428 Loss:  0.5862364 accurracy:  0.95574737\n",
      "Epoch:  6429 Loss:  0.5862362 accurracy:  0.9557491\n",
      "Epoch:  6430 Loss:  0.5862357 accurracy:  0.95575076\n",
      "Epoch:  6431 Loss:  0.58623517 accurracy:  0.9557525\n",
      "Epoch:  6432 Loss:  0.5862348 accurracy:  0.95575416\n",
      "Epoch:  6433 Loss:  0.58623415 accurracy:  0.9557559\n",
      "Epoch:  6434 Loss:  0.5862335 accurracy:  0.95575756\n",
      "Epoch:  6435 Loss:  0.5862329 accurracy:  0.9557593\n",
      "Epoch:  6436 Loss:  0.5862328 accurracy:  0.95576096\n",
      "Epoch:  6437 Loss:  0.5862325 accurracy:  0.9557627\n",
      "Epoch:  6438 Loss:  0.58623224 accurracy:  0.95576435\n",
      "Epoch:  6439 Loss:  0.5862315 accurracy:  0.955766\n",
      "Epoch:  6440 Loss:  0.586231 accurracy:  0.95576775\n",
      "Epoch:  6441 Loss:  0.5862307 accurracy:  0.9557694\n",
      "Epoch:  6442 Loss:  0.58623034 accurracy:  0.95577115\n",
      "Epoch:  6443 Loss:  0.58622986 accurracy:  0.9557728\n",
      "Epoch:  6444 Loss:  0.5862293 accurracy:  0.9557745\n",
      "Epoch:  6445 Loss:  0.58622897 accurracy:  0.9557762\n",
      "Epoch:  6446 Loss:  0.58622843 accurracy:  0.9557779\n",
      "Epoch:  6447 Loss:  0.5862281 accurracy:  0.95577955\n",
      "Epoch:  6448 Loss:  0.5862276 accurracy:  0.9557813\n",
      "Epoch:  6449 Loss:  0.58622706 accurracy:  0.95578295\n",
      "Epoch:  6450 Loss:  0.58622646 accurracy:  0.9557846\n",
      "Epoch:  6451 Loss:  0.58622587 accurracy:  0.95578635\n",
      "Epoch:  6452 Loss:  0.58622545 accurracy:  0.955788\n",
      "Epoch:  6453 Loss:  0.5862253 accurracy:  0.9557897\n",
      "Epoch:  6454 Loss:  0.5862249 accurracy:  0.95579135\n",
      "Epoch:  6455 Loss:  0.5862245 accurracy:  0.9557931\n",
      "Epoch:  6456 Loss:  0.5862239 accurracy:  0.95579475\n",
      "Epoch:  6457 Loss:  0.58622336 accurracy:  0.9557964\n",
      "Epoch:  6458 Loss:  0.5862228 accurracy:  0.9557981\n",
      "Epoch:  6459 Loss:  0.5862225 accurracy:  0.9557998\n",
      "Epoch:  6460 Loss:  0.58622223 accurracy:  0.9558015\n",
      "Epoch:  6461 Loss:  0.5862218 accurracy:  0.95580316\n",
      "Epoch:  6462 Loss:  0.58622116 accurracy:  0.9558048\n",
      "Epoch:  6463 Loss:  0.58622044 accurracy:  0.9558065\n",
      "Epoch:  6464 Loss:  0.5862199 accurracy:  0.9558082\n",
      "Epoch:  6465 Loss:  0.5862199 accurracy:  0.9558099\n",
      "Epoch:  6466 Loss:  0.58621967 accurracy:  0.95581156\n",
      "Epoch:  6467 Loss:  0.58621913 accurracy:  0.9558132\n",
      "Epoch:  6468 Loss:  0.58621854 accurracy:  0.9558149\n",
      "Epoch:  6469 Loss:  0.5862179 accurracy:  0.95581657\n",
      "Epoch:  6470 Loss:  0.58621764 accurracy:  0.9558183\n",
      "Epoch:  6471 Loss:  0.5862173 accurracy:  0.95581996\n",
      "Epoch:  6472 Loss:  0.58621687 accurracy:  0.95582163\n",
      "Epoch:  6473 Loss:  0.58621633 accurracy:  0.9558233\n",
      "Epoch:  6474 Loss:  0.5862159 accurracy:  0.955825\n",
      "Epoch:  6475 Loss:  0.58621544 accurracy:  0.95582664\n",
      "Epoch:  6476 Loss:  0.58621496 accurracy:  0.9558283\n",
      "Epoch:  6477 Loss:  0.5862146 accurracy:  0.95583\n",
      "Epoch:  6478 Loss:  0.5862143 accurracy:  0.95583165\n",
      "Epoch:  6479 Loss:  0.5862138 accurracy:  0.9558333\n",
      "Epoch:  6480 Loss:  0.58621323 accurracy:  0.955835\n",
      "Epoch:  6481 Loss:  0.58621275 accurracy:  0.95583665\n",
      "Epoch:  6482 Loss:  0.58621234 accurracy:  0.9558383\n",
      "Epoch:  6483 Loss:  0.5862121 accurracy:  0.95584\n",
      "Epoch:  6484 Loss:  0.58621174 accurracy:  0.95584166\n",
      "Epoch:  6485 Loss:  0.58621126 accurracy:  0.9558433\n",
      "Epoch:  6486 Loss:  0.5862106 accurracy:  0.955845\n",
      "Epoch:  6487 Loss:  0.5862102 accurracy:  0.95584667\n",
      "Epoch:  6488 Loss:  0.58620983 accurracy:  0.95584834\n",
      "Epoch:  6489 Loss:  0.58620936 accurracy:  0.95585\n",
      "Epoch:  6490 Loss:  0.58620864 accurracy:  0.9558517\n",
      "Epoch:  6491 Loss:  0.5862084 accurracy:  0.95585334\n",
      "Epoch:  6492 Loss:  0.5862082 accurracy:  0.955855\n",
      "Epoch:  6493 Loss:  0.5862078 accurracy:  0.9558567\n",
      "Epoch:  6494 Loss:  0.58620715 accurracy:  0.95585835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  6495 Loss:  0.58620656 accurracy:  0.95586\n",
      "Epoch:  6496 Loss:  0.5862062 accurracy:  0.9558617\n",
      "Epoch:  6497 Loss:  0.5862058 accurracy:  0.95586336\n",
      "Epoch:  6498 Loss:  0.5862056 accurracy:  0.955865\n",
      "Epoch:  6499 Loss:  0.5862053 accurracy:  0.9558667\n",
      "Epoch:  6500 Loss:  0.5862046 accurracy:  0.9558683\n",
      "Epoch:  6501 Loss:  0.5862039 accurracy:  0.95587\n",
      "Epoch:  6502 Loss:  0.5862037 accurracy:  0.95587164\n",
      "Epoch:  6503 Loss:  0.5862036 accurracy:  0.9558733\n",
      "Epoch:  6504 Loss:  0.58620316 accurracy:  0.955875\n",
      "Epoch:  6505 Loss:  0.5862025 accurracy:  0.95587665\n",
      "Epoch:  6506 Loss:  0.5862016 accurracy:  0.95587826\n",
      "Epoch:  6507 Loss:  0.5862011 accurracy:  0.9558799\n",
      "Epoch:  6508 Loss:  0.58620125 accurracy:  0.9558816\n",
      "Epoch:  6509 Loss:  0.5862011 accurracy:  0.95588326\n",
      "Epoch:  6510 Loss:  0.5862005 accurracy:  0.95588493\n",
      "Epoch:  6511 Loss:  0.5861997 accurracy:  0.95588654\n",
      "Epoch:  6512 Loss:  0.586199 accurracy:  0.9558882\n",
      "Epoch:  6513 Loss:  0.58619887 accurracy:  0.9558899\n",
      "Epoch:  6514 Loss:  0.5861987 accurracy:  0.95589155\n",
      "Epoch:  6515 Loss:  0.58619845 accurracy:  0.95589316\n",
      "Epoch:  6516 Loss:  0.5861979 accurracy:  0.9558948\n",
      "Epoch:  6517 Loss:  0.5861969 accurracy:  0.9558965\n",
      "Epoch:  6518 Loss:  0.58619606 accurracy:  0.95589817\n",
      "Epoch:  6519 Loss:  0.58619595 accurracy:  0.9558998\n",
      "Epoch:  6520 Loss:  0.58619606 accurracy:  0.95590144\n",
      "Epoch:  6521 Loss:  0.58619595 accurracy:  0.9559031\n",
      "Epoch:  6522 Loss:  0.5861952 accurracy:  0.9559047\n",
      "Epoch:  6523 Loss:  0.58619416 accurracy:  0.9559064\n",
      "Epoch:  6524 Loss:  0.5861937 accurracy:  0.95590806\n",
      "Epoch:  6525 Loss:  0.58619374 accurracy:  0.95590967\n",
      "Epoch:  6526 Loss:  0.5861936 accurracy:  0.95591134\n",
      "Epoch:  6527 Loss:  0.58619297 accurracy:  0.955913\n",
      "Epoch:  6528 Loss:  0.5861922 accurracy:  0.9559146\n",
      "Epoch:  6529 Loss:  0.5861915 accurracy:  0.9559163\n",
      "Epoch:  6530 Loss:  0.58619124 accurracy:  0.95591795\n",
      "Epoch:  6531 Loss:  0.5861913 accurracy:  0.95591956\n",
      "Epoch:  6532 Loss:  0.58619094 accurracy:  0.95592123\n",
      "Epoch:  6533 Loss:  0.58619 accurracy:  0.95592284\n",
      "Epoch:  6534 Loss:  0.5861892 accurracy:  0.9559245\n",
      "Epoch:  6535 Loss:  0.5861889 accurracy:  0.9559262\n",
      "Epoch:  6536 Loss:  0.58618903 accurracy:  0.9559278\n",
      "Epoch:  6537 Loss:  0.58618873 accurracy:  0.95592946\n",
      "Epoch:  6538 Loss:  0.58618814 accurracy:  0.95593107\n",
      "Epoch:  6539 Loss:  0.5861873 accurracy:  0.95593274\n",
      "Epoch:  6540 Loss:  0.58618677 accurracy:  0.95593435\n",
      "Epoch:  6541 Loss:  0.5861867 accurracy:  0.955936\n",
      "Epoch:  6542 Loss:  0.5861866 accurracy:  0.9559376\n",
      "Epoch:  6543 Loss:  0.586186 accurracy:  0.9559393\n",
      "Epoch:  6544 Loss:  0.5861853 accurracy:  0.9559409\n",
      "Epoch:  6545 Loss:  0.5861846 accurracy:  0.9559426\n",
      "Epoch:  6546 Loss:  0.58618444 accurracy:  0.9559442\n",
      "Epoch:  6547 Loss:  0.5861842 accurracy:  0.95594585\n",
      "Epoch:  6548 Loss:  0.58618367 accurracy:  0.95594746\n",
      "Epoch:  6549 Loss:  0.5861832 accurracy:  0.9559491\n",
      "Epoch:  6550 Loss:  0.5861827 accurracy:  0.95595074\n",
      "Epoch:  6551 Loss:  0.5861824 accurracy:  0.9559524\n",
      "Epoch:  6552 Loss:  0.586182 accurracy:  0.955954\n",
      "Epoch:  6553 Loss:  0.5861817 accurracy:  0.9559556\n",
      "Epoch:  6554 Loss:  0.5861811 accurracy:  0.9559573\n",
      "Epoch:  6555 Loss:  0.5861807 accurracy:  0.9559589\n",
      "Epoch:  6556 Loss:  0.5861804 accurracy:  0.9559606\n",
      "Epoch:  6557 Loss:  0.58618 accurracy:  0.9559622\n",
      "Epoch:  6558 Loss:  0.5861795 accurracy:  0.9559638\n",
      "Epoch:  6559 Loss:  0.5861789 accurracy:  0.95596546\n",
      "Epoch:  6560 Loss:  0.5861784 accurracy:  0.95596707\n",
      "Epoch:  6561 Loss:  0.586178 accurracy:  0.95596874\n",
      "Epoch:  6562 Loss:  0.5861778 accurracy:  0.95597035\n",
      "Epoch:  6563 Loss:  0.5861773 accurracy:  0.95597196\n",
      "Epoch:  6564 Loss:  0.5861768 accurracy:  0.9559736\n",
      "Epoch:  6565 Loss:  0.5861761 accurracy:  0.95597523\n",
      "Epoch:  6566 Loss:  0.5861758 accurracy:  0.95597684\n",
      "Epoch:  6567 Loss:  0.5861757 accurracy:  0.95597845\n",
      "Epoch:  6568 Loss:  0.5861754 accurracy:  0.9559801\n",
      "Epoch:  6569 Loss:  0.5861747 accurracy:  0.95598173\n",
      "Epoch:  6570 Loss:  0.58617413 accurracy:  0.95598334\n",
      "Epoch:  6571 Loss:  0.58617383 accurracy:  0.955985\n",
      "Epoch:  6572 Loss:  0.58617365 accurracy:  0.9559866\n",
      "Epoch:  6573 Loss:  0.58617324 accurracy:  0.9559882\n",
      "Epoch:  6574 Loss:  0.5861727 accurracy:  0.95598984\n",
      "Epoch:  6575 Loss:  0.58617216 accurracy:  0.9559915\n",
      "Epoch:  6576 Loss:  0.5861718 accurracy:  0.9559931\n",
      "Epoch:  6577 Loss:  0.5861712 accurracy:  0.9559947\n",
      "Epoch:  6578 Loss:  0.58617085 accurracy:  0.95599633\n",
      "Epoch:  6579 Loss:  0.58617043 accurracy:  0.95599794\n",
      "Epoch:  6580 Loss:  0.5861701 accurracy:  0.9559996\n",
      "Epoch:  6581 Loss:  0.58616966 accurracy:  0.9560012\n",
      "Epoch:  6582 Loss:  0.58616924 accurracy:  0.95600283\n",
      "Epoch:  6583 Loss:  0.5861689 accurracy:  0.95600444\n",
      "Epoch:  6584 Loss:  0.58616847 accurracy:  0.95600605\n",
      "Epoch:  6585 Loss:  0.58616805 accurracy:  0.9560077\n",
      "Epoch:  6586 Loss:  0.58616745 accurracy:  0.9560093\n",
      "Epoch:  6587 Loss:  0.58616716 accurracy:  0.95601094\n",
      "Epoch:  6588 Loss:  0.58616674 accurracy:  0.95601255\n",
      "Epoch:  6589 Loss:  0.5861664 accurracy:  0.95601416\n",
      "Epoch:  6590 Loss:  0.58616585 accurracy:  0.95601577\n",
      "Epoch:  6591 Loss:  0.58616525 accurracy:  0.9560174\n",
      "Epoch:  6592 Loss:  0.58616483 accurracy:  0.956019\n",
      "Epoch:  6593 Loss:  0.5861645 accurracy:  0.95602065\n",
      "Epoch:  6594 Loss:  0.5861642 accurracy:  0.95602226\n",
      "Epoch:  6595 Loss:  0.58616376 accurracy:  0.9560239\n",
      "Epoch:  6596 Loss:  0.5861632 accurracy:  0.9560255\n",
      "Epoch:  6597 Loss:  0.5861627 accurracy:  0.9560271\n",
      "Epoch:  6598 Loss:  0.5861624 accurracy:  0.9560287\n",
      "Epoch:  6599 Loss:  0.5861622 accurracy:  0.9560303\n",
      "Epoch:  6600 Loss:  0.5861618 accurracy:  0.9560319\n",
      "Epoch:  6601 Loss:  0.58616126 accurracy:  0.9560335\n",
      "Epoch:  6602 Loss:  0.58616066 accurracy:  0.95603514\n",
      "Epoch:  6603 Loss:  0.5861604 accurracy:  0.95603675\n",
      "Epoch:  6604 Loss:  0.5861603 accurracy:  0.95603836\n",
      "Epoch:  6605 Loss:  0.5861598 accurracy:  0.95603997\n",
      "Epoch:  6606 Loss:  0.5861589 accurracy:  0.9560416\n",
      "Epoch:  6607 Loss:  0.58615816 accurracy:  0.9560432\n",
      "Epoch:  6608 Loss:  0.586158 accurracy:  0.9560448\n",
      "Epoch:  6609 Loss:  0.5861578 accurracy:  0.9560464\n",
      "Epoch:  6610 Loss:  0.5861575 accurracy:  0.956048\n",
      "Epoch:  6611 Loss:  0.58615685 accurracy:  0.9560496\n",
      "Epoch:  6612 Loss:  0.58615595 accurracy:  0.95605123\n",
      "Epoch:  6613 Loss:  0.58615565 accurracy:  0.95605284\n",
      "Epoch:  6614 Loss:  0.5861556 accurracy:  0.95605445\n",
      "Epoch:  6615 Loss:  0.58615535 accurracy:  0.956056\n",
      "Epoch:  6616 Loss:  0.5861548 accurracy:  0.9560576\n",
      "Epoch:  6617 Loss:  0.5861543 accurracy:  0.9560592\n",
      "Epoch:  6618 Loss:  0.5861537 accurracy:  0.9560608\n",
      "Epoch:  6619 Loss:  0.58615327 accurracy:  0.95606244\n",
      "Epoch:  6620 Loss:  0.58615315 accurracy:  0.95606405\n",
      "Epoch:  6621 Loss:  0.58615303 accurracy:  0.95606565\n",
      "Epoch:  6622 Loss:  0.58615226 accurracy:  0.95606726\n",
      "Epoch:  6623 Loss:  0.58615136 accurracy:  0.9560688\n",
      "Epoch:  6624 Loss:  0.586151 accurracy:  0.9560704\n",
      "Epoch:  6625 Loss:  0.5861509 accurracy:  0.95607203\n",
      "Epoch:  6626 Loss:  0.5861507 accurracy:  0.95607364\n",
      "Epoch:  6627 Loss:  0.5861501 accurracy:  0.95607525\n",
      "Epoch:  6628 Loss:  0.58614933 accurracy:  0.95607686\n",
      "Epoch:  6629 Loss:  0.586149 accurracy:  0.9560784\n",
      "Epoch:  6630 Loss:  0.5861487 accurracy:  0.95608\n",
      "Epoch:  6631 Loss:  0.58614844 accurracy:  0.9560816\n",
      "Epoch:  6632 Loss:  0.5861481 accurracy:  0.95608324\n",
      "Epoch:  6633 Loss:  0.5861476 accurracy:  0.9560848\n",
      "Epoch:  6634 Loss:  0.5861472 accurracy:  0.9560864\n",
      "Epoch:  6635 Loss:  0.5861467 accurracy:  0.956088\n",
      "Epoch:  6636 Loss:  0.5861463 accurracy:  0.9560896\n",
      "Epoch:  6637 Loss:  0.5861461 accurracy:  0.95609117\n",
      "Epoch:  6638 Loss:  0.5861457 accurracy:  0.9560928\n",
      "Epoch:  6639 Loss:  0.58614504 accurracy:  0.9560944\n",
      "Epoch:  6640 Loss:  0.58614457 accurracy:  0.956096\n",
      "Epoch:  6641 Loss:  0.5861442 accurracy:  0.95609754\n",
      "Epoch:  6642 Loss:  0.58614385 accurracy:  0.95609915\n",
      "Epoch:  6643 Loss:  0.58614343 accurracy:  0.95610076\n",
      "Epoch:  6644 Loss:  0.5861427 accurracy:  0.9561023\n",
      "Epoch:  6645 Loss:  0.58614236 accurracy:  0.9561039\n",
      "Epoch:  6646 Loss:  0.5861421 accurracy:  0.95610553\n",
      "Epoch:  6647 Loss:  0.5861418 accurracy:  0.9561071\n",
      "Epoch:  6648 Loss:  0.58614147 accurracy:  0.9561087\n",
      "Epoch:  6649 Loss:  0.586141 accurracy:  0.9561103\n",
      "Epoch:  6650 Loss:  0.5861405 accurracy:  0.95611185\n",
      "Epoch:  6651 Loss:  0.58614004 accurracy:  0.95611346\n",
      "Epoch:  6652 Loss:  0.5861398 accurracy:  0.956115\n",
      "Epoch:  6653 Loss:  0.5861394 accurracy:  0.9561166\n",
      "Epoch:  6654 Loss:  0.5861388 accurracy:  0.9561182\n",
      "Epoch:  6655 Loss:  0.5861381 accurracy:  0.9561198\n",
      "Epoch:  6656 Loss:  0.58613783 accurracy:  0.9561214\n",
      "Epoch:  6657 Loss:  0.5861378 accurracy:  0.95612293\n",
      "Epoch:  6658 Loss:  0.58613753 accurracy:  0.95612454\n",
      "Epoch:  6659 Loss:  0.5861369 accurracy:  0.95612615\n",
      "Epoch:  6660 Loss:  0.5861361 accurracy:  0.9561277\n",
      "Epoch:  6661 Loss:  0.5861357 accurracy:  0.9561293\n",
      "Epoch:  6662 Loss:  0.5861355 accurracy:  0.95613086\n",
      "Epoch:  6663 Loss:  0.5861355 accurracy:  0.9561325\n",
      "Epoch:  6664 Loss:  0.586135 accurracy:  0.956134\n",
      "Epoch:  6665 Loss:  0.5861343 accurracy:  0.95613563\n",
      "Epoch:  6666 Loss:  0.5861337 accurracy:  0.9561372\n",
      "Epoch:  6667 Loss:  0.58613324 accurracy:  0.9561388\n",
      "Epoch:  6668 Loss:  0.58613324 accurracy:  0.95614034\n",
      "Epoch:  6669 Loss:  0.5861328 accurracy:  0.95614195\n",
      "Epoch:  6670 Loss:  0.58613217 accurracy:  0.9561435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  6671 Loss:  0.5861317 accurracy:  0.9561451\n",
      "Epoch:  6672 Loss:  0.5861312 accurracy:  0.95614666\n",
      "Epoch:  6673 Loss:  0.58613104 accurracy:  0.9561482\n",
      "Epoch:  6674 Loss:  0.58613086 accurracy:  0.9561498\n",
      "Epoch:  6675 Loss:  0.5861304 accurracy:  0.95615137\n",
      "Epoch:  6676 Loss:  0.5861299 accurracy:  0.956153\n",
      "Epoch:  6677 Loss:  0.5861293 accurracy:  0.9561545\n",
      "Epoch:  6678 Loss:  0.58612895 accurracy:  0.95615613\n",
      "Epoch:  6679 Loss:  0.5861286 accurracy:  0.9561577\n",
      "Epoch:  6680 Loss:  0.58612823 accurracy:  0.95615923\n",
      "Epoch:  6681 Loss:  0.5861278 accurracy:  0.95616084\n",
      "Epoch:  6682 Loss:  0.58612746 accurracy:  0.9561624\n",
      "Epoch:  6683 Loss:  0.5861271 accurracy:  0.956164\n",
      "Epoch:  6684 Loss:  0.5861265 accurracy:  0.95616555\n",
      "Epoch:  6685 Loss:  0.5861258 accurracy:  0.9561671\n",
      "Epoch:  6686 Loss:  0.58612543 accurracy:  0.9561687\n",
      "Epoch:  6687 Loss:  0.5861253 accurracy:  0.95617026\n",
      "Epoch:  6688 Loss:  0.5861251 accurracy:  0.9561718\n",
      "Epoch:  6689 Loss:  0.58612454 accurracy:  0.9561734\n",
      "Epoch:  6690 Loss:  0.58612406 accurracy:  0.95617497\n",
      "Epoch:  6691 Loss:  0.58612376 accurracy:  0.9561765\n",
      "Epoch:  6692 Loss:  0.5861234 accurracy:  0.95617807\n",
      "Epoch:  6693 Loss:  0.58612317 accurracy:  0.9561797\n",
      "Epoch:  6694 Loss:  0.5861225 accurracy:  0.9561812\n",
      "Epoch:  6695 Loss:  0.5861219 accurracy:  0.9561828\n",
      "Epoch:  6696 Loss:  0.5861214 accurracy:  0.9561844\n",
      "Epoch:  6697 Loss:  0.58612114 accurracy:  0.95618594\n",
      "Epoch:  6698 Loss:  0.5861209 accurracy:  0.9561875\n",
      "Epoch:  6699 Loss:  0.5861208 accurracy:  0.95618904\n",
      "Epoch:  6700 Loss:  0.58612 accurracy:  0.95619065\n",
      "Epoch:  6701 Loss:  0.58611935 accurracy:  0.9561922\n",
      "Epoch:  6702 Loss:  0.5861188 accurracy:  0.95619375\n",
      "Epoch:  6703 Loss:  0.5861187 accurracy:  0.9561953\n",
      "Epoch:  6704 Loss:  0.5861184 accurracy:  0.95619684\n",
      "Epoch:  6705 Loss:  0.5861178 accurracy:  0.95619845\n",
      "Epoch:  6706 Loss:  0.5861173 accurracy:  0.9562\n",
      "Epoch:  6707 Loss:  0.5861169 accurracy:  0.95620155\n",
      "Epoch:  6708 Loss:  0.58611673 accurracy:  0.9562031\n",
      "Epoch:  6709 Loss:  0.58611643 accurracy:  0.95620465\n",
      "Epoch:  6710 Loss:  0.5861158 accurracy:  0.9562062\n",
      "Epoch:  6711 Loss:  0.5861151 accurracy:  0.9562078\n",
      "Epoch:  6712 Loss:  0.58611494 accurracy:  0.95620936\n",
      "Epoch:  6713 Loss:  0.5861147 accurracy:  0.9562109\n",
      "Epoch:  6714 Loss:  0.58611417 accurracy:  0.95621246\n",
      "Epoch:  6715 Loss:  0.58611375 accurracy:  0.956214\n",
      "Epoch:  6716 Loss:  0.5861133 accurracy:  0.95621556\n",
      "Epoch:  6717 Loss:  0.58611286 accurracy:  0.9562171\n",
      "Epoch:  6718 Loss:  0.58611244 accurracy:  0.95621866\n",
      "Epoch:  6719 Loss:  0.58611196 accurracy:  0.9562202\n",
      "Epoch:  6720 Loss:  0.58611166 accurracy:  0.9562218\n",
      "Epoch:  6721 Loss:  0.5861114 accurracy:  0.95622337\n",
      "Epoch:  6722 Loss:  0.58611107 accurracy:  0.9562249\n",
      "Epoch:  6723 Loss:  0.5861105 accurracy:  0.95622647\n",
      "Epoch:  6724 Loss:  0.58610994 accurracy:  0.956228\n",
      "Epoch:  6725 Loss:  0.5861098 accurracy:  0.95622957\n",
      "Epoch:  6726 Loss:  0.5861097 accurracy:  0.9562311\n",
      "Epoch:  6727 Loss:  0.58610916 accurracy:  0.95623267\n",
      "Epoch:  6728 Loss:  0.5861085 accurracy:  0.9562342\n",
      "Epoch:  6729 Loss:  0.58610785 accurracy:  0.95623577\n",
      "Epoch:  6730 Loss:  0.5861077 accurracy:  0.9562373\n",
      "Epoch:  6731 Loss:  0.5861075 accurracy:  0.95623887\n",
      "Epoch:  6732 Loss:  0.58610713 accurracy:  0.9562404\n",
      "Epoch:  6733 Loss:  0.5861064 accurracy:  0.95624197\n",
      "Epoch:  6734 Loss:  0.58610594 accurracy:  0.9562435\n",
      "Epoch:  6735 Loss:  0.5861054 accurracy:  0.95624506\n",
      "Epoch:  6736 Loss:  0.58610517 accurracy:  0.9562466\n",
      "Epoch:  6737 Loss:  0.586105 accurracy:  0.95624816\n",
      "Epoch:  6738 Loss:  0.5861046 accurracy:  0.9562497\n",
      "Epoch:  6739 Loss:  0.5861041 accurracy:  0.95625126\n",
      "Epoch:  6740 Loss:  0.58610356 accurracy:  0.95625275\n",
      "Epoch:  6741 Loss:  0.5861034 accurracy:  0.9562543\n",
      "Epoch:  6742 Loss:  0.5861032 accurracy:  0.95625585\n",
      "Epoch:  6743 Loss:  0.58610266 accurracy:  0.9562574\n",
      "Epoch:  6744 Loss:  0.58610195 accurracy:  0.95625895\n",
      "Epoch:  6745 Loss:  0.58610153 accurracy:  0.9562605\n",
      "Epoch:  6746 Loss:  0.5861015 accurracy:  0.95626205\n",
      "Epoch:  6747 Loss:  0.5861013 accurracy:  0.9562636\n",
      "Epoch:  6748 Loss:  0.58610076 accurracy:  0.95626515\n",
      "Epoch:  6749 Loss:  0.58610004 accurracy:  0.95626664\n",
      "Epoch:  6750 Loss:  0.5860995 accurracy:  0.9562682\n",
      "Epoch:  6751 Loss:  0.5860993 accurracy:  0.95626974\n",
      "Epoch:  6752 Loss:  0.586099 accurracy:  0.9562713\n",
      "Epoch:  6753 Loss:  0.5860986 accurracy:  0.95627284\n",
      "Epoch:  6754 Loss:  0.586098 accurracy:  0.9562744\n",
      "Epoch:  6755 Loss:  0.5860975 accurracy:  0.9562759\n",
      "Epoch:  6756 Loss:  0.58609706 accurracy:  0.95627743\n",
      "Epoch:  6757 Loss:  0.58609694 accurracy:  0.956279\n",
      "Epoch:  6758 Loss:  0.5860968 accurracy:  0.9562805\n",
      "Epoch:  6759 Loss:  0.58609635 accurracy:  0.9562821\n",
      "Epoch:  6760 Loss:  0.5860956 accurracy:  0.95628357\n",
      "Epoch:  6761 Loss:  0.5860951 accurracy:  0.9562851\n",
      "Epoch:  6762 Loss:  0.5860949 accurracy:  0.95628667\n",
      "Epoch:  6763 Loss:  0.5860948 accurracy:  0.9562882\n",
      "Epoch:  6764 Loss:  0.58609456 accurracy:  0.9562897\n",
      "Epoch:  6765 Loss:  0.5860939 accurracy:  0.95629126\n",
      "Epoch:  6766 Loss:  0.5860931 accurracy:  0.9562928\n",
      "Epoch:  6767 Loss:  0.5860929 accurracy:  0.9562943\n",
      "Epoch:  6768 Loss:  0.58609253 accurracy:  0.95629585\n",
      "Epoch:  6769 Loss:  0.586092 accurracy:  0.9562974\n",
      "Epoch:  6770 Loss:  0.5860916 accurracy:  0.95629895\n",
      "Epoch:  6771 Loss:  0.5860912 accurracy:  0.95630044\n",
      "Epoch:  6772 Loss:  0.586091 accurracy:  0.956302\n",
      "Epoch:  6773 Loss:  0.5860906 accurracy:  0.95630354\n",
      "Epoch:  6774 Loss:  0.5860902 accurracy:  0.956305\n",
      "Epoch:  6775 Loss:  0.5860898 accurracy:  0.9563066\n",
      "Epoch:  6776 Loss:  0.5860892 accurracy:  0.9563081\n",
      "Epoch:  6777 Loss:  0.5860889 accurracy:  0.9563096\n",
      "Epoch:  6778 Loss:  0.58608854 accurracy:  0.95631117\n",
      "Epoch:  6779 Loss:  0.5860882 accurracy:  0.95631266\n",
      "Epoch:  6780 Loss:  0.5860878 accurracy:  0.9563142\n",
      "Epoch:  6781 Loss:  0.5860874 accurracy:  0.95631576\n",
      "Epoch:  6782 Loss:  0.58608705 accurracy:  0.95631725\n",
      "Epoch:  6783 Loss:  0.5860866 accurracy:  0.9563188\n",
      "Epoch:  6784 Loss:  0.58608615 accurracy:  0.9563203\n",
      "Epoch:  6785 Loss:  0.58608544 accurracy:  0.95632184\n",
      "Epoch:  6786 Loss:  0.58608514 accurracy:  0.9563234\n",
      "Epoch:  6787 Loss:  0.5860849 accurracy:  0.9563249\n",
      "Epoch:  6788 Loss:  0.5860846 accurracy:  0.9563264\n",
      "Epoch:  6789 Loss:  0.5860843 accurracy:  0.9563279\n",
      "Epoch:  6790 Loss:  0.5860837 accurracy:  0.95632946\n",
      "Epoch:  6791 Loss:  0.5860833 accurracy:  0.95633096\n",
      "Epoch:  6792 Loss:  0.586083 accurracy:  0.9563325\n",
      "Epoch:  6793 Loss:  0.5860826 accurracy:  0.956334\n",
      "Epoch:  6794 Loss:  0.58608234 accurracy:  0.95633554\n",
      "Epoch:  6795 Loss:  0.5860819 accurracy:  0.95633703\n",
      "Epoch:  6796 Loss:  0.58608145 accurracy:  0.9563386\n",
      "Epoch:  6797 Loss:  0.5860809 accurracy:  0.9563401\n",
      "Epoch:  6798 Loss:  0.5860807 accurracy:  0.9563416\n",
      "Epoch:  6799 Loss:  0.5860803 accurracy:  0.9563431\n",
      "Epoch:  6800 Loss:  0.58607996 accurracy:  0.95634466\n",
      "Epoch:  6801 Loss:  0.5860794 accurracy:  0.95634615\n",
      "Epoch:  6802 Loss:  0.58607894 accurracy:  0.9563477\n",
      "Epoch:  6803 Loss:  0.5860785 accurracy:  0.9563492\n",
      "Epoch:  6804 Loss:  0.5860784 accurracy:  0.95635074\n",
      "Epoch:  6805 Loss:  0.5860783 accurracy:  0.95635223\n",
      "Epoch:  6806 Loss:  0.5860776 accurracy:  0.9563537\n",
      "Epoch:  6807 Loss:  0.58607674 accurracy:  0.9563553\n",
      "Epoch:  6808 Loss:  0.5860764 accurracy:  0.95635676\n",
      "Epoch:  6809 Loss:  0.58607596 accurracy:  0.9563583\n",
      "Epoch:  6810 Loss:  0.58607596 accurracy:  0.9563598\n",
      "Epoch:  6811 Loss:  0.58607584 accurracy:  0.9563613\n",
      "Epoch:  6812 Loss:  0.5860752 accurracy:  0.95636284\n",
      "Epoch:  6813 Loss:  0.5860745 accurracy:  0.95636433\n",
      "Epoch:  6814 Loss:  0.5860739 accurracy:  0.9563659\n",
      "Epoch:  6815 Loss:  0.5860739 accurracy:  0.9563674\n",
      "Epoch:  6816 Loss:  0.58607376 accurracy:  0.95636886\n",
      "Epoch:  6817 Loss:  0.58607334 accurracy:  0.9563704\n",
      "Epoch:  6818 Loss:  0.5860728 accurracy:  0.9563719\n",
      "Epoch:  6819 Loss:  0.58607197 accurracy:  0.9563734\n",
      "Epoch:  6820 Loss:  0.58607155 accurracy:  0.95637494\n",
      "Epoch:  6821 Loss:  0.5860714 accurracy:  0.95637643\n",
      "Epoch:  6822 Loss:  0.5860713 accurracy:  0.9563779\n",
      "Epoch:  6823 Loss:  0.5860709 accurracy:  0.9563795\n",
      "Epoch:  6824 Loss:  0.5860703 accurracy:  0.95638096\n",
      "Epoch:  6825 Loss:  0.58606976 accurracy:  0.95638245\n",
      "Epoch:  6826 Loss:  0.5860692 accurracy:  0.95638394\n",
      "Epoch:  6827 Loss:  0.586069 accurracy:  0.9563855\n",
      "Epoch:  6828 Loss:  0.58606887 accurracy:  0.956387\n",
      "Epoch:  6829 Loss:  0.5860687 accurracy:  0.9563885\n",
      "Epoch:  6830 Loss:  0.58606803 accurracy:  0.95638996\n",
      "Epoch:  6831 Loss:  0.5860672 accurracy:  0.9563915\n",
      "Epoch:  6832 Loss:  0.58606666 accurracy:  0.956393\n",
      "Epoch:  6833 Loss:  0.58606654 accurracy:  0.9563945\n",
      "Epoch:  6834 Loss:  0.58606654 accurracy:  0.956396\n",
      "Epoch:  6835 Loss:  0.5860664 accurracy:  0.9563975\n",
      "Epoch:  6836 Loss:  0.58606553 accurracy:  0.956399\n",
      "Epoch:  6837 Loss:  0.58606464 accurracy:  0.9564005\n",
      "Epoch:  6838 Loss:  0.58606434 accurracy:  0.956402\n",
      "Epoch:  6839 Loss:  0.5860644 accurracy:  0.9564035\n",
      "Epoch:  6840 Loss:  0.5860644 accurracy:  0.956405\n",
      "Epoch:  6841 Loss:  0.5860639 accurracy:  0.95640653\n",
      "Epoch:  6842 Loss:  0.586063 accurracy:  0.956408\n",
      "Epoch:  6843 Loss:  0.5860625 accurracy:  0.9564095\n",
      "Epoch:  6844 Loss:  0.5860623 accurracy:  0.956411\n",
      "Epoch:  6845 Loss:  0.5860624 accurracy:  0.9564125\n",
      "Epoch:  6846 Loss:  0.58606184 accurracy:  0.956414\n",
      "Epoch:  6847 Loss:  0.5860611 accurracy:  0.9564155\n",
      "Epoch:  6848 Loss:  0.58606046 accurracy:  0.956417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  6849 Loss:  0.5860602 accurracy:  0.9564185\n",
      "Epoch:  6850 Loss:  0.58606017 accurracy:  0.95642\n",
      "Epoch:  6851 Loss:  0.58606 accurracy:  0.9564215\n",
      "Epoch:  6852 Loss:  0.58605945 accurracy:  0.956423\n",
      "Epoch:  6853 Loss:  0.5860588 accurracy:  0.9564245\n",
      "Epoch:  6854 Loss:  0.5860584 accurracy:  0.95642596\n",
      "Epoch:  6855 Loss:  0.5860579 accurracy:  0.95642745\n",
      "Epoch:  6856 Loss:  0.5860578 accurracy:  0.95642895\n",
      "Epoch:  6857 Loss:  0.5860575 accurracy:  0.95643044\n",
      "Epoch:  6858 Loss:  0.58605677 accurracy:  0.9564319\n",
      "Epoch:  6859 Loss:  0.5860565 accurracy:  0.9564334\n",
      "Epoch:  6860 Loss:  0.5860563 accurracy:  0.9564349\n",
      "Epoch:  6861 Loss:  0.5860558 accurracy:  0.9564364\n",
      "Epoch:  6862 Loss:  0.5860554 accurracy:  0.9564379\n",
      "Epoch:  6863 Loss:  0.5860549 accurracy:  0.9564394\n",
      "Epoch:  6864 Loss:  0.5860546 accurracy:  0.95644087\n",
      "Epoch:  6865 Loss:  0.58605415 accurracy:  0.95644236\n",
      "Epoch:  6866 Loss:  0.58605385 accurracy:  0.95644385\n",
      "Epoch:  6867 Loss:  0.5860535 accurracy:  0.95644534\n",
      "Epoch:  6868 Loss:  0.5860531 accurracy:  0.9564468\n",
      "Epoch:  6869 Loss:  0.58605283 accurracy:  0.9564483\n",
      "Epoch:  6870 Loss:  0.5860525 accurracy:  0.9564498\n",
      "Epoch:  6871 Loss:  0.58605194 accurracy:  0.9564513\n",
      "Epoch:  6872 Loss:  0.5860516 accurracy:  0.9564528\n",
      "Epoch:  6873 Loss:  0.58605117 accurracy:  0.9564543\n",
      "Epoch:  6874 Loss:  0.58605075 accurracy:  0.95645577\n",
      "Epoch:  6875 Loss:  0.5860502 accurracy:  0.95645726\n",
      "Epoch:  6876 Loss:  0.5860498 accurracy:  0.95645875\n",
      "Epoch:  6877 Loss:  0.5860495 accurracy:  0.95646024\n",
      "Epoch:  6878 Loss:  0.58604914 accurracy:  0.95646167\n",
      "Epoch:  6879 Loss:  0.58604884 accurracy:  0.95646316\n",
      "Epoch:  6880 Loss:  0.5860484 accurracy:  0.95646465\n",
      "Epoch:  6881 Loss:  0.5860481 accurracy:  0.95646614\n",
      "Epoch:  6882 Loss:  0.5860476 accurracy:  0.9564676\n",
      "Epoch:  6883 Loss:  0.5860471 accurracy:  0.9564691\n",
      "Epoch:  6884 Loss:  0.5860469 accurracy:  0.9564706\n",
      "Epoch:  6885 Loss:  0.58604676 accurracy:  0.95647204\n",
      "Epoch:  6886 Loss:  0.58604634 accurracy:  0.9564735\n",
      "Epoch:  6887 Loss:  0.5860458 accurracy:  0.956475\n",
      "Epoch:  6888 Loss:  0.5860453 accurracy:  0.9564765\n",
      "Epoch:  6889 Loss:  0.58604497 accurracy:  0.956478\n",
      "Epoch:  6890 Loss:  0.5860446 accurracy:  0.9564795\n",
      "Epoch:  6891 Loss:  0.58604425 accurracy:  0.9564809\n",
      "Epoch:  6892 Loss:  0.5860438 accurracy:  0.9564824\n",
      "Epoch:  6893 Loss:  0.5860433 accurracy:  0.9564839\n",
      "Epoch:  6894 Loss:  0.58604306 accurracy:  0.9564854\n",
      "Epoch:  6895 Loss:  0.58604264 accurracy:  0.9564869\n",
      "Epoch:  6896 Loss:  0.5860424 accurracy:  0.9564883\n",
      "Epoch:  6897 Loss:  0.58604205 accurracy:  0.9564898\n",
      "Epoch:  6898 Loss:  0.5860416 accurracy:  0.9564913\n",
      "Epoch:  6899 Loss:  0.5860414 accurracy:  0.9564928\n",
      "Epoch:  6900 Loss:  0.58604103 accurracy:  0.9564942\n",
      "Epoch:  6901 Loss:  0.5860405 accurracy:  0.9564957\n",
      "Epoch:  6902 Loss:  0.58603996 accurracy:  0.9564972\n",
      "Epoch:  6903 Loss:  0.5860397 accurracy:  0.9564986\n",
      "Epoch:  6904 Loss:  0.58603936 accurracy:  0.9565001\n",
      "Epoch:  6905 Loss:  0.5860391 accurracy:  0.9565016\n",
      "Epoch:  6906 Loss:  0.5860386 accurracy:  0.9565031\n",
      "Epoch:  6907 Loss:  0.58603805 accurracy:  0.9565045\n",
      "Epoch:  6908 Loss:  0.58603776 accurracy:  0.956506\n",
      "Epoch:  6909 Loss:  0.5860376 accurracy:  0.9565075\n",
      "Epoch:  6910 Loss:  0.586037 accurracy:  0.95650893\n",
      "Epoch:  6911 Loss:  0.5860363 accurracy:  0.9565104\n",
      "Epoch:  6912 Loss:  0.58603585 accurracy:  0.9565119\n",
      "Epoch:  6913 Loss:  0.5860358 accurracy:  0.95651335\n",
      "Epoch:  6914 Loss:  0.58603585 accurracy:  0.95651484\n",
      "Epoch:  6915 Loss:  0.58603543 accurracy:  0.95651627\n",
      "Epoch:  6916 Loss:  0.5860348 accurracy:  0.95651776\n",
      "Epoch:  6917 Loss:  0.58603424 accurracy:  0.95651925\n",
      "Epoch:  6918 Loss:  0.58603376 accurracy:  0.9565207\n",
      "Epoch:  6919 Loss:  0.5860335 accurracy:  0.95652217\n",
      "Epoch:  6920 Loss:  0.5860334 accurracy:  0.9565236\n",
      "Epoch:  6921 Loss:  0.5860331 accurracy:  0.9565251\n",
      "Epoch:  6922 Loss:  0.58603257 accurracy:  0.9565266\n",
      "Epoch:  6923 Loss:  0.586032 accurracy:  0.956528\n",
      "Epoch:  6924 Loss:  0.58603173 accurracy:  0.9565295\n",
      "Epoch:  6925 Loss:  0.5860315 accurracy:  0.9565309\n",
      "Epoch:  6926 Loss:  0.5860311 accurracy:  0.9565324\n",
      "Epoch:  6927 Loss:  0.5860307 accurracy:  0.95653385\n",
      "Epoch:  6928 Loss:  0.58603007 accurracy:  0.95653534\n",
      "Epoch:  6929 Loss:  0.5860294 accurracy:  0.95653677\n",
      "Epoch:  6930 Loss:  0.5860292 accurracy:  0.95653826\n",
      "Epoch:  6931 Loss:  0.5860292 accurracy:  0.9565397\n",
      "Epoch:  6932 Loss:  0.5860289 accurracy:  0.9565412\n",
      "Epoch:  6933 Loss:  0.5860283 accurracy:  0.9565426\n",
      "Epoch:  6934 Loss:  0.5860278 accurracy:  0.9565441\n",
      "Epoch:  6935 Loss:  0.58602726 accurracy:  0.95654553\n",
      "Epoch:  6936 Loss:  0.5860271 accurracy:  0.956547\n",
      "Epoch:  6937 Loss:  0.5860268 accurracy:  0.95654845\n",
      "Epoch:  6938 Loss:  0.5860265 accurracy:  0.95654994\n",
      "Epoch:  6939 Loss:  0.586026 accurracy:  0.9565514\n",
      "Epoch:  6940 Loss:  0.58602554 accurracy:  0.95655286\n",
      "Epoch:  6941 Loss:  0.58602524 accurracy:  0.9565543\n",
      "Epoch:  6942 Loss:  0.586025 accurracy:  0.9565558\n",
      "Epoch:  6943 Loss:  0.5860247 accurracy:  0.9565572\n",
      "Epoch:  6944 Loss:  0.58602434 accurracy:  0.9565587\n",
      "Epoch:  6945 Loss:  0.58602387 accurracy:  0.95656013\n",
      "Epoch:  6946 Loss:  0.58602357 accurracy:  0.95656157\n",
      "Epoch:  6947 Loss:  0.58602303 accurracy:  0.95656306\n",
      "Epoch:  6948 Loss:  0.5860224 accurracy:  0.9565645\n",
      "Epoch:  6949 Loss:  0.58602184 accurracy:  0.956566\n",
      "Epoch:  6950 Loss:  0.5860217 accurracy:  0.9565674\n",
      "Epoch:  6951 Loss:  0.58602166 accurracy:  0.95656884\n",
      "Epoch:  6952 Loss:  0.58602136 accurracy:  0.9565703\n",
      "Epoch:  6953 Loss:  0.58602065 accurracy:  0.95657176\n",
      "Epoch:  6954 Loss:  0.5860202 accurracy:  0.9565732\n",
      "Epoch:  6955 Loss:  0.5860199 accurracy:  0.9565747\n",
      "Epoch:  6956 Loss:  0.58601975 accurracy:  0.9565761\n",
      "Epoch:  6957 Loss:  0.58601946 accurracy:  0.95657754\n",
      "Epoch:  6958 Loss:  0.5860191 accurracy:  0.956579\n",
      "Epoch:  6959 Loss:  0.58601844 accurracy:  0.95658046\n",
      "Epoch:  6960 Loss:  0.58601785 accurracy:  0.9565819\n",
      "Epoch:  6961 Loss:  0.5860177 accurracy:  0.9565834\n",
      "Epoch:  6962 Loss:  0.5860176 accurracy:  0.9565848\n",
      "Epoch:  6963 Loss:  0.5860174 accurracy:  0.95658624\n",
      "Epoch:  6964 Loss:  0.5860167 accurracy:  0.9565877\n",
      "Epoch:  6965 Loss:  0.58601606 accurracy:  0.95658916\n",
      "Epoch:  6966 Loss:  0.58601576 accurracy:  0.9565906\n",
      "Epoch:  6967 Loss:  0.58601546 accurracy:  0.956592\n",
      "Epoch:  6968 Loss:  0.58601505 accurracy:  0.9565935\n",
      "Epoch:  6969 Loss:  0.58601457 accurracy:  0.95659494\n",
      "Epoch:  6970 Loss:  0.58601415 accurracy:  0.9565964\n",
      "Epoch:  6971 Loss:  0.5860138 accurracy:  0.9565978\n",
      "Epoch:  6972 Loss:  0.58601344 accurracy:  0.95659924\n",
      "Epoch:  6973 Loss:  0.5860132 accurracy:  0.9566007\n",
      "Epoch:  6974 Loss:  0.58601296 accurracy:  0.95660216\n",
      "Epoch:  6975 Loss:  0.5860124 accurracy:  0.9566036\n",
      "Epoch:  6976 Loss:  0.58601177 accurracy:  0.956605\n",
      "Epoch:  6977 Loss:  0.58601147 accurracy:  0.9566065\n",
      "Epoch:  6978 Loss:  0.5860113 accurracy:  0.95660794\n",
      "Epoch:  6979 Loss:  0.5860111 accurracy:  0.95660937\n",
      "Epoch:  6980 Loss:  0.5860107 accurracy:  0.9566108\n",
      "Epoch:  6981 Loss:  0.5860101 accurracy:  0.9566122\n",
      "Epoch:  6982 Loss:  0.58600974 accurracy:  0.95661366\n",
      "Epoch:  6983 Loss:  0.58600944 accurracy:  0.95661515\n",
      "Epoch:  6984 Loss:  0.5860093 accurracy:  0.9566166\n",
      "Epoch:  6985 Loss:  0.5860089 accurracy:  0.956618\n",
      "Epoch:  6986 Loss:  0.5860082 accurracy:  0.95661944\n",
      "Epoch:  6987 Loss:  0.5860074 accurracy:  0.9566209\n",
      "Epoch:  6988 Loss:  0.58600724 accurracy:  0.9566223\n",
      "Epoch:  6989 Loss:  0.58600736 accurracy:  0.95662373\n",
      "Epoch:  6990 Loss:  0.58600706 accurracy:  0.95662516\n",
      "Epoch:  6991 Loss:  0.5860064 accurracy:  0.9566266\n",
      "Epoch:  6992 Loss:  0.58600587 accurracy:  0.9566281\n",
      "Epoch:  6993 Loss:  0.58600545 accurracy:  0.9566295\n",
      "Epoch:  6994 Loss:  0.58600515 accurracy:  0.95663095\n",
      "Epoch:  6995 Loss:  0.5860051 accurracy:  0.9566324\n",
      "Epoch:  6996 Loss:  0.58600485 accurracy:  0.9566338\n",
      "Epoch:  6997 Loss:  0.58600426 accurracy:  0.95663524\n",
      "Epoch:  6998 Loss:  0.5860035 accurracy:  0.95663667\n",
      "Epoch:  6999 Loss:  0.586003 accurracy:  0.9566381\n",
      "Epoch:  7000 Loss:  0.586003 accurracy:  0.9566395\n",
      "Epoch:  7001 Loss:  0.586003 accurracy:  0.95664096\n",
      "Epoch:  7002 Loss:  0.5860026 accurracy:  0.9566424\n",
      "Epoch:  7003 Loss:  0.5860018 accurracy:  0.9566438\n",
      "Epoch:  7004 Loss:  0.5860013 accurracy:  0.95664525\n",
      "Epoch:  7005 Loss:  0.58600104 accurracy:  0.9566467\n",
      "Epoch:  7006 Loss:  0.5860011 accurracy:  0.9566481\n",
      "Epoch:  7007 Loss:  0.586001 accurracy:  0.95664954\n",
      "Epoch:  7008 Loss:  0.5860003 accurracy:  0.956651\n",
      "Epoch:  7009 Loss:  0.5859994 accurracy:  0.9566524\n",
      "Epoch:  7010 Loss:  0.58599895 accurracy:  0.95665383\n",
      "Epoch:  7011 Loss:  0.5859989 accurracy:  0.95665526\n",
      "Epoch:  7012 Loss:  0.58599913 accurracy:  0.9566567\n",
      "Epoch:  7013 Loss:  0.58599865 accurracy:  0.9566581\n",
      "Epoch:  7014 Loss:  0.5859977 accurracy:  0.95665956\n",
      "Epoch:  7015 Loss:  0.58599716 accurracy:  0.956661\n",
      "Epoch:  7016 Loss:  0.58599716 accurracy:  0.9566624\n",
      "Epoch:  7017 Loss:  0.58599705 accurracy:  0.9566638\n",
      "Epoch:  7018 Loss:  0.58599675 accurracy:  0.9566652\n",
      "Epoch:  7019 Loss:  0.58599627 accurracy:  0.95666665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  7020 Loss:  0.5859957 accurracy:  0.9566681\n",
      "Epoch:  7021 Loss:  0.58599514 accurracy:  0.9566695\n",
      "Epoch:  7022 Loss:  0.58599484 accurracy:  0.95667094\n",
      "Epoch:  7023 Loss:  0.5859948 accurracy:  0.9566724\n",
      "Epoch:  7024 Loss:  0.58599466 accurracy:  0.9566738\n",
      "Epoch:  7025 Loss:  0.58599406 accurracy:  0.95667523\n",
      "Epoch:  7026 Loss:  0.58599335 accurracy:  0.9566766\n",
      "Epoch:  7027 Loss:  0.5859928 accurracy:  0.95667803\n",
      "Epoch:  7028 Loss:  0.5859928 accurracy:  0.95667946\n",
      "Epoch:  7029 Loss:  0.5859928 accurracy:  0.9566809\n",
      "Epoch:  7030 Loss:  0.58599246 accurracy:  0.9566823\n",
      "Epoch:  7031 Loss:  0.5859919 accurracy:  0.95668375\n",
      "Epoch:  7032 Loss:  0.58599114 accurracy:  0.9566851\n",
      "Epoch:  7033 Loss:  0.5859907 accurracy:  0.95668656\n",
      "Epoch:  7034 Loss:  0.58599067 accurracy:  0.956688\n",
      "Epoch:  7035 Loss:  0.58599055 accurracy:  0.9566894\n",
      "Epoch:  7036 Loss:  0.58599013 accurracy:  0.95669085\n",
      "Epoch:  7037 Loss:  0.5859894 accurracy:  0.9566922\n",
      "Epoch:  7038 Loss:  0.5859889 accurracy:  0.95669365\n",
      "Epoch:  7039 Loss:  0.58598876 accurracy:  0.9566951\n",
      "Epoch:  7040 Loss:  0.5859887 accurracy:  0.9566965\n",
      "Epoch:  7041 Loss:  0.5859884 accurracy:  0.9566979\n",
      "Epoch:  7042 Loss:  0.585988 accurracy:  0.9566993\n",
      "Epoch:  7043 Loss:  0.5859873 accurracy:  0.95670074\n",
      "Epoch:  7044 Loss:  0.5859869 accurracy:  0.9567022\n",
      "Epoch:  7045 Loss:  0.58598673 accurracy:  0.95670354\n",
      "Epoch:  7046 Loss:  0.58598626 accurracy:  0.956705\n",
      "Epoch:  7047 Loss:  0.58598584 accurracy:  0.9567064\n",
      "Epoch:  7048 Loss:  0.5859854 accurracy:  0.95670784\n",
      "Epoch:  7049 Loss:  0.58598524 accurracy:  0.9567092\n",
      "Epoch:  7050 Loss:  0.58598495 accurracy:  0.95671064\n",
      "Epoch:  7051 Loss:  0.5859846 accurracy:  0.95671207\n",
      "Epoch:  7052 Loss:  0.58598405 accurracy:  0.95671344\n",
      "Epoch:  7053 Loss:  0.58598363 accurracy:  0.95671487\n",
      "Epoch:  7054 Loss:  0.58598334 accurracy:  0.9567163\n",
      "Epoch:  7055 Loss:  0.5859833 accurracy:  0.95671767\n",
      "Epoch:  7056 Loss:  0.5859829 accurracy:  0.9567191\n",
      "Epoch:  7057 Loss:  0.58598226 accurracy:  0.95672053\n",
      "Epoch:  7058 Loss:  0.58598167 accurracy:  0.9567219\n",
      "Epoch:  7059 Loss:  0.5859814 accurracy:  0.95672333\n",
      "Epoch:  7060 Loss:  0.58598125 accurracy:  0.9567247\n",
      "Epoch:  7061 Loss:  0.58598083 accurracy:  0.95672613\n",
      "Epoch:  7062 Loss:  0.58598053 accurracy:  0.95672756\n",
      "Epoch:  7063 Loss:  0.5859799 accurracy:  0.95672894\n",
      "Epoch:  7064 Loss:  0.5859794 accurracy:  0.95673037\n",
      "Epoch:  7065 Loss:  0.5859792 accurracy:  0.9567318\n",
      "Epoch:  7066 Loss:  0.5859791 accurracy:  0.95673317\n",
      "Epoch:  7067 Loss:  0.58597875 accurracy:  0.9567346\n",
      "Epoch:  7068 Loss:  0.5859782 accurracy:  0.95673597\n",
      "Epoch:  7069 Loss:  0.5859777 accurracy:  0.9567374\n",
      "Epoch:  7070 Loss:  0.5859773 accurracy:  0.95673877\n",
      "Epoch:  7071 Loss:  0.58597714 accurracy:  0.9567402\n",
      "Epoch:  7072 Loss:  0.58597684 accurracy:  0.9567416\n",
      "Epoch:  7073 Loss:  0.58597654 accurracy:  0.956743\n",
      "Epoch:  7074 Loss:  0.5859762 accurracy:  0.95674443\n",
      "Epoch:  7075 Loss:  0.58597565 accurracy:  0.9567458\n",
      "Epoch:  7076 Loss:  0.5859753 accurracy:  0.95674723\n",
      "Epoch:  7077 Loss:  0.585975 accurracy:  0.9567486\n",
      "Epoch:  7078 Loss:  0.58597463 accurracy:  0.95675004\n",
      "Epoch:  7079 Loss:  0.5859743 accurracy:  0.9567514\n",
      "Epoch:  7080 Loss:  0.5859739 accurracy:  0.95675284\n",
      "Epoch:  7081 Loss:  0.58597344 accurracy:  0.9567542\n",
      "Epoch:  7082 Loss:  0.58597296 accurracy:  0.95675564\n",
      "Epoch:  7083 Loss:  0.5859727 accurracy:  0.956757\n",
      "Epoch:  7084 Loss:  0.5859726 accurracy:  0.95675844\n",
      "Epoch:  7085 Loss:  0.5859722 accurracy:  0.9567598\n",
      "Epoch:  7086 Loss:  0.5859718 accurracy:  0.9567612\n",
      "Epoch:  7087 Loss:  0.5859714 accurracy:  0.9567626\n",
      "Epoch:  7088 Loss:  0.585971 accurracy:  0.956764\n",
      "Epoch:  7089 Loss:  0.58597046 accurracy:  0.9567654\n",
      "Epoch:  7090 Loss:  0.58597 accurracy:  0.9567668\n",
      "Epoch:  7091 Loss:  0.5859697 accurracy:  0.9567682\n",
      "Epoch:  7092 Loss:  0.58596957 accurracy:  0.9567696\n",
      "Epoch:  7093 Loss:  0.58596927 accurracy:  0.95677096\n",
      "Epoch:  7094 Loss:  0.5859689 accurracy:  0.9567724\n",
      "Epoch:  7095 Loss:  0.58596826 accurracy:  0.95677376\n",
      "Epoch:  7096 Loss:  0.58596784 accurracy:  0.9567752\n",
      "Epoch:  7097 Loss:  0.5859678 accurracy:  0.95677656\n",
      "Epoch:  7098 Loss:  0.5859678 accurracy:  0.95677793\n",
      "Epoch:  7099 Loss:  0.58596724 accurracy:  0.95677936\n",
      "Epoch:  7100 Loss:  0.5859667 accurracy:  0.95678073\n",
      "Epoch:  7101 Loss:  0.5859661 accurracy:  0.9567821\n",
      "Epoch:  7102 Loss:  0.5859659 accurracy:  0.95678353\n",
      "Epoch:  7103 Loss:  0.58596575 accurracy:  0.9567849\n",
      "Epoch:  7104 Loss:  0.58596545 accurracy:  0.9567863\n",
      "Epoch:  7105 Loss:  0.5859651 accurracy:  0.9567877\n",
      "Epoch:  7106 Loss:  0.58596444 accurracy:  0.9567891\n",
      "Epoch:  7107 Loss:  0.5859641 accurracy:  0.95679045\n",
      "Epoch:  7108 Loss:  0.5859638 accurracy:  0.9567919\n",
      "Epoch:  7109 Loss:  0.5859635 accurracy:  0.95679325\n",
      "Epoch:  7110 Loss:  0.58596325 accurracy:  0.9567946\n",
      "Epoch:  7111 Loss:  0.58596265 accurracy:  0.95679605\n",
      "Epoch:  7112 Loss:  0.5859623 accurracy:  0.9567974\n",
      "Epoch:  7113 Loss:  0.5859621 accurracy:  0.9567988\n",
      "Epoch:  7114 Loss:  0.58596176 accurracy:  0.95680016\n",
      "Epoch:  7115 Loss:  0.58596146 accurracy:  0.9568016\n",
      "Epoch:  7116 Loss:  0.5859609 accurracy:  0.95680296\n",
      "Epoch:  7117 Loss:  0.58596045 accurracy:  0.95680434\n",
      "Epoch:  7118 Loss:  0.5859604 accurracy:  0.9568057\n",
      "Epoch:  7119 Loss:  0.58596015 accurracy:  0.95680714\n",
      "Epoch:  7120 Loss:  0.5859598 accurracy:  0.9568085\n",
      "Epoch:  7121 Loss:  0.5859594 accurracy:  0.9568099\n",
      "Epoch:  7122 Loss:  0.5859589 accurracy:  0.95681125\n",
      "Epoch:  7123 Loss:  0.5859586 accurracy:  0.9568127\n",
      "Epoch:  7124 Loss:  0.58595824 accurracy:  0.95681405\n",
      "Epoch:  7125 Loss:  0.58595794 accurracy:  0.9568154\n",
      "Epoch:  7126 Loss:  0.5859576 accurracy:  0.9568168\n",
      "Epoch:  7127 Loss:  0.585957 accurracy:  0.95681816\n",
      "Epoch:  7128 Loss:  0.5859566 accurracy:  0.95681953\n",
      "Epoch:  7129 Loss:  0.58595634 accurracy:  0.95682096\n",
      "Epoch:  7130 Loss:  0.5859562 accurracy:  0.95682234\n",
      "Epoch:  7131 Loss:  0.5859559 accurracy:  0.9568237\n",
      "Epoch:  7132 Loss:  0.5859552 accurracy:  0.9568251\n",
      "Epoch:  7133 Loss:  0.5859546 accurracy:  0.95682645\n",
      "Epoch:  7134 Loss:  0.5859545 accurracy:  0.9568278\n",
      "Epoch:  7135 Loss:  0.5859543 accurracy:  0.95682925\n",
      "Epoch:  7136 Loss:  0.58595407 accurracy:  0.9568306\n",
      "Epoch:  7137 Loss:  0.5859536 accurracy:  0.956832\n",
      "Epoch:  7138 Loss:  0.5859531 accurracy:  0.95683336\n",
      "Epoch:  7139 Loss:  0.5859527 accurracy:  0.95683473\n",
      "Epoch:  7140 Loss:  0.5859524 accurracy:  0.9568361\n",
      "Epoch:  7141 Loss:  0.5859524 accurracy:  0.9568375\n",
      "Epoch:  7142 Loss:  0.5859521 accurracy:  0.95683885\n",
      "Epoch:  7143 Loss:  0.58595157 accurracy:  0.9568402\n",
      "Epoch:  7144 Loss:  0.5859511 accurracy:  0.9568416\n",
      "Epoch:  7145 Loss:  0.58595073 accurracy:  0.956843\n",
      "Epoch:  7146 Loss:  0.5859506 accurracy:  0.9568444\n",
      "Epoch:  7147 Loss:  0.5859505 accurracy:  0.95684576\n",
      "Epoch:  7148 Loss:  0.58594996 accurracy:  0.95684713\n",
      "Epoch:  7149 Loss:  0.58594936 accurracy:  0.9568485\n",
      "Epoch:  7150 Loss:  0.58594906 accurracy:  0.9568499\n",
      "Epoch:  7151 Loss:  0.5859488 accurracy:  0.95685124\n",
      "Epoch:  7152 Loss:  0.5859483 accurracy:  0.9568526\n",
      "Epoch:  7153 Loss:  0.5859478 accurracy:  0.956854\n",
      "Epoch:  7154 Loss:  0.5859474 accurracy:  0.95685536\n",
      "Epoch:  7155 Loss:  0.5859471 accurracy:  0.9568567\n",
      "Epoch:  7156 Loss:  0.58594704 accurracy:  0.9568581\n",
      "Epoch:  7157 Loss:  0.58594674 accurracy:  0.95685947\n",
      "Epoch:  7158 Loss:  0.58594626 accurracy:  0.95686084\n",
      "Epoch:  7159 Loss:  0.5859457 accurracy:  0.9568622\n",
      "Epoch:  7160 Loss:  0.5859454 accurracy:  0.9568636\n",
      "Epoch:  7161 Loss:  0.58594525 accurracy:  0.95686495\n",
      "Epoch:  7162 Loss:  0.585945 accurracy:  0.9568663\n",
      "Epoch:  7163 Loss:  0.5859447 accurracy:  0.9568677\n",
      "Epoch:  7164 Loss:  0.58594406 accurracy:  0.95686907\n",
      "Epoch:  7165 Loss:  0.5859438 accurracy:  0.9568704\n",
      "Epoch:  7166 Loss:  0.5859435 accurracy:  0.95687175\n",
      "Epoch:  7167 Loss:  0.5859432 accurracy:  0.9568731\n",
      "Epoch:  7168 Loss:  0.5859428 accurracy:  0.9568745\n",
      "Epoch:  7169 Loss:  0.5859425 accurracy:  0.95687586\n",
      "Epoch:  7170 Loss:  0.5859422 accurracy:  0.95687723\n",
      "Epoch:  7171 Loss:  0.58594173 accurracy:  0.9568786\n",
      "Epoch:  7172 Loss:  0.5859413 accurracy:  0.95688\n",
      "Epoch:  7173 Loss:  0.5859411 accurracy:  0.95688134\n",
      "Epoch:  7174 Loss:  0.5859408 accurracy:  0.9568827\n",
      "Epoch:  7175 Loss:  0.5859402 accurracy:  0.9568841\n",
      "Epoch:  7176 Loss:  0.5859395 accurracy:  0.9568854\n",
      "Epoch:  7177 Loss:  0.5859393 accurracy:  0.95688677\n",
      "Epoch:  7178 Loss:  0.5859393 accurracy:  0.95688814\n",
      "Epoch:  7179 Loss:  0.5859393 accurracy:  0.9568895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  7180 Loss:  0.5859387 accurracy:  0.9568909\n",
      "Epoch:  7181 Loss:  0.58593786 accurracy:  0.95689225\n",
      "Epoch:  7182 Loss:  0.58593756 accurracy:  0.95689356\n",
      "Epoch:  7183 Loss:  0.5859375 accurracy:  0.95689493\n",
      "Epoch:  7184 Loss:  0.5859374 accurracy:  0.9568963\n",
      "Epoch:  7185 Loss:  0.58593714 accurracy:  0.9568977\n",
      "Epoch:  7186 Loss:  0.5859366 accurracy:  0.95689905\n",
      "Epoch:  7187 Loss:  0.5859362 accurracy:  0.9569004\n",
      "Epoch:  7188 Loss:  0.5859357 accurracy:  0.9569017\n",
      "Epoch:  7189 Loss:  0.5859355 accurracy:  0.9569031\n",
      "Epoch:  7190 Loss:  0.58593524 accurracy:  0.9569045\n",
      "Epoch:  7191 Loss:  0.5859349 accurracy:  0.95690584\n",
      "Epoch:  7192 Loss:  0.58593446 accurracy:  0.95690715\n",
      "Epoch:  7193 Loss:  0.5859342 accurracy:  0.9569085\n",
      "Epoch:  7194 Loss:  0.58593374 accurracy:  0.9569099\n",
      "Epoch:  7195 Loss:  0.58593345 accurracy:  0.95691127\n",
      "Epoch:  7196 Loss:  0.58593297 accurracy:  0.9569126\n",
      "Epoch:  7197 Loss:  0.5859324 accurracy:  0.95691395\n",
      "Epoch:  7198 Loss:  0.58593214 accurracy:  0.9569153\n",
      "Epoch:  7199 Loss:  0.585932 accurracy:  0.9569167\n",
      "Epoch:  7200 Loss:  0.5859318 accurracy:  0.956918\n",
      "Epoch:  7201 Loss:  0.5859314 accurracy:  0.9569194\n",
      "Epoch:  7202 Loss:  0.5859307 accurracy:  0.95692074\n",
      "Epoch:  7203 Loss:  0.5859304 accurracy:  0.95692205\n",
      "Epoch:  7204 Loss:  0.5859302 accurracy:  0.9569234\n",
      "Epoch:  7205 Loss:  0.5859301 accurracy:  0.9569248\n",
      "Epoch:  7206 Loss:  0.5859296 accurracy:  0.9569261\n",
      "Epoch:  7207 Loss:  0.585929 accurracy:  0.9569275\n",
      "Epoch:  7208 Loss:  0.5859286 accurracy:  0.95692885\n",
      "Epoch:  7209 Loss:  0.5859287 accurracy:  0.95693016\n",
      "Epoch:  7210 Loss:  0.58592856 accurracy:  0.95693153\n",
      "Epoch:  7211 Loss:  0.58592796 accurracy:  0.9569329\n",
      "Epoch:  7212 Loss:  0.5859272 accurracy:  0.9569342\n",
      "Epoch:  7213 Loss:  0.58592695 accurracy:  0.9569356\n",
      "Epoch:  7214 Loss:  0.58592695 accurracy:  0.95693696\n",
      "Epoch:  7215 Loss:  0.58592683 accurracy:  0.95693827\n",
      "Epoch:  7216 Loss:  0.58592635 accurracy:  0.95693964\n",
      "Epoch:  7217 Loss:  0.5859259 accurracy:  0.956941\n",
      "Epoch:  7218 Loss:  0.58592546 accurracy:  0.9569423\n",
      "Epoch:  7219 Loss:  0.5859249 accurracy:  0.9569437\n",
      "Epoch:  7220 Loss:  0.5859245 accurracy:  0.956945\n",
      "Epoch:  7221 Loss:  0.58592415 accurracy:  0.9569464\n",
      "Epoch:  7222 Loss:  0.5859241 accurracy:  0.9569477\n",
      "Epoch:  7223 Loss:  0.5859238 accurracy:  0.95694906\n",
      "Epoch:  7224 Loss:  0.5859234 accurracy:  0.9569504\n",
      "Epoch:  7225 Loss:  0.5859229 accurracy:  0.95695174\n",
      "Epoch:  7226 Loss:  0.5859224 accurracy:  0.9569531\n",
      "Epoch:  7227 Loss:  0.58592206 accurracy:  0.9569544\n",
      "Epoch:  7228 Loss:  0.58592206 accurracy:  0.9569558\n",
      "Epoch:  7229 Loss:  0.58592165 accurracy:  0.9569571\n",
      "Epoch:  7230 Loss:  0.5859211 accurracy:  0.9569585\n",
      "Epoch:  7231 Loss:  0.5859209 accurracy:  0.9569598\n",
      "Epoch:  7232 Loss:  0.58592063 accurracy:  0.95696115\n",
      "Epoch:  7233 Loss:  0.5859204 accurracy:  0.95696247\n",
      "Epoch:  7234 Loss:  0.5859198 accurracy:  0.95696384\n",
      "Epoch:  7235 Loss:  0.5859194 accurracy:  0.95696515\n",
      "Epoch:  7236 Loss:  0.5859191 accurracy:  0.9569665\n",
      "Epoch:  7237 Loss:  0.58591896 accurracy:  0.95696783\n",
      "Epoch:  7238 Loss:  0.5859187 accurracy:  0.9569692\n",
      "Epoch:  7239 Loss:  0.58591825 accurracy:  0.9569705\n",
      "Epoch:  7240 Loss:  0.58591783 accurracy:  0.9569719\n",
      "Epoch:  7241 Loss:  0.58591765 accurracy:  0.9569732\n",
      "Epoch:  7242 Loss:  0.5859173 accurracy:  0.95697457\n",
      "Epoch:  7243 Loss:  0.5859166 accurracy:  0.9569759\n",
      "Epoch:  7244 Loss:  0.58591616 accurracy:  0.95697725\n",
      "Epoch:  7245 Loss:  0.5859162 accurracy:  0.95697856\n",
      "Epoch:  7246 Loss:  0.58591616 accurracy:  0.9569799\n",
      "Epoch:  7247 Loss:  0.5859157 accurracy:  0.95698124\n",
      "Epoch:  7248 Loss:  0.58591497 accurracy:  0.95698255\n",
      "Epoch:  7249 Loss:  0.5859145 accurracy:  0.9569839\n",
      "Epoch:  7250 Loss:  0.5859144 accurracy:  0.95698524\n",
      "Epoch:  7251 Loss:  0.58591425 accurracy:  0.9569866\n",
      "Epoch:  7252 Loss:  0.58591396 accurracy:  0.9569879\n",
      "Epoch:  7253 Loss:  0.5859136 accurracy:  0.9569892\n",
      "Epoch:  7254 Loss:  0.5859131 accurracy:  0.9569906\n",
      "Epoch:  7255 Loss:  0.5859128 accurracy:  0.9569919\n",
      "Epoch:  7256 Loss:  0.5859126 accurracy:  0.9569932\n",
      "Epoch:  7257 Loss:  0.58591217 accurracy:  0.9569946\n",
      "Epoch:  7258 Loss:  0.5859116 accurracy:  0.9569959\n",
      "Epoch:  7259 Loss:  0.5859112 accurracy:  0.9569972\n",
      "Epoch:  7260 Loss:  0.58591115 accurracy:  0.9569986\n",
      "Epoch:  7261 Loss:  0.5859111 accurracy:  0.9569999\n",
      "Epoch:  7262 Loss:  0.58591074 accurracy:  0.95700127\n",
      "Epoch:  7263 Loss:  0.58591 accurracy:  0.9570026\n",
      "Epoch:  7264 Loss:  0.58590966 accurracy:  0.9570039\n",
      "Epoch:  7265 Loss:  0.5859094 accurracy:  0.9570052\n",
      "Epoch:  7266 Loss:  0.585909 accurracy:  0.9570066\n",
      "Epoch:  7267 Loss:  0.5859086 accurracy:  0.9570079\n",
      "Epoch:  7268 Loss:  0.58590823 accurracy:  0.9570092\n",
      "Epoch:  7269 Loss:  0.5859081 accurracy:  0.95701057\n",
      "Epoch:  7270 Loss:  0.58590776 accurracy:  0.9570119\n",
      "Epoch:  7271 Loss:  0.58590734 accurracy:  0.9570132\n",
      "Epoch:  7272 Loss:  0.58590704 accurracy:  0.9570145\n",
      "Epoch:  7273 Loss:  0.5859066 accurracy:  0.9570159\n",
      "Epoch:  7274 Loss:  0.5859062 accurracy:  0.9570172\n",
      "Epoch:  7275 Loss:  0.58590597 accurracy:  0.9570185\n",
      "Epoch:  7276 Loss:  0.5859058 accurracy:  0.9570198\n",
      "Epoch:  7277 Loss:  0.58590543 accurracy:  0.9570212\n",
      "Epoch:  7278 Loss:  0.5859051 accurracy:  0.9570225\n",
      "Epoch:  7279 Loss:  0.5859047 accurracy:  0.9570238\n",
      "Epoch:  7280 Loss:  0.5859044 accurracy:  0.9570251\n",
      "Epoch:  7281 Loss:  0.58590394 accurracy:  0.9570265\n",
      "Epoch:  7282 Loss:  0.5859037 accurracy:  0.9570278\n",
      "Epoch:  7283 Loss:  0.5859034 accurracy:  0.9570291\n",
      "Epoch:  7284 Loss:  0.58590305 accurracy:  0.9570304\n",
      "Epoch:  7285 Loss:  0.58590263 accurracy:  0.9570317\n",
      "Epoch:  7286 Loss:  0.58590233 accurracy:  0.9570331\n",
      "Epoch:  7287 Loss:  0.58590215 accurracy:  0.9570344\n",
      "Epoch:  7288 Loss:  0.5859019 accurracy:  0.9570357\n",
      "Epoch:  7289 Loss:  0.5859013 accurracy:  0.95703703\n",
      "Epoch:  7290 Loss:  0.5859007 accurracy:  0.95703834\n",
      "Epoch:  7291 Loss:  0.58590037 accurracy:  0.95703965\n",
      "Epoch:  7292 Loss:  0.5859003 accurracy:  0.957041\n",
      "Epoch:  7293 Loss:  0.58590025 accurracy:  0.95704234\n",
      "Epoch:  7294 Loss:  0.5858999 accurracy:  0.95704365\n",
      "Epoch:  7295 Loss:  0.58589923 accurracy:  0.95704496\n",
      "Epoch:  7296 Loss:  0.5858987 accurracy:  0.9570463\n",
      "Epoch:  7297 Loss:  0.58589846 accurracy:  0.9570476\n",
      "Epoch:  7298 Loss:  0.5858985 accurracy:  0.9570489\n",
      "Epoch:  7299 Loss:  0.5858983 accurracy:  0.9570502\n",
      "Epoch:  7300 Loss:  0.5858977 accurracy:  0.9570516\n",
      "Epoch:  7301 Loss:  0.5858972 accurracy:  0.9570529\n",
      "Epoch:  7302 Loss:  0.5858969 accurracy:  0.9570542\n",
      "Epoch:  7303 Loss:  0.58589673 accurracy:  0.9570555\n",
      "Epoch:  7304 Loss:  0.5858964 accurracy:  0.9570568\n",
      "Epoch:  7305 Loss:  0.5858959 accurracy:  0.95705813\n",
      "Epoch:  7306 Loss:  0.5858956 accurracy:  0.95705944\n",
      "Epoch:  7307 Loss:  0.5858954 accurracy:  0.95706075\n",
      "Epoch:  7308 Loss:  0.58589524 accurracy:  0.95706207\n",
      "Epoch:  7309 Loss:  0.5858945 accurracy:  0.9570634\n",
      "Epoch:  7310 Loss:  0.58589417 accurracy:  0.9570647\n",
      "Epoch:  7311 Loss:  0.58589417 accurracy:  0.957066\n",
      "Epoch:  7312 Loss:  0.5858939 accurracy:  0.9570673\n",
      "Epoch:  7313 Loss:  0.5858933 accurracy:  0.9570686\n",
      "Epoch:  7314 Loss:  0.58589244 accurracy:  0.95706993\n",
      "Epoch:  7315 Loss:  0.58589196 accurracy:  0.95707124\n",
      "Epoch:  7316 Loss:  0.5858921 accurracy:  0.95707256\n",
      "Epoch:  7317 Loss:  0.5858921 accurracy:  0.95707387\n",
      "Epoch:  7318 Loss:  0.585892 accurracy:  0.9570752\n",
      "Epoch:  7319 Loss:  0.58589137 accurracy:  0.9570765\n",
      "Epoch:  7320 Loss:  0.58589053 accurracy:  0.9570778\n",
      "Epoch:  7321 Loss:  0.5858901 accurracy:  0.9570791\n",
      "Epoch:  7322 Loss:  0.5858901 accurracy:  0.9570804\n",
      "Epoch:  7323 Loss:  0.5858902 accurracy:  0.95708174\n",
      "Epoch:  7324 Loss:  0.5858899 accurracy:  0.95708305\n",
      "Epoch:  7325 Loss:  0.5858893 accurracy:  0.95708436\n",
      "Epoch:  7326 Loss:  0.5858887 accurracy:  0.95708567\n",
      "Epoch:  7327 Loss:  0.5858883 accurracy:  0.957087\n",
      "Epoch:  7328 Loss:  0.58588815 accurracy:  0.9570883\n",
      "Epoch:  7329 Loss:  0.5858881 accurracy:  0.9570896\n",
      "Epoch:  7330 Loss:  0.5858878 accurracy:  0.9570909\n",
      "Epoch:  7331 Loss:  0.5858873 accurracy:  0.9570922\n",
      "Epoch:  7332 Loss:  0.5858869 accurracy:  0.9570935\n",
      "Epoch:  7333 Loss:  0.58588636 accurracy:  0.9570948\n",
      "Epoch:  7334 Loss:  0.5858861 accurracy:  0.9570961\n",
      "Epoch:  7335 Loss:  0.585886 accurracy:  0.9570974\n",
      "Epoch:  7336 Loss:  0.5858857 accurracy:  0.9570987\n",
      "Epoch:  7337 Loss:  0.5858853 accurracy:  0.95710003\n",
      "Epoch:  7338 Loss:  0.58588475 accurracy:  0.95710135\n",
      "Epoch:  7339 Loss:  0.5858844 accurracy:  0.95710266\n",
      "Epoch:  7340 Loss:  0.5858843 accurracy:  0.9571039\n",
      "Epoch:  7341 Loss:  0.5858841 accurracy:  0.9571052\n",
      "Epoch:  7342 Loss:  0.58588374 accurracy:  0.95710653\n",
      "Epoch:  7343 Loss:  0.5858832 accurracy:  0.95710784\n",
      "Epoch:  7344 Loss:  0.5858827 accurracy:  0.95710915\n",
      "Epoch:  7345 Loss:  0.58588254 accurracy:  0.95711046\n",
      "Epoch:  7346 Loss:  0.5858824 accurracy:  0.9571118\n",
      "Epoch:  7347 Loss:  0.5858823 accurracy:  0.957113\n",
      "Epoch:  7348 Loss:  0.58588165 accurracy:  0.95711434\n",
      "Epoch:  7349 Loss:  0.5858812 accurracy:  0.95711565\n",
      "Epoch:  7350 Loss:  0.58588094 accurracy:  0.95711696\n",
      "Epoch:  7351 Loss:  0.58588094 accurracy:  0.9571183\n",
      "Epoch:  7352 Loss:  0.5858805 accurracy:  0.9571195\n",
      "Epoch:  7353 Loss:  0.58588004 accurracy:  0.95712084\n",
      "Epoch:  7354 Loss:  0.5858796 accurracy:  0.95712215\n",
      "Epoch:  7355 Loss:  0.5858795 accurracy:  0.95712346\n",
      "Epoch:  7356 Loss:  0.5858794 accurracy:  0.9571247\n",
      "Epoch:  7357 Loss:  0.585879 accurracy:  0.957126\n",
      "Epoch:  7358 Loss:  0.5858785 accurracy:  0.95712733\n",
      "Epoch:  7359 Loss:  0.585878 accurracy:  0.95712864\n",
      "Epoch:  7360 Loss:  0.58587766 accurracy:  0.9571299\n",
      "Epoch:  7361 Loss:  0.5858775 accurracy:  0.9571312\n",
      "Epoch:  7362 Loss:  0.5858772 accurracy:  0.9571325\n",
      "Epoch:  7363 Loss:  0.5858766 accurracy:  0.9571338\n",
      "Epoch:  7364 Loss:  0.58587617 accurracy:  0.9571351\n",
      "Epoch:  7365 Loss:  0.58587605 accurracy:  0.9571364\n",
      "Epoch:  7366 Loss:  0.5858759 accurracy:  0.9571377\n",
      "Epoch:  7367 Loss:  0.5858757 accurracy:  0.95713896\n",
      "Epoch:  7368 Loss:  0.5858751 accurracy:  0.95714027\n",
      "Epoch:  7369 Loss:  0.5858745 accurracy:  0.9571416\n",
      "Epoch:  7370 Loss:  0.5858744 accurracy:  0.95714283\n",
      "Epoch:  7371 Loss:  0.5858745 accurracy:  0.95714414\n",
      "Epoch:  7372 Loss:  0.58587426 accurracy:  0.95714545\n",
      "Epoch:  7373 Loss:  0.58587366 accurracy:  0.9571467\n",
      "Epoch:  7374 Loss:  0.585873 accurracy:  0.957148\n",
      "Epoch:  7375 Loss:  0.58587277 accurracy:  0.9571493\n",
      "Epoch:  7376 Loss:  0.58587277 accurracy:  0.9571506\n",
      "Epoch:  7377 Loss:  0.58587253 accurracy:  0.9571519\n",
      "Epoch:  7378 Loss:  0.58587223 accurracy:  0.9571532\n",
      "Epoch:  7379 Loss:  0.58587164 accurracy:  0.95715445\n",
      "Epoch:  7380 Loss:  0.5858711 accurracy:  0.95715576\n",
      "Epoch:  7381 Loss:  0.585871 accurracy:  0.9571571\n",
      "Epoch:  7382 Loss:  0.58587086 accurracy:  0.9571583\n",
      "Epoch:  7383 Loss:  0.5858706 accurracy:  0.95715964\n",
      "Epoch:  7384 Loss:  0.5858703 accurracy:  0.9571609\n",
      "Epoch:  7385 Loss:  0.5858698 accurracy:  0.9571622\n",
      "Epoch:  7386 Loss:  0.5858694 accurracy:  0.9571635\n",
      "Epoch:  7387 Loss:  0.5858691 accurracy:  0.95716476\n",
      "Epoch:  7388 Loss:  0.5858686 accurracy:  0.9571661\n",
      "Epoch:  7389 Loss:  0.5858682 accurracy:  0.9571673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  7390 Loss:  0.58586794 accurracy:  0.95716864\n",
      "Epoch:  7391 Loss:  0.5858677 accurracy:  0.9571699\n",
      "Epoch:  7392 Loss:  0.58586746 accurracy:  0.9571712\n",
      "Epoch:  7393 Loss:  0.58586717 accurracy:  0.95717245\n",
      "Epoch:  7394 Loss:  0.5858668 accurracy:  0.95717376\n",
      "Epoch:  7395 Loss:  0.5858664 accurracy:  0.9571751\n",
      "Epoch:  7396 Loss:  0.5858661 accurracy:  0.9571763\n",
      "Epoch:  7397 Loss:  0.5858659 accurracy:  0.95717764\n",
      "Epoch:  7398 Loss:  0.5858656 accurracy:  0.9571789\n",
      "Epoch:  7399 Loss:  0.58586496 accurracy:  0.9571802\n",
      "Epoch:  7400 Loss:  0.58586466 accurracy:  0.95718145\n",
      "Epoch:  7401 Loss:  0.58586466 accurracy:  0.95718277\n",
      "Epoch:  7402 Loss:  0.5858646 accurracy:  0.957184\n",
      "Epoch:  7403 Loss:  0.5858641 accurracy:  0.9571853\n",
      "Epoch:  7404 Loss:  0.5858635 accurracy:  0.9571866\n",
      "Epoch:  7405 Loss:  0.585863 accurracy:  0.9571879\n",
      "Epoch:  7406 Loss:  0.58586293 accurracy:  0.95718914\n",
      "Epoch:  7407 Loss:  0.58586276 accurracy:  0.95719045\n",
      "Epoch:  7408 Loss:  0.58586246 accurracy:  0.9571917\n",
      "Epoch:  7409 Loss:  0.5858621 accurracy:  0.95719296\n",
      "Epoch:  7410 Loss:  0.58586144 accurracy:  0.95719427\n",
      "Epoch:  7411 Loss:  0.5858612 accurracy:  0.9571955\n",
      "Epoch:  7412 Loss:  0.58586097 accurracy:  0.95719683\n",
      "Epoch:  7413 Loss:  0.5858604 accurracy:  0.9571981\n",
      "Epoch:  7414 Loss:  0.58585995 accurracy:  0.9571994\n",
      "Epoch:  7415 Loss:  0.58585954 accurracy:  0.95720065\n",
      "Epoch:  7416 Loss:  0.5858595 accurracy:  0.9572019\n",
      "Epoch:  7417 Loss:  0.5858594 accurracy:  0.9572032\n",
      "Epoch:  7418 Loss:  0.58585894 accurracy:  0.95720446\n",
      "Epoch:  7419 Loss:  0.58585817 accurracy:  0.9572058\n",
      "Epoch:  7420 Loss:  0.58585775 accurracy:  0.957207\n",
      "Epoch:  7421 Loss:  0.58585775 accurracy:  0.9572083\n",
      "Epoch:  7422 Loss:  0.58585805 accurracy:  0.9572096\n",
      "Epoch:  7423 Loss:  0.5858577 accurracy:  0.95721084\n",
      "Epoch:  7424 Loss:  0.58585674 accurracy:  0.95721215\n",
      "Epoch:  7425 Loss:  0.58585626 accurracy:  0.9572134\n",
      "Epoch:  7426 Loss:  0.5858561 accurracy:  0.95721465\n",
      "Epoch:  7427 Loss:  0.5858561 accurracy:  0.95721596\n",
      "Epoch:  7428 Loss:  0.585856 accurracy:  0.9572172\n",
      "Epoch:  7429 Loss:  0.5858555 accurracy:  0.95721847\n",
      "Epoch:  7430 Loss:  0.58585477 accurracy:  0.9572198\n",
      "Epoch:  7431 Loss:  0.5858544 accurracy:  0.95722103\n",
      "Epoch:  7432 Loss:  0.5858545 accurracy:  0.9572223\n",
      "Epoch:  7433 Loss:  0.5858544 accurracy:  0.9572236\n",
      "Epoch:  7434 Loss:  0.58585393 accurracy:  0.95722485\n",
      "Epoch:  7435 Loss:  0.58585346 accurracy:  0.9572261\n",
      "Epoch:  7436 Loss:  0.5858529 accurracy:  0.95722735\n",
      "Epoch:  7437 Loss:  0.58585274 accurracy:  0.95722866\n",
      "Epoch:  7438 Loss:  0.58585274 accurracy:  0.9572299\n",
      "Epoch:  7439 Loss:  0.5858524 accurracy:  0.95723116\n",
      "Epoch:  7440 Loss:  0.5858516 accurracy:  0.9572325\n",
      "Epoch:  7441 Loss:  0.58585113 accurracy:  0.9572337\n",
      "Epoch:  7442 Loss:  0.5858511 accurracy:  0.957235\n",
      "Epoch:  7443 Loss:  0.585851 accurracy:  0.95723623\n",
      "Epoch:  7444 Loss:  0.5858506 accurracy:  0.95723754\n",
      "Epoch:  7445 Loss:  0.5858499 accurracy:  0.9572388\n",
      "Epoch:  7446 Loss:  0.5858495 accurracy:  0.95724005\n",
      "Epoch:  7447 Loss:  0.5858494 accurracy:  0.9572413\n",
      "Epoch:  7448 Loss:  0.58584946 accurracy:  0.9572426\n",
      "Epoch:  7449 Loss:  0.58584917 accurracy:  0.95724386\n",
      "Epoch:  7450 Loss:  0.5858485 accurracy:  0.9572451\n",
      "Epoch:  7451 Loss:  0.585848 accurracy:  0.95724636\n",
      "Epoch:  7452 Loss:  0.58584785 accurracy:  0.9572476\n",
      "Epoch:  7453 Loss:  0.58584774 accurracy:  0.9572489\n",
      "Epoch:  7454 Loss:  0.58584756 accurracy:  0.9572502\n",
      "Epoch:  7455 Loss:  0.5858471 accurracy:  0.9572514\n",
      "Epoch:  7456 Loss:  0.5858465 accurracy:  0.9572527\n",
      "Epoch:  7457 Loss:  0.58584607 accurracy:  0.95725393\n",
      "Epoch:  7458 Loss:  0.5858461 accurracy:  0.95725524\n",
      "Epoch:  7459 Loss:  0.58584595 accurracy:  0.9572565\n",
      "Epoch:  7460 Loss:  0.5858456 accurracy:  0.95725775\n",
      "Epoch:  7461 Loss:  0.58584505 accurracy:  0.957259\n",
      "Epoch:  7462 Loss:  0.5858447 accurracy:  0.95726025\n",
      "Epoch:  7463 Loss:  0.58584446 accurracy:  0.9572615\n",
      "Epoch:  7464 Loss:  0.58584446 accurracy:  0.95726275\n",
      "Epoch:  7465 Loss:  0.585844 accurracy:  0.95726407\n",
      "Epoch:  7466 Loss:  0.58584327 accurracy:  0.9572653\n",
      "Epoch:  7467 Loss:  0.58584285 accurracy:  0.95726657\n",
      "Epoch:  7468 Loss:  0.58584285 accurracy:  0.9572678\n",
      "Epoch:  7469 Loss:  0.5858429 accurracy:  0.9572691\n",
      "Epoch:  7470 Loss:  0.58584243 accurracy:  0.9572703\n",
      "Epoch:  7471 Loss:  0.585842 accurracy:  0.9572716\n",
      "Epoch:  7472 Loss:  0.5858415 accurracy:  0.9572728\n",
      "Epoch:  7473 Loss:  0.58584106 accurracy:  0.9572741\n",
      "Epoch:  7474 Loss:  0.5858409 accurracy:  0.9572754\n",
      "Epoch:  7475 Loss:  0.58584064 accurracy:  0.95727664\n",
      "Epoch:  7476 Loss:  0.58584046 accurracy:  0.9572779\n",
      "Epoch:  7477 Loss:  0.58584034 accurracy:  0.95727915\n",
      "Epoch:  7478 Loss:  0.58583987 accurracy:  0.9572804\n",
      "Epoch:  7479 Loss:  0.5858393 accurracy:  0.95728165\n",
      "Epoch:  7480 Loss:  0.58583903 accurracy:  0.9572829\n",
      "Epoch:  7481 Loss:  0.5858389 accurracy:  0.95728415\n",
      "Epoch:  7482 Loss:  0.5858387 accurracy:  0.9572854\n",
      "Epoch:  7483 Loss:  0.5858384 accurracy:  0.95728666\n",
      "Epoch:  7484 Loss:  0.58583796 accurracy:  0.9572879\n",
      "Epoch:  7485 Loss:  0.5858376 accurracy:  0.95728916\n",
      "Epoch:  7486 Loss:  0.5858373 accurracy:  0.9572904\n",
      "Epoch:  7487 Loss:  0.58583695 accurracy:  0.95729166\n",
      "Epoch:  7488 Loss:  0.5858367 accurracy:  0.9572929\n",
      "Epoch:  7489 Loss:  0.5858365 accurracy:  0.95729417\n",
      "Epoch:  7490 Loss:  0.58583635 accurracy:  0.9572954\n",
      "Epoch:  7491 Loss:  0.58583605 accurracy:  0.95729667\n",
      "Epoch:  7492 Loss:  0.5858354 accurracy:  0.9572979\n",
      "Epoch:  7493 Loss:  0.58583456 accurracy:  0.9572992\n",
      "Epoch:  7494 Loss:  0.58583426 accurracy:  0.9573004\n",
      "Epoch:  7495 Loss:  0.5858343 accurracy:  0.9573017\n",
      "Epoch:  7496 Loss:  0.58583456 accurracy:  0.9573029\n",
      "Epoch:  7497 Loss:  0.58583426 accurracy:  0.9573042\n",
      "Epoch:  7498 Loss:  0.5858335 accurracy:  0.95730543\n",
      "Epoch:  7499 Loss:  0.5858329 accurracy:  0.9573067\n",
      "Epoch:  7500 Loss:  0.5858327 accurracy:  0.95730793\n",
      "Epoch:  7501 Loss:  0.5858328 accurracy:  0.9573092\n",
      "Epoch:  7502 Loss:  0.5858325 accurracy:  0.95731044\n",
      "Epoch:  7503 Loss:  0.5858318 accurracy:  0.95731163\n",
      "Epoch:  7504 Loss:  0.58583134 accurracy:  0.9573129\n",
      "Epoch:  7505 Loss:  0.585831 accurracy:  0.95731413\n",
      "Epoch:  7506 Loss:  0.58583105 accurracy:  0.9573154\n",
      "Epoch:  7507 Loss:  0.5858312 accurracy:  0.95731664\n",
      "Epoch:  7508 Loss:  0.58583057 accurracy:  0.9573179\n",
      "Epoch:  7509 Loss:  0.5858299 accurracy:  0.95731914\n",
      "Epoch:  7510 Loss:  0.58582944 accurracy:  0.9573204\n",
      "Epoch:  7511 Loss:  0.5858295 accurracy:  0.95732164\n",
      "Epoch:  7512 Loss:  0.5858295 accurracy:  0.95732284\n",
      "Epoch:  7513 Loss:  0.5858293 accurracy:  0.9573241\n",
      "Epoch:  7514 Loss:  0.58582866 accurracy:  0.95732534\n",
      "Epoch:  7515 Loss:  0.5858281 accurracy:  0.9573266\n",
      "Epoch:  7516 Loss:  0.5858279 accurracy:  0.95732784\n",
      "Epoch:  7517 Loss:  0.5858279 accurracy:  0.9573291\n",
      "Epoch:  7518 Loss:  0.58582765 accurracy:  0.95733035\n",
      "Epoch:  7519 Loss:  0.5858271 accurracy:  0.95733154\n",
      "Epoch:  7520 Loss:  0.5858266 accurracy:  0.9573328\n",
      "Epoch:  7521 Loss:  0.58582604 accurracy:  0.95733404\n",
      "Epoch:  7522 Loss:  0.58582586 accurracy:  0.9573353\n",
      "Epoch:  7523 Loss:  0.58582586 accurracy:  0.95733654\n",
      "Epoch:  7524 Loss:  0.58582586 accurracy:  0.95733774\n",
      "Epoch:  7525 Loss:  0.5858253 accurracy:  0.957339\n",
      "Epoch:  7526 Loss:  0.5858248 accurracy:  0.95734024\n",
      "Epoch:  7527 Loss:  0.5858242 accurracy:  0.9573415\n",
      "Epoch:  7528 Loss:  0.5858242 accurracy:  0.95734274\n",
      "Epoch:  7529 Loss:  0.5858242 accurracy:  0.95734394\n",
      "Epoch:  7530 Loss:  0.58582395 accurracy:  0.9573452\n",
      "Epoch:  7531 Loss:  0.58582336 accurracy:  0.95734644\n",
      "Epoch:  7532 Loss:  0.58582264 accurracy:  0.9573477\n",
      "Epoch:  7533 Loss:  0.5858222 accurracy:  0.9573489\n",
      "Epoch:  7534 Loss:  0.5858223 accurracy:  0.95735013\n",
      "Epoch:  7535 Loss:  0.58582246 accurracy:  0.9573514\n",
      "Epoch:  7536 Loss:  0.58582217 accurracy:  0.95735264\n",
      "Epoch:  7537 Loss:  0.5858214 accurracy:  0.95735383\n",
      "Epoch:  7538 Loss:  0.5858208 accurracy:  0.9573551\n",
      "Epoch:  7539 Loss:  0.5858205 accurracy:  0.95735633\n",
      "Epoch:  7540 Loss:  0.5858205 accurracy:  0.9573576\n",
      "Epoch:  7541 Loss:  0.5858206 accurracy:  0.9573588\n",
      "Epoch:  7542 Loss:  0.5858202 accurracy:  0.95736\n",
      "Epoch:  7543 Loss:  0.58581954 accurracy:  0.9573613\n",
      "Epoch:  7544 Loss:  0.5858191 accurracy:  0.9573625\n",
      "Epoch:  7545 Loss:  0.58581895 accurracy:  0.9573637\n",
      "Epoch:  7546 Loss:  0.5858189 accurracy:  0.957365\n",
      "Epoch:  7547 Loss:  0.5858187 accurracy:  0.95736617\n",
      "Epoch:  7548 Loss:  0.5858181 accurracy:  0.9573674\n",
      "Epoch:  7549 Loss:  0.5858174 accurracy:  0.9573687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  7550 Loss:  0.5858171 accurracy:  0.95736986\n",
      "Epoch:  7551 Loss:  0.5858171 accurracy:  0.9573711\n",
      "Epoch:  7552 Loss:  0.5858171 accurracy:  0.95737237\n",
      "Epoch:  7553 Loss:  0.5858167 accurracy:  0.95737356\n",
      "Epoch:  7554 Loss:  0.5858161 accurracy:  0.9573748\n",
      "Epoch:  7555 Loss:  0.5858158 accurracy:  0.95737606\n",
      "Epoch:  7556 Loss:  0.58581555 accurracy:  0.95737725\n",
      "Epoch:  7557 Loss:  0.58581537 accurracy:  0.9573785\n",
      "Epoch:  7558 Loss:  0.58581513 accurracy:  0.9573797\n",
      "Epoch:  7559 Loss:  0.5858147 accurracy:  0.95738095\n",
      "Epoch:  7560 Loss:  0.5858143 accurracy:  0.9573822\n",
      "Epoch:  7561 Loss:  0.58581376 accurracy:  0.9573834\n",
      "Epoch:  7562 Loss:  0.58581364 accurracy:  0.95738465\n",
      "Epoch:  7563 Loss:  0.5858137 accurracy:  0.95738584\n",
      "Epoch:  7564 Loss:  0.58581334 accurracy:  0.9573871\n",
      "Epoch:  7565 Loss:  0.58581275 accurracy:  0.95738834\n",
      "Epoch:  7566 Loss:  0.58581203 accurracy:  0.95738953\n",
      "Epoch:  7567 Loss:  0.5858119 accurracy:  0.9573908\n",
      "Epoch:  7568 Loss:  0.58581185 accurracy:  0.957392\n",
      "Epoch:  7569 Loss:  0.5858119 accurracy:  0.9573932\n",
      "Epoch:  7570 Loss:  0.58581173 accurracy:  0.9573944\n",
      "Epoch:  7571 Loss:  0.5858111 accurracy:  0.9573957\n",
      "Epoch:  7572 Loss:  0.58581036 accurracy:  0.95739686\n",
      "Epoch:  7573 Loss:  0.58581024 accurracy:  0.9573981\n",
      "Epoch:  7574 Loss:  0.58581024 accurracy:  0.95739937\n",
      "Epoch:  7575 Loss:  0.5858101 accurracy:  0.95740056\n",
      "Epoch:  7576 Loss:  0.5858095 accurracy:  0.9574018\n",
      "Epoch:  7577 Loss:  0.5858087 accurracy:  0.957403\n",
      "Epoch:  7578 Loss:  0.58580846 accurracy:  0.95740426\n",
      "Epoch:  7579 Loss:  0.5858086 accurracy:  0.95740545\n",
      "Epoch:  7580 Loss:  0.58580863 accurracy:  0.9574067\n",
      "Epoch:  7581 Loss:  0.5858081 accurracy:  0.9574079\n",
      "Epoch:  7582 Loss:  0.58580744 accurracy:  0.95740914\n",
      "Epoch:  7583 Loss:  0.5858069 accurracy:  0.95741034\n",
      "Epoch:  7584 Loss:  0.5858068 accurracy:  0.9574116\n",
      "Epoch:  7585 Loss:  0.5858068 accurracy:  0.9574128\n",
      "Epoch:  7586 Loss:  0.58580667 accurracy:  0.957414\n",
      "Epoch:  7587 Loss:  0.58580613 accurracy:  0.9574152\n",
      "Epoch:  7588 Loss:  0.58580554 accurracy:  0.9574164\n",
      "Epoch:  7589 Loss:  0.5858051 accurracy:  0.95741767\n",
      "Epoch:  7590 Loss:  0.58580524 accurracy:  0.95741886\n",
      "Epoch:  7591 Loss:  0.5858052 accurracy:  0.9574201\n",
      "Epoch:  7592 Loss:  0.58580476 accurracy:  0.9574213\n",
      "Epoch:  7593 Loss:  0.5858042 accurracy:  0.95742255\n",
      "Epoch:  7594 Loss:  0.5858036 accurracy:  0.95742375\n",
      "Epoch:  7595 Loss:  0.58580345 accurracy:  0.95742494\n",
      "Epoch:  7596 Loss:  0.58580345 accurracy:  0.9574262\n",
      "Epoch:  7597 Loss:  0.5858032 accurracy:  0.9574274\n",
      "Epoch:  7598 Loss:  0.58580273 accurracy:  0.95742863\n",
      "Epoch:  7599 Loss:  0.5858022 accurracy:  0.9574298\n",
      "Epoch:  7600 Loss:  0.5858019 accurracy:  0.957431\n",
      "Epoch:  7601 Loss:  0.5858017 accurracy:  0.95743227\n",
      "Epoch:  7602 Loss:  0.58580154 accurracy:  0.95743346\n",
      "Epoch:  7603 Loss:  0.5858013 accurracy:  0.95743465\n",
      "Epoch:  7604 Loss:  0.58580095 accurracy:  0.9574359\n",
      "Epoch:  7605 Loss:  0.58580047 accurracy:  0.9574371\n",
      "Epoch:  7606 Loss:  0.5858001 accurracy:  0.95743835\n",
      "Epoch:  7607 Loss:  0.58579975 accurracy:  0.95743954\n",
      "Epoch:  7608 Loss:  0.5857994 accurracy:  0.95744073\n",
      "Epoch:  7609 Loss:  0.58579916 accurracy:  0.957442\n",
      "Epoch:  7610 Loss:  0.58579904 accurracy:  0.9574432\n",
      "Epoch:  7611 Loss:  0.5857989 accurracy:  0.95744437\n",
      "Epoch:  7612 Loss:  0.58579844 accurracy:  0.9574456\n",
      "Epoch:  7613 Loss:  0.58579797 accurracy:  0.9574468\n",
      "Epoch:  7614 Loss:  0.58579755 accurracy:  0.957448\n",
      "Epoch:  7615 Loss:  0.5857976 accurracy:  0.95744926\n",
      "Epoch:  7616 Loss:  0.5857975 accurracy:  0.95745045\n",
      "Epoch:  7617 Loss:  0.5857969 accurracy:  0.95745164\n",
      "Epoch:  7618 Loss:  0.5857962 accurracy:  0.95745283\n",
      "Epoch:  7619 Loss:  0.5857961 accurracy:  0.9574541\n",
      "Epoch:  7620 Loss:  0.58579636 accurracy:  0.9574553\n",
      "Epoch:  7621 Loss:  0.5857962 accurracy:  0.95745647\n",
      "Epoch:  7622 Loss:  0.5857955 accurracy:  0.9574577\n",
      "Epoch:  7623 Loss:  0.5857948 accurracy:  0.9574589\n",
      "Epoch:  7624 Loss:  0.58579445 accurracy:  0.9574601\n",
      "Epoch:  7625 Loss:  0.58579457 accurracy:  0.9574613\n",
      "Epoch:  7626 Loss:  0.5857945 accurracy:  0.95746255\n",
      "Epoch:  7627 Loss:  0.58579427 accurracy:  0.95746374\n",
      "Epoch:  7628 Loss:  0.5857937 accurracy:  0.95746493\n",
      "Epoch:  7629 Loss:  0.5857929 accurracy:  0.9574661\n",
      "Epoch:  7630 Loss:  0.5857926 accurracy:  0.9574674\n",
      "Epoch:  7631 Loss:  0.58579266 accurracy:  0.95746857\n",
      "Epoch:  7632 Loss:  0.5857928 accurracy:  0.95746976\n",
      "Epoch:  7633 Loss:  0.5857924 accurracy:  0.95747095\n",
      "Epoch:  7634 Loss:  0.58579165 accurracy:  0.95747215\n",
      "Epoch:  7635 Loss:  0.58579123 accurracy:  0.9574734\n",
      "Epoch:  7636 Loss:  0.58579105 accurracy:  0.9574746\n",
      "Epoch:  7637 Loss:  0.58579093 accurracy:  0.9574758\n",
      "Epoch:  7638 Loss:  0.58579063 accurracy:  0.957477\n",
      "Epoch:  7639 Loss:  0.5857904 accurracy:  0.95747817\n",
      "Epoch:  7640 Loss:  0.58579 accurracy:  0.95747936\n",
      "Epoch:  7641 Loss:  0.58578974 accurracy:  0.9574806\n",
      "Epoch:  7642 Loss:  0.5857895 accurracy:  0.9574818\n",
      "Epoch:  7643 Loss:  0.58578897 accurracy:  0.957483\n",
      "Epoch:  7644 Loss:  0.5857885 accurracy:  0.9574842\n",
      "Epoch:  7645 Loss:  0.58578837 accurracy:  0.9574854\n",
      "Epoch:  7646 Loss:  0.5857885 accurracy:  0.95748657\n",
      "Epoch:  7647 Loss:  0.58578837 accurracy:  0.9574878\n",
      "Epoch:  7648 Loss:  0.5857877 accurracy:  0.957489\n",
      "Epoch:  7649 Loss:  0.58578706 accurracy:  0.9574902\n",
      "Epoch:  7650 Loss:  0.5857867 accurracy:  0.9574914\n",
      "Epoch:  7651 Loss:  0.5857867 accurracy:  0.9574926\n",
      "Epoch:  7652 Loss:  0.58578676 accurracy:  0.9574938\n",
      "Epoch:  7653 Loss:  0.5857863 accurracy:  0.957495\n",
      "Epoch:  7654 Loss:  0.58578557 accurracy:  0.95749617\n",
      "Epoch:  7655 Loss:  0.58578503 accurracy:  0.95749736\n",
      "Epoch:  7656 Loss:  0.585785 accurracy:  0.9574986\n",
      "Epoch:  7657 Loss:  0.58578515 accurracy:  0.9574998\n",
      "Epoch:  7658 Loss:  0.5857851 accurracy:  0.957501\n",
      "Epoch:  7659 Loss:  0.5857846 accurracy:  0.9575022\n",
      "Epoch:  7660 Loss:  0.5857839 accurracy:  0.9575034\n",
      "Epoch:  7661 Loss:  0.58578336 accurracy:  0.9575046\n",
      "Epoch:  7662 Loss:  0.5857831 accurracy:  0.95750576\n",
      "Epoch:  7663 Loss:  0.58578324 accurracy:  0.95750695\n",
      "Epoch:  7664 Loss:  0.58578324 accurracy:  0.95750815\n",
      "Epoch:  7665 Loss:  0.5857827 accurracy:  0.95750934\n",
      "Epoch:  7666 Loss:  0.5857817 accurracy:  0.95751053\n",
      "Epoch:  7667 Loss:  0.5857812 accurracy:  0.9575117\n",
      "Epoch:  7668 Loss:  0.58578146 accurracy:  0.9575129\n",
      "Epoch:  7669 Loss:  0.58578163 accurracy:  0.9575141\n",
      "Epoch:  7670 Loss:  0.58578146 accurracy:  0.9575153\n",
      "Epoch:  7671 Loss:  0.5857807 accurracy:  0.9575165\n",
      "Epoch:  7672 Loss:  0.5857797 accurracy:  0.9575177\n",
      "Epoch:  7673 Loss:  0.5857794 accurracy:  0.9575189\n",
      "Epoch:  7674 Loss:  0.5857799 accurracy:  0.95752007\n",
      "Epoch:  7675 Loss:  0.58578014 accurracy:  0.95752126\n",
      "Epoch:  7676 Loss:  0.5857797 accurracy:  0.95752245\n",
      "Epoch:  7677 Loss:  0.58577853 accurracy:  0.95752364\n",
      "Epoch:  7678 Loss:  0.58577806 accurracy:  0.95752484\n",
      "Epoch:  7679 Loss:  0.5857782 accurracy:  0.957526\n",
      "Epoch:  7680 Loss:  0.58577853 accurracy:  0.9575272\n",
      "Epoch:  7681 Loss:  0.58577836 accurracy:  0.9575284\n",
      "Epoch:  7682 Loss:  0.58577746 accurracy:  0.9575296\n",
      "Epoch:  7683 Loss:  0.58577675 accurracy:  0.9575308\n",
      "Epoch:  7684 Loss:  0.5857767 accurracy:  0.957532\n",
      "Epoch:  7685 Loss:  0.58577675 accurracy:  0.9575332\n",
      "Epoch:  7686 Loss:  0.58577657 accurracy:  0.9575344\n",
      "Epoch:  7687 Loss:  0.58577615 accurracy:  0.95753556\n",
      "Epoch:  7688 Loss:  0.58577555 accurracy:  0.95753676\n",
      "Epoch:  7689 Loss:  0.58577526 accurracy:  0.95753795\n",
      "Epoch:  7690 Loss:  0.5857752 accurracy:  0.95753914\n",
      "Epoch:  7691 Loss:  0.58577514 accurracy:  0.9575403\n",
      "Epoch:  7692 Loss:  0.5857747 accurracy:  0.95754147\n",
      "Epoch:  7693 Loss:  0.58577424 accurracy:  0.95754266\n",
      "Epoch:  7694 Loss:  0.58577377 accurracy:  0.95754385\n",
      "Epoch:  7695 Loss:  0.5857737 accurracy:  0.95754504\n",
      "Epoch:  7696 Loss:  0.58577335 accurracy:  0.95754623\n",
      "Epoch:  7697 Loss:  0.58577275 accurracy:  0.9575474\n",
      "Epoch:  7698 Loss:  0.5857725 accurracy:  0.9575486\n",
      "Epoch:  7699 Loss:  0.58577234 accurracy:  0.9575498\n",
      "Epoch:  7700 Loss:  0.5857722 accurracy:  0.95755094\n",
      "Epoch:  7701 Loss:  0.5857721 accurracy:  0.95755213\n",
      "Epoch:  7702 Loss:  0.5857717 accurracy:  0.9575533\n",
      "Epoch:  7703 Loss:  0.5857712 accurracy:  0.9575545\n",
      "Epoch:  7704 Loss:  0.58577055 accurracy:  0.9575557\n",
      "Epoch:  7705 Loss:  0.5857703 accurracy:  0.9575569\n",
      "Epoch:  7706 Loss:  0.5857704 accurracy:  0.95755804\n",
      "Epoch:  7707 Loss:  0.5857704 accurracy:  0.9575592\n",
      "Epoch:  7708 Loss:  0.5857703 accurracy:  0.9575604\n",
      "Epoch:  7709 Loss:  0.58576965 accurracy:  0.9575616\n",
      "Epoch:  7710 Loss:  0.585769 accurracy:  0.9575628\n",
      "Epoch:  7711 Loss:  0.58576864 accurracy:  0.957564\n",
      "Epoch:  7712 Loss:  0.5857685 accurracy:  0.9575651\n",
      "Epoch:  7713 Loss:  0.58576864 accurracy:  0.9575663\n",
      "Epoch:  7714 Loss:  0.5857685 accurracy:  0.9575675\n",
      "Epoch:  7715 Loss:  0.5857679 accurracy:  0.9575687\n",
      "Epoch:  7716 Loss:  0.5857671 accurracy:  0.9575699\n",
      "Epoch:  7717 Loss:  0.5857668 accurracy:  0.957571\n",
      "Epoch:  7718 Loss:  0.58576685 accurracy:  0.9575722\n",
      "Epoch:  7719 Loss:  0.58576685 accurracy:  0.9575734\n",
      "Epoch:  7720 Loss:  0.5857668 accurracy:  0.9575746\n",
      "Epoch:  7721 Loss:  0.5857664 accurracy:  0.95757574\n",
      "Epoch:  7722 Loss:  0.5857656 accurracy:  0.95757693\n",
      "Epoch:  7723 Loss:  0.5857652 accurracy:  0.9575781\n",
      "Epoch:  7724 Loss:  0.5857652 accurracy:  0.9575793\n",
      "Epoch:  7725 Loss:  0.5857651 accurracy:  0.95758045\n",
      "Epoch:  7726 Loss:  0.58576494 accurracy:  0.95758164\n",
      "Epoch:  7727 Loss:  0.5857643 accurracy:  0.95758283\n",
      "Epoch:  7728 Loss:  0.5857635 accurracy:  0.95758396\n",
      "Epoch:  7729 Loss:  0.58576316 accurracy:  0.95758516\n",
      "Epoch:  7730 Loss:  0.5857633 accurracy:  0.95758635\n",
      "Epoch:  7731 Loss:  0.5857631 accurracy:  0.95758754\n",
      "Epoch:  7732 Loss:  0.5857628 accurracy:  0.9575887\n",
      "Epoch:  7733 Loss:  0.5857624 accurracy:  0.95758986\n",
      "Epoch:  7734 Loss:  0.585762 accurracy:  0.95759106\n",
      "Epoch:  7735 Loss:  0.5857618 accurracy:  0.9575922\n",
      "Epoch:  7736 Loss:  0.5857615 accurracy:  0.9575934\n",
      "Epoch:  7737 Loss:  0.58576125 accurracy:  0.9575946\n",
      "Epoch:  7738 Loss:  0.585761 accurracy:  0.9575957\n",
      "Epoch:  7739 Loss:  0.5857608 accurracy:  0.9575969\n",
      "Epoch:  7740 Loss:  0.5857605 accurracy:  0.9575981\n",
      "Epoch:  7741 Loss:  0.58576024 accurracy:  0.9575992\n",
      "Epoch:  7742 Loss:  0.5857599 accurracy:  0.9576004\n",
      "Epoch:  7743 Loss:  0.58575946 accurracy:  0.9576016\n",
      "Epoch:  7744 Loss:  0.5857592 accurracy:  0.95760274\n",
      "Epoch:  7745 Loss:  0.5857592 accurracy:  0.95760393\n",
      "Epoch:  7746 Loss:  0.5857591 accurracy:  0.9576051\n",
      "Epoch:  7747 Loss:  0.58575845 accurracy:  0.95760626\n",
      "Epoch:  7748 Loss:  0.58575785 accurracy:  0.95760745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  7749 Loss:  0.5857576 accurracy:  0.9576086\n",
      "Epoch:  7750 Loss:  0.5857576 accurracy:  0.9576098\n",
      "Epoch:  7751 Loss:  0.5857575 accurracy:  0.95761096\n",
      "Epoch:  7752 Loss:  0.5857572 accurracy:  0.9576121\n",
      "Epoch:  7753 Loss:  0.58575696 accurracy:  0.9576133\n",
      "Epoch:  7754 Loss:  0.58575654 accurracy:  0.9576144\n",
      "Epoch:  7755 Loss:  0.58575594 accurracy:  0.9576156\n",
      "Epoch:  7756 Loss:  0.58575565 accurracy:  0.9576168\n",
      "Epoch:  7757 Loss:  0.5857556 accurracy:  0.95761794\n",
      "Epoch:  7758 Loss:  0.5857555 accurracy:  0.95761913\n",
      "Epoch:  7759 Loss:  0.5857552 accurracy:  0.95762026\n",
      "Epoch:  7760 Loss:  0.58575445 accurracy:  0.95762146\n",
      "Epoch:  7761 Loss:  0.58575374 accurracy:  0.9576226\n",
      "Epoch:  7762 Loss:  0.58575386 accurracy:  0.9576238\n",
      "Epoch:  7763 Loss:  0.58575416 accurracy:  0.9576249\n",
      "Epoch:  7764 Loss:  0.5857541 accurracy:  0.9576261\n",
      "Epoch:  7765 Loss:  0.58575326 accurracy:  0.95762724\n",
      "Epoch:  7766 Loss:  0.58575237 accurracy:  0.9576284\n",
      "Epoch:  7767 Loss:  0.5857521 accurracy:  0.9576296\n",
      "Epoch:  7768 Loss:  0.58575237 accurracy:  0.95763075\n",
      "Epoch:  7769 Loss:  0.58575237 accurracy:  0.95763195\n",
      "Epoch:  7770 Loss:  0.5857519 accurracy:  0.9576331\n",
      "Epoch:  7771 Loss:  0.5857513 accurracy:  0.95763427\n",
      "Epoch:  7772 Loss:  0.5857507 accurracy:  0.9576354\n",
      "Epoch:  7773 Loss:  0.5857508 accurracy:  0.9576366\n",
      "Epoch:  7774 Loss:  0.5857508 accurracy:  0.9576377\n",
      "Epoch:  7775 Loss:  0.5857506 accurracy:  0.95763886\n",
      "Epoch:  7776 Loss:  0.58574986 accurracy:  0.95764005\n",
      "Epoch:  7777 Loss:  0.5857493 accurracy:  0.9576412\n",
      "Epoch:  7778 Loss:  0.5857492 accurracy:  0.9576424\n",
      "Epoch:  7779 Loss:  0.5857495 accurracy:  0.9576435\n",
      "Epoch:  7780 Loss:  0.58574945 accurracy:  0.9576447\n",
      "Epoch:  7781 Loss:  0.58574873 accurracy:  0.95764583\n",
      "Epoch:  7782 Loss:  0.585748 accurracy:  0.957647\n",
      "Epoch:  7783 Loss:  0.5857475 accurracy:  0.95764816\n",
      "Epoch:  7784 Loss:  0.58574754 accurracy:  0.95764935\n",
      "Epoch:  7785 Loss:  0.58574796 accurracy:  0.9576505\n",
      "Epoch:  7786 Loss:  0.58574784 accurracy:  0.9576516\n",
      "Epoch:  7787 Loss:  0.585747 accurracy:  0.9576528\n",
      "Epoch:  7788 Loss:  0.5857461 accurracy:  0.95765394\n",
      "Epoch:  7789 Loss:  0.5857458 accurracy:  0.95765513\n",
      "Epoch:  7790 Loss:  0.5857461 accurracy:  0.95765626\n",
      "Epoch:  7791 Loss:  0.5857465 accurracy:  0.9576574\n",
      "Epoch:  7792 Loss:  0.585746 accurracy:  0.9576586\n",
      "Epoch:  7793 Loss:  0.58574474 accurracy:  0.9576597\n",
      "Epoch:  7794 Loss:  0.5857441 accurracy:  0.9576609\n",
      "Epoch:  7795 Loss:  0.5857443 accurracy:  0.95766205\n",
      "Epoch:  7796 Loss:  0.58574474 accurracy:  0.9576632\n",
      "Epoch:  7797 Loss:  0.5857446 accurracy:  0.9576644\n",
      "Epoch:  7798 Loss:  0.585744 accurracy:  0.9576655\n",
      "Epoch:  7799 Loss:  0.58574325 accurracy:  0.9576667\n",
      "Epoch:  7800 Loss:  0.5857429 accurracy:  0.9576678\n",
      "Epoch:  7801 Loss:  0.58574283 accurracy:  0.95766896\n",
      "Epoch:  7802 Loss:  0.5857429 accurracy:  0.95767015\n",
      "Epoch:  7803 Loss:  0.58574265 accurracy:  0.9576713\n",
      "Epoch:  7804 Loss:  0.58574206 accurracy:  0.9576724\n",
      "Epoch:  7805 Loss:  0.5857417 accurracy:  0.9576736\n",
      "Epoch:  7806 Loss:  0.58574134 accurracy:  0.95767474\n",
      "Epoch:  7807 Loss:  0.5857411 accurracy:  0.9576759\n",
      "Epoch:  7808 Loss:  0.58574116 accurracy:  0.95767707\n",
      "Epoch:  7809 Loss:  0.58574086 accurracy:  0.9576782\n",
      "Epoch:  7810 Loss:  0.5857404 accurracy:  0.95767933\n",
      "Epoch:  7811 Loss:  0.58574015 accurracy:  0.95768046\n",
      "Epoch:  7812 Loss:  0.58573985 accurracy:  0.95768166\n",
      "Epoch:  7813 Loss:  0.5857395 accurracy:  0.9576828\n",
      "Epoch:  7814 Loss:  0.58573925 accurracy:  0.9576839\n",
      "Epoch:  7815 Loss:  0.5857391 accurracy:  0.9576851\n",
      "Epoch:  7816 Loss:  0.5857389 accurracy:  0.95768625\n",
      "Epoch:  7817 Loss:  0.5857387 accurracy:  0.9576874\n",
      "Epoch:  7818 Loss:  0.58573836 accurracy:  0.9576885\n",
      "Epoch:  7819 Loss:  0.585738 accurracy:  0.9576897\n",
      "Epoch:  7820 Loss:  0.5857376 accurracy:  0.95769083\n",
      "Epoch:  7821 Loss:  0.58573735 accurracy:  0.95769197\n",
      "Epoch:  7822 Loss:  0.5857371 accurracy:  0.9576931\n",
      "Epoch:  7823 Loss:  0.585737 accurracy:  0.9576943\n",
      "Epoch:  7824 Loss:  0.585737 accurracy:  0.9576954\n",
      "Epoch:  7825 Loss:  0.58573645 accurracy:  0.95769656\n",
      "Epoch:  7826 Loss:  0.5857356 accurracy:  0.9576977\n",
      "Epoch:  7827 Loss:  0.5857352 accurracy:  0.9576989\n",
      "Epoch:  7828 Loss:  0.5857352 accurracy:  0.9577\n",
      "Epoch:  7829 Loss:  0.5857353 accurracy:  0.95770115\n",
      "Epoch:  7830 Loss:  0.5857351 accurracy:  0.9577023\n",
      "Epoch:  7831 Loss:  0.5857344 accurracy:  0.9577034\n",
      "Epoch:  7832 Loss:  0.58573407 accurracy:  0.9577046\n",
      "Epoch:  7833 Loss:  0.58573395 accurracy:  0.95770574\n",
      "Epoch:  7834 Loss:  0.5857338 accurracy:  0.95770687\n",
      "Epoch:  7835 Loss:  0.5857334 accurracy:  0.957708\n",
      "Epoch:  7836 Loss:  0.5857332 accurracy:  0.95770913\n",
      "Epoch:  7837 Loss:  0.5857329 accurracy:  0.9577103\n",
      "Epoch:  7838 Loss:  0.5857326 accurracy:  0.95771146\n",
      "Epoch:  7839 Loss:  0.5857322 accurracy:  0.9577126\n",
      "Epoch:  7840 Loss:  0.5857319 accurracy:  0.9577137\n",
      "Epoch:  7841 Loss:  0.5857318 accurracy:  0.95771486\n",
      "Epoch:  7842 Loss:  0.58573157 accurracy:  0.957716\n",
      "Epoch:  7843 Loss:  0.5857312 accurracy:  0.9577172\n",
      "Epoch:  7844 Loss:  0.5857308 accurracy:  0.9577183\n",
      "Epoch:  7845 Loss:  0.5857306 accurracy:  0.95771945\n",
      "Epoch:  7846 Loss:  0.5857305 accurracy:  0.9577206\n",
      "Epoch:  7847 Loss:  0.5857302 accurracy:  0.9577217\n",
      "Epoch:  7848 Loss:  0.5857296 accurracy:  0.95772284\n",
      "Epoch:  7849 Loss:  0.58572936 accurracy:  0.957724\n",
      "Epoch:  7850 Loss:  0.58572906 accurracy:  0.9577251\n",
      "Epoch:  7851 Loss:  0.5857293 accurracy:  0.95772624\n",
      "Epoch:  7852 Loss:  0.58572906 accurracy:  0.95772743\n",
      "Epoch:  7853 Loss:  0.5857285 accurracy:  0.95772856\n",
      "Epoch:  7854 Loss:  0.5857278 accurracy:  0.9577297\n",
      "Epoch:  7855 Loss:  0.58572763 accurracy:  0.9577308\n",
      "Epoch:  7856 Loss:  0.58572775 accurracy:  0.95773196\n",
      "Epoch:  7857 Loss:  0.5857278 accurracy:  0.9577331\n",
      "Epoch:  7858 Loss:  0.58572733 accurracy:  0.9577342\n",
      "Epoch:  7859 Loss:  0.58572656 accurracy:  0.95773536\n",
      "Epoch:  7860 Loss:  0.585726 accurracy:  0.9577365\n",
      "Epoch:  7861 Loss:  0.5857259 accurracy:  0.9577376\n",
      "Epoch:  7862 Loss:  0.5857259 accurracy:  0.95773876\n",
      "Epoch:  7863 Loss:  0.58572567 accurracy:  0.9577399\n",
      "Epoch:  7864 Loss:  0.58572525 accurracy:  0.957741\n",
      "Epoch:  7865 Loss:  0.5857248 accurracy:  0.95774215\n",
      "Epoch:  7866 Loss:  0.58572465 accurracy:  0.9577433\n",
      "Epoch:  7867 Loss:  0.5857246 accurracy:  0.9577445\n",
      "Epoch:  7868 Loss:  0.5857244 accurracy:  0.9577456\n",
      "Epoch:  7869 Loss:  0.585724 accurracy:  0.95774674\n",
      "Epoch:  7870 Loss:  0.5857235 accurracy:  0.9577479\n",
      "Epoch:  7871 Loss:  0.58572334 accurracy:  0.957749\n",
      "Epoch:  7872 Loss:  0.5857233 accurracy:  0.95775014\n",
      "Epoch:  7873 Loss:  0.58572316 accurracy:  0.9577513\n",
      "Epoch:  7874 Loss:  0.58572274 accurracy:  0.9577524\n",
      "Epoch:  7875 Loss:  0.5857222 accurracy:  0.95775354\n",
      "Epoch:  7876 Loss:  0.58572197 accurracy:  0.9577547\n",
      "Epoch:  7877 Loss:  0.5857218 accurracy:  0.9577558\n",
      "Epoch:  7878 Loss:  0.58572143 accurracy:  0.9577569\n",
      "Epoch:  7879 Loss:  0.5857212 accurracy:  0.957758\n",
      "Epoch:  7880 Loss:  0.58572096 accurracy:  0.95775914\n",
      "Epoch:  7881 Loss:  0.5857207 accurracy:  0.9577603\n",
      "Epoch:  7882 Loss:  0.58572024 accurracy:  0.9577614\n",
      "Epoch:  7883 Loss:  0.58571976 accurracy:  0.95776254\n",
      "Epoch:  7884 Loss:  0.5857194 accurracy:  0.9577637\n",
      "Epoch:  7885 Loss:  0.58571935 accurracy:  0.9577648\n",
      "Epoch:  7886 Loss:  0.5857193 accurracy:  0.95776594\n",
      "Epoch:  7887 Loss:  0.58571905 accurracy:  0.95776707\n",
      "Epoch:  7888 Loss:  0.5857188 accurracy:  0.9577682\n",
      "Epoch:  7889 Loss:  0.58571845 accurracy:  0.95776933\n",
      "Epoch:  7890 Loss:  0.58571804 accurracy:  0.95777047\n",
      "Epoch:  7891 Loss:  0.5857178 accurracy:  0.9577716\n",
      "Epoch:  7892 Loss:  0.58571756 accurracy:  0.95777273\n",
      "Epoch:  7893 Loss:  0.58571726 accurracy:  0.95777386\n",
      "Epoch:  7894 Loss:  0.58571714 accurracy:  0.95777494\n",
      "Epoch:  7895 Loss:  0.58571655 accurracy:  0.95777607\n",
      "Epoch:  7896 Loss:  0.58571607 accurracy:  0.9577772\n",
      "Epoch:  7897 Loss:  0.5857159 accurracy:  0.95777833\n",
      "Epoch:  7898 Loss:  0.5857159 accurracy:  0.95777947\n",
      "Epoch:  7899 Loss:  0.58571565 accurracy:  0.9577806\n",
      "Epoch:  7900 Loss:  0.58571523 accurracy:  0.95778173\n",
      "Epoch:  7901 Loss:  0.5857149 accurracy:  0.95778286\n",
      "Epoch:  7902 Loss:  0.5857146 accurracy:  0.95778394\n",
      "Epoch:  7903 Loss:  0.58571446 accurracy:  0.95778507\n",
      "Epoch:  7904 Loss:  0.5857142 accurracy:  0.9577862\n",
      "Epoch:  7905 Loss:  0.5857138 accurracy:  0.95778733\n",
      "Epoch:  7906 Loss:  0.58571357 accurracy:  0.95778847\n",
      "Epoch:  7907 Loss:  0.5857133 accurracy:  0.9577896\n",
      "Epoch:  7908 Loss:  0.5857131 accurracy:  0.9577907\n",
      "Epoch:  7909 Loss:  0.5857128 accurracy:  0.9577918\n",
      "Epoch:  7910 Loss:  0.58571255 accurracy:  0.95779294\n",
      "Epoch:  7911 Loss:  0.5857123 accurracy:  0.9577941\n",
      "Epoch:  7912 Loss:  0.5857119 accurracy:  0.9577952\n",
      "Epoch:  7913 Loss:  0.58571154 accurracy:  0.95779634\n",
      "Epoch:  7914 Loss:  0.5857113 accurracy:  0.9577974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  7915 Loss:  0.5857112 accurracy:  0.95779854\n",
      "Epoch:  7916 Loss:  0.5857108 accurracy:  0.9577997\n",
      "Epoch:  7917 Loss:  0.58571064 accurracy:  0.9578008\n",
      "Epoch:  7918 Loss:  0.5857104 accurracy:  0.95780194\n",
      "Epoch:  7919 Loss:  0.5857099 accurracy:  0.957803\n",
      "Epoch:  7920 Loss:  0.5857094 accurracy:  0.95780414\n",
      "Epoch:  7921 Loss:  0.58570904 accurracy:  0.9578053\n",
      "Epoch:  7922 Loss:  0.58570915 accurracy:  0.9578064\n",
      "Epoch:  7923 Loss:  0.5857092 accurracy:  0.9578075\n",
      "Epoch:  7924 Loss:  0.58570886 accurracy:  0.9578086\n",
      "Epoch:  7925 Loss:  0.58570844 accurracy:  0.95780975\n",
      "Epoch:  7926 Loss:  0.58570796 accurracy:  0.9578109\n",
      "Epoch:  7927 Loss:  0.5857076 accurracy:  0.95781195\n",
      "Epoch:  7928 Loss:  0.5857075 accurracy:  0.9578131\n",
      "Epoch:  7929 Loss:  0.5857075 accurracy:  0.9578142\n",
      "Epoch:  7930 Loss:  0.58570725 accurracy:  0.95781535\n",
      "Epoch:  7931 Loss:  0.5857066 accurracy:  0.9578164\n",
      "Epoch:  7932 Loss:  0.585706 accurracy:  0.95781755\n",
      "Epoch:  7933 Loss:  0.5857059 accurracy:  0.9578187\n",
      "Epoch:  7934 Loss:  0.58570594 accurracy:  0.95781976\n",
      "Epoch:  7935 Loss:  0.5857058 accurracy:  0.9578209\n",
      "Epoch:  7936 Loss:  0.58570546 accurracy:  0.957822\n",
      "Epoch:  7937 Loss:  0.5857048 accurracy:  0.95782316\n",
      "Epoch:  7938 Loss:  0.58570445 accurracy:  0.95782423\n",
      "Epoch:  7939 Loss:  0.58570445 accurracy:  0.95782536\n",
      "Epoch:  7940 Loss:  0.58570445 accurracy:  0.9578265\n",
      "Epoch:  7941 Loss:  0.58570415 accurracy:  0.95782757\n",
      "Epoch:  7942 Loss:  0.5857035 accurracy:  0.9578287\n",
      "Epoch:  7943 Loss:  0.58570296 accurracy:  0.95782983\n",
      "Epoch:  7944 Loss:  0.5857029 accurracy:  0.9578309\n",
      "Epoch:  7945 Loss:  0.58570313 accurracy:  0.95783204\n",
      "Epoch:  7946 Loss:  0.58570296 accurracy:  0.9578332\n",
      "Epoch:  7947 Loss:  0.58570254 accurracy:  0.95783424\n",
      "Epoch:  7948 Loss:  0.5857018 accurracy:  0.9578354\n",
      "Epoch:  7949 Loss:  0.5857015 accurracy:  0.95783645\n",
      "Epoch:  7950 Loss:  0.5857013 accurracy:  0.9578376\n",
      "Epoch:  7951 Loss:  0.58570135 accurracy:  0.9578387\n",
      "Epoch:  7952 Loss:  0.5857012 accurracy:  0.9578398\n",
      "Epoch:  7953 Loss:  0.58570087 accurracy:  0.9578409\n",
      "Epoch:  7954 Loss:  0.58570033 accurracy:  0.95784205\n",
      "Epoch:  7955 Loss:  0.58569974 accurracy:  0.9578431\n",
      "Epoch:  7956 Loss:  0.5856996 accurracy:  0.95784426\n",
      "Epoch:  7957 Loss:  0.5856996 accurracy:  0.95784533\n",
      "Epoch:  7958 Loss:  0.58569944 accurracy:  0.95784646\n",
      "Epoch:  7959 Loss:  0.5856991 accurracy:  0.9578476\n",
      "Epoch:  7960 Loss:  0.58569884 accurracy:  0.95784867\n",
      "Epoch:  7961 Loss:  0.58569837 accurracy:  0.9578498\n",
      "Epoch:  7962 Loss:  0.58569825 accurracy:  0.9578509\n",
      "Epoch:  7963 Loss:  0.5856983 accurracy:  0.957852\n",
      "Epoch:  7964 Loss:  0.585698 accurracy:  0.9578531\n",
      "Epoch:  7965 Loss:  0.5856973 accurracy:  0.9578542\n",
      "Epoch:  7966 Loss:  0.58569694 accurracy:  0.95785534\n",
      "Epoch:  7967 Loss:  0.5856968 accurracy:  0.9578564\n",
      "Epoch:  7968 Loss:  0.58569664 accurracy:  0.95785755\n",
      "Epoch:  7969 Loss:  0.58569634 accurracy:  0.9578586\n",
      "Epoch:  7970 Loss:  0.58569604 accurracy:  0.95785975\n",
      "Epoch:  7971 Loss:  0.5856956 accurracy:  0.9578608\n",
      "Epoch:  7972 Loss:  0.5856954 accurracy:  0.95786196\n",
      "Epoch:  7973 Loss:  0.5856952 accurracy:  0.95786303\n",
      "Epoch:  7974 Loss:  0.5856951 accurracy:  0.95786417\n",
      "Epoch:  7975 Loss:  0.5856949 accurracy:  0.95786524\n",
      "Epoch:  7976 Loss:  0.58569455 accurracy:  0.9578664\n",
      "Epoch:  7977 Loss:  0.58569425 accurracy:  0.95786744\n",
      "Epoch:  7978 Loss:  0.5856938 accurracy:  0.9578686\n",
      "Epoch:  7979 Loss:  0.58569354 accurracy:  0.95786965\n",
      "Epoch:  7980 Loss:  0.58569336 accurracy:  0.9578708\n",
      "Epoch:  7981 Loss:  0.58569306 accurracy:  0.95787185\n",
      "Epoch:  7982 Loss:  0.58569294 accurracy:  0.957873\n",
      "Epoch:  7983 Loss:  0.5856927 accurracy:  0.95787406\n",
      "Epoch:  7984 Loss:  0.58569235 accurracy:  0.9578752\n",
      "Epoch:  7985 Loss:  0.5856921 accurracy:  0.95787627\n",
      "Epoch:  7986 Loss:  0.5856918 accurracy:  0.9578774\n",
      "Epoch:  7987 Loss:  0.58569163 accurracy:  0.9578785\n",
      "Epoch:  7988 Loss:  0.5856913 accurracy:  0.9578796\n",
      "Epoch:  7989 Loss:  0.5856909 accurracy:  0.9578807\n",
      "Epoch:  7990 Loss:  0.58569074 accurracy:  0.9578818\n",
      "Epoch:  7991 Loss:  0.5856905 accurracy:  0.9578829\n",
      "Epoch:  7992 Loss:  0.5856903 accurracy:  0.95788395\n",
      "Epoch:  7993 Loss:  0.58569026 accurracy:  0.9578851\n",
      "Epoch:  7994 Loss:  0.5856899 accurracy:  0.95788616\n",
      "Epoch:  7995 Loss:  0.5856894 accurracy:  0.9578873\n",
      "Epoch:  7996 Loss:  0.5856889 accurracy:  0.95788836\n",
      "Epoch:  7997 Loss:  0.58568895 accurracy:  0.9578895\n",
      "Epoch:  7998 Loss:  0.585689 accurracy:  0.95789057\n",
      "Epoch:  7999 Loss:  0.58568865 accurracy:  0.95789164\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       0.93      1.00      0.97        14\n",
      "           2       1.00      0.88      0.93         8\n",
      "\n",
      "   micro avg       0.97      0.97      0.97        30\n",
      "   macro avg       0.98      0.96      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf_x = tf.placeholder(tf.float32, [None, 4])     # input x\n",
    "tf_y = tf.placeholder(tf.int32, [None])     # input y\n",
    "l1 = tf.layers.dense(tf_x, 10, tf.nn.relu)          # hidden layers. The activation function is relu\n",
    "l2 = tf.layers.dense(l1, 10, tf.nn.relu)            \n",
    "output = tf.layers.dense(l2, 3, tf.nn.softmax)                     # output layer\n",
    "loss = tf.losses.sparse_softmax_cross_entropy(labels=tf_y, logits=output) # use softmax loss cross entropy, because there are more than 2 categories\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "#optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01) # use batch gradient descent\n",
    "train_op = optimizer.minimize(loss) # call this for training.\n",
    "accuracy = tf.metrics.accuracy( # return (acc, update_op), and create 2 local variables\n",
    "    labels=tf.squeeze(tf_y), predictions=tf.argmax(output, axis=1))[1] \n",
    "\n",
    "sess = tf.Session()                                                                 \n",
    "init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "sess.run(init_op)     # initialize var\n",
    "\n",
    "for epoch in range(8000):\n",
    "    sess.run(train_op, {tf_x: train_feature, tf_y: train_label}) # feed training x and y\n",
    "    print(\"Epoch: \", epoch, \"Loss: \", sess.run(loss, {tf_x: test_feature, tf_y: test_label}), \"accurracy: \", sess.run(accuracy, {tf_x: test_feature, tf_y: test_label}))  \n",
    "    if epoch == 7999:\n",
    "        import sklearn.metrics\n",
    "        test_output = sess.run(output, {tf_x: test_feature})\n",
    "        pred_y = np.argmax(test_output, 1)\n",
    "        print(sklearn.metrics.classification_report(test_label, pred_y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
